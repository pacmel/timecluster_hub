{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedbf1f4",
   "metadata": {
    "tags": [
     "ploomber-engine-error-cell"
    ]
   },
   "source": [
    "## <span style=\"color:red\">An Exception has occured at cell 14</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d500f3ff",
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.054243,
     "timestamp_start": 1716302342.053922
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Injected parameters\n",
    "print_flag = False\n",
    "show_plots = False\n",
    "reset_kernel = False\n",
    "pre_configured_case = False\n",
    "case_id = None\n",
    "frequency_factor = 1\n",
    "frequency_factor_change_alias = True\n",
    "cuda_device = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.054611,
     "timestamp_start": 1716302342.054369
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "print_flag                    = None \n",
    "show_plots                    = None\n",
    "reset_kernel                  = None \n",
    "pre_configured_case           = None\n",
    "case_id                       = None\n",
    "frequency_factor              = None\n",
    "frequency_factor_change_alias = None\n",
    "cuda_device                   = None\n",
    "check_parameters              = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.054928,
     "timestamp_start": 1716302342.054684
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check parameters ---\n",
      "print_flag: None show_plots: None reset_kernel: None pre_configured_case: None case_id: None frequency_factor: None frequency_factor_change_alias: None cuda_device: None\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if check_parameters:\n",
    "    print(\"--- Check parameters ---\")\n",
    "    print(\n",
    "        \"print_flag:\", print_flag,\n",
    "        \"show_plots:\",show_plots,\n",
    "        \"reset_kernel:\",reset_kernel,\n",
    "        \"pre_configured_case:\",pre_configured_case,\n",
    "        \"case_id:\",case_id,\n",
    "        \"frequency_factor:\", frequency_factor, \n",
    "        \"frequency_factor_change_alias:\", frequency_factor_change_alias,\n",
    "        \"cuda_device:\", cuda_device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set default input parameter values ensuring no errors\n",
    "### Values explained below in their natural execution place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.055484,
     "timestamp_start": 1716302342.055126
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "print_flag                    = True  if print_flag is None else print_flag\n",
    "show_plots                    = False if show_plots is None else show_plots\n",
    "reset_kernel                  = True  if reset_kernel is None else reset_kernel\n",
    "pre_configured_case           = False if pre_configured_case is None else pre_configured_case\n",
    "case_id                       = 1 if case_id is None else case_id\n",
    "frequency_factor              = 5 if frequency_factor is None else frequency_factor\n",
    "frequency_factor_change_alias = True if frequency_factor_change_alias is None else frequency_factor_change_alias\n",
    "cuda_device                   = 0 if  cuda_device is None else cuda_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create artifact from time series dataframe\n",
    "Gets a .tsf or .csv with a time serie, convert int to np.dataframe and loads it to weights and biases (W&B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Initial notebook setup and specific debugging and pre-configured cases selection\n",
    "### VsCode update patch\n",
    "Initial notebook setup when using VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.523395,
     "timestamp_start": 1716302342.055559
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    ut.DisplayHandle.update = ut.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging variables\n",
    "- `print_flag`. If `True` it adds debbuging messages in those functions that allows so (eg. `get_enc_embeddings`)\n",
    "- `reset_kernel`. If `True` it resets the kernel by the end of the execution. Use only in case that memory management is needed.\n",
    "- `show_plots`. If `True` all plots are shown within the execution of the notebook. Otherwise, none of them will be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.523884,
     "timestamp_start": 1716302342.52374
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "##### ----- This cell should be substituted by input parameters ------ #####\n",
    "##### See _ploomber_engine_example_.ipynb\n",
    "##### Uncomment for direct Notebook execution\n",
    "# print_flag   = True\n",
    "# reset_kernel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfigurated cases selection\n",
    "- `pre_configured_case`. If `True`, a preconfigured case will be selected, forcing the artifact to get the expected configuration based on the information in `config\\*.yml` and `utils\\config.py`.\n",
    "- `case_id`. If `preconfigured_case` is `True`, it forces to select the configuration of the `case_id` preconfigured samples. The available preconfigured samples are shown in the next cell.\n",
    "- `frequency_factor`. If `pre_configured_case` is `True`, frequency will be resampled by `config.freq*frequency_factor`\n",
    "  `frequency_factor_change_alias`. If `pre_configured_case` is `True` and `frequency_factor != 1` then the dataset alias will be modified for adding the new frequency as suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.687965,
     "timestamp_start": 1716302342.523965
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.688483,
     "timestamp_start": 1716302342.688279
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "cfg_.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.688892,
     "timestamp_start": 1716302342.688763
    }
   },
   "outputs": [],
   "source": [
    "#| export \n",
    "##### ----- This cell should be substituted by input parameters ------ #####\n",
    "##### See _ploomber_engine_example_.ipynb\n",
    "##### Uncomment for direct Notebook execution\n",
    "#pre_configured_case = False\n",
    "#case_id = None\n",
    "#frequency_factor = 1\n",
    "#frequency_factor_change_alias = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.696171,
     "timestamp_start": 1716302342.688965
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "from dvats.load import TSArtifact, infer_or_inject_freq\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tsai.data.external import convert_tsf_to_dataframe\n",
    "from tsai.utils import stack_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and Artiffact configurattions\n",
    "This notebook gets configuration from `config\\base.yaml` and `config\\01-dataset_artifact.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.696449,
     "timestamp_start": 1716302342.696278
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "base_path = Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.702679,
     "timestamp_start": 1716302342.696532
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "config = cfg_.get_artifact_config_sd2a(print_flag = False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_sd2a(\n",
    "        config = config, \n",
    "        id = case_id, \n",
    "        print_flag = print_flag, \n",
    "        both = print_flag, \n",
    "        frequency_factor = frequency_factor, \n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is assumed to come as a dataframe, either as a binarized  picke file or\n",
    "as a csv file. It can also come as a `.tsf` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check file content (if wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302342.703232,
     "timestamp_start": 1716302342.702774
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/macu/data/PulsusParadoxusSP02_30_10000.csv\n",
      "Error while converting file. Maybe not a tsf:  [Errno 2] No such file or directory: '/home/macu/data/PulsusParadoxusSP02_30_10000.csv'\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if print_flag:\n",
    "    fpath=os.path.expanduser(config.data_fpath)\n",
    "    print(fpath)\n",
    "    try: \n",
    "        with open(fpath, 'r') as file:\n",
    "            for _ in range(13):\n",
    "                line = file.readline()\n",
    "                print(line, end='')\n",
    "        data, _, _, _, _ = convert_tsf_to_dataframe(fpath)\n",
    "        print(\"Timestamp\", data.start_timestamp)\n",
    "    except Exception as e:\n",
    "        print(\"Error while converting file. Maybe not a tsf: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ed1fe",
   "metadata": {
    "tags": [
     "ploomber-engine-error-cell"
    ]
   },
   "source": [
    "## <span style=\"color:red\">Ploomber Engine raised an exception due to the cell below </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ploomber": {
     "timestamp_end": 1716302343.012734,
     "timestamp_start": 1716302342.703438
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/macu/data/PulsusParadoxusSP02_30_10000.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m",
      "\u001b[1;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(config\u001b[38;5;241m.\u001b[39mdata_fpath)",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m]:",
      "\u001b[0;32m----> 8\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_fpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv_config\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsf\u001b[39m\u001b[38;5;124m'\u001b[39m:",
      "\u001b[1;32m     11\u001b[0m     data, _, _, _, _ \u001b[38;5;241m=\u001b[39m convert_tsf_to_dataframe(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(config\u001b[38;5;241m.\u001b[39mdata_fpath))",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m",
      "\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:",
      "\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value",
      "\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m",
      "\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:",
      "\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(",
      "\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),",
      "\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,",
      "\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),",
      "\u001b[1;32m    330\u001b[0m     )",
      "\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m",
      "\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(",
      "\u001b[1;32m    936\u001b[0m     dialect,",
      "\u001b[1;32m    937\u001b[0m     delimiter,",
      "\u001b[0;32m   (...)\u001b[0m",
      "\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},",
      "\u001b[1;32m    947\u001b[0m )",
      "\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)",
      "\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m",
      "\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))",
      "\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m",
      "\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:",
      "\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m",
      "\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]",
      "\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m",
      "\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m",
      "\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:",
      "\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m",
      "\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m",
      "\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m",
      "\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle",
      "",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m",
      "\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):",
      "\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m",
      "\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m",
      "\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:",
      "\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m",
      "\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m",
      "\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m",
      "\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:",
      "\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m",
      "\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)",
      "",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/macu/data/PulsusParadoxusSP02_30_10000.csv'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "ext = str(config.data_fpath).split('.')[-1]\n",
    "\n",
    "if ext == 'pickle':\n",
    "    df = pd.read_pickle(config.data_fpath)\n",
    "    \n",
    "elif ext in ['csv','txt']:\n",
    "    df = pd.read_csv(config.data_fpath, **config.csv_config)\n",
    "    \n",
    "elif ext == 'tsf':\n",
    "    data, _, _, _, _ = convert_tsf_to_dataframe(os.path.expanduser(config.data_fpath))\n",
    "    config.update({'start_date': data.start_timestamp[0]}, allow_val_change=True)\n",
    "    date_format = config.date_format\n",
    "    df = pd.DataFrame(stack_pad(data.series_value).T)\n",
    "    \n",
    "else:\n",
    "    raise Exception('The data file path has an unsupported extension')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if print_flag:\n",
    "    print(f'File loaded successfully')\n",
    "    print(df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the time column (if any) as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if config.time_col is not None:\n",
    "    if print_flag: print(\"time_col: \"+str(config.time_col))\n",
    "    \n",
    "    if isinstance(config.time_col, int): \n",
    "        if print_flag: print(\"Op 1: time_col int\")\n",
    "        datetime = df.iloc[:, config.time_col]\n",
    "    \n",
    "    elif isinstance(config.time_col, list): \n",
    "        if print_flag: print(\"Op 2: time_col list\")\n",
    "        datetime = df.iloc[:, config.time_col].apply(lambda x: x.astype(str).str.cat(sep='-'), axis=1)\n",
    "    \n",
    "    index = pd.DatetimeIndex(datetime)\n",
    "    \n",
    "    if config.date_offset:\n",
    "        index += config.date_offset\n",
    "    \n",
    "    df = df.set_index(index, drop=False)   \n",
    "    \n",
    "    #Delete Timestamp col\n",
    "    col_name = df.columns[config.time_col]\n",
    "    \n",
    "    if print_flag: print(\"... drop Timestamp col \" + str(col_name))\n",
    "    \n",
    "    df = df.drop(col_name, axis=1)\n",
    "    \n",
    "if print_flag: display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataframe frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "df = infer_or_inject_freq(\n",
    "    df, \n",
    "    injected_freq=config.freq, \n",
    "    start_date=config.start_date, \n",
    "    format=config.date_format\n",
    ")\n",
    "if print_flag: print(df.index.freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Subset of variables\n",
    "if config.data_cols:\n",
    "    if print_flag: print(\"data_cols: \", config.data_cols)\n",
    "    df = df.iloc[:, config.data_cols]\n",
    "\n",
    "if print_flag: print(f'Num. variables: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Duplicated rows\n",
    "if print_flag: print(\"df shape before dropping duplicates\", df.shape)\n",
    "df.drop_duplicates()\n",
    "if print_flag: print(\"df shape after dropping duplicates\", df.shape)\n",
    "# Verificar si hay duplicados en el índice del dataframe\n",
    "if df.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Replace the default missing values by np.NaN\n",
    "if config.missing_values_constant:\n",
    "    df.replace(config.missing_values_constant, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if show_plots:\n",
    "    # Show time series plot\n",
    "    fig, ax = plt.subplots(1, figsize=(15,5), )\n",
    "    cmap = matplotlib.colormaps.get_cmap('viridis')\n",
    "    #df.plot(color=cmap(0.05), ax=ax) # or use colormap=cmap\n",
    "    df.plot(colormap=cmap, ax=ax) # or use colormap=cmap\n",
    "    # rect = Rectangle((5000, -4.2), 3000, 8.4, facecolor='lightgrey', alpha=0.5)\n",
    "    # ax.add_patch(rect)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    display(plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Handle Missing Values, Resample and Normalize__\n",
    "\n",
    "> In this second part, Time Series Artifact (TSArtifact) object can be created and missing values handling techniques, resampling and normalization can be applied.\n",
    "> \n",
    "> This techniques should be applied on the three subsets that must be previously created: training, validation and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "rg = config.range_training\n",
    "\n",
    "if isinstance(rg, list):\n",
    "    rg_training = rg\n",
    "    \n",
    "elif isinstance(rg, dict):\n",
    "    rg_training = pd.date_range(rg['start'], rg['end'], freq=rg['freq'])\n",
    "    \n",
    "elif config.test_split:\n",
    "    rg_training = df.index[:math.ceil(len(df) * (1-config.test_split))]\n",
    "\n",
    "else:\n",
    "    rg_training = None\n",
    "    \n",
    "df_training = df[df.index.isin(rg_training)] if rg_training is not None else df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build training artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "training_artifact = TSArtifact.from_df(\n",
    "    df_training, \n",
    "    name=config.artifact_name, \n",
    "    missing_values_technique=config.missing_values_technique,\n",
    "    resampling_freq=config.resampling_freq, \n",
    "    normalize=config.normalize_training, \n",
    "    path=str(Path.home()/config.wandb_artifacts_path)\n",
    ")\n",
    "if print_flag: display(training_artifact.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Debugging \n",
    "if df_training.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe & artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Testing data\n",
    "rg = config.range_testing\n",
    "\n",
    "if rg or config.test_split:\n",
    "    \n",
    "    if isinstance(rg, list):\n",
    "        rg_testing = rg\n",
    "\n",
    "    elif isinstance(rg, dict):\n",
    "        rg_testing = pd.date_range(rg['start'], rg['end'], freq=rg['freq'])\n",
    "\n",
    "    elif config.test_split:\n",
    "        rg_testing = df.index[math.ceil(len(df) * (1 - config.test_split)):]\n",
    "\n",
    "    else:\n",
    "        rg_testing = None\n",
    "    \n",
    "    df_testing = df[df.index.isin(rg_testing)]\n",
    "    testing_artifact = TSArtifact.from_df(df_testing,\n",
    "                                          name=config.artifact_name, \n",
    "                                          missing_values_technique=config.missing_values_technique,\n",
    "                                          resampling_freq=config.resampling_freq, \n",
    "                                          normalize=False,\n",
    "                                          path=str(Path.home()/config.wandb_artifacts_path))\n",
    "    display(testing_artifact.metadata)\n",
    "    if df_testing.index.duplicated().any():\n",
    "        print(\"There exist duplicated value(s) in the index dataframe.\")\n",
    "    else:\n",
    "        if print_flag: print(\"There is no duplicated value in the index dataframe.\")\n",
    "else:\n",
    "    if print_flag: print(\"rg \"+ str(rg) + \" | test_split \"+ str(config.test_split))\n",
    "    testing_artifact = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training + Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe & artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Training + Testing data\n",
    "if(config.joining_train_test):\n",
    "    print(\"joining_train_test: \"+ str(config.joining_train_test))\n",
    "    df_train_test = pd.concat([df_training, df_testing])\n",
    "    train_test_artifact = TSArtifact.from_df(\n",
    "        df_train_test,\n",
    "        name=config.artifact_name, \n",
    "        missing_values_technique=config.missing_values_technique,\n",
    "        resampling_freq=config.resampling_freq, \n",
    "        normalize=False,\n",
    "        path=str(Path.home()/config.wandb_artifacts_path)\n",
    "    )\n",
    "    if df_train_test.index.duplicated().any():\n",
    "        print(\"There exist duplicated value(s) within the dataframe index.\")\n",
    "    else:\n",
    "        if print_flag: print(\"There is no duplicated value in the dtaframe index\")\n",
    "    if print_flag: display(train_test_artifact.metadata)\n",
    "else:\n",
    "    train_test_artifact = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "> \n",
    "Before running this notebook part, make sure you have the `$WANDB_API_KEY`, `$WANDB_ENTITY` and `$WANDB_PROJECT` environment varibales defined with your API_KEY and your ENTITY and PROJECT names (run in a terminal `echo $WANDB_API_KEY` to see it, same with the other variables). If not, run in a terminal `wandb login [API_KEY]` to set the first one. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account. Run in a terminal `export WANDB_ENTITY=entity_name` and/or `export WANDB_PROJECT=project_name` to set the other two\n",
    "> \n",
    "> <span style=\"color:red\"> TODO: Modify config.ipynb so it gets wandb config from base.yml </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"01_dataset_artifact\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "mode = 'online' if config.use_wandb else 'disabled'\n",
    "\n",
    "# Make the run that will produce the artifact\n",
    "with wandb.init(job_type='create_dataset', resume=True, mode=mode, config=config, name=runname) as run:\n",
    "    if testing_artifact: \n",
    "        run.log_artifact(training_artifact, aliases=['train'])\n",
    "        run.log_artifact(testing_artifact, aliases=['test'])\n",
    "        \n",
    "        if train_test_artifact:\n",
    "            run.log_artifact(train_test_artifact, aliases=['all'])\n",
    "    \n",
    "    else:\n",
    "        run.log_artifact(training_artifact, aliases=['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dvats.imports import beep\n",
    "print(\"Execution ended\")\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
