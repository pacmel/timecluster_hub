{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import nbs_pipeline.utils.vscode  as vs\n",
    "vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# OR-ELM: Online Recurrent Extreme Learning Machine for time-series prediction\n",
    "\n",
    "> This notebook applies visual analytics to [OR_ELM](https://github.com/chickenbestlover/Online-Recurrent-Extreme-Learning-Machine) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize loss function\n",
      "Initialize loss function\n",
      "Initialize loss function\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tsai.all import *\n",
    "except:\n",
    "    from tsai.all import * # TODO: Weird error when loading tsai!from tchub.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from fastcore.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.schedule import *\n",
    "from dvats.all import *\n",
    "import nbs.orelm.orelm_torch as orelm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "Before running this notebook, make sure you have the `$WANDB_API_KEY` environment varibale defined with your API_KEY (run in a terminal `echo $WANDB_API_KEY` to see it). If not, run in a terminal `wandb login [API_KEY]`. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/02c-encoder_orelm.yaml\n",
      "... About to replace includes with content\n",
      "Before configuration reading \n",
      "-include: None\n",
      "-user_preferences:\n",
      "\t-use_wandb: False\n",
      "\t-wdb:\n",
      "\t\t-user: mi-santamaria\n",
      "\t\t-project_name: test-project\n",
      "\t\t-version: 0\n",
      "\t\t-mode: offline\n",
      "\t\t-artifacts_path: ./data/wandb_artifacts\n",
      "\t-data:\n",
      "\t\t-folder: ~/data/\n",
      "\t\t-fname: speed_6005\n",
      "\t\t-ftype: .csv\n",
      "\t\t-cols: [1]\n",
      "\t\t-freq: 1s\n",
      "\t-artifact:\n",
      "\t\t-alias: TiltABP\n",
      "\t-directories:\n",
      "\t\t-tmp: tmp\n",
      "\t\t-data: ~/data/speed_6005.csv\n",
      "-data:\n",
      "\t-name: speed_6005\n",
      "\t-path: ~/data/speed_6005.csv\n",
      "\t-alias: TiltABP\n",
      "\t-cols: [1]\n",
      "\t-csv_config:\n",
      "\t-date_offset: None\n",
      "\t-date_format: %Y-%m-%d %H:%M:%S\n",
      "\t-freq: 1s\n",
      "\t-joining_train_test: False\n",
      "\t-missing_values:\n",
      "\t\t-technique: None\n",
      "\t\t-constant: None\n",
      "\t-normalize_training: False\n",
      "\t-range_training: None\n",
      "\t-range_testing: None\n",
      "\t-resampling_freq: None\n",
      "\t-start_date: None\n",
      "\t-test_split: None\n",
      "\t-time_col: None\n",
      "-wandb:\n",
      "\t-user: mi-santamaria\n",
      "\t-dir: ~/test-project\n",
      "\t-enabled: False\n",
      "\t-group: None\n",
      "\t-log_learner: False\n",
      "\t-mode: offline\n",
      "\t-project: test-project\n",
      "\t-version: 0\n",
      "\t-artifacts_path: ./data/wandb_artifacts\n",
      "-configuration:\n",
      "\t-job_type: encoder_ORELM\n",
      "\t-alias: TiltABP\n",
      "\t-wandb:\n",
      "\t\t-use: False\n",
      "\t\t-entity: mi-santamaria\n",
      "\t\t-group: None\n",
      "\t\t-project: test-project\n",
      "\t-artifacts:\n",
      "\t\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t\t-valid:\n",
      "\t\t\t-data: None\n",
      "\t\t\t-size: 0.1\n",
      "\t-specifications:\n",
      "\t\t-algorithm: OSELM\n",
      "\t\t-n_epoch: 200\n",
      "\t\t-random_seed: 6\n",
      "\t\t-numHiddenNeurons: 25\n",
      "\t\t-activationFunction: sig\n",
      "\t\t-LN: True\n",
      "\t\t-AE: True\n",
      "\t\t-ORTH: True\n",
      "\t\t-lamb: 0.0001\n",
      "\t\t-weight_forgetting_factors:\n",
      "\t\t\t-input: 1\n",
      "\t\t\t-output: 0.92\n",
      "\t\t-sliding_windows:\n",
      "\t\t\t-stride: 1\n",
      "\t\t\t-size: 200\n",
      "After reading config\n",
      "-job_type: encoder_ORELM\n",
      "-alias: TiltABP\n",
      "-wandb:\n",
      "\t-use: False\n",
      "\t-entity: mi-santamaria\n",
      "\t-group: None\n",
      "\t-project: test-project\n",
      "-artifacts:\n",
      "\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t-valid:\n",
      "\t\t-data: None\n",
      "\t\t-size: 0.1\n",
      "-specifications:\n",
      "\t-algorithm: OSELM\n",
      "\t-n_epoch: 200\n",
      "\t-random_seed: 6\n",
      "\t-numHiddenNeurons: 25\n",
      "\t-activationFunction: sig\n",
      "\t-LN: True\n",
      "\t-AE: True\n",
      "\t-ORTH: True\n",
      "\t-lamb: 0.0001\n",
      "\t-weight_forgetting_factors:\n",
      "\t\t-input: 1\n",
      "\t\t-output: 0.92\n",
      "\t-sliding_windows:\n",
      "\t\t-stride: 1\n",
      "\t\t-size: 200\n"
     ]
    }
   ],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "config, job_type, dataSet = cfg.get_artifact_config_ORELM(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: test-project\n"
     ]
    }
   ],
   "source": [
    "print(\"Project: \"+config.wandb_project)\n",
    "run = wandb.init(\n",
    "    entity          = config.wandb_entity,\n",
    "    project         = config.wandb_project,\n",
    "    group           = config.wandb_group,\n",
    "    job_type        = job_type,\n",
    "    allow_val_change= True,\n",
    "    mode            = 'online' if config.use_wandb else 'disabled',\n",
    "    config          = config,\n",
    "    resume          = False\n",
    ")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dataSet:\n",
      "-folder: ~/data/\n",
      "-fname: speed_6005\n",
      "-ftype: .csv\n",
      "-cols: [1]\n",
      "-freq: 1s\n"
     ]
    }
   ],
   "source": [
    "print(\"Used dataSet:\")\n",
    "cfg.recursive_print_attrdict(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is a $w \\times s \\times t$ matrix. The first step consists in slicing the original multivariate time series into slices of shape ($w \\times d$), as shown in this figure from the paper.\n",
    "<img src=\"https://i.imgur.com/R9Fx8uO.png\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of this sliding window approach are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLIDING WINDOW --\n",
      "Len: 200\n",
      "Stride: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"--- SLIDING WINDOW --\")\n",
    "print(\"Len: \" + str(config.w))\n",
    "print(\"Stride: \" + str(config.stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>2015-08-31 18:22:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>2015-08-31 18:32:00</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>2015-08-31 18:57:00</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>2015-08-31 19:07:00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>2015-08-31 19:12:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               timestamp  value\n",
       "1970-01-01 00:00:00  2015-08-31 18:22:00     90\n",
       "1970-01-01 00:00:01  2015-08-31 18:32:00     80\n",
       "1970-01-01 00:00:02  2015-08-31 18:57:00     84\n",
       "1970-01-01 00:00:03  2015-08-31 19:07:00     94\n",
       "1970-01-01 00:00:04  2015-08-31 19:12:00     90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get artiffact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "#convert to pandas dataset\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. variables: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of variables\n",
    "if dataSet.cols:\n",
    "    df_train = df_train.iloc[:, dataSet.cols]\n",
    "print(f'Num. variables: {len(df_train.columns)}')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:35</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:36</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:37</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:38</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:39</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90\n",
       "...                    ...\n",
       "1970-01-01 00:41:35     81\n",
       "1970-01-01 00:41:36     89\n",
       "1970-01-01 00:41:37     87\n",
       "1970-01-01 00:41:38     82\n",
       "1970-01-01 00:41:39     83\n",
       "\n",
       "[2500 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.9068\n",
      "8.744856417346142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize data by subtracting mean and dividing by std\n",
    "meanSeq     = np.mean(df_train['value'])\n",
    "print(meanSeq)\n",
    "stdSeq      = np.std(df_train['value'])\n",
    "print(stdSeq)\n",
    "df_train['value'] = (df_train['value'] - meanSeq)/stdSeq\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset shape</td>\n",
       "      <td>(2500, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Sliding windows</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sliding window shape</td>\n",
       "      <td>(1, 200)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Description      Value\n",
       "0              Dataset shape  (2500, 1)\n",
       "1  Number of Sliding windows       2301\n",
       "2       Sliding window shape   (1, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup Training windows\n",
    "X_train, _ = sw(df_train) #Windows\n",
    "data = {\n",
    "    \"Description\": [\n",
    "        \"Dataset shape\", \n",
    "        \"Number of Sliding windows\", \n",
    "        \"Sliding window shape\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(df_train.shape), \n",
    "        str(X_train.shape[0]), \n",
    "        f\"({X_train.shape[1]}, {X_train.shape[2]})\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "training_info = pd.DataFrame(data)\n",
    "training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No validation artifact. Random items to get: 0.1\n"
     ]
    }
   ],
   "source": [
    "if config.valid_artifact:\n",
    "    valid_artifact = artifacts_gettr(config.valid_artifact)\n",
    "    df_val = valid_artifact.to_df()\n",
    "    X_valid, _ = sw(df_val)\n",
    "    df_val.shape, X_valid.shape\n",
    "    print(\"valid_artifact\")\n",
    "    print(valid_artifact)\n",
    "    print(\"df_val\")\n",
    "    print(df_val)\n",
    "    print(\"X_valid\")\n",
    "    print(X_valid)\n",
    "    print(\"df_val.shape\")\n",
    "    print(df_val.shape)\n",
    "    print(\"X_valid.shape\")\n",
    "    print(X_valid.shape)\n",
    "else:\n",
    "    print(\"No validation artifact. Random items to get:\", config.valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: METER EXPLICACIÓN DE OR-ELM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: AQUI VA LA EXPLICACIÓN CON EL EJEMPLO QUE SE META EN EL PAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2301, 1, 200)\n",
      "y.shape: (2301, 1, 200)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset\n",
    "random.seed = config.random_seed\n",
    "if config.valid_artifact:\n",
    "    X, y, splits  = combine_split_data(xs=[X_train, X_valid], ys=[X_train, X_valid])\n",
    "else:\n",
    "    X = X_train\n",
    "    y = X_train\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size)\n",
    "splits\n",
    "print(\"X.shape: \"+str(X.shape))\n",
    "print(\"y.shape: \"+str(y.shape))\n",
    "#print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the model\n",
    "#features = pd.DataFrame(dls.dataset[0][0])\n",
    "#targets = pd.DataFrame(dls.dataset[0][1]) #1\n",
    "\n",
    "#print(\"dls len: \" + str(len(dls.dataset)))\n",
    "\n",
    "#print(\"Features shape: \" + str(features.shape))\n",
    "#print(\"Targets shape: \" + str(features.shape))\n",
    "\n",
    "#dls.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLags         = X_train.shape[0] #config.epochs\n",
    "nDimInput       = numLags\n",
    "nDimOutput      = 1 #targets.shape[1] #1\n",
    "numNeurons      = config.numHiddenNeurons #nDimInput  #config.numHiddenNeurons\n",
    "algorithm       = config.algorithm\n",
    "LN              = config.LN \n",
    "AE              = config.AE\n",
    "InWeightFF      = config.inputWeightForgettingFactor #1.0\n",
    "OutWeightFF     = config.outputWeightForgettingFactor #0.92\n",
    "HiddenWeightFF  = config.inputWeightForgettingFactor #1.0\n",
    "lamb            = config.lamb\n",
    "predictionStep  = config.stride #5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   Description           Value\n",
       "0               Dataset shape       (2500, 1)\n",
       "1   Number of Sliding windows            2301\n",
       "2        Sliding window shape        (1, 200)\n",
       "3      inputs/Charasteristics            2301\n",
       "4               Targets shape  (2301, 1, 200)\n",
       "5               X_train shape  (2301, 1, 200)\n",
       "6               Input Weights      (25, 2301)\n",
       "7              Hidden Weights        (25, 25)\n",
       "8                    Hidden A         (1, 25)\n",
       "9                        Bias         (1, 25)\n",
       "10                   Features       (1, 2301)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_to_append = {\n",
    "    \"Description\": [\n",
    "        \"inputs/Charasteristics\", \n",
    "        \"Targets shape\", \n",
    "        \"X_train shape\", \n",
    "        \"Input Weights\", \n",
    "        \"Hidden Weights\", \n",
    "        \"Hidden A\", \n",
    "        \"Bias\", \n",
    "        \"Features\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(nDimInput),\n",
    "        str(y.shape),\n",
    "        str(X_train.shape),\n",
    "        f\"({numNeurons}, {nDimInput})\",\n",
    "        f\"({numNeurons}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {nDimInput})\"\n",
    "    ]\n",
    "}\n",
    "data_to_append = pd.DataFrame(data_to_append)\n",
    "training_info = training_info.append(data_to_append, ignore_index = True)\n",
    "training_info.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with fastai Learner class, to abstract from Pytorch's training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To track the performance of this model fit, go to the project dashboard in Weights & Biases. The link is provided at the beginning of this notebook, after the execution of the function `wandb.init()'' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, log the learner to be used by the next notebook in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: 200\n",
      "outputs: 1\n",
      "numNeurons: 25\n",
      "Out weight FF: 0.92\n",
      "(25, 200)\n",
      "Foselm -- before bias\n",
      "Foselm -- before beta\n",
      "Foselm -- before bias\n",
      "Foselm -- before beta\n",
      "--> Initialize_Phase: Input Weights initialized. Shape: torch.Size([25, 200])\n",
      "Foselm - initialize phase\n",
      "Foselm - initialize phase\n",
      "ORELM_torch(\n",
      "  (inputAE): FOSELM_torch()\n",
      "  (hiddenAE): FOSELM_torch()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = orelm.ORELM_torch(\n",
    "    inputs                      =   X_train.shape[2], #nDimInput,\n",
    "    outputs                     =   nDimOutput,\n",
    "    numHiddenNeurons            =   config.numHiddenNeurons,\n",
    "    activationFunction          =   config.activationFunction,\n",
    "    LN                          =   config.LN,\n",
    "    AE                          =   config.AE,\n",
    "    ORTH                        =   config.ORTH,\n",
    "    inputWeightForgettingFactor =   config.inputWeightForgettingFactor,\n",
    "    outputWeightForgettingFactor=   config.outputWeightForgettingFactor\n",
    ")\n",
    "m.initializePhase(lamb=0.0001)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [ToFloat(), ToFloat()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape[0]: 2301\n",
      "X.shape: (2301, 1, 200)\n",
      "y.shape: (2301, 1, 200)\n",
      "dls.shape: (2301, 1, 200)\n",
      "Last dls.shape: (1, 200)\n",
      "32\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n",
      "El 1. torch.Size([64, 1, 200])\n"
     ]
    }
   ],
   "source": [
    "#Preparando dlstfms = [ToFloat(), ToFloat()]\n",
    "\n",
    "#DataLoader\n",
    "print(\"X_train shape[0]: \" + str(X_train.shape[0]))\n",
    "print(\"X.shape: \"+str(X.shape))\n",
    "print(\"y.shape: \"+str(y.shape))\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "print(\"dls.shape: \"+str(X.shape))\n",
    "print(\"Last dls.shape: \"+str(X[-1].shape))\n",
    "print(len(dls.train))\n",
    "for batch in dls.train:\n",
    "    #print(\"El 0. \" + str(batch[0]))\n",
    "    print(\"El 1. \" + str(batch[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize loss function\n",
      "<class 'tsai.data.core.TSDataLoaders'>\n",
      "<class 'nbs.orelm.orelm_torch.ORELM_torch'>\n"
     ]
    }
   ],
   "source": [
    "#Build learner\n",
    "learn =  Learner(\n",
    "    dls         = dls, \n",
    "    model       = m, \n",
    "    loss_func   = nn.MSELoss(), #\n",
    "    opt_func    = Adam, #Creates an optimizer\n",
    "    cbs         = [WandbCallback(log_preds=False)] #List of callbacks\n",
    ")\n",
    "\n",
    "print(type(dls))\n",
    "print(type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORELM_torch(\n",
      "  (inputAE): FOSELM_torch()\n",
      "  (hiddenAE): FOSELM_torch()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### Prueba comprobar tamaños para m \"en pequeño\"\\nstep = 0\\npredictions = []\\ntarget = []\\nmaxStep = X.shape[0]\\nfor i in range(maxStep-1):\\n    training_dataset = X[i]\\n    targets = y[i]\\n    features = X[i+1] \\n    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\\n    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\\n    m.train(training_dataset, targets)\\n    Y = m.predict(features)\\n    predictions.append(Y[0][0])\\n    target.append(y[i+1][0])\\n    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#### Prueba comprobar tamaños para m \"en pequeño\"\n",
    "step = 0\n",
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]\n",
    "for i in range(maxStep-1):\n",
    "    training_dataset = X[i]\n",
    "    targets = y[i]\n",
    "    features = X[i+1] \n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    m.train(training_dataset, targets)\n",
    "    Y = m.predict(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(y[i+1][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#print(\"self.dls shape: \" + str(learn.dls.train.shape))\\n#print(\"self.dls.train \" + str(len(learn.dls.train)))\\n\\nimport sys\\n\\n# Abre un archivo para redirigir la salida de print\\noutput_file = open(\\'my_logs.txt\\', \\'w\\')\\nsys.stdout = output_file\\n\\n#cprofiler = cProfile.Profile()\\nlr_valley, lr_steep =   learn.lr_find(\\n                            suggest_funcs=[valley, steep]\\n                            )\\n\\n#lr_valley, lr_steep = learn.lr_finsd(suggest_funcs=[valley, steep]) --> original\\n#learn.fit_one_cycle(1, lr_max=lr_valley)\\n#learn.fit_one_cycle(config.epochs, lr_max=lr_valley)\\n#learn.plot_metrics()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#print(\"self.dls shape: \" + str(learn.dls.train.shape))\n",
    "#print(\"self.dls.train \" + str(len(learn.dls.train)))\n",
    "\n",
    "import sys\n",
    "\n",
    "# Abre un archivo para redirigir la salida de print\n",
    "output_file = open('my_logs.txt', 'w')\n",
    "sys.stdout = output_file\n",
    "\n",
    "#cprofiler = cProfile.Profile()\n",
    "lr_valley, lr_steep =   learn.lr_find(\n",
    "                            suggest_funcs=[valley, steep]\n",
    "                            )\n",
    "\n",
    "#lr_valley, lr_steep = learn.lr_finsd(suggest_funcs=[valley, steep]) --> original\n",
    "#learn.fit_one_cycle(1, lr_max=lr_valley)\n",
    "#learn.fit_one_cycle(config.epochs, lr_max=lr_valley)\n",
    "#learn.plot_metrics()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pstats\\n\\n# Genera el informe de perfil\\ninforme_perfil = pstats.Stats(cprofiler)\\ninforme_perfil.strip_dirs()  # Elimina información de directorios\\ninforme_perfil.sort_stats('cumulative')  # Ordena por tiempo acumulativo\\ninforme_perfil.print_stats()  # Imprime el informe\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pstats\n",
    "\n",
    "# Genera el informe de perfil\n",
    "informe_perfil = pstats.Stats(cprofiler)\n",
    "informe_perfil.strip_dirs()  # Elimina información de directorios\n",
    "informe_perfil.sort_stats('cumulative')  # Ordena por tiempo acumulativo\n",
    "informe_perfil.print_stats()  # Imprime el informe\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Step: 1\n",
      "Generate time embedded matrix\n",
      "inDim =2301\n",
      "outDim =1\n",
      "X.shape (200, 2301)\n",
      "T.shape (200, 1)\n",
      "X_train ~  (2301, 1, 200)\n",
      "Input shape:  (200, 2301)\n",
      "Target shape:  (200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Step: \" + str(predictionStep))\n",
    "#X = np.array([X[w][0] for w in range(X_train.shape[0])]).T\n",
    "#T = np.array([y[w][0] for w in range(X_train.shape[0])]).T   \n",
    "#T = np.array([y[w][0][predictionStep] for w in range(X_train.shape[0])]).T   \n",
    "\n",
    "def getTimeEmbeddedMatrix(sequence, numLags=100, predictionStep=1, inDim=100, outDim = 1):\n",
    "  print(\"Generate time embedded matrix\")\n",
    "  print(\"inDim =\"+ str(inDim))\n",
    "  print(\"outDim =\"+ str(outDim))\n",
    "  #total = len(sequence)\n",
    "  total = X_train.shape[2]\n",
    "  X = np.zeros(shape=(total, inDim))\n",
    "  T = np.zeros(shape=(total, outDim))\n",
    "  print(\"X.shape \" + str(X.shape))\n",
    "  print(\"T.shape \" + str(T.shape))\n",
    "  for i in range(numLags-1, total-predictionStep):\n",
    "    X[i, :] = np.array(sequence[(i-numLags+1):(i+1)])\n",
    "    T[i, :] = sequence[i+predictionStep]\n",
    "  return (X, T)\n",
    "\n",
    "(X, T) = getTimeEmbeddedMatrix(X_train[0], numLags, predictionStep, nDimInput, nDimOutput)\n",
    "print(\"X_train ~ \", str(X_train.shape))\n",
    "print('Input shape: ', str(X.shape))\n",
    "print('Target shape: ', str(T.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num steps: 198\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]-predictionStep-1\n",
    "print(\"Num steps: \" + str(maxStep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training[0] shape: torch.Size([1, 2301])\n",
      "Targets[0] shape: torch.Size([1, 1])\n",
      "Features[0] shape: torch.Size([1, 2301])\n",
      "ORELM:TRAIN:samples = weights: 1 | outputs: 1\n",
      "ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1\n",
      "ORELM:TRAIN:Weights number: 1 = 1\n",
      "--> Calculate Hidden Activation 1\n",
      "--> Foselm: Train\n",
      "targets shape torch.Size([1, 2301])\n",
      "FOSELM:TRAIN:2SHAPED\n",
      "Check if a better partition can be done: last window has just 2301 inputs instead of 200\n",
      "FOSELM:Train:END -->\n",
      "--> Foselm: Train\n",
      "targets shape torch.Size([1, 25])\n",
      "FOSELM:TRAIN:2SHAPED\n",
      "Dimensions ok\n",
      "Features ~ torch.Size([1, 25])\n",
      "Targets ~ torch.Size([1, 25])\n",
      "Inputs ~ 25\n",
      "1 1\n",
      "--> Train func (single)\n",
      "Foselm - Calculate Hidden layer activation\n",
      "Features: torch.Size([1, 25])\n",
      "weights: torch.Size([25, 25])\n",
      "Foselm - Layer normalizatison\n",
      "--> SigmoidActFunc V ~ torch.Size([1, 25])\n",
      "SigmoidActFunc -->\n",
      "FOSELM: Calculate hidden layer activation -->\n",
      "non RLS\n",
      "Train func (single) -->\n",
      "FOSELM:Train:END -->\n",
      "Before LR 1: torch.Size([1, 2301])\n",
      "---> Linear_recurrent\n",
      "numSamples: 1\n",
      "numInputs: 200\n",
      "numHiddenNeuron: 25\n",
      "Features = (samples, inputs): torch.Size([1, 2301])\n",
      "NumInputs = (hidden, inputs): torch.Size([25, 200])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2301 and 200x25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/macu/work/nbs_pipeline/02c_encoder_ORELM_going_back.ipynb Celda 43\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_going_back.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTargets[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m] shape: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(targets\u001b[39m.\u001b[39mshape))\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_going_back.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFeatures[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m] shape: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(features\u001b[39m.\u001b[39mshape))\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_going_back.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m m\u001b[39m.\u001b[39;49mtrain_func(training_dataset, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_going_back.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m Y \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mpredict(features)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_going_back.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m predictions\u001b[39m.\u001b[39mappend(Y[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/work/nbs/orelm/orelm_torch.py:200\u001b[0m, in \u001b[0;36mORELM_torch.train_func\u001b[0;34m(self, features, targets, RESETTING)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39massert\u001b[39;00m (features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m numSamples), \\\n\u001b[1;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNumber of columns of features and weights differ\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfprint(\u001b[39m\"\u001b[39m\u001b[39m--> Calculate Hidden Activation 1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_flag)\n\u001b[0;32m--> 200\u001b[0m H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculateHiddenLayerActivation(features, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfprint(\u001b[39m\"\u001b[39m\u001b[39mCalculate Hidden Activation 1 -->\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_flag)\n\u001b[1;32m    202\u001b[0m Ht \u001b[39m=\u001b[39m H\u001b[39m.\u001b[39mt()\n",
      "File \u001b[0;32m~/work/nbs/orelm/orelm_torch.py:124\u001b[0m, in \u001b[0;36mORELM_torch.calculateHiddenLayerActivation\u001b[0;34m(self, features, flag_debug)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhiddenWeights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__calculateHiddenWeightsUsingAE(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mH)\n\u001b[1;32m    123\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBefore LR \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(flag_debug) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(features\u001b[39m.\u001b[39mshape))\n\u001b[0;32m--> 124\u001b[0m V \u001b[39m=\u001b[39m linear_recurrent(\n\u001b[1;32m    125\u001b[0m     features    \u001b[39m=\u001b[39;49m features,\n\u001b[1;32m    126\u001b[0m     inputW      \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputWeights,\n\u001b[1;32m    127\u001b[0m     hiddenW     \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhiddenWeights,\n\u001b[1;32m    128\u001b[0m     hiddenA     \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mH,\n\u001b[1;32m    129\u001b[0m     bias        \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLN: \u001b[39m#? -> Aqui es siempre true para Alaiñe\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     V \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayerNormalization(V)\n",
      "File \u001b[0;32m~/work/nbs/orelm/utils.py:15\u001b[0m, in \u001b[0;36mlinear_recurrent\u001b[0;34m(features, inputW, hiddenW, hiddenA, bias, print_flag)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFeatures = (samples, inputs): \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(features\u001b[39m.\u001b[39mshape))\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumInputs = (hidden, inputs): \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(inputW\u001b[39m.\u001b[39mshape))\n\u001b[0;32m---> 15\u001b[0m V \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmm(features, inputW\u001b[39m.\u001b[39;49mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmm(hiddenA, hiddenW) \u001b[39m+\u001b[39m bias\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m (print_flag):\n\u001b[1;32m     17\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLinear_recurrent --->\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2301 and 200x25)"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for i in range(1):\n",
    "    training_dataset = torch.from_numpy(X[[i],:]).float()\n",
    "    targets = torch.from_numpy(T[[i],:]).float()\n",
    "    features = torch.from_numpy(X[[i+1],:]).float()\n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    print(\"Features[\"+str(i)+\"] shape: \" + str(features.shape))\n",
    "    m.train_func(training_dataset, targets)\n",
    "    Y = m.predict(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(T[i][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Calculate total Normalizedd Root Mean Square Error (NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct original value\n",
    "predictions = np.array(predictions)\n",
    "target = np.array(target)\n",
    "predictions = predictions * stdSeq + meanSeq\n",
    "target = target * stdSeq + meanSeq\n",
    "  \n",
    "def computeSquareDeviation(predictions, truth):\n",
    "  squareDeviation = np.square(predictions-truth)\n",
    "  return squareDeviation\n",
    "\n",
    "# Calculate NRMSE from skip_eval to the end\n",
    "skip_eval=100\n",
    "squareDeviation = computeSquareDeviation(predictions, target)\n",
    "squareDeviation[:skip_eval] = None\n",
    "nrmse = np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions)\n",
    "print(\"NRMSE {}\".format(nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target len: \" + str(len(target)) + str(target))\n",
    "print(\"Prediction len: \" + str(len(predictions))+str(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "algorithm = config.algorithm\n",
    "print(algorithm)\n",
    "print(config.job_type)\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "targetPlot,=plt.plot(target,label='target',color='red',marker='.',linestyle='-')\n",
    "predictedPlot,=plt.plot(predictions,label='predicted',color='blue',marker='.',linestyle=':')\n",
    "plt.xlim([0, 200])\n",
    "plt.ylim([60, 100])\n",
    "plt.ylabel('value',fontsize=15)\n",
    "plt.xlabel('time',fontsize=15)\n",
    "plt.ion()\n",
    "plt.grid()\n",
    "plt.legend(handles=[targetPlot, predictedPlot])\n",
    "plt.title('Time-series Prediction of '+ config.job_type + ' algorithm: ' + algorithm +' on '+dataSet.fname+' dataset' ,fontsize=20,fontweight=40)\n",
    "plot_path = './predictionPlot.png'\n",
    "#plt.savefig(plot_path,plot_pathbbox_inches='tight')\n",
    "plt.savefig(plot_path,bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.pause(0)\n",
    "print('Prediction plot is saved to'+plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning and prediction of OR-ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
