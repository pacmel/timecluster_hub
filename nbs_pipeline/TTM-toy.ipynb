{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6238809c-a69a-4d49-b8f6-34c247611361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: source: not found\n",
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! pip install \"tsfm_public[notebooks] @ git+https://github.com/ibm-granite/granite-tsfm.git\" --no-deps\n",
    "#! pip install aiohttp dill multiprocess xxhash --no-deps\n",
    "#! pip install datasets --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea8478a-c8fe-4ca8-84ae-b50b26849d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(182): Could not remove or rename /usr/local/share/miniconda3/envs/env/conda-meta/pytorch-1.13.0-py3.10_cuda11.7_cudnn8.5.0_0.json.  Please remove this file manually (you may need to reboot to free file handles)\n",
      "WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(182): Could not remove or rename /usr/local/share/miniconda3/envs/env/conda-meta/numpy-1.26.4-py310hb13e2d6_0.json.  Please remove this file manually (you may need to reboot to free file handles)\n",
      "# packages in environment at /usr/local/share/miniconda3/envs/env:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n"
     ]
    }
   ],
   "source": [
    "! conda list multidict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a4187f3-6180-4fa4-8c29-2bc916f81e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: datasets\n",
      "Version: 3.0.0\n",
      "Summary: HuggingFace community-driven open-source library of datasets\n",
      "Home-page: https://github.com/huggingface/datasets\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /home/macu/.local/lib/python3.10/site-packages\n",
      "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n",
      "Required-by: tsfm_public\n"
     ]
    }
   ],
   "source": [
    "! pip show datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c038ffa1-9e0e-47fc-9d19-19f3e0d60303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - rapidsai\n",
      " - nvidia\n",
      " - fastai\n",
      " - pytorch\n",
      " - timeseriesai\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.4.0\n",
      "    latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/share/miniconda3/envs/env\n",
      "\n",
      "  added / updated specs:\n",
      "    - multidict\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  multidict          conda-forge/linux-64::multidict-6.0.5-py310h2372a71_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.8.30-hbcca054_0 \n",
      "  certifi                             2024.2.2-pyhd8ed1ab_0 --> 2024.8.30-pyhd8ed1ab_0 \n",
      "  openssl                                  3.1.5-hd590300_0 --> 3.1.6-h4ab18f5_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /usr/local/share/miniconda3/envs/env\n",
      "  uid: 1004\n",
      "  gid: 1004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#conda install -c huggingface -c conda-forge datasets\n",
    "#! conda install -c conda-forge multidict -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fddd3cf-dea9-49b7-a4bf-2d68d071a0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f0140396e90>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc4f153-b6dc-41b4-b301-5f84b2b5ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b8844a-22e2-42ec-8b2c-dde7b5d1a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(182): Could not remove or rename /usr/local/share/miniconda3/envs/env/conda-meta/pytorch-1.13.0-py3.10_cuda11.7_cudnn8.5.0_0.json.  Please remove this file manually (you may need to reboot to free file handles)\n",
      "WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(182): Could not remove or rename /usr/local/share/miniconda3/envs/env/conda-meta/numpy-1.26.4-py310hb13e2d6_0.json.  Please remove this file manually (you may need to reboot to free file handles)\n",
      "# packages in environment at /usr/local/share/miniconda3/envs/env:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n"
     ]
    }
   ],
   "source": [
    "! conda list multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccaca8ca-a50f-42e3-aacf-24c4ad6efcaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdill\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dill'"
     ]
    }
   ],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c1d057-9a47-4e45-8370-03f8cddcab31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dataset' from 'datasets' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dataset' from 'datasets' (unknown location)"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89a8e38-5dff-4602-9a64-2bc4e9e7a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvats.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83289bff-270b-47d5-aff2-a5a7f4388783",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import tsfm_public.toolkit because of the following error (look up to see its traceback):\ncannot import name 'Dataset' from 'datasets' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/transformers/utils/import_utils.py:1184\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tsfm_public/toolkit/__init__.py:5\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrackingCallback\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_handling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecastDFDataset, PretrainDFDataset, RegressionDFDataset\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tsfm_public/toolkit/data_handling.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtime_series_preprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesPreprocessor, get_datasets\n\u001b[1;32m     16\u001b[0m LOGGER \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tsfm_public/toolkit/time_series_preprocessor.py:15\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dataset' from 'datasets' (unknown location)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# tsfm library\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfm_public\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     TimeSeriesPreprocessor,\n\u001b[1;32m     17\u001b[0m     TinyTimeMixerForPrediction,\n\u001b[1;32m     18\u001b[0m     TrackingCallback,\n\u001b[1;32m     19\u001b[0m     count_parameters\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsfm_public\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoolkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_predictions\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/transformers/utils/import_utils.py:1174\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1174\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/transformers/utils/import_utils.py:1186\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1189\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import tsfm_public.toolkit because of the following error (look up to see its traceback):\ncannot import name 'Dataset' from 'datasets' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Standard\n",
    "import os\n",
    "import math\n",
    "import tempfile\n",
    "import torch\n",
    "\n",
    "# Third Party\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments, set_seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tsfm library\n",
    "from tsfm_public import (\n",
    "    TimeSeriesPreprocessor,\n",
    "    TinyTimeMixerForPrediction,\n",
    "    TrackingCallback,\n",
    "    count_parameters\n",
    ")\n",
    "from tsfm_public.toolkit.visualization import plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd98580-83d3-4edd-b45a-71671ec016ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc39ca5d-1023-4a0a-846a-3ac079ce5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Data loading, cleaning, manipulation, visualization, and saving tasks are performed in another notebook and saved in a github repository.\n",
    "target_dataset = \"venice\"\n",
    "\n",
    "# Results dir\n",
    "OUT_DIR = \"ttm_finetuned_models/\"\n",
    "\n",
    "# TTM model branch\n",
    "TTM_MODEL_REVISION = \"1024_96_v1\"\n",
    "TTM_INPUT_SEQ_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7dfd4bb-4538-4339-9247-14778ef545f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre configured case id: 7\n",
      "Selecting  stumpy_toy_0\n",
      "wandb_artifacts_path: ./data/wandb_artifacts\u001b[0m\n",
      "range_testing: None\u001b[0m\n",
      "\u001b[94mdata_fpath: ~/data/PulsusParadoxusSP02_30_10000.csv\u001b[0m -> ~/data/toy.csv\u001b[0m\n",
      "resampling_freq: None\u001b[0m\n",
      "date_format: %Y-%m-%d %H:%M:%S\u001b[0m\n",
      "missing_values_technique: None\u001b[0m\n",
      "use_wandb: True\u001b[0m\n",
      "start_date: None\u001b[0m\n",
      "\u001b[94martifact_name: PulsusParadoxus-SP02\u001b[0m -> toy\u001b[0m\n",
      "freq: 1s\u001b[0m\n",
      "date_offset: None\u001b[0m\n",
      "missing_values_constant: None\u001b[0m\n",
      "\u001b[94mcsv_config: {'header': None}\u001b[0m -> {}\u001b[0m\n",
      "joining_train_test: False\u001b[0m\n",
      "range_training: None\u001b[0m\n",
      "time_col: None\u001b[0m\n",
      "test_split: None\u001b[0m\n",
      "\u001b[94mdata_cols: [0]\u001b[0m -> []\u001b[0m\n",
      "normalize_training: False\u001b[0m\n",
      "artifact_name: toy\n",
      "csv_config: {}\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "date_format: %Y-%m-%d %H:%M:%S\n",
      "date_offset: None\n",
      "freq: 1s\n",
      "joining_train_test: False\n",
      "missing_values_technique: None\n",
      "missing_values_constant: None\n",
      "normalize_training: False\n",
      "range_training: None\n",
      "range_testing: None\n",
      "resampling_freq: None\n",
      "start_date: None\n",
      "test_split: None\n",
      "time_col: None\n",
      "use_wandb: True\n",
      "wandb_artifacts_path: ./data/wandb_artifacts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T3        T2        T1\n",
       "0  0.741822  0.637180  0.565117\n",
       "1  0.739731  0.629415  0.493513\n",
       "2  0.718757  0.539220  0.469350\n",
       "3  0.730169  0.577670  0.444100\n",
       "4  0.752406  0.570180  0.373008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df, config = ttm.load_from_config_df_base(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52184440-9da1-463d-bdfb-07c8116ae119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T3        T2        T1\n",
       "0  0.741822  0.637180  0.565117\n",
       "1  0.739731  0.629415  0.493513\n",
       "2  0.718757  0.539220  0.469350\n",
       "3  0.730169  0.577670  0.444100\n",
       "4  0.752406  0.570180  0.373008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5376c9f6-f9bc-4b2a-bc7f-f8822e0618c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot infer freq from a non-convertible index of dtype int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mttm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_or_inject_freq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minjected_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate_format\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mfreq)\n",
      "File \u001b[0;32m~/work/dvats/load.py:185\u001b[0m, in \u001b[0;36minfer_or_inject_freq\u001b[0;34m(df, injected_freq, start_date, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129m@delegates\u001b[39m(pd\u001b[38;5;241m.\u001b[39mto_datetime)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer_or_inject_freq\u001b[39m(df, injected_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1s\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m        Infer index frequency. If there's not a proper time index, create fake timestamps,\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m        keeping the desired `injected_freq`. If that is None, set a default one of 1 second.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m        start_date: the first date of the index (int or string).\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     inferred_freq \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_freq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m injected_freq\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmo\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/tseries/frequencies.py:148\u001b[0m, in \u001b[0;36minfer_freq\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inferer\u001b[38;5;241m.\u001b[39mget_freq()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_numeric_dtype(index\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot infer freq from a non-convertible index of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, DatetimeIndex):\n\u001b[1;32m    153\u001b[0m     index \u001b[38;5;241m=\u001b[39m DatetimeIndex(index)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot infer freq from a non-convertible index of dtype int64"
     ]
    }
   ],
   "source": [
    "df = infer_or_inject_freq(\n",
    "    df,\n",
    "    injected_freq = config.freq,\n",
    "    start_date = config.start_date,\n",
    "    format = config.date_format\n",
    ")\n",
    "if verbose > 0: print(df.index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510b2a6-1704-4555-909a-b15871b5a4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce02780-3f97-48b5-b70a-1ab1a5d697b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7ed9a-a83f-4127-8178-cdf0a181ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_map = {\n",
    "        \"toy\": {\n",
    "            \"dataset_path\": \"~/data/toy.csv\",\n",
    "            \"timestamp_column\": \"\",\n",
    "            \"id_columns\": [],\n",
    "            \"target_columns\": [\"T1\", \"T2\", \"T3\"],\n",
    "            \"control_columns\": [], \n",
    "            \"split_config\": {\n",
    "                \"train\": 0.7,\n",
    "                #\"valid\": 0.1,\n",
    "                \"test\": 0.2,\n",
    "            },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3761a96-4b2a-4b31-9aca-9aec42f534b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm.get_data(\"toy\", TTM_INPUT_SEQ_LEN, 96, 1.0, config_map, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5bf36-d439-4796-9029-f92e66d79139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroshot_eval(\n",
    "    dataset_name, \n",
    "    batch_size,\n",
    "    context_length=TTM_INPUT_SEQ_LEN,\n",
    "    forecast_length=96,\n",
    "    prediction_filter_length=None\n",
    "):\n",
    "    # Get data\n",
    "    _, _, dset_test = get_data(dataset_name=dataset_name, \n",
    "                               context_length=context_length, \n",
    "                               forecast_length=forecast_length, \n",
    "                               fewshot_fraction=1.0\n",
    "                              )\n",
    "    \n",
    "    # Load model\n",
    "    if prediction_filter_length is None:\n",
    "        zeroshot_model = TinyTimeMixerForPrediction.from_pretrained(\n",
    "            \"ibm/TTM\", revision=TTM_MODEL_REVISION\n",
    "        )\n",
    "    else:\n",
    "        if prediction_filter_length <= forecast_length:\n",
    "            zeroshot_model = TinyTimeMixerForPrediction.from_pretrained(\n",
    "                \"ibm/TTM\", revision=TTM_MODEL_REVISION, prediction_filter_length=prediction_filter_length\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"`prediction_filter_length` should be <= `forecast_length\")\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    # zeroshot_trainer\n",
    "    zeroshot_trainer = Trainer(\n",
    "        model=zeroshot_model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=temp_dir,\n",
    "            per_device_eval_batch_size=batch_size, \n",
    "            no_cuda=True # Necessary if you want to run the code without GPU (comment this line if you want to use cuda)\n",
    "        )\n",
    "    )\n",
    "    # evaluate = zero-shot performance\n",
    "    print(\"+\" * 20, \"Test MSE zero-shot\", \"+\" * 20)\n",
    "    zeroshot_output = zeroshot_trainer.evaluate(dset_test)\n",
    "    print(zeroshot_output)\n",
    "\n",
    "    # plot\n",
    "    plot_predictions(model=zeroshot_trainer.model, dset=dset_test, plot_dir=os.path.join(OUT_DIR, dataset_name), plot_prefix=\"test_zeroshot\", channel=0)\n",
    "    return zeroshot_model, zeroshot_trainer, zeroshot_output, dset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9ab3a-bc44-4ef0-8937-ed9e563b9aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9ae1b-dc80-49a1-86b5-c9143f1b139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer, output, input_data = zeroshot_eval(dataset_name=target_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea405c88-0710-49b9-856c-53e28117331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "? model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f62f71-b29c-4cd3-8e99-2d798b9fd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "? trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688023f-ce1e-43b8-837b-5b29e91460eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "? output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d54d9-43fd-4515-bb36-2a2deee144b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "? TinyTimeMixerForPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f930451-18fe-42c0-9edd-6c3b8409cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "? TinyTimeMixerForPrediction.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c978b1-4c2b-49bf-b760-c66005df18a4",
   "metadata": {},
   "source": [
    "Obtener los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574faf98-5457-4473-ac25-658721a2ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "? target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c6d41-4eed-4f5c-a41e-e61f277418d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "? input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a02ae-2b9b-4cc1-88bb-b65f7be5c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[0]['past_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e16f7-a748-4650-82af-499655ff5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.backbone(input_data[0]['past_values'])\n",
    "    embeddings = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573995a9-9149-4a48-bda0-af076e3e27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "? output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9cfea-6433-4d19-a448-c0cbeb17414e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45284d8-cf5b-4a33-aa8b-386d845dec39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13f44f-5680-410f-a24a-7fc1e9692cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b66c1d-04fd-49f6-ae28-bd42e091df15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45c76d-4fb5-46c3-8ca5-5617e106205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroshot_eval_with_embeddings(\n",
    "    dataset_name, \n",
    "    batch_size,\n",
    "    context_length=TTM_INPUT_SEQ_LEN,\n",
    "    forecast_length=96,\n",
    "    prediction_filter_length=None\n",
    "):\n",
    "    # Get data\n",
    "    _, _, dset_test = get_data(dataset_name=dataset_name, \n",
    "                               context_length=context_length, \n",
    "                               forecast_length=forecast_length, \n",
    "                               fewshot_fraction=1.0\n",
    "                              )\n",
    "    \n",
    "    # Load model\n",
    "    if prediction_filter_length is None:\n",
    "        zeroshot_model = TinyTimeMixerForPrediction.from_pretrained(\n",
    "            \"ibm/TTM\", revision=TTM_MODEL_REVISION\n",
    "        )\n",
    "    else:\n",
    "        if prediction_filter_length <= forecast_length:\n",
    "            zeroshot_model = TinyTimeMixerForPrediction.from_pretrained(\n",
    "                \"ibm/TTM\", revision=TTM_MODEL_REVISION, prediction_filter_length=prediction_filter_length\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"`prediction_filter_length` should be <= `forecast_length\")\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # zeroshot_trainer\n",
    "    zeroshot_trainer = Trainer(\n",
    "        model=zeroshot_model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=temp_dir,\n",
    "            per_device_eval_batch_size=batch_size, \n",
    "            no_cuda=True # Necessary if you want to run the code without GPU\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Prepare to extract embeddings\n",
    "    embeddings_list = []\n",
    "\n",
    "    def compute_embeddings(model, inputs, prediction_loss_only=False, ignore_keys=None):\n",
    "        # Forward pass to get embeddings\n",
    "        with torch.no_grad():\n",
    "            past_values = inputs['past_values']\n",
    "            # Obtenemos la salida del backbone\n",
    "            output = model.backbone(past_values)\n",
    "            # Inspeccionamos el objeto devuelto\n",
    "            #print(output)  # Esto te ayudará a ver qué contiene `output`\n",
    "            \n",
    "            # Asegúrate de extraer el atributo correcto. Por ejemplo:\n",
    "            embeddings = output.last_hidden_state  # Esto es un ejemplo, ajusta según el contenido real\n",
    "            embeddings_list.append(embeddings.cpu().numpy())  # Almacena los embeddings en la lista\n",
    "\n",
    "        return None, None, None\n",
    "\n",
    "    # Register the function to be called during evaluation\n",
    "    zeroshot_trainer.prediction_step = compute_embeddings\n",
    "\n",
    "    # Evaluate and compute embeddings\n",
    "    print(\"+\" * 20, \"Test MSE zero-shot\", \"+\" * 20)\n",
    "    zeroshot_output = zeroshot_trainer.evaluate(dset_test)\n",
    "\n",
    "    # embeddings_list contendrá los embeddings obtenidos\n",
    "    embeddings_list = np.concatenate(embeddings_list, axis=0)\n",
    "    print(f\"Extracted embeddings shape: {embeddings_list.shape}\")\n",
    "\n",
    "    # plot predictions (opcional)\n",
    "    plot_predictions(model=zeroshot_trainer.model, dset=dset_test, plot_dir=os.path.join(OUT_DIR, dataset_name), plot_prefix=\"test_zeroshot\", channel=0)\n",
    "    \n",
    "    return zeroshot_model, zeroshot_trainer, zeroshot_output, embeddings_list, dset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae461b01-3a8f-4209-a94a-3e3f25a7f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer, output, embs, input_data = zeroshot_eval_with_embeddings(\n",
    "    dataset_name=target_dataset, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741f3c2-cce6-445f-bee1-313895c8d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66071d-31e9-4ce8-bd64-98e9d0f8e405",
   "metadata": {},
   "source": [
    "2960 es el número de timestamps de \"venice\"\n",
    "2 es ¿?\n",
    "16 es ¿?\n",
    "192 es ¿forecast horizon - fl ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
