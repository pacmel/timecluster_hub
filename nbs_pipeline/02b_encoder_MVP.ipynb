{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b6c9b7-dd2a-4d74-bf5a-cedadcc9347f",
   "metadata": {},
   "source": [
    "# Encoder - MVP\n",
    "\n",
    "> Self supervised learning Masked Value Prediction (MVP) as a way to create the embeddings.\n",
    "Based on tsai's MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185023c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import sys\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    import nbs_pipeline.utils.vscode  as vs\n",
    "    vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a511d12-df7f-420e-b570-f37bc13d1781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961dbf47-71de-4471-80d5-2fdabbd6e360",
   "metadata": {},
   "source": [
    "## Setup CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb164924-13e2-4099-ba35-06e675035d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuda_device=1\n",
    "cuda_device=0\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:2048'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb7848-0ac0-4f55-a6e6-49478d7cac25",
   "metadata": {},
   "source": [
    "## Get configutation from yml\n",
    "> This file used the configuration files './config/base.yml' and './config/02b_encoder_MVP.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b845205-b133-4ee1-baaf-acc2ddd6533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "user, project, version, data, config, job_type = cfg.get_artifact_config_MVP(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e3e5fb-6359-4ab1-b197-bb3e1f5abb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias: Monash-Australian_electricity_demand\n",
      "analysis_mode: online\n",
      "batch_size: 512\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: (10, 30)\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 900\n",
      "train_artifact: mi-santamaria/deepvats/Monash-Australian_electricity_demand:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71052bbf-f65b-45ea-aa8f-e3ee665f27ba",
   "metadata": {},
   "source": [
    "## Setup Weights & biases artiffact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30caa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 02b_encoder_MVP\n"
     ]
    }
   ],
   "source": [
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"02b_encoder_MVP\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4411368-d772-4381-9cc0-5c9b7ea5361a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mi-santamaria. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20240130_170656-ltkjtywh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/ltkjtywh' target=\"_blank\">02b_encoder_MVP</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/ltkjtywh' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/ltkjtywh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'stream.Stream' object attribute 'write' is read-only\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', resume=False,\n",
    "    name = runname\n",
    ")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0515d-4f2a-4ba6-8c41-a6f480ff6f4b",
   "metadata": {},
   "source": [
    "## Split data using Sliding Window & Get training artiffact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b6f3e-27e0-434b-aa71-eaed928d8dc9",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff09dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a82ad4-45ca-4c9e-8d87-aa56f4d2fdd2",
   "metadata": {},
   "source": [
    "### Get W&B train artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78dced3c-8280-460e-bd11-8188495bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_artifact = artifacts_gettr(config.train_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8acf714f-0fe1-4aed-8b57-23ccd31b22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "ename": "<class 'pyarrow.lib.ArrowInvalid'>",
     "evalue": "Not a Feather V1 or Arrow IPC file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m train_artifact\u001b[38;5;241m.\u001b[39mto_df()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead\n",
      "File \u001b[0;32m~/work/dvats/load.py:137\u001b[0m, in \u001b[0;36mto_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload())\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom-df\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Call read_pickle with the single file from dir\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m#return pd.read_pickle(dir.ls()[0])\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: Only from_df method is allowed yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/pyarrow/feather.py:231\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads, memory_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mRead a pandas.DataFrame from Feather format. To read as pyarrow.Table use\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mfeather.read_table.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mdf : pandas.DataFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    230\u001b[0m _check_pandas_version()\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas(use_threads\u001b[38;5;241m=\u001b[39muse_threads))\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/pyarrow/feather.py:256\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, memory_map, use_threads)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_table\u001b[39m(source, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    Read a pyarrow.Table from Feather format\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    table : pyarrow.Table\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43m_feather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatherReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_memory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/pyarrow/_feather.pyx:79\u001b[0m, in \u001b[0;36mpyarrow._feather.FeatherReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Not a Feather V1 or Arrow IPC file"
     ]
    }
   ],
   "source": [
    "df_train = train_artifact.to_df()\n",
    "print(df_train.shape)\n",
    "df_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a303a-11eb-46d0-af8e-a78a265d055d",
   "metadata": {},
   "source": [
    "#### Check no duplicated index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a3174d-43df-4a3a-979a-54d77dbdcb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_train.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5e800-ace5-48e9-bb27-d288abfc108e",
   "metadata": {},
   "source": [
    "#### Get training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25ab5a-b1e6-4eb7-8542-e4dc87f2a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = sw(df_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8154ab5-1001-4b59-bf4a-99dfcc0c8913",
   "metadata": {},
   "source": [
    "### Split training set into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e270e-c6a2-4dc0-a54d-8f6fdc7565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "print(X.shape)\n",
    "if config.analysis_mode == 'online':\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=True)(X)\n",
    "    \n",
    "elif config.analysis_mode == 'offline':\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size)\n",
    "    \n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb702b4-8b10-4164-8755-456ffd2759f9",
   "metadata": {},
   "source": [
    "## MVP - Encoder training\n",
    "> Train MVP with optional adaptable window sizes, to allow for inference with different\n",
    "window sizes, to provide an easier exploration of the embedding space through different\n",
    "ways of sliding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156687d8-27b4-451c-b4ae-d5e6859fce25",
   "metadata": {},
   "source": [
    "### Set callback list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = L(WandbCallback(log_preds=False)) if config.use_wandb else L()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31668027-6769-405d-8223-09699a4f1b7f",
   "metadata": {},
   "source": [
    "### Set transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97038fe-116f-4d6c-8569-e9a9c015a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [ToFloat(), None]\n",
    "batch_tfms = [TSStandardize(by_sample=config.norm_by_sample, \n",
    "               use_single_batch=config.norm_use_single_batch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ae849-6b83-4298-9132-b68746b982f8",
   "metadata": {},
   "source": [
    "### Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_ts_dls(X, splits=splits, tfms=tfms, bs=config.batch_size, batch_tfms=batch_tfms)\n",
    "dls.show_at(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b997218-945b-49df-b48e-e83eff7f3463",
   "metadata": {},
   "source": [
    "### Build MVP TS Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2b562-c1d8-4b01-aa69-6aa974ee959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgc = ShowGraphCallback2()\n",
    "learn = ts_learner(dls, InceptionTimePlus, \n",
    "                   cbs= cbs + sgc + MVP(\n",
    "                       r = config.r, \n",
    "                        window_size=config.mvp_ws, \n",
    "                        future_mask = config.mask_future, \n",
    "                        target_dir='./models', \n",
    "                        sync = config.mask_sync, \n",
    "                        stateful = config.mask_stateful,\n",
    "                        fname=f'encoder_MVP'\n",
    "                    ), y_range=[X.min(), X.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675240ed-a3b9-4a8d-b5cb-41c48b68909c",
   "metadata": {},
   "source": [
    "### Example mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c923f-31e8-49f2-b3d9-8b1fe370bcc6",
   "metadata": {},
   "source": [
    "#### Create mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dd304-6691-49b7-9ffc-f004757f3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mask_future:\n",
    "    example_mask = create_future_mask(torch.from_numpy(X[0]), config.r, sync=config.mask_sync)\n",
    "else:\n",
    "    example_mask = create_subsequence_mask(torch.from_numpy(X[0]), config.r, stateful=config.mask_stateful, sync=config.mask_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d81f4-2d4a-484c-bf9b-88ccab1cd4d6",
   "metadata": {},
   "source": [
    "#### Show mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563efbd4-bc93-4969-b7e8-bed4b191291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "plt.pcolormesh(example_mask[0], cmap=colors.ListedColormap(['whitesmoke', 'orchid']))\n",
    "plt.title(f'r={config.r},  future={config.mask_future},  stateful={config.mask_stateful},  sync={config.mask_sync}')\n",
    "ax.set_ylabel('variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb64be-3389-4f2b-997d-a8799e1a5469",
   "metadata": {},
   "source": [
    " ## Check window size configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63c043-6d89-47f6-a579-2f028980237e",
   "metadata": {},
   "source": [
    "### Check config attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d5cc8-fac5-4f9d-bbd9-4083c2c60d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_window_size = config.mvp_ws\n",
    "print(\"w\", config.w, \"mvp_ws\", config.mvp_ws)\n",
    "print(\"expected \", expected_window_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21896f59-e2a0-434f-9437-aa958f90fb67",
   "metadata": {},
   "source": [
    "### Check obtained attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e5d4c-84de-440c-9572-8688951c2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_cb = learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0]  # Encuentra el callback MVP\n",
    "obtained_window_size=mvp_cb.window_size\n",
    "print(\"obtained \", obtained_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3112-ba6b-4756-9ce1-e15e4c2af1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (expected_window_size != obtained_window_size):\n",
    "    raise ValueError(\"Obtained window_size for MVP training different from expected window size. Check size, ws1 & ws2 parameters in '02b-encoder_MVP.yaml'\")\n",
    "else: \n",
    "    print(\"Obtained window size tuple is the expected one. Continue!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc784e8-59a1-45e9-8af1-b61ba01a9fc6",
   "metadata": {},
   "source": [
    "#### Check w1 < w2 for MVP random window size selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272a132-9026-419c-81b0-d16d03894f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (obtained_window_size[1] < obtained_window_size[0]):\n",
    "    raise ValueError(\"Ws2 must be greater than Ws1 as they are the maximun and minimum window size respectively. Please ensure w2 > w1\")\n",
    "else: \n",
    "    w_sizes = np.random.randint(obtained_window_size)\n",
    "    print(w_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a4a5f-23ba-46a0-abd4-f9854356c3a9",
   "metadata": {},
   "source": [
    "#### Check self.x.shape[-1] for np.random.randint(0, self.x.shape[-1] - ws) MMVP calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a49d0-7ee1-4519-a871-b4f82f94c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data batch\n",
    "x = next(iter(dls.train))\n",
    "print(\"x\", x)\n",
    "x_data=x[0]\n",
    "print(\"Data shape: \" + str( x_data.shape))\n",
    "time_serie_len = x_data.shape[-1]\n",
    "print(\"Time serie len: \" + str( time_serie_len))\n",
    "#Just in case\n",
    "for ws in w_sizes:\n",
    "    diff = time_serie_len - ws\n",
    "    print(\"diff time serie len - ws\", diff)\n",
    "    result = np.random.randint(0, diff)\n",
    "    print(\"ws \", ws, \"diff\", diff, \"result\",  result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05917f56-5e62-4e45-b546-5996a72106bd",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dd97f-1cb2-4364-9748-db882ac6162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_valley, lr_steep = learn.lr_find(suggest_funcs=(valley, steep))\n",
    "learn.fit_one_cycle(n_epoch=config.epochs, lr_max=lr_valley,  cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.000001, patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae82aae-70dd-40de-baf8-22a2bf3d99c0",
   "metadata": {},
   "source": [
    "#### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db4834-1e28-4251-8f58-662cdf5f24bf",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf3667-a698-451a-9900-0ac1d6fa0cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.MVP.show_preds(sharey=True, nrows=2) # error with nwors=1 or ncols=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4ff29-1d59-4c1d-8499-a8e2b0b6c012",
   "metadata": {},
   "source": [
    "## Save artifact to W&B\n",
    "> Remove extra information and saving the learner object as an weight and biases artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bf350-4f52-4a18-ad19-9d260bd060d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the ShowGraphCallback2 callback to avoid errors in the frontend (TODO)\n",
    "learn.remove_cb(sgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0de64-aced-433e-9c10-28fbcf4f9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the learner without the datasets\n",
    "aux_learn = learn.export_and_get()\n",
    "if config.use_wandb: \n",
    "    run.log_artifact(\n",
    "        ReferenceArtifact(\n",
    "            aux_learn, \n",
    "            f'mvp', \n",
    "            type='learner', \n",
    "            metadata=dict(run.config)\n",
    "        ), \n",
    "        aliases=config.alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97de068-dc91-4cfc-b0a0-2a52b52a9f80",
   "metadata": {},
   "source": [
    "## Close W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe12cd-6e5f-40eb-8f84-12d2db7a355b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be8af8-dd40-4e87-af14-e200b9740e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_kernel=True\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
