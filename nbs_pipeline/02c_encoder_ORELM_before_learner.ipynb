{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import nbs_pipeline.utils.vscode  as vs\n",
    "vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# OR-ELM: Online Recurrent Extreme Learning Machine for time-series prediction\n",
    "\n",
    "> This notebook applies visual analytics to [OR_ELM](https://github.com/chickenbestlover/Online-Recurrent-Extreme-Learning-Machine) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize loss function\n",
      "Initialize loss function\n",
      "Initialize loss function\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tsai.all import *\n",
    "except:\n",
    "    from tsai.all import * # TODO: Weird error when loading tsai!from tchub.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from fastcore.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.schedule import *\n",
    "from dvats.all import *\n",
    "import nbs.orelm.orelm_torch as orelm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "Before running this notebook, make sure you have the `$WANDB_API_KEY` environment varibale defined with your API_KEY (run in a terminal `echo $WANDB_API_KEY` to see it). If not, run in a terminal `wandb login [API_KEY]`. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/02c-encoder_orelm.yaml\n",
      "... About to replace includes with content\n",
      "Before configuration reading \n",
      "-include: None\n",
      "-user_preferences:\n",
      "\t-use_wandb: False\n",
      "\t-wdb:\n",
      "\t\t-user: mi-santamaria\n",
      "\t\t-project_name: test-project\n",
      "\t\t-version: 0\n",
      "\t\t-mode: offline\n",
      "\t\t-artifacts_path: ./data/wandb_artifacts\n",
      "\t-data:\n",
      "\t\t-folder: ~/data/\n",
      "\t\t-fname: speed_6005\n",
      "\t\t-ftype: .csv\n",
      "\t\t-cols: [1]\n",
      "\t\t-freq: 1s\n",
      "\t-artifact:\n",
      "\t\t-alias: TiltABP\n",
      "\t-directories:\n",
      "\t\t-tmp: tmp\n",
      "\t\t-data: ~/data/speed_6005.csv\n",
      "-data:\n",
      "\t-name: speed_6005\n",
      "\t-path: ~/data/speed_6005.csv\n",
      "\t-alias: TiltABP\n",
      "\t-cols: [1]\n",
      "\t-csv_config:\n",
      "\t-date_offset: None\n",
      "\t-date_format: %Y-%m-%d %H:%M:%S\n",
      "\t-freq: 1s\n",
      "\t-joining_train_test: False\n",
      "\t-missing_values:\n",
      "\t\t-technique: None\n",
      "\t\t-constant: None\n",
      "\t-normalize_training: False\n",
      "\t-range_training: None\n",
      "\t-range_testing: None\n",
      "\t-resampling_freq: None\n",
      "\t-start_date: None\n",
      "\t-test_split: None\n",
      "\t-time_col: None\n",
      "-wandb:\n",
      "\t-user: mi-santamaria\n",
      "\t-dir: ~/test-project\n",
      "\t-enabled: False\n",
      "\t-group: None\n",
      "\t-log_learner: False\n",
      "\t-mode: offline\n",
      "\t-project: test-project\n",
      "\t-version: 0\n",
      "\t-artifacts_path: ./data/wandb_artifacts\n",
      "-configuration:\n",
      "\t-job_type: encoder_ORELM\n",
      "\t-alias: TiltABP\n",
      "\t-wandb:\n",
      "\t\t-use: False\n",
      "\t\t-entity: mi-santamaria\n",
      "\t\t-group: None\n",
      "\t\t-project: test-project\n",
      "\t-artifacts:\n",
      "\t\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t\t-valid:\n",
      "\t\t\t-data: None\n",
      "\t\t\t-size: 0.1\n",
      "\t-specifications:\n",
      "\t\t-algorithm: OSELM\n",
      "\t\t-n_epoch: 200\n",
      "\t\t-random_seed: 6\n",
      "\t\t-numHiddenNeurons: 25\n",
      "\t\t-activationFunction: sig\n",
      "\t\t-LN: True\n",
      "\t\t-AE: True\n",
      "\t\t-ORTH: True\n",
      "\t\t-lamb: 0.0001\n",
      "\t\t-weight_forgetting_factors:\n",
      "\t\t\t-input: 1\n",
      "\t\t\t-output: 0.92\n",
      "\t\t-sliding_windows:\n",
      "\t\t\t-stride: 1\n",
      "\t\t\t-size: 25\n",
      "After reading config\n",
      "-job_type: encoder_ORELM\n",
      "-alias: TiltABP\n",
      "-wandb:\n",
      "\t-use: False\n",
      "\t-entity: mi-santamaria\n",
      "\t-group: None\n",
      "\t-project: test-project\n",
      "-artifacts:\n",
      "\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t-valid:\n",
      "\t\t-data: None\n",
      "\t\t-size: 0.1\n",
      "-specifications:\n",
      "\t-algorithm: OSELM\n",
      "\t-n_epoch: 200\n",
      "\t-random_seed: 6\n",
      "\t-numHiddenNeurons: 25\n",
      "\t-activationFunction: sig\n",
      "\t-LN: True\n",
      "\t-AE: True\n",
      "\t-ORTH: True\n",
      "\t-lamb: 0.0001\n",
      "\t-weight_forgetting_factors:\n",
      "\t\t-input: 1\n",
      "\t\t-output: 0.92\n",
      "\t-sliding_windows:\n",
      "\t\t-stride: 1\n",
      "\t\t-size: 25\n"
     ]
    }
   ],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "config, job_type, dataSet = cfg.get_artifact_config_ORELM(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: test-project\n"
     ]
    }
   ],
   "source": [
    "print(\"Project: \"+config.wandb_project)\n",
    "run = wandb.init(\n",
    "    entity          = config.wandb_entity,\n",
    "    project         = config.wandb_project,\n",
    "    group           = config.wandb_group,\n",
    "    job_type        = job_type,\n",
    "    allow_val_change= True,\n",
    "    mode            = 'online' if config.use_wandb else 'disabled',\n",
    "    config          = config,\n",
    "    resume          = False\n",
    ")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dataSet:\n",
      "-folder: ~/data/\n",
      "-fname: speed_6005\n",
      "-ftype: .csv\n",
      "-cols: [1]\n",
      "-freq: 1s\n"
     ]
    }
   ],
   "source": [
    "print(\"Used dataSet:\")\n",
    "cfg.recursive_print_attrdict(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is a $w \\times s \\times t$ matrix. The first step consists in slicing the original multivariate time series into slices of shape ($w \\times d$), as shown in this figure from the paper.\n",
    "<img src=\"https://i.imgur.com/R9Fx8uO.png\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of this sliding window approach are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLIDING WINDOW --\n",
      "Len: 25\n",
      "Stride: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"--- SLIDING WINDOW --\")\n",
    "print(\"Len: \" + str(config.w))\n",
    "print(\"Stride: \" + str(config.stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>2015-08-31 18:22:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>2015-08-31 18:32:00</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>2015-08-31 18:57:00</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>2015-08-31 19:07:00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>2015-08-31 19:12:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               timestamp  value\n",
       "1970-01-01 00:00:00  2015-08-31 18:22:00     90\n",
       "1970-01-01 00:00:01  2015-08-31 18:32:00     80\n",
       "1970-01-01 00:00:02  2015-08-31 18:57:00     84\n",
       "1970-01-01 00:00:03  2015-08-31 19:07:00     94\n",
       "1970-01-01 00:00:04  2015-08-31 19:12:00     90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get artiffact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "#convert to pandas dataset\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. variables: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of variables\n",
    "if dataSet.cols:\n",
    "    df_train = df_train.iloc[:, dataSet.cols]\n",
    "print(f'Num. variables: {len(df_train.columns)}')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:35</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:36</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:37</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:38</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:39</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90\n",
       "...                    ...\n",
       "1970-01-01 00:41:35     81\n",
       "1970-01-01 00:41:36     89\n",
       "1970-01-01 00:41:37     87\n",
       "1970-01-01 00:41:38     82\n",
       "1970-01-01 00:41:39     83\n",
       "\n",
       "[2500 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.9068\n",
      "8.744856417346142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize data by subtracting mean and dividing by std\n",
    "meanSeq     = np.mean(df_train['value'])\n",
    "print(meanSeq)\n",
    "stdSeq      = np.std(df_train['value'])\n",
    "print(stdSeq)\n",
    "df_train['value'] = (df_train['value'] - meanSeq)/stdSeq\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset shape</td>\n",
       "      <td>(2500, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Sliding windows</td>\n",
       "      <td>2476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sliding window shape</td>\n",
       "      <td>(1, 25)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Description      Value\n",
       "0              Dataset shape  (2500, 1)\n",
       "1  Number of Sliding windows       2476\n",
       "2       Sliding window shape    (1, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup Training windows\n",
    "X_train, _ = sw(df_train) #Windows\n",
    "data = {\n",
    "    \"Description\": [\n",
    "        \"Dataset shape\", \n",
    "        \"Number of Sliding windows\", \n",
    "        \"Sliding window shape\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(df_train.shape), \n",
    "        str(X_train.shape[0]), \n",
    "        f\"({X_train.shape[1]}, {X_train.shape[2]})\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "training_info = pd.DataFrame(data)\n",
    "training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No validation artifact. Random items to get: 0.1\n"
     ]
    }
   ],
   "source": [
    "if config.valid_artifact:\n",
    "    valid_artifact = artifacts_gettr(config.valid_artifact)\n",
    "    df_val = valid_artifact.to_df()\n",
    "    X_valid, _ = sw(df_val)\n",
    "    df_val.shape, X_valid.shape\n",
    "    print(\"valid_artifact\")\n",
    "    print(valid_artifact)\n",
    "    print(\"df_val\")\n",
    "    print(df_val)\n",
    "    print(\"X_valid\")\n",
    "    print(X_valid)\n",
    "    print(\"df_val.shape\")\n",
    "    print(df_val.shape)\n",
    "    print(\"X_valid.shape\")\n",
    "    print(X_valid.shape)\n",
    "else:\n",
    "    print(\"No validation artifact. Random items to get:\", config.valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: METER EXPLICACIÓN DE OR-ELM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: AQUI VA LA EXPLICACIÓN CON EL EJEMPLO QUE SE META EN EL PAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1615, 1960, 783, 636, 434, 1325, 542, 1399, 2356, 509, 1129, 1343, 837, 457, 1053, 604, 637, 2447, 1942, 1612, 426, 1293, 1096, 818, 1653, 102, 577, 827, 986, 1178, 1884, 1763, 959, 123, 79, 1054, 125, 2463, 902, 2396, 947, 523, 1290, 440, 2446, 2069, 168, 694, 2473, 405, 1209, 247, 1641, 997, 1158, 1497, 425, 452, 1457, 1244, 2305, 923, 36, 775, 1880, 1768, 385, 1424, 12, 983, 298, 1956, 2467, 1801, 598, 483, 1312, 451, 1840, 2411, 2387, 1969, 889, 1065, 1148, 766, 1090, 721, 1865, 641, 2455, 797, 359, 1622, 676, 2161, 1414, 1544, 531, 2180, 190, 40, 877, 1071, 931, 198, 282, 1621, 355, 1780, 924, 2001, 1823, 371, 75, 2222, 1370, 1916, 1156, 661, 236, 352, 277, 2450, 2402, 470, 1010, 1441, 2346, 1219, 2095, 397, 83, 2192, 2380, 185, 174, 1949, 1928, 2424, 1235, 2014, 1915, 400, 2151, 2166, 1303, 910, 2398, 1406, 1231, 297, 1269, 159, 1946, 1163, 1537, 334, 1154, 1385, 2279, 472, 2416, 920, 2431, 553, 1936, 562, 2049, 2314, 173, 2173, 582, 1553, 1714, 2065, 1245, 16, 2066, 1772, 507, 1909, 1752, 1853, 1565, 1997, 682, 1112, 1970, 764, 552, 144, 2148, 203, 949, 675, 1341, 1427, 517, 271, 126, 1340, 1423, 1151, 1887, 1140, 1357, 2212, 55, 348, 330, 114, 671, 406, 2253, 2012, 1702, 771, 2310, 1731, 2099, 1098, 269, 1336, 882, 2163, 1003, 1186, 1917, 254, 124, 1087, 1318, 154, 2077, 1331, 1416, 1038, 904, 138, 950, 286, 1616, 793, 2404, 1925, 622, 1083, 2374, 368, 261, 2285, 843, 2266, 1165, 1128, 2292, 2085, 693, 2045, 1757, 1889, 664, 81, 257, 404, 1941, 1289, 2321, 730, 1867, 2226, 2324, 727, 1095, 2263, 2298, 1800, 92, 619, 1635, 1558, 751, 2252, 1673, 521, 585, 755, 1932, 1734, 1818, 2421, 876, 2006, 624, 625, 912, 946, 1975, 2033, 894, 2425, 71, 20, 649, 811, 2273, 1229, 1672, 377, 1280, 63, 1504, 104, 921, 563, 1810, 1143, 2196, 2008, 110, 2432, 415, 813, 1000, 255, 2175, 1631, 1643, 1812, 2117, 1202, 1639, 1939, 2430, 1436, 731, 117, 1548, 2136, 1694, 1633, 329, 1991, 2436, 1989, 1484, 1455, 1698, 2042, 814, 422, 1715, 993, 1658, 1073, 556, 166, 197, 702, 499, 687, 804, 1980, 1088, 2021, 808, 1127, 1364, 1374, 479, 2207, 2225, 313, 312, 343, 1998, 390, 1259, 2319, 1417, 66, 1627, 91, 307, 663, 1862, 2419, 1509, 2115, 1152, 1134, 1203, 1251, 1329, 227, 1506, 2214, 1375, 30, 922, 1682, 568, 2132, 777, 2294, 4, 0, 1623, 1700, 681, 815, 1822, 2466, 1961, 758, 2191, 2243, 219, 130, 809, 1527, 609, 373, 1051, 1837, 1832, 411, 139, 925, 1001, 2030, 1217, 2384, 48, 1526, 791, 1237, 1517, 2109, 2340, 8, 1551, 1131, 2359, 1912, 1747, 1904, 1741, 2164, 2341, 1903, 129, 2394, 610, 398, 491, 1922, 1011, 696, 634, 2464, 378, 101, 724, 2244, 929, 984, 1371, 853, 1253, 639, 1108, 1174, 960, 2276, 206, 143, 961, 1578, 722, 527, 593, 2169, 2264, 2043, 38, 823, 2460, 284, 1798, 2288, 1567, 1883, 1833, 1522, 358, 200, 2338, 513, 111, 1179, 2106, 2327, 2230, 278, 2270, 781, 2031, 1729, 839, 734, 1170, 2137, 382, 347, 1390, 1296, 413, 2233, 1630, 1539, 697, 1381, 1358, 2086, 433, 1294, 1266, 7, 22, 1434, 768, 67, 951, 1298, 424, 2342, 31, 1016, 1082, 928, 1207, 1905, 1263, 2344, 932, 341, 1722, 225, 1843, 995, 417, 942, 844, 866, 1322, 52, 988, 965, 1855, 623, 2423, 26, 536, 644, 708, 757, 2096, 2328, 2104, 1629, 294, 1816, 314, 587, 1153, 1376, 835, 2004, 2056, 1272, 1669, 2118, 873, 976, 581, 468, 1814, 1620, 2007, 1523, 914, 1664, 794, 1705, 1160, 1844, 856, 375, 301, 987, 1651, 621, 1050, 630, 930, 937, 601, 1783, 2039, 989, 1271, 1524, 686, 1538, 2057, 707, 95, 2362, 1686, 2149, 47, 1959, 2366, 1897, 1047, 1068, 1869, 848, 1344, 391, 1761, 1656, 2290, 841, 381, 1766, 2003, 2282, 1879, 1193, 2364, 590, 1564, 726, 462, 2139, 1554, 2323, 2391, 2332, 39, 283, 230, 1465, 147, 1409, 1124, 1788, 50, 2357, 2224, 735, 1392, 1723, 1557, 1114, 600, 1020, 51, 713, 2441, 667, 662, 2345, 1787, 1447, 1482, 1485, 673, 1270, 647, 2198, 1288, 94, 934, 194, 2197, 1452, 2124, 1953, 2265, 579, 714, 41, 2105, 1093, 732, 37, 1872, 1297, 23, 1035, 1938, 544, 136, 819, 761, 1532, 205, 1121, 1214, 2428, 1019, 2260, 718, 613, 1748, 2303, 439, 800, 1555, 135, 826, 84, 763, 251, 384, 1183, 528, 2405, 1248, 1292, 1466, 1033, 750, 1795, 2291, 1291, 419, 267, 864, 2130, 854, 660, 803, 2267, 2311, 2352, 572, 172, 1141, 407, 2427, 1948, 1605, 706, 970, 325, 2268, 42, 1442, 388, 1687, 1769, 1222, 719, 2261, 1210, 1195, 2370, 753, 1171, 275, 2189, 1308, 1573, 2147, 142, 1319, 607, 459, 274, 1834, 720, 2155, 954, 1309, 1215, 1265, 725, 209, 1585, 830, 1775, 2361, 467, 1518, 2355, 508, 956, 292, 2002, 2358, 2318, 985, 1043, 784, 223, 1274, 545, 2280, 2145, 1159, 456, 369, 18, 728, 2054, 519, 801, 916, 1048, 1204, 287, 1676, 1901, 2259, 1351, 495, 611, 237, 999, 493, 128, 1671, 2112, 2216, 966, 974, 1395, 2297, 293, 1246, 2235, 210, 367, 1132, 1864, 2140, 344, 1696, 1828, 1250, 2194, 1401, 1652, 1468, 1657, 281, 1593, 863, 1666, 1232, 1728, 2067, 2379, 2452, 1155, 665, 2005, 2162, 224, 1777, 429, 2331, 2429, 454, 893, 906, 383, 1604, 1188, 308, 150, 1678, 1049, 2188, 1474, 865, 1444, 1345, 360, 1420, 1899, 253, 13, 1479, 767, 1494, 1199, 2025, 1299, 555, 2426, 2435, 759, 165, 315, 2029, 1226, 212, 2440, 1595, 1099, 1512, 1791, 953, 689, 2228, 127, 1841, 445, 1650, 1142, 2082, 977, 473, 1874, 137, 2418, 1139, 782, 1359, 1771, 1396, 851, 1285, 191, 2317, 1674, 443, 2469, 746, 2375, 1528, 2456, 1710, 2275, 1793, 1972, 2422, 1937, 1785, 310, 1037, 2152, 1205, 2091, 2016, 1919, 1906, 1426, 450, 672, 2129, 1496, 868, 2000, 648, 2377, 834, 148, 850, 943, 2363, 1898, 958, 1776, 2070, 349, 1287, 1119, 6, 1730, 691, 948, 857, 1944, 752, 2200, 645, 543, 1782, 2296, 939, 1891, 852, 1624, 24, 2123, 2038, 1609, 2053, 716, 32, 1701, 533, 1893, 1061, 1945, 376, 522, 21, 2174, 1348, 2474, 867, 739, 366, 2449, 736, 715, 968, 1759, 1602, 2471, 1699, 1261, 1982, 2211, 1425, 1435, 2134, 538, 905, 2050, 1515, 121, 1876, 836, 1552, 915, 879, 1438, 674, 1598, 1692, 1197, 1240, 2159, 1125, 1561, 1380, 184, 1875, 90, 305, 829, 151, 573, 1361, 374, 1784, 1541, 392, 1260, 2044, 2100, 1216, 1995, 962, 1502, 394, 402, 17, 1150, 497, 1587, 2326, 1115, 1391, 97, 969, 2302, 1640, 1525, 1431, 524, 370, 2445, 1247, 892, 113, 1339, 204, 1637, 2365, 2074, 802, 262, 1935, 70, 1963, 561, 1654, 14, 1851, 316, 652, 134, 1990, 1709, 9, 155, 182, 1078, 885, 1835, 1443, 1069, 913, 1437, 241, 299, 1955, 1977, 295, 2315, 216, 2027, 1510, 1824, 2231, 1106, 2406, 1092, 1882, 1655, 762, 870, 350, 861, 769, 1842, 1827, 2035, 77, 403, 2459, 2183, 250, 1685, 1252, 1507, 1008, 1900, 1063, 1445, 447, 1028, 1120, 635, 115, 1888, 372, 311, 270, 318, 1978, 1064, 43, 2046, 1799, 2286, 1591, 1034, 453, 1311, 1386, 448, 614, 891, 1530, 1314, 1284, 2399, 1242, 1983, 698, 862, 2417, 1794, 2368, 488, 526, 2083, 1397, 1533, 73, 646, 45, 1089, 2458, 87, 586, 379, 1077, 1754, 1378, 1661, 1726, 228, 1243, 265, 353, 1192, 1516, 2238, 1194, 774, 2150, 1012, 1453, 2433, 1315, 982, 1398, 1408, 2088, 72, 1749, 416, 2024, 655, 1330, 1704, 967, 657, 240, 1767, 551, 2465, 1097, 157, 1017, 2, 1342, 1649, 880, 1005, 1483, 560, 2186, 2116, 1952, 1908, 2215, 252, 1847, 222, 1276, 1871, 1923, 1930, 1859, 1556, 218, 58, 1413, 2312, 1733, 703, 776, 1574, 1354, 2330, 908, 669, 2407, 1429, 1724, 1670, 1619, 1320, 486, 2339, 907, 2257, 1642, 82, 2262, 1032, 2165, 2075, 1996, 1373, 945, 2320, 2325, 1491, 2051, 1147, 1104, 259, 1347, 2094, 1109, 1638, 1713, 1815, 1831, 1531, 2349, 1014, 1727, 2143, 1586, 2068, 1802, 1230, 1372, 399, 1206, 1797, 78, 2448, 324, 617, 1895, 2249, 221, 2146, 1813, 306, 1138, 820, 952, 2293, 2018, 2388, 1421, 1758, 1393, 1868, 1454, 27, 1201, 860, 2316, 1838, 1175, 709, 733, 432, 2444, 2250, 1581, 423, 972, 2126, 1958, 2076, 1789, 2201, 754, 421, 248, 919, 1988, 181, 1611, 1589, 2308, 338, 1286, 389, 1688, 654, 98, 86, 1190, 1255, 1764, 2131, 322, 201, 112, 1820, 875, 615, 1102, 1575, 1180, 357, 926, 1940, 874, 2160, 1807, 1742, 1697, 10, 244, 1562, 738, 2181, 1418, 2413, 1432, 2059, 2300, 817, 2097, 2193, 2367, 1954, 559, 490, 807, 1107, 2127, 651, 1792, 2403, 539, 2064, 412, 1075, 1137, 981, 1861, 430, 2386, 756, 530, 1021, 1513, 2017, 1572, 679, 162, 179, 745, 2060, 496, 395, 2390, 1584, 437, 2354, 1588, 1806, 2171, 597, 1974, 1535, 1808, 354, 1979, 512, 1463, 500, 189, 156, 2080, 1471, 232, 855, 688, 1353, 2220, 1464, 1878, 1277, 700, 1031, 188, 683, 361, 1684, 1519, 1439, 1750, 1022, 2245, 458, 567, 632, 2373, 810, 321, 1328, 57, 1105, 1866, 235, 936, 2414, 333, 109, 1027, 1307, 328, 1045, 765, 941, 2223, 518, 2205, 213, 264, 1257, 273, 1046, 498, 2236, 846, 2281, 145, 1264, 1962, 1739, 692, 1467, 917, 1885, 1337, 787, 2089, 1208, 2048, 1613, 463, 2395, 1310, 2409, 909, 506, 54, 1006, 106, 1583, 96, 1926, 2037, 1984, 2410, 888, 975, 859, 599, 1677, 1781, 465, 1135, 2277, 1520, 1965, 99, 534, 474, 1461, 1679, 955, 326, 140, 1218, 1346, 1829, 638, 1579, 656, 1603, 196, 487, 100, 1074, 996, 1617, 2381, 266, 327, 584, 516, 583, 1166, 1041, 1161, 356, 2019, 246, 1450, 2234, 832, 1745, 1976, 1736, 2348, 1333, 187, 161, 927, 840, 806, 1227, 1332, 1614, 1258, 175, 1224, 1563, 589, 1770, 2272, 2185, 2278, 2350, 1751, 2009, 2178, 963, 2438, 2081, 2255, 427, 2063, 1601, 263, 895, 1690, 62, 1058, 2098, 1236, 833, 670, 1103, 319, 964, 320, 2457, 1169, 1985, 2307, 2475, 2119, 2385, 2372, 460, 890, 1848, 501, 1986, 29, 401, 1693, 1762, 1718, 11, 886, 226, 790, 1663, 666, 653, 1560, 2369, 93, 1856, 900, 896, 1675, 49, 444, 1707, 302, 1321, 796, 881, 1212, 1716, 76, 363, 576, 1662, 1644, 268, 1, 414, 1313, 1773, 2154, 1839, 668, 239, 1349, 2084, 1411, 778, 1755, 2015, 164, 1738, 1149, 1185, 260, 466, 603, 1228, 2141, 482, 1597, 1929, 214, 812, 2218, 594, 1405, 1007, 1238, 409, 1059, 869, 2133, 303, 309, 1304, 503, 1967, 242, 1610, 595, 1446, 1968, 1067, 616, 1536, 1744, 1592, 46, 591, 1362, 1018, 1951, 710, 122, 2032, 1241, 2322, 1459, 1220, 2087, 1725, 991, 1415, 1044, 133, 2010, 1275, 1505, 2113, 2412, 335, 74, 1987, 1462, 2304, 2058, 1472, 1146, 1400, 705, 2254, 387, 1920, 2055, 208, 2400, 1753, 2120, 2309, 792, 1826, 107, 1327, 346, 2195, 1404, 1324, 2313, 2227, 541, 2090, 990, 351, 1913, 2468, 1790, 1196, 729, 408, 1786, 272, 1821, 215, 2239, 1042, 1026, 1233, 1052, 2111, 108, 1708, 1873, 2144, 103, 1665, 1894, 1056, 628, 520, 747, 199, 971, 2114, 2122, 602, 994, 1009, 1040, 2454, 5, 1646, 59, 2179, 2061, 1081, 35, 1123, 1334, 1487, 1881, 1306, 1667, 1221, 1122, 744, 998, 1628, 633, 464, 1101, 678, 1473, 285, 564, 1580, 2102, 1514, 88, 1681, 2371, 883, 1283, 1394, 872, 393, 2028, 723, 2237, 1384, 1689, 1451, 1545, 1911, 548, 2299, 288, 773, 1350, 1256, 1456, 884, 737, 704, 2121, 2153, 1387, 1449, 1902, 557, 1126, 2392, 1062, 1743, 2284, 685, 2158, 2062, 1950, 279, 2462, 588, 1668, 549, 2408, 2256, 849, 89, 231, 345, 131, 978, 1711, 1717, 2437, 1999, 1167, 211, 640, 438, 1577, 2209, 2221, 300, 1144, 1273, 618, 2472, 980, 1632, 627, 957, 1735, 1184, 695, 2023, 1177, 2242, 1703, 1249, 2360, 2092, 822, 2138, 1756, 2072, 207, 217, 537, 317, 858, 1659, 280, 386, 1412, 899, 1860, 1634, 1025, 1503, 795, 332, 1072, 2232, 677, 2040, 492, 502, 1957, 1947, 1057, 642, 772, 362, 2022, 2110, 741, 1355, 566, 2182, 2453, 291, 481, 132, 183, 1480, 152, 580, 1680, 68, 1076, 578, 1896, 1172, 1060, 1223, 471, 1110, 61, 296, 2295, 2287, 418, 1568, 1365, 290, 1317, 1326, 2206, 1852, 2269, 1907, 2128, 935, 2258, 3, 550, 234, 2187, 1492, 789, 1433, 1493, 1534, 2190, 171, 1225, 141, 1927, 1542, 2271, 69, 410, 331, 1117, 650, 1971, 2274, 1849, 2241, 229, 323, 554, 1145, 1282, 1133, 1164, 2020, 2156, 2333, 33, 2389, 612, 178, 1825, 1890, 1402, 1262, 1819, 2172, 575, 1086, 2034, 2376, 712, 1740, 1549, 2415, 1590, 2170, 469, 1377, 1428, 15, 342, 918, 2336, 2470, 1796, 304, 1187, 365, 1804, 525, 1550, 2199, 2071, 1924, 780, 1481, 53, 1279, 1410, 824, 1189, 2079, 1964, 1316, 2203, 1173, 28, 249, 620, 1024, 887, 2093, 1886, 1191, 170, 1660, 1352, 1023, 1501, 480, 256, 177, 1213, 1477, 1576, 1080, 1448, 289, 786, 1836, 484, 2047, 195, 1921, 1430, 1079, 1648, 1234, 1695, 1981, 1570, 1540, 1683, 1030, 1594, 2204, 1300, 992, 105, 1914, 1475, 878, 1892, 1013, 2103, 118, 2013, 565, 1721, 779, 1470, 2251, 186, 64, 2135, 1211, 1846, 2247, 1066, 202, 2026, 494, 903, 2202, 1367, 1809, 690, 65, 1779, 1388, 605, 1994, 2217, 933, 1993, 1870, 1857, 163, 1498, 220, 2420, 2142, 1877, 1162, 529, 2219, 1440, 44, 2073, 898, 2246, 1486, 842, 592, 569, 1379, 938, 1368, 1369, 1626, 825, 1934, 1136, 1039, 1543, 973, 1559, 2036, 760, 1085, 1596, 515, 816, 940, 1645, 1111, 1817, 1521, 1036, 1116, 116, 514], [770, 2208, 2101, 56, 2451, 1599, 476, 2383, 2306, 1363, 1157, 1323, 629, 743, 169, 2011, 160, 1719, 831, 1712, 1933, 2229, 1606, 1511, 1760, 436, 60, 1582, 1100, 1858, 193, 1546, 1529, 441, 1608, 1973, 504, 1850, 1383, 153, 1910, 449, 276, 1029, 788, 748, 192, 1460, 120, 258, 446, 838, 2108, 574, 340, 119, 1778, 1198, 2461, 364, 2329, 740, 701, 1803, 1015, 1181, 596, 339, 558, 798, 1200, 570, 2168, 1746, 2289, 2157, 2382, 1488, 901, 1268, 658, 2393, 1547, 2248, 336, 2353, 461, 680, 2301, 34, 475, 1302, 2078, 146, 897, 1691, 1500, 821, 1489, 428, 2210, 2343, 643, 245, 2240, 1407, 1495, 717, 2434, 420, 2167, 337, 699, 1774, 2125, 2401, 2397, 1422, 2439, 631, 2442, 485, 2041, 1918, 749, 85, 243, 80, 742, 1182, 1931, 1267, 1508, 1278, 1600, 1499, 510, 1356, 1469, 606, 1118, 1338, 477, 149, 1360, 1458, 1301, 1647, 979, 1084, 1113, 546, 505, 2213, 2378, 845, 1094, 2443, 1830, 1943, 1732, 1419, 180, 1002, 1618, 911, 608, 1992, 167, 2335, 2334, 1571, 435, 1720, 1566, 1382, 19, 233, 2351, 1004, 1636, 1305, 2052, 2337, 2176, 1476, 1737, 455, 1805, 511, 1863, 1335, 1091, 158, 828, 799, 1845, 532, 1490, 489, 1389, 571, 1239, 2177, 2107, 547, 176, 1176, 396, 1254, 478, 535, 2184, 1607, 1055, 25, 1706, 1070, 1366, 659, 380, 1966, 684, 1168, 1625, 944, 540, 847, 1403, 2347, 431, 1295, 238, 1811, 785, 805, 1130, 871, 2283, 626, 1478, 1854, 1281, 1765, 442, 711, 1569])\n"
     ]
    }
   ],
   "source": [
    "#Split dataset\n",
    "random.seed = config.random_seed\n",
    "if config.valid_artifact:\n",
    "    X, y, splits  = combine_split_data(xs=[X_train, X_valid], ys=[X_train, X_valid])\n",
    "else:\n",
    "    X = X_train\n",
    "    y = X_train\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size)\n",
    "splits\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the model\n",
    "#features = pd.DataFrame(dls.dataset[0][0])\n",
    "#targets = pd.DataFrame(dls.dataset[0][1]) #1\n",
    "\n",
    "#print(\"dls len: \" + str(len(dls.dataset)))\n",
    "\n",
    "#print(\"Features shape: \" + str(features.shape))\n",
    "#print(\"Targets shape: \" + str(features.shape))\n",
    "\n",
    "#dls.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLags     = X_train.shape[0] #config.epochs\n",
    "nDimInput   = numLags\n",
    "nDimOutput  = 1 #targets.shape[1] #1\n",
    "numNeurons  = config.numHiddenNeurons #nDimInput  #config.numHiddenNeurons\n",
    "algorithm   = config.algorithm\n",
    "LN              = config.LN \n",
    "AE              = config.AE\n",
    "InWeightFF      = config.inputWeightForgettingFactor #1.0\n",
    "OutWeightFF     = config.outputWeightForgettingFactor #0.92\n",
    "HiddenWeightFF  = config.inputWeightForgettingFactor #1.0\n",
    "lamb            = config.lamb\n",
    "predictionStep  = config.stride #5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   Description          Value\n",
       "0               Dataset shape      (2500, 1)\n",
       "1   Number of Sliding windows           2476\n",
       "2        Sliding window shape        (1, 25)\n",
       "3      inputs/Charasteristics           2476\n",
       "4               Targets shape  (2476, 1, 25)\n",
       "5               X_train shape  (2476, 1, 25)\n",
       "6               Input Weights     (25, 2476)\n",
       "7              Hidden Weights       (25, 25)\n",
       "8                    Hidden A        (1, 25)\n",
       "9                        Bias        (1, 25)\n",
       "10                   Features      (1, 2476)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_to_append = {\n",
    "    \"Description\": [\n",
    "        \"inputs/Charasteristics\", \n",
    "        \"Targets shape\", \n",
    "        \"X_train shape\", \n",
    "        \"Input Weights\", \n",
    "        \"Hidden Weights\", \n",
    "        \"Hidden A\", \n",
    "        \"Bias\", \n",
    "        \"Features\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(nDimInput),\n",
    "        str(y.shape),\n",
    "        str(X_train.shape),\n",
    "        f\"({numNeurons}, {nDimInput})\",\n",
    "        f\"({numNeurons}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {nDimInput})\"\n",
    "    ]\n",
    "}\n",
    "data_to_append = pd.DataFrame(data_to_append)\n",
    "training_info = training_info.append(data_to_append, ignore_index = True)\n",
    "training_info.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with fastai Learner class, to abstract from Pytorch's training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To track the performance of this model fit, go to the project dashboard in Weights & Biases. The link is provided at the beginning of this notebook, after the execution of the function `wandb.init()'' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, log the learner to be used by the next notebook in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: 2476\n",
      "outputs: 1\n",
      "numNeurons: 25\n",
      "Out weight FF: 0.92\n",
      "Window size: 1\n",
      "(25, 2476)\n",
      "orelm-H ~  torch.Size([1, 25])\n",
      "-------- num_inputs, window_size = 2476,1\n",
      "Foselm -- before bias\n",
      "Foselm -- before beta\n",
      "input FOSELM model FOSELM_torch()\n",
      "input, output 2476 2476\n",
      "Foselm -- before bias\n",
      "Foselm -- before beta\n",
      "Output FOSELM model FOSELM_torch()\n",
      "input, output 25 25\n",
      "--> Initialize_Phase: Input Weights initialized. Shape: torch.Size([25, 2476])\n",
      "Foselm - initialize phase\n",
      "Foselm - initialize phase\n",
      "ORELM_torch(\n",
      "  (inputAE): FOSELM_torch()\n",
      "  (hiddenAE): FOSELM_torch()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = orelm.ORELM_torch(\n",
    "    inputs                      =   nDimInput,\n",
    "    outputs                     =   nDimOutput,\n",
    "    numHiddenNeurons            =   config.numHiddenNeurons,\n",
    "    activationFunction          =   config.activationFunction,\n",
    "    LN                          =   config.LN,\n",
    "    AE                          =   config.AE,\n",
    "    ORTH                        =   config.ORTH,\n",
    "    inputWeightForgettingFactor =   config.inputWeightForgettingFactor,\n",
    "    outputWeightForgettingFactor=   config.outputWeightForgettingFactor\n",
    ")\n",
    "m.initializePhase(lamb=0.0001)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (25, 2476)\n",
      "Target shape:  (25, 2476)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([X[w][0] for w in range(X_train.shape[0])]).T\n",
    "T = np.array([y[w][0] for w in range(X_train.shape[0])]).T   \n",
    "print('Input shape: ', str(X.shape))\n",
    "print('Target shape: ', str(T.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num steps: 23\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]-predictionStep-1\n",
    "print(\"Num steps: \" + str(maxStep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/macu/work/nbs_pipeline/02c_encoder_ORELM_before_learner.ipynb Celda 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_before_learner.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m] shape: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(training_dataset\u001b[39m.\u001b[39mshape))\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_before_learner.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTargets[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m] shape: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(targets\u001b[39m.\u001b[39mshape))\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_before_learner.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m m\u001b[39m.\u001b[39;49mtrain_func(training_dataset, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_before_learner.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m Y \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mforward(features)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM_before_learner.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m predictions\u001b[39m.\u001b[39mappend(Y[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/work/nbs/orelm/orelm_torch.py:243\u001b[0m, in \u001b[0;36mORELM_torch.train_func\u001b[0;34m(self, features, targets, RESETTING)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39massert\u001b[39;00m (features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m numSamples), \\\n\u001b[1;32m    241\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNumber of columns of features and weights differ\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfprint(\u001b[39m\"\u001b[39m\u001b[39m--> Calculate Hidden Activation 1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_flag)\n\u001b[0;32m--> 243\u001b[0m H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculateHiddenLayerActivation(features, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    244\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfprint(\u001b[39m\"\u001b[39m\u001b[39mCalculate Hidden Activation 1 -->\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_flag)\n\u001b[1;32m    245\u001b[0m Ht \u001b[39m=\u001b[39m H\u001b[39m.\u001b[39mt()\n",
      "File \u001b[0;32m~/work/nbs/orelm/orelm_torch.py:136\u001b[0m, in \u001b[0;36mORELM_torch.calculateHiddenLayerActivation\u001b[0;34m(self, features, flag_debug)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivationFunction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msig\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAE:\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputWeights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__calculateInputWeightsUsingAE(features)\n\u001b[1;32m    137\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFeatures ~ \u001b[39m\u001b[39m\"\u001b[39m, features\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    138\u001b[0m         num_samples \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/work/nbs/orelm/orelm_torch.py:117\u001b[0m, in \u001b[0;36mORELM_torch.__calculateInputWeightsUsingAE\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__calculateInputWeightsUsingAE\u001b[39m(\u001b[39mself\u001b[39m, features):\n\u001b[1;32m    116\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--> Input AE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputAE\u001b[39m.\u001b[39;49mtrain_func(features\u001b[39m=\u001b[39;49mfeatures,targets\u001b[39m=\u001b[39;49mfeatures)\n\u001b[1;32m    118\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInput AE -->\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputAE\u001b[39m.\u001b[39mbeta\n",
      "File \u001b[0;32m~/work/nbs/orelm/foselm_torch.py:184\u001b[0m, in \u001b[0;36mFOSELM_torch.train_func\u001b[0;34m(self, features, targets)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39m#if len(targets.shape) == 3:\u001b[39;00m\n\u001b[1;32m    181\u001b[0m  \u001b[39m# print(\"FOSELM:TRAIN:3SHAPED\")\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39massert\u001b[39;00m features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m targets\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \\\n\u001b[1;32m    183\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mFOS_ELM:train: differs number of samples features \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m targets \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(targets\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 184\u001b[0m \u001b[39massert\u001b[39;00m features\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m] \u001b[39m==\u001b[39m targets\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], \\\n\u001b[1;32m    185\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mFOS_ELM:train: differs number of steps features \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(features\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m targets \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(targets\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    187\u001b[0m (num_samples, num_outputs, num_steps) \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mshape\n\u001b[1;32m    188\u001b[0m (num_samples, num_inputs, num_steps) \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "output_file = open('bf_logs.txt', 'w')\n",
    "sys.stdout = output_file\n",
    "step = 0\n",
    "for i in range(maxStep):\n",
    "    training_dataset = X[[i],:]\n",
    "    targets = T[[i],:]\n",
    "    features = X[[i+1],:]\n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    m.train_func(training_dataset, targets)\n",
    "    Y = m.forward(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(T[i][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Calculate total Normalizedd Root Mean Square Error (NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct original value\n",
    "predictions = np.array(predictions)\n",
    "target = np.array(target)\n",
    "predictions = predictions * stdSeq + meanSeq\n",
    "target = target * stdSeq + meanSeq\n",
    "  \n",
    "def computeSquareDeviation(predictions, truth):\n",
    "  squareDeviation = np.square(predictions-truth)\n",
    "  return squareDeviation\n",
    "\n",
    "# Calculate NRMSE from skip_eval to the end\n",
    "skip_eval=100\n",
    "squareDeviation = computeSquareDeviation(predictions, target)\n",
    "squareDeviation[:skip_eval] = None\n",
    "nrmse = np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions)\n",
    "print(\"NRMSE {}\".format(nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target len: \" + str(len(target)) + str(target))\n",
    "print(\"Prediction len: \" + str(len(predictions))+str(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "algorithm = config.algorithm\n",
    "print(algorithm)\n",
    "print(config.job_type)\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "targetPlot,=plt.plot(target,label='target',color='red',marker='.',linestyle='-')\n",
    "predictedPlot,=plt.plot(predictions,label='predicted',color='blue',marker='.',linestyle=':')\n",
    "plt.xlim([0, 200])\n",
    "plt.ylim([60, 100])\n",
    "plt.ylabel('value',fontsize=15)\n",
    "plt.xlabel('time',fontsize=15)\n",
    "plt.ion()\n",
    "plt.grid()\n",
    "plt.legend(handles=[targetPlot, predictedPlot])\n",
    "plt.title('Time-series Prediction of '+ config.job_type + ' algorithm: ' + algorithm +' on '+dataSet.fname+' dataset' ,fontsize=20,fontweight=40)\n",
    "plot_path = './predictionPlot.png'\n",
    "#plt.savefig(plot_path,plot_pathbbox_inches='tight')\n",
    "plt.savefig(plot_path,bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.pause(0)\n",
    "print('Prediction plot is saved to'+plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = config.job_type\n",
    "plt.figure(figsize=(15,6))\n",
    "targetPlot,=plt.plot(target,label='target',color='red',marker='.',linestyle='-')\n",
    "predictedPlot,=plt.plot(predictions,label='predicted',color='blue',marker='.',linestyle=':')\n",
    "plt.xlim([8500,9000])\n",
    "plt.ylim([0, 30000])\n",
    "plt.ylabel('value',fontsize=15)\n",
    "plt.xlabel('time',fontsize=15)\n",
    "plt.ion()\n",
    "plt.grid()\n",
    "plt.legend(handles=[targetPlot, predictedPlot])\n",
    "plt.title('Time-series Prediction of '+algorithm+' on '+dataSet+' dataset',fontsize=20,fontweight=40)\n",
    "plot_path = './predictionPlot.png'\n",
    "#plt.savefig(plot_path,plot_pathbbox_inches='tight')\n",
    "plt.savefig(plot_path,bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.pause(0)\n",
    "print('Prediction plot is saved to'+plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning and prediction of OR-ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
