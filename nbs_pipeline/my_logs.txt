-->     1th/ 2299
Training[0] shape: torch.Size([1, 200])
Targets[0] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
1th/2299 (0) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.7358)
-->     2th/ 2299
Training[1] shape: torch.Size([1, 200])
Targets[1] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
2th/2299 (1) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.1124)
-->     3th/ 2299
Training[2] shape: torch.Size([1, 200])
Targets[2] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
3th/2299 (2) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1206)
-->     4th/ 2299
Training[3] shape: torch.Size([1, 200])
Targets[3] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
4th/2299 (3) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.8117)
-->     5th/ 2299
Training[4] shape: torch.Size([1, 200])
Targets[4] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
5th/2299 (4) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.6623)
-->     6th/ 2299
Training[5] shape: torch.Size([1, 200])
Targets[5] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
6th/2299 (5) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.5802)
-->     7th/ 2299
Training[6] shape: torch.Size([1, 200])
Targets[6] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
7th/2299 (6) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(-0.2142)
-->     8th/ 2299
Training[7] shape: torch.Size([1, 200])
Targets[7] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
8th/2299 (7) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.3388)
-->     9th/ 2299
Training[8] shape: torch.Size([1, 200])
Targets[8] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
9th/2299 (8) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(0.3490)
-->    10th/ 2299
Training[9] shape: torch.Size([1, 200])
Targets[9] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
10th/2299 (9) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2300)
-->    11th/ 2299
Training[10] shape: torch.Size([1, 200])
Targets[10] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
11th/2299 (10) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.7145)
-->    12th/ 2299
Training[11] shape: torch.Size([1, 200])
Targets[11] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
12th/2299 (11) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.5705)
-->    13th/ 2299
Training[12] shape: torch.Size([1, 200])
Targets[12] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
13th/2299 (12) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(0.2409)
-->    14th/ 2299
Training[13] shape: torch.Size([1, 200])
Targets[13] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
14th/2299 (13) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.6099)
-->    15th/ 2299
Training[14] shape: torch.Size([1, 200])
Targets[14] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
15th/2299 (14) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.0149)
-->    16th/ 2299
Training[15] shape: torch.Size([1, 200])
Targets[15] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
16th/2299 (15) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.6862)
-->    17th/ 2299
Training[16] shape: torch.Size([1, 200])
Targets[16] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
17th/2299 (16) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.0737)
-->    18th/ 2299
Training[17] shape: torch.Size([1, 200])
Targets[17] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
18th/2299 (17) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.1088)
-->    19th/ 2299
Training[18] shape: torch.Size([1, 200])
Targets[18] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
19th/2299 (18) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.4842)
-->    20th/ 2299
Training[19] shape: torch.Size([1, 200])
Targets[19] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
20th/2299 (19) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0910)
-->    21th/ 2299
Training[20] shape: torch.Size([1, 200])
Targets[20] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
21th/2299 (20) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.2672)
-->    22th/ 2299
Training[21] shape: torch.Size([1, 200])
Targets[21] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
22th/2299 (21) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.1021)
-->    23th/ 2299
Training[22] shape: torch.Size([1, 200])
Targets[22] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
23th/2299 (22) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-1.0029)
-->    24th/ 2299
Training[23] shape: torch.Size([1, 200])
Targets[23] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
24th/2299 (23) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.0760)
-->    25th/ 2299
Training[24] shape: torch.Size([1, 200])
Targets[24] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
25th/2299 (24) timeStep of 2299 -  target: -2.8481656886435913 |    prediction: tensor(-1.9971)
-->    26th/ 2299
Training[25] shape: torch.Size([1, 200])
Targets[25] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
26th/2299 (25) timeStep of 2299 -  target: -4.44910678268258 |    prediction: tensor(-3.4991)
-->    27th/ 2299
Training[26] shape: torch.Size([1, 200])
Targets[26] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
27th/2299 (26) timeStep of 2299 -  target: -3.991695041528583 |    prediction: tensor(-2.9753)
-->    28th/ 2299
Training[27] shape: torch.Size([1, 200])
Targets[27] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
28th/2299 (27) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-2.7943)
-->    29th/ 2299
Training[28] shape: torch.Size([1, 200])
Targets[28] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
29th/2299 (28) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.1512)
-->    30th/ 2299
Training[29] shape: torch.Size([1, 200])
Targets[29] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
30th/2299 (29) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.2506)
-->    31th/ 2299
Training[30] shape: torch.Size([1, 200])
Targets[30] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
31th/2299 (30) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.6331)
-->    32th/ 2299
Training[31] shape: torch.Size([1, 200])
Targets[31] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
32th/2299 (31) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.1831)
-->    33th/ 2299
Training[32] shape: torch.Size([1, 200])
Targets[32] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
33th/2299 (32) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.9015)
-->    34th/ 2299
Training[33] shape: torch.Size([1, 200])
Targets[33] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
34th/2299 (33) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.1330)
-->    35th/ 2299
Training[34] shape: torch.Size([1, 200])
Targets[34] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
35th/2299 (34) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-0.5053)
-->    36th/ 2299
Training[35] shape: torch.Size([1, 200])
Targets[35] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
36th/2299 (35) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.8780)
-->    37th/ 2299
Training[36] shape: torch.Size([1, 200])
Targets[36] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
37th/2299 (36) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.2932)
-->    38th/ 2299
Training[37] shape: torch.Size([1, 200])
Targets[37] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
38th/2299 (37) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.9629)
-->    39th/ 2299
Training[38] shape: torch.Size([1, 200])
Targets[38] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
39th/2299 (38) timeStep of 2299 -  target: -3.191224494509089 |    prediction: tensor(-1.6728)
-->    40th/ 2299
Training[39] shape: torch.Size([1, 200])
Targets[39] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
40th/2299 (39) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.7686)
-->    41th/ 2299
Training[40] shape: torch.Size([1, 200])
Targets[40] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
41th/2299 (40) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.8983)
-->    42th/ 2299
Training[41] shape: torch.Size([1, 200])
Targets[41] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
42th/2299 (41) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.6511)
-->    43th/ 2299
Training[42] shape: torch.Size([1, 200])
Targets[42] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
43th/2299 (42) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-0.0138)
-->    44th/ 2299
Training[43] shape: torch.Size([1, 200])
Targets[43] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
44th/2299 (43) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-0.6716)
-->    45th/ 2299
Training[44] shape: torch.Size([1, 200])
Targets[44] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
45th/2299 (44) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.9429)
-->    46th/ 2299
Training[45] shape: torch.Size([1, 200])
Targets[45] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
46th/2299 (45) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(1.0367)
-->    47th/ 2299
Training[46] shape: torch.Size([1, 200])
Targets[46] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
47th/2299 (46) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.2738)
-->    48th/ 2299
Training[47] shape: torch.Size([1, 200])
Targets[47] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
48th/2299 (47) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.4833)
-->    49th/ 2299
Training[48] shape: torch.Size([1, 200])
Targets[48] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
49th/2299 (48) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.7218)
-->    50th/ 2299
Training[49] shape: torch.Size([1, 200])
Targets[49] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
50th/2299 (49) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(1.0010)
-->    51th/ 2299
Training[50] shape: torch.Size([1, 200])
Targets[50] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
51th/2299 (50) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.4293)
-->    52th/ 2299
Training[51] shape: torch.Size([1, 200])
Targets[51] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
52th/2299 (51) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(1.0152)
-->    53th/ 2299
Training[52] shape: torch.Size([1, 200])
Targets[52] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
53th/2299 (52) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.2081)
-->    54th/ 2299
Training[53] shape: torch.Size([1, 200])
Targets[53] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
54th/2299 (53) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.3371)
-->    55th/ 2299
Training[54] shape: torch.Size([1, 200])
Targets[54] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
55th/2299 (54) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.0444)
-->    56th/ 2299
Training[55] shape: torch.Size([1, 200])
Targets[55] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
56th/2299 (55) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.1127)
-->    57th/ 2299
Training[56] shape: torch.Size([1, 200])
Targets[56] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
57th/2299 (56) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.1570)
-->    58th/ 2299
Training[57] shape: torch.Size([1, 200])
Targets[57] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
58th/2299 (57) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.3999)
-->    59th/ 2299
Training[58] shape: torch.Size([1, 200])
Targets[58] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
59th/2299 (58) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.3732)
-->    60th/ 2299
Training[59] shape: torch.Size([1, 200])
Targets[59] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
60th/2299 (59) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.1357)
-->    61th/ 2299
Training[60] shape: torch.Size([1, 200])
Targets[60] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
61th/2299 (60) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(1.3538)
-->    62th/ 2299
Training[61] shape: torch.Size([1, 200])
Targets[61] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
62th/2299 (61) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(0.0509)
-->    63th/ 2299
Training[62] shape: torch.Size([1, 200])
Targets[62] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
63th/2299 (62) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(-0.9998)
-->    64th/ 2299
Training[63] shape: torch.Size([1, 200])
Targets[63] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
64th/2299 (63) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-1.5981)
-->    65th/ 2299
Training[64] shape: torch.Size([1, 200])
Targets[64] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
65th/2299 (64) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(-0.3063)
-->    66th/ 2299
Training[65] shape: torch.Size([1, 200])
Targets[65] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
66th/2299 (65) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(-0.7640)
-->    67th/ 2299
Training[66] shape: torch.Size([1, 200])
Targets[66] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
67th/2299 (66) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2439)
-->    68th/ 2299
Training[67] shape: torch.Size([1, 200])
Targets[67] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
68th/2299 (67) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.6474)
-->    69th/ 2299
Training[68] shape: torch.Size([1, 200])
Targets[68] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
69th/2299 (68) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(0.2702)
-->    70th/ 2299
Training[69] shape: torch.Size([1, 200])
Targets[69] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
70th/2299 (69) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.2424)
-->    71th/ 2299
Training[70] shape: torch.Size([1, 200])
Targets[70] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
71th/2299 (70) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.4369)
-->    72th/ 2299
Training[71] shape: torch.Size([1, 200])
Targets[71] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
72th/2299 (71) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.1901)
-->    73th/ 2299
Training[72] shape: torch.Size([1, 200])
Targets[72] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
73th/2299 (72) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.1866)
-->    74th/ 2299
Training[73] shape: torch.Size([1, 200])
Targets[73] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
74th/2299 (73) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.4210)
-->    75th/ 2299
Training[74] shape: torch.Size([1, 200])
Targets[74] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
75th/2299 (74) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(1.4026)
-->    76th/ 2299
Training[75] shape: torch.Size([1, 200])
Targets[75] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
76th/2299 (75) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.9413)
-->    77th/ 2299
Training[76] shape: torch.Size([1, 200])
Targets[76] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
77th/2299 (76) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(1.2676)
-->    78th/ 2299
Training[77] shape: torch.Size([1, 200])
Targets[77] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
78th/2299 (77) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.4977)
-->    79th/ 2299
Training[78] shape: torch.Size([1, 200])
Targets[78] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
79th/2299 (78) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(0.1893)
-->    80th/ 2299
Training[79] shape: torch.Size([1, 200])
Targets[79] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
80th/2299 (79) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.4361)
-->    81th/ 2299
Training[80] shape: torch.Size([1, 200])
Targets[80] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
81th/2299 (80) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.3541)
-->    82th/ 2299
Training[81] shape: torch.Size([1, 200])
Targets[81] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
82th/2299 (81) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.7431)
-->    83th/ 2299
Training[82] shape: torch.Size([1, 200])
Targets[82] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
83th/2299 (82) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.2470)
-->    84th/ 2299
Training[83] shape: torch.Size([1, 200])
Targets[83] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
84th/2299 (83) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.0019)
-->    85th/ 2299
Training[84] shape: torch.Size([1, 200])
Targets[84] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
85th/2299 (84) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.3189)
-->    86th/ 2299
Training[85] shape: torch.Size([1, 200])
Targets[85] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
86th/2299 (85) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.6525)
-->    87th/ 2299
Training[86] shape: torch.Size([1, 200])
Targets[86] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
87th/2299 (86) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.0425)
-->    88th/ 2299
Training[87] shape: torch.Size([1, 200])
Targets[87] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
88th/2299 (87) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.9477)
-->    89th/ 2299
Training[88] shape: torch.Size([1, 200])
Targets[88] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
89th/2299 (88) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.6334)
-->    90th/ 2299
Training[89] shape: torch.Size([1, 200])
Targets[89] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
90th/2299 (89) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.4381)
-->    91th/ 2299
Training[90] shape: torch.Size([1, 200])
Targets[90] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
91th/2299 (90) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.2818)
-->    92th/ 2299
Training[91] shape: torch.Size([1, 200])
Targets[91] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
92th/2299 (91) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.5129)
-->    93th/ 2299
Training[92] shape: torch.Size([1, 200])
Targets[92] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
93th/2299 (92) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.2348)
-->    94th/ 2299
Training[93] shape: torch.Size([1, 200])
Targets[93] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
94th/2299 (93) timeStep of 2299 -  target: 2.0690105287618725 |    prediction: tensor(0.7706)
-->    95th/ 2299
Training[94] shape: torch.Size([1, 200])
Targets[94] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
95th/2299 (94) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.9702)
-->    96th/ 2299
Training[95] shape: torch.Size([1, 200])
Targets[95] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
96th/2299 (95) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.5159)
-->    97th/ 2299
Training[96] shape: torch.Size([1, 200])
Targets[96] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
97th/2299 (96) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.8594)
-->    98th/ 2299
Training[97] shape: torch.Size([1, 200])
Targets[97] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
98th/2299 (97) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(-0.8365)
-->    99th/ 2299
Training[98] shape: torch.Size([1, 200])
Targets[98] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
99th/2299 (98) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.3300)
-->   100th/ 2299
Training[99] shape: torch.Size([1, 200])
Targets[99] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
100th/2299 (99) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.5621)
-->   101th/ 2299
Training[100] shape: torch.Size([1, 200])
Targets[100] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
101th/2299 (100) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.1870)
-->   102th/ 2299
Training[101] shape: torch.Size([1, 200])
Targets[101] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
102th/2299 (101) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.0193)
-->   103th/ 2299
Training[102] shape: torch.Size([1, 200])
Targets[102] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
103th/2299 (102) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-1.2878)
-->   104th/ 2299
Training[103] shape: torch.Size([1, 200])
Targets[103] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
104th/2299 (103) timeStep of 2299 -  target: -2.7338127533550924 |    prediction: tensor(-2.3993)
-->   105th/ 2299
Training[104] shape: torch.Size([1, 200])
Targets[104] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
105th/2299 (104) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-1.4528)
-->   106th/ 2299
Training[105] shape: torch.Size([1, 200])
Targets[105] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
106th/2299 (105) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.5791)
-->   107th/ 2299
Training[106] shape: torch.Size([1, 200])
Targets[106] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
107th/2299 (106) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-1.0770)
-->   108th/ 2299
Training[107] shape: torch.Size([1, 200])
Targets[107] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
108th/2299 (107) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-1.7298)
-->   109th/ 2299
Training[108] shape: torch.Size([1, 200])
Targets[108] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
109th/2299 (108) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.6001)
-->   110th/ 2299
Training[109] shape: torch.Size([1, 200])
Targets[109] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
110th/2299 (109) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.5335)
-->   111th/ 2299
Training[110] shape: torch.Size([1, 200])
Targets[110] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
111th/2299 (110) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.1819)
-->   112th/ 2299
Training[111] shape: torch.Size([1, 200])
Targets[111] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
112th/2299 (111) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.9136)
-->   113th/ 2299
Training[112] shape: torch.Size([1, 200])
Targets[112] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
113th/2299 (112) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.5358)
-->   114th/ 2299
Training[113] shape: torch.Size([1, 200])
Targets[113] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
114th/2299 (113) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.6665)
-->   115th/ 2299
Training[114] shape: torch.Size([1, 200])
Targets[114] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
115th/2299 (114) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(0.5759)
-->   116th/ 2299
Training[115] shape: torch.Size([1, 200])
Targets[115] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
116th/2299 (115) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.4778)
-->   117th/ 2299
Training[116] shape: torch.Size([1, 200])
Targets[116] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
117th/2299 (116) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(-0.5425)
-->   118th/ 2299
Training[117] shape: torch.Size([1, 200])
Targets[117] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
118th/2299 (117) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.5618)
-->   119th/ 2299
Training[118] shape: torch.Size([1, 200])
Targets[118] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
119th/2299 (118) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-1.7528)
-->   120th/ 2299
Training[119] shape: torch.Size([1, 200])
Targets[119] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
120th/2299 (119) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.5805)
-->   121th/ 2299
Training[120] shape: torch.Size([1, 200])
Targets[120] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
121th/2299 (120) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.0969)
-->   122th/ 2299
Training[121] shape: torch.Size([1, 200])
Targets[121] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
122th/2299 (121) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.5083)
-->   123th/ 2299
Training[122] shape: torch.Size([1, 200])
Targets[122] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
123th/2299 (122) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.8734)
-->   124th/ 2299
Training[123] shape: torch.Size([1, 200])
Targets[123] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
124th/2299 (123) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.6616)
-->   125th/ 2299
Training[124] shape: torch.Size([1, 200])
Targets[124] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
125th/2299 (124) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.6438)
-->   126th/ 2299
Training[125] shape: torch.Size([1, 200])
Targets[125] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
126th/2299 (125) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.1731)
-->   127th/ 2299
Training[126] shape: torch.Size([1, 200])
Targets[126] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
127th/2299 (126) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.0203)
-->   128th/ 2299
Training[127] shape: torch.Size([1, 200])
Targets[127] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
128th/2299 (127) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.3305)
-->   129th/ 2299
Training[128] shape: torch.Size([1, 200])
Targets[128] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
129th/2299 (128) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.8829)
-->   130th/ 2299
Training[129] shape: torch.Size([1, 200])
Targets[129] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
130th/2299 (129) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.9568)
-->   131th/ 2299
Training[130] shape: torch.Size([1, 200])
Targets[130] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
131th/2299 (130) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.4008)
-->   132th/ 2299
Training[131] shape: torch.Size([1, 200])
Targets[131] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
132th/2299 (131) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(-0.6162)
-->   133th/ 2299
Training[132] shape: torch.Size([1, 200])
Targets[132] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
133th/2299 (132) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.5598)
-->   134th/ 2299
Training[133] shape: torch.Size([1, 200])
Targets[133] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
134th/2299 (133) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.4065)
-->   135th/ 2299
Training[134] shape: torch.Size([1, 200])
Targets[134] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
135th/2299 (134) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.3558)
-->   136th/ 2299
Training[135] shape: torch.Size([1, 200])
Targets[135] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
136th/2299 (135) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(1.4225)
-->   137th/ 2299
Training[136] shape: torch.Size([1, 200])
Targets[136] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
137th/2299 (136) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(-0.4853)
-->   138th/ 2299
Training[137] shape: torch.Size([1, 200])
Targets[137] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
138th/2299 (137) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-1.2148)
-->   139th/ 2299
Training[138] shape: torch.Size([1, 200])
Targets[138] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
139th/2299 (138) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.8152)
-->   140th/ 2299
Training[139] shape: torch.Size([1, 200])
Targets[139] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
140th/2299 (139) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.9126)
-->   141th/ 2299
Training[140] shape: torch.Size([1, 200])
Targets[140] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
141th/2299 (140) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.7454)
-->   142th/ 2299
Training[141] shape: torch.Size([1, 200])
Targets[141] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
142th/2299 (141) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(-0.6437)
-->   143th/ 2299
Training[142] shape: torch.Size([1, 200])
Targets[142] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
143th/2299 (142) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.3937)
-->   144th/ 2299
Training[143] shape: torch.Size([1, 200])
Targets[143] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
144th/2299 (143) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0180)
-->   145th/ 2299
Training[144] shape: torch.Size([1, 200])
Targets[144] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
145th/2299 (144) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.7494)
-->   146th/ 2299
Training[145] shape: torch.Size([1, 200])
Targets[145] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
146th/2299 (145) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.0319)
-->   147th/ 2299
Training[146] shape: torch.Size([1, 200])
Targets[146] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
147th/2299 (146) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-1.5293)
-->   148th/ 2299
Training[147] shape: torch.Size([1, 200])
Targets[147] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
148th/2299 (147) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(-0.0818)
-->   149th/ 2299
Training[148] shape: torch.Size([1, 200])
Targets[148] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
149th/2299 (148) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.5626)
-->   150th/ 2299
Training[149] shape: torch.Size([1, 200])
Targets[149] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
150th/2299 (149) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(0.6068)
-->   151th/ 2299
Training[150] shape: torch.Size([1, 200])
Targets[150] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
151th/2299 (150) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.1928)
-->   152th/ 2299
Training[151] shape: torch.Size([1, 200])
Targets[151] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
152th/2299 (151) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.0131)
-->   153th/ 2299
Training[152] shape: torch.Size([1, 200])
Targets[152] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
153th/2299 (152) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.5534)
-->   154th/ 2299
Training[153] shape: torch.Size([1, 200])
Targets[153] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
154th/2299 (153) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.5672)
-->   155th/ 2299
Training[154] shape: torch.Size([1, 200])
Targets[154] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
155th/2299 (154) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.8926)
-->   156th/ 2299
Training[155] shape: torch.Size([1, 200])
Targets[155] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
156th/2299 (155) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.0150)
-->   157th/ 2299
Training[156] shape: torch.Size([1, 200])
Targets[156] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
157th/2299 (156) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.4756)
-->   158th/ 2299
Training[157] shape: torch.Size([1, 200])
Targets[157] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
158th/2299 (157) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.4709)
-->   159th/ 2299
Training[158] shape: torch.Size([1, 200])
Targets[158] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
159th/2299 (158) timeStep of 2299 -  target: -1.933342206335598 |    prediction: tensor(-1.1116)
-->   160th/ 2299
Training[159] shape: torch.Size([1, 200])
Targets[159] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
160th/2299 (159) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.1017)
-->   161th/ 2299
Training[160] shape: torch.Size([1, 200])
Targets[160] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
161th/2299 (160) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.3140)
-->   162th/ 2299
Training[161] shape: torch.Size([1, 200])
Targets[161] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
162th/2299 (161) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(1.3232)
-->   163th/ 2299
Training[162] shape: torch.Size([1, 200])
Targets[162] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
163th/2299 (162) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(0.2466)
-->   164th/ 2299
Training[163] shape: torch.Size([1, 200])
Targets[163] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
164th/2299 (163) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.0343)
-->   165th/ 2299
Training[164] shape: torch.Size([1, 200])
Targets[164] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
165th/2299 (164) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.5182)
-->   166th/ 2299
Training[165] shape: torch.Size([1, 200])
Targets[165] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
166th/2299 (165) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.1393)
-->   167th/ 2299
Training[166] shape: torch.Size([1, 200])
Targets[166] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
167th/2299 (166) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.0280)
-->   168th/ 2299
Training[167] shape: torch.Size([1, 200])
Targets[167] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
168th/2299 (167) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.0753)
-->   169th/ 2299
Training[168] shape: torch.Size([1, 200])
Targets[168] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
169th/2299 (168) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.4524)
-->   170th/ 2299
Training[169] shape: torch.Size([1, 200])
Targets[169] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
170th/2299 (169) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.4697)
-->   171th/ 2299
Training[170] shape: torch.Size([1, 200])
Targets[170] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
171th/2299 (170) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.6769)
-->   172th/ 2299
Training[171] shape: torch.Size([1, 200])
Targets[171] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
172th/2299 (171) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.4107)
-->   173th/ 2299
Training[172] shape: torch.Size([1, 200])
Targets[172] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
173th/2299 (172) timeStep of 2299 -  target: -2.0476951416240974 |    prediction: tensor(-0.2339)
-->   174th/ 2299
Training[173] shape: torch.Size([1, 200])
Targets[173] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
174th/2299 (173) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.5732)
-->   175th/ 2299
Training[174] shape: torch.Size([1, 200])
Targets[174] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
175th/2299 (174) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-1.4490)
-->   176th/ 2299
Training[175] shape: torch.Size([1, 200])
Targets[175] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
176th/2299 (175) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-1.2764)
-->   177th/ 2299
Training[176] shape: torch.Size([1, 200])
Targets[176] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
177th/2299 (176) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-1.1663)
-->   178th/ 2299
Training[177] shape: torch.Size([1, 200])
Targets[177] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
178th/2299 (177) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.3988)
-->   179th/ 2299
Training[178] shape: torch.Size([1, 200])
Targets[178] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
179th/2299 (178) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.9395)
-->   180th/ 2299
Training[179] shape: torch.Size([1, 200])
Targets[179] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
180th/2299 (179) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.1973)
-->   181th/ 2299
Training[180] shape: torch.Size([1, 200])
Targets[180] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
181th/2299 (180) timeStep of 2299 -  target: 1.4972458523193768 |    prediction: tensor(1.9827)
-->   182th/ 2299
Training[181] shape: torch.Size([1, 200])
Targets[181] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
182th/2299 (181) timeStep of 2299 -  target: 1.8403046581848743 |    prediction: tensor(1.9840)
-->   183th/ 2299
Training[182] shape: torch.Size([1, 200])
Targets[182] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
183th/2299 (182) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-0.1967)
-->   184th/ 2299
Training[183] shape: torch.Size([1, 200])
Targets[183] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
184th/2299 (183) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.2399)
-->   185th/ 2299
Training[184] shape: torch.Size([1, 200])
Targets[184] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
185th/2299 (184) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-0.7086)
-->   186th/ 2299
Training[185] shape: torch.Size([1, 200])
Targets[185] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
186th/2299 (185) timeStep of 2299 -  target: -2.619459818066593 |    prediction: tensor(-0.5657)
-->   187th/ 2299
Training[186] shape: torch.Size([1, 200])
Targets[186] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
187th/2299 (186) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.1606)
-->   188th/ 2299
Training[187] shape: torch.Size([1, 200])
Targets[187] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
188th/2299 (187) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(-0.3744)
-->   189th/ 2299
Training[188] shape: torch.Size([1, 200])
Targets[188] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
189th/2299 (188) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.6933)
-->   190th/ 2299
Training[189] shape: torch.Size([1, 200])
Targets[189] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
190th/2299 (189) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.2403)
-->   191th/ 2299
Training[190] shape: torch.Size([1, 200])
Targets[190] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
191th/2299 (190) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(2.0696)
-->   192th/ 2299
Training[191] shape: torch.Size([1, 200])
Targets[191] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
192th/2299 (191) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(-0.0924)
-->   193th/ 2299
Training[192] shape: torch.Size([1, 200])
Targets[192] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
193th/2299 (192) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.2568)
-->   194th/ 2299
Training[193] shape: torch.Size([1, 200])
Targets[193] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
194th/2299 (193) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.1205)
-->   195th/ 2299
Training[194] shape: torch.Size([1, 200])
Targets[194] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
195th/2299 (194) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1518)
-->   196th/ 2299
Training[195] shape: torch.Size([1, 200])
Targets[195] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
196th/2299 (195) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.5188)
-->   197th/ 2299
Training[196] shape: torch.Size([1, 200])
Targets[196] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
197th/2299 (196) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.3045)
-->   198th/ 2299
Training[197] shape: torch.Size([1, 200])
Targets[197] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
198th/2299 (197) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.2340)
-->   199th/ 2299
Training[198] shape: torch.Size([1, 200])
Targets[198] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
199th/2299 (198) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(0.3880)
-->   200th/ 2299
Training[199] shape: torch.Size([1, 200])
Targets[199] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
200th/2299 (199) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(1.6319)
-->   201th/ 2299
Current: /home/macu/work/nbs_pipeline
yml: ./config/02c-encoder_orelm.yaml
... About to replace includes with content
Before configuration reading 
-include: None
-user_preferences:
	-use_wandb: False
	-wdb:
		-user: mi-santamaria
		-project_name: test-project
		-version: 0
		-mode: offline
		-artifacts_path: ./data/wandb_artifacts
	-data:
		-folder: ~/data/
		-fname: speed_6005
		-ftype: .csv
		-cols: [1]
		-freq: 1s
	-artifact:
		-alias: TiltABP
	-directories:
		-tmp: tmp
		-data: ~/data/speed_6005.csv
-data:
	-name: speed_6005
	-path: ~/data/speed_6005.csv
	-alias: TiltABP
	-cols: [1]
	-csv_config:
	-date_offset: None
	-date_format: %Y-%m-%d %H:%M:%S
	-freq: 1s
	-joining_train_test: False
	-missing_values:
		-technique: None
		-constant: None
	-normalize_training: False
	-range_training: None
	-range_testing: None
	-resampling_freq: None
	-start_date: None
	-test_split: None
	-time_col: None
-wandb:
	-user: mi-santamaria
	-dir: ~/test-project
	-enabled: False
	-group: None
	-log_learner: False
	-mode: offline
	-project: test-project
	-version: 0
	-artifacts_path: ./data/wandb_artifacts
-configuration:
	-job_type: encoder_ORELM
	-alias: TiltABP
	-wandb:
		-use: False
		-entity: mi-santamaria
		-group: None
		-project: test-project
	-artifacts:
		-train: mi-santamaria/test-project/speed_6005:v0
		-valid:
			-data: None
			-size: 0.1
	-specifications:
		-algorithm: OSELM
		-n_epoch: 200
		-random_seed: 6
		-numHiddenNeurons: 25
		-activationFunction: sig
		-LN: True
		-AE: True
		-ORTH: True
		-lamb: 0.0001
		-weight_forgetting_factors:
			-input: 1
			-output: 0.92
		-sliding_windows:
			-stride: 1
			-size: 200
After reading config
-job_type: encoder_ORELM
-alias: TiltABP
-wandb:
	-use: False
	-entity: mi-santamaria
	-group: None
	-project: test-project
-artifacts:
	-train: mi-santamaria/test-project/speed_6005:v0
	-valid:
		-data: None
		-size: 0.1
-specifications:
	-algorithm: OSELM
	-n_epoch: 200
	-random_seed: 6
	-numHiddenNeurons: 25
	-activationFunction: sig
	-LN: True
	-AE: True
	-ORTH: True
	-lamb: 0.0001
	-weight_forgetting_factors:
		-input: 1
		-output: 0.92
	-sliding_windows:
		-stride: 1
		-size: 200
Project: test-project
Used dataSet:
-folder: ~/data/
-fname: speed_6005
-ftype: .csv
-cols: [1]
-freq: 1s
--- SLIDING WINDOW --
Len: 200
Stride: 1
Num. variables: 1
81.9068
8.744856417346142
No validation artifact. Random items to get: 0.1
X.shape: (2301, 1, 200)
y.shape: (2301, 1, 200)
inputs: 200
outputs: 1
numNeurons: 25
Out weight FF: 0.92
(25, 200)
Foselm -- before bias
Foselm -- before beta
Foselm -- before bias
Foselm -- before beta
--> Initialize_Phase: Input Weights initialized. Shape: torch.Size([25, 200])
Foselm - initialize phase
Foselm - initialize phase
ORELM_torch(
  (inputAE): FOSELM_torch()
  (hiddenAE): FOSELM_torch()
)
X_train shape[0]: 2301
X.shape: (2301, 1, 200)
y.shape: (2301, 1, 200)
dls.shape: (2301, 1, 200)
Last dls.shape: (1, 200)
32
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
El 1. torch.Size([64, 1, 200])
Initialize loss function
<class 'tsai.data.core.TSDataLoaders'>
<class 'nbs.orelm.orelm_torch.ORELM_torch'>
ORELM_torch(
  (inputAE): FOSELM_torch()
  (hiddenAE): FOSELM_torch()
)
Input shape:  (2301, 200)
Target shape:  (200, 2301)
Num steps: 2299
-->     1th/ 2299
Training[0] shape: torch.Size([1, 200])
Targets[0] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
1th/2299 (0) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.7060)
-->     2th/ 2299
Training[1] shape: torch.Size([1, 200])
Targets[1] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
2th/2299 (1) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.1894)
-->     3th/ 2299
Training[2] shape: torch.Size([1, 200])
Targets[2] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
3th/2299 (2) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1348)
-->     4th/ 2299
Training[3] shape: torch.Size([1, 200])
Targets[3] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
4th/2299 (3) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.6819)
-->     5th/ 2299
Training[4] shape: torch.Size([1, 200])
Targets[4] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
5th/2299 (4) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.7106)
-->     6th/ 2299
Training[5] shape: torch.Size([1, 200])
Targets[5] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
6th/2299 (5) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.5677)
-->     7th/ 2299
Training[6] shape: torch.Size([1, 200])
Targets[6] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
7th/2299 (6) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(-0.2687)
-->     8th/ 2299
Training[7] shape: torch.Size([1, 200])
Targets[7] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
8th/2299 (7) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.4102)
-->     9th/ 2299
Training[8] shape: torch.Size([1, 200])
Targets[8] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
9th/2299 (8) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(0.3829)
-->    10th/ 2299
Training[9] shape: torch.Size([1, 200])
Targets[9] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
10th/2299 (9) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2269)
-->    11th/ 2299
Training[10] shape: torch.Size([1, 200])
Targets[10] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
11th/2299 (10) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.4652)
-->    12th/ 2299
Training[11] shape: torch.Size([1, 200])
Targets[11] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
12th/2299 (11) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.6171)
-->    13th/ 2299
Training[12] shape: torch.Size([1, 200])
Targets[12] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
13th/2299 (12) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.4592)
-->    14th/ 2299
Training[13] shape: torch.Size([1, 200])
Targets[13] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
14th/2299 (13) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.4358)
-->    15th/ 2299
Training[14] shape: torch.Size([1, 200])
Targets[14] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
15th/2299 (14) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.1083)
-->    16th/ 2299
Training[15] shape: torch.Size([1, 200])
Targets[15] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
16th/2299 (15) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.5699)
-->    17th/ 2299
Training[16] shape: torch.Size([1, 200])
Targets[16] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
17th/2299 (16) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.2806)
-->    18th/ 2299
Training[17] shape: torch.Size([1, 200])
Targets[17] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
18th/2299 (17) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.0946)
-->    19th/ 2299
Training[18] shape: torch.Size([1, 200])
Targets[18] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
19th/2299 (18) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.0620)
-->    20th/ 2299
Training[19] shape: torch.Size([1, 200])
Targets[19] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
20th/2299 (19) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0647)
-->    21th/ 2299
Training[20] shape: torch.Size([1, 200])
Targets[20] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
21th/2299 (20) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.2179)
-->    22th/ 2299
Training[21] shape: torch.Size([1, 200])
Targets[21] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
22th/2299 (21) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.6290)
-->    23th/ 2299
Training[22] shape: torch.Size([1, 200])
Targets[22] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
23th/2299 (22) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.2918)
-->    24th/ 2299
Training[23] shape: torch.Size([1, 200])
Targets[23] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
24th/2299 (23) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(0.0149)
-->    25th/ 2299
Training[24] shape: torch.Size([1, 200])
Targets[24] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
25th/2299 (24) timeStep of 2299 -  target: -2.8481656886435913 |    prediction: tensor(-0.8841)
-->    26th/ 2299
Training[25] shape: torch.Size([1, 200])
Targets[25] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
26th/2299 (25) timeStep of 2299 -  target: -4.44910678268258 |    prediction: tensor(2.0999)
-->    27th/ 2299
Training[26] shape: torch.Size([1, 200])
Targets[26] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
27th/2299 (26) timeStep of 2299 -  target: -3.991695041528583 |    prediction: tensor(-1.6070)
-->    28th/ 2299
Training[27] shape: torch.Size([1, 200])
Targets[27] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
28th/2299 (27) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(0.7013)
-->    29th/ 2299
Training[28] shape: torch.Size([1, 200])
Targets[28] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
29th/2299 (28) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.2520)
-->    30th/ 2299
Training[29] shape: torch.Size([1, 200])
Targets[29] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
30th/2299 (29) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-2.2129)
-->    31th/ 2299
Training[30] shape: torch.Size([1, 200])
Targets[30] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
31th/2299 (30) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.2613)
-->    32th/ 2299
Training[31] shape: torch.Size([1, 200])
Targets[31] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
32th/2299 (31) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.1911)
-->    33th/ 2299
Training[32] shape: torch.Size([1, 200])
Targets[32] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
33th/2299 (32) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-1.0801)
-->    34th/ 2299
Training[33] shape: torch.Size([1, 200])
Targets[33] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
34th/2299 (33) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.9409)
-->    35th/ 2299
Training[34] shape: torch.Size([1, 200])
Targets[34] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
35th/2299 (34) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-2.2275)
-->    36th/ 2299
Training[35] shape: torch.Size([1, 200])
Targets[35] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
36th/2299 (35) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.6550)
-->    37th/ 2299
Training[36] shape: torch.Size([1, 200])
Targets[36] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
37th/2299 (36) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.0143)
-->    38th/ 2299
Training[37] shape: torch.Size([1, 200])
Targets[37] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
38th/2299 (37) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-1.0278)
-->    39th/ 2299
Training[38] shape: torch.Size([1, 200])
Targets[38] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
39th/2299 (38) timeStep of 2299 -  target: -3.191224494509089 |    prediction: tensor(-0.6091)
-->    40th/ 2299
Training[39] shape: torch.Size([1, 200])
Targets[39] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
40th/2299 (39) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.1073)
-->    41th/ 2299
Training[40] shape: torch.Size([1, 200])
Targets[40] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
41th/2299 (40) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-1.0677)
-->    42th/ 2299
Training[41] shape: torch.Size([1, 200])
Targets[41] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
42th/2299 (41) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.1521)
-->    43th/ 2299
Training[42] shape: torch.Size([1, 200])
Targets[42] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
43th/2299 (42) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-1.0761)
-->    44th/ 2299
Training[43] shape: torch.Size([1, 200])
Targets[43] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
44th/2299 (43) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(0.3698)
-->    45th/ 2299
Training[44] shape: torch.Size([1, 200])
Targets[44] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
45th/2299 (44) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.1991)
-->    46th/ 2299
Training[45] shape: torch.Size([1, 200])
Targets[45] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
46th/2299 (45) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(0.1234)
-->    47th/ 2299
Training[46] shape: torch.Size([1, 200])
Targets[46] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
47th/2299 (46) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.4186)
-->    48th/ 2299
Training[47] shape: torch.Size([1, 200])
Targets[47] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
48th/2299 (47) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.0687)
-->    49th/ 2299
Training[48] shape: torch.Size([1, 200])
Targets[48] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
49th/2299 (48) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-1.4862)
-->    50th/ 2299
Training[49] shape: torch.Size([1, 200])
Targets[49] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
50th/2299 (49) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.1690)
-->    51th/ 2299
Training[50] shape: torch.Size([1, 200])
Targets[50] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
51th/2299 (50) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-1.2296)
-->    52th/ 2299
Training[51] shape: torch.Size([1, 200])
Targets[51] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
52th/2299 (51) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.6164)
-->    53th/ 2299
Training[52] shape: torch.Size([1, 200])
Targets[52] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
53th/2299 (52) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.6535)
-->    54th/ 2299
Training[53] shape: torch.Size([1, 200])
Targets[53] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
54th/2299 (53) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-1.2466)
-->    55th/ 2299
Training[54] shape: torch.Size([1, 200])
Targets[54] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
55th/2299 (54) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.7514)
-->    56th/ 2299
Training[55] shape: torch.Size([1, 200])
Targets[55] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
56th/2299 (55) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.1880)
-->    57th/ 2299
Training[56] shape: torch.Size([1, 200])
Targets[56] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
57th/2299 (56) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.9390)
-->    58th/ 2299
Training[57] shape: torch.Size([1, 200])
Targets[57] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
58th/2299 (57) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.9112)
-->    59th/ 2299
Training[58] shape: torch.Size([1, 200])
Targets[58] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
59th/2299 (58) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.0840)
-->    60th/ 2299
Training[59] shape: torch.Size([1, 200])
Targets[59] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
60th/2299 (59) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.5670)
-->    61th/ 2299
Training[60] shape: torch.Size([1, 200])
Targets[60] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
61th/2299 (60) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.5502)
-->    62th/ 2299
Training[61] shape: torch.Size([1, 200])
Targets[61] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
62th/2299 (61) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-0.0439)
-->    63th/ 2299
Training[62] shape: torch.Size([1, 200])
Targets[62] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
63th/2299 (62) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(-0.6109)
-->    64th/ 2299
Training[63] shape: torch.Size([1, 200])
Targets[63] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
64th/2299 (63) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-1.0573)
-->    65th/ 2299
Training[64] shape: torch.Size([1, 200])
Targets[64] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
65th/2299 (64) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(0.9864)
-->    66th/ 2299
Training[65] shape: torch.Size([1, 200])
Targets[65] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
66th/2299 (65) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.5233)
-->    67th/ 2299
Training[66] shape: torch.Size([1, 200])
Targets[66] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
67th/2299 (66) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1951)
-->    68th/ 2299
Training[67] shape: torch.Size([1, 200])
Targets[67] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
68th/2299 (67) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.1327)
-->    69th/ 2299
Training[68] shape: torch.Size([1, 200])
Targets[68] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
69th/2299 (68) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(-0.1334)
-->    70th/ 2299
Training[69] shape: torch.Size([1, 200])
Targets[69] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
70th/2299 (69) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.7877)
-->    71th/ 2299
Training[70] shape: torch.Size([1, 200])
Targets[70] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
71th/2299 (70) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(-0.1301)
-->    72th/ 2299
Training[71] shape: torch.Size([1, 200])
Targets[71] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
72th/2299 (71) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.3029)
-->    73th/ 2299
Training[72] shape: torch.Size([1, 200])
Targets[72] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
73th/2299 (72) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.1488)
-->    74th/ 2299
Training[73] shape: torch.Size([1, 200])
Targets[73] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
74th/2299 (73) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.8453)
-->    75th/ 2299
Training[74] shape: torch.Size([1, 200])
Targets[74] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
75th/2299 (74) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(2.1458)
-->    76th/ 2299
Training[75] shape: torch.Size([1, 200])
Targets[75] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
76th/2299 (75) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(1.5620)
-->    77th/ 2299
Training[76] shape: torch.Size([1, 200])
Targets[76] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
77th/2299 (76) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.3874)
-->    78th/ 2299
Training[77] shape: torch.Size([1, 200])
Targets[77] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
78th/2299 (77) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.9672)
-->    79th/ 2299
Training[78] shape: torch.Size([1, 200])
Targets[78] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
79th/2299 (78) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(0.0330)
-->    80th/ 2299
Training[79] shape: torch.Size([1, 200])
Targets[79] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
80th/2299 (79) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(1.1094)
-->    81th/ 2299
Training[80] shape: torch.Size([1, 200])
Targets[80] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
81th/2299 (80) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.4282)
-->    82th/ 2299
Training[81] shape: torch.Size([1, 200])
Targets[81] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
82th/2299 (81) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.1093)
-->    83th/ 2299
Training[82] shape: torch.Size([1, 200])
Targets[82] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
83th/2299 (82) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.2715)
-->    84th/ 2299
Training[83] shape: torch.Size([1, 200])
Targets[83] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
84th/2299 (83) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.9159)
-->    85th/ 2299
Training[84] shape: torch.Size([1, 200])
Targets[84] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
85th/2299 (84) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-1.3413)
-->    86th/ 2299
Training[85] shape: torch.Size([1, 200])
Targets[85] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
86th/2299 (85) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(0.0138)
-->    87th/ 2299
Training[86] shape: torch.Size([1, 200])
Targets[86] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
87th/2299 (86) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(-0.1809)
-->    88th/ 2299
Training[87] shape: torch.Size([1, 200])
Targets[87] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
88th/2299 (87) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-1.2033)
-->    89th/ 2299
Training[88] shape: torch.Size([1, 200])
Targets[88] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
89th/2299 (88) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(1.0407)
-->    90th/ 2299
Training[89] shape: torch.Size([1, 200])
Targets[89] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
90th/2299 (89) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.1389)
-->    91th/ 2299
Training[90] shape: torch.Size([1, 200])
Targets[90] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
91th/2299 (90) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.4047)
-->    92th/ 2299
Training[91] shape: torch.Size([1, 200])
Targets[91] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
92th/2299 (91) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.2505)
-->    93th/ 2299
Training[92] shape: torch.Size([1, 200])
Targets[92] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
93th/2299 (92) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(2.2252)
-->    94th/ 2299
Training[93] shape: torch.Size([1, 200])
Targets[93] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
94th/2299 (93) timeStep of 2299 -  target: 2.0690105287618725 |    prediction: tensor(1.3692)
-->    95th/ 2299
Training[94] shape: torch.Size([1, 200])
Targets[94] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
95th/2299 (94) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.3579)
-->    96th/ 2299
Training[95] shape: torch.Size([1, 200])
Targets[95] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
96th/2299 (95) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.1690)
-->    97th/ 2299
Training[96] shape: torch.Size([1, 200])
Targets[96] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
97th/2299 (96) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.7294)
-->    98th/ 2299
Training[97] shape: torch.Size([1, 200])
Targets[97] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
98th/2299 (97) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.3278)
-->    99th/ 2299
Training[98] shape: torch.Size([1, 200])
Targets[98] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
99th/2299 (98) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.5951)
-->   100th/ 2299
Training[99] shape: torch.Size([1, 200])
Targets[99] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
100th/2299 (99) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.0372)
-->   101th/ 2299
Training[100] shape: torch.Size([1, 200])
Targets[100] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
101th/2299 (100) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.8541)
-->   102th/ 2299
Training[101] shape: torch.Size([1, 200])
Targets[101] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
102th/2299 (101) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.5596)
-->   103th/ 2299
Training[102] shape: torch.Size([1, 200])
Targets[102] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
103th/2299 (102) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.1251)
-->   104th/ 2299
Training[103] shape: torch.Size([1, 200])
Targets[103] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
104th/2299 (103) timeStep of 2299 -  target: -2.7338127533550924 |    prediction: tensor(-2.1321)
-->   105th/ 2299
Training[104] shape: torch.Size([1, 200])
Targets[104] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
105th/2299 (104) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.6173)
-->   106th/ 2299
Training[105] shape: torch.Size([1, 200])
Targets[105] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
106th/2299 (105) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(0.3958)
-->   107th/ 2299
Training[106] shape: torch.Size([1, 200])
Targets[106] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
107th/2299 (106) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.1704)
-->   108th/ 2299
Training[107] shape: torch.Size([1, 200])
Targets[107] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
108th/2299 (107) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.5063)
-->   109th/ 2299
Training[108] shape: torch.Size([1, 200])
Targets[108] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
109th/2299 (108) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.5774)
-->   110th/ 2299
Training[109] shape: torch.Size([1, 200])
Targets[109] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
110th/2299 (109) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.3951)
-->   111th/ 2299
Training[110] shape: torch.Size([1, 200])
Targets[110] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
111th/2299 (110) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.0251)
-->   112th/ 2299
Training[111] shape: torch.Size([1, 200])
Targets[111] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
112th/2299 (111) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-1.3768)
-->   113th/ 2299
Training[112] shape: torch.Size([1, 200])
Targets[112] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
113th/2299 (112) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.5132)
-->   114th/ 2299
Training[113] shape: torch.Size([1, 200])
Targets[113] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
114th/2299 (113) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.3431)
-->   115th/ 2299
Training[114] shape: torch.Size([1, 200])
Targets[114] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
115th/2299 (114) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-1.3305)
-->   116th/ 2299
Training[115] shape: torch.Size([1, 200])
Targets[115] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
116th/2299 (115) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.0858)
-->   117th/ 2299
Training[116] shape: torch.Size([1, 200])
Targets[116] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
117th/2299 (116) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.6034)
-->   118th/ 2299
Training[117] shape: torch.Size([1, 200])
Targets[117] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
118th/2299 (117) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(0.3006)
-->   119th/ 2299
Training[118] shape: torch.Size([1, 200])
Targets[118] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
119th/2299 (118) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.7414)
-->   120th/ 2299
Training[119] shape: torch.Size([1, 200])
Targets[119] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
120th/2299 (119) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.0387)
-->   121th/ 2299
Training[120] shape: torch.Size([1, 200])
Targets[120] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
121th/2299 (120) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.7713)
-->   122th/ 2299
Training[121] shape: torch.Size([1, 200])
Targets[121] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
122th/2299 (121) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.2106)
-->   123th/ 2299
Training[122] shape: torch.Size([1, 200])
Targets[122] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
123th/2299 (122) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-0.0120)
-->   124th/ 2299
Training[123] shape: torch.Size([1, 200])
Targets[123] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
124th/2299 (123) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.9060)
-->   125th/ 2299
Training[124] shape: torch.Size([1, 200])
Targets[124] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
125th/2299 (124) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.6694)
-->   126th/ 2299
Training[125] shape: torch.Size([1, 200])
Targets[125] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
126th/2299 (125) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.4296)
-->   127th/ 2299
Training[126] shape: torch.Size([1, 200])
Targets[126] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
127th/2299 (126) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.5541)
-->   128th/ 2299
Training[127] shape: torch.Size([1, 200])
Targets[127] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
128th/2299 (127) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.6856)
-->   129th/ 2299
Training[128] shape: torch.Size([1, 200])
Targets[128] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
129th/2299 (128) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.1751)
-->   130th/ 2299
Training[129] shape: torch.Size([1, 200])
Targets[129] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
130th/2299 (129) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.3346)
-->   131th/ 2299
Training[130] shape: torch.Size([1, 200])
Targets[130] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
131th/2299 (130) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.3336)
-->   132th/ 2299
Training[131] shape: torch.Size([1, 200])
Targets[131] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
132th/2299 (131) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.2489)
-->   133th/ 2299
Training[132] shape: torch.Size([1, 200])
Targets[132] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
133th/2299 (132) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.2132)
-->   134th/ 2299
Training[133] shape: torch.Size([1, 200])
Targets[133] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
134th/2299 (133) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.1450)
-->   135th/ 2299
Training[134] shape: torch.Size([1, 200])
Targets[134] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
135th/2299 (134) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.5382)
-->   136th/ 2299
Training[135] shape: torch.Size([1, 200])
Targets[135] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
136th/2299 (135) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(1.4072)
-->   137th/ 2299
Training[136] shape: torch.Size([1, 200])
Targets[136] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
137th/2299 (136) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(0.9473)
-->   138th/ 2299
Training[137] shape: torch.Size([1, 200])
Targets[137] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
138th/2299 (137) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(0.4748)
-->   139th/ 2299
Training[138] shape: torch.Size([1, 200])
Targets[138] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
139th/2299 (138) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.4334)
-->   140th/ 2299
Training[139] shape: torch.Size([1, 200])
Targets[139] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
140th/2299 (139) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(-0.2302)
-->   141th/ 2299
Training[140] shape: torch.Size([1, 200])
Targets[140] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
141th/2299 (140) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(1.1519)
-->   142th/ 2299
Training[141] shape: torch.Size([1, 200])
Targets[141] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
142th/2299 (141) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.9815)
-->   143th/ 2299
Training[142] shape: torch.Size([1, 200])
Targets[142] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
143th/2299 (142) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.2366)
-->   144th/ 2299
Training[143] shape: torch.Size([1, 200])
Targets[143] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
144th/2299 (143) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.4132)
-->   145th/ 2299
Training[144] shape: torch.Size([1, 200])
Targets[144] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
145th/2299 (144) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.5185)
-->   146th/ 2299
Training[145] shape: torch.Size([1, 200])
Targets[145] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
146th/2299 (145) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.7818)
-->   147th/ 2299
Training[146] shape: torch.Size([1, 200])
Targets[146] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
147th/2299 (146) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-0.1840)
-->   148th/ 2299
Training[147] shape: torch.Size([1, 200])
Targets[147] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
148th/2299 (147) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.3830)
-->   149th/ 2299
Training[148] shape: torch.Size([1, 200])
Targets[148] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
149th/2299 (148) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.5654)
-->   150th/ 2299
Training[149] shape: torch.Size([1, 200])
Targets[149] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
150th/2299 (149) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-0.5538)
-->   151th/ 2299
Training[150] shape: torch.Size([1, 200])
Targets[150] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
151th/2299 (150) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.5861)
-->   152th/ 2299
Training[151] shape: torch.Size([1, 200])
Targets[151] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
152th/2299 (151) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.7983)
-->   153th/ 2299
Training[152] shape: torch.Size([1, 200])
Targets[152] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
153th/2299 (152) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.4412)
-->   154th/ 2299
Training[153] shape: torch.Size([1, 200])
Targets[153] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
154th/2299 (153) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.0588)
-->   155th/ 2299
Training[154] shape: torch.Size([1, 200])
Targets[154] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
155th/2299 (154) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.7880)
-->   156th/ 2299
Training[155] shape: torch.Size([1, 200])
Targets[155] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
156th/2299 (155) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.2582)
-->   157th/ 2299
Training[156] shape: torch.Size([1, 200])
Targets[156] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
157th/2299 (156) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.0353)
-->   158th/ 2299
Training[157] shape: torch.Size([1, 200])
Targets[157] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
158th/2299 (157) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.0337)
-->   159th/ 2299
Training[158] shape: torch.Size([1, 200])
Targets[158] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
159th/2299 (158) timeStep of 2299 -  target: -1.933342206335598 |    prediction: tensor(-1.3543)
-->   160th/ 2299
Training[159] shape: torch.Size([1, 200])
Targets[159] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
160th/2299 (159) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.0888)
-->   161th/ 2299
Training[160] shape: torch.Size([1, 200])
Targets[160] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
161th/2299 (160) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.4403)
-->   162th/ 2299
Training[161] shape: torch.Size([1, 200])
Targets[161] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
162th/2299 (161) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(-0.5289)
-->   163th/ 2299
Training[162] shape: torch.Size([1, 200])
Targets[162] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
163th/2299 (162) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(0.3841)
-->   164th/ 2299
Training[163] shape: torch.Size([1, 200])
Targets[163] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
164th/2299 (163) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(-0.1435)
-->   165th/ 2299
Training[164] shape: torch.Size([1, 200])
Targets[164] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
165th/2299 (164) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.3673)
-->   166th/ 2299
Training[165] shape: torch.Size([1, 200])
Targets[165] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
166th/2299 (165) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.8188)
-->   167th/ 2299
Training[166] shape: torch.Size([1, 200])
Targets[166] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
167th/2299 (166) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.2614)
-->   168th/ 2299
Training[167] shape: torch.Size([1, 200])
Targets[167] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
168th/2299 (167) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.1251)
-->   169th/ 2299
Training[168] shape: torch.Size([1, 200])
Targets[168] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
169th/2299 (168) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.0085)
-->   170th/ 2299
Training[169] shape: torch.Size([1, 200])
Targets[169] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
170th/2299 (169) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.4532)
-->   171th/ 2299
Training[170] shape: torch.Size([1, 200])
Targets[170] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
171th/2299 (170) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.6596)
-->   172th/ 2299
Training[171] shape: torch.Size([1, 200])
Targets[171] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
172th/2299 (171) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.5926)
-->   173th/ 2299
Training[172] shape: torch.Size([1, 200])
Targets[172] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
173th/2299 (172) timeStep of 2299 -  target: -2.0476951416240974 |    prediction: tensor(0.8861)
-->   174th/ 2299
Training[173] shape: torch.Size([1, 200])
Targets[173] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
174th/2299 (173) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.2982)
-->   175th/ 2299
Training[174] shape: torch.Size([1, 200])
Targets[174] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
175th/2299 (174) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-1.6248)
-->   176th/ 2299
Training[175] shape: torch.Size([1, 200])
Targets[175] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
176th/2299 (175) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-0.4917)
-->   177th/ 2299
Training[176] shape: torch.Size([1, 200])
Targets[176] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
177th/2299 (176) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.3320)
-->   178th/ 2299
Training[177] shape: torch.Size([1, 200])
Targets[177] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
178th/2299 (177) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.3371)
-->   179th/ 2299
Training[178] shape: torch.Size([1, 200])
Targets[178] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
179th/2299 (178) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.1160)
-->   180th/ 2299
Training[179] shape: torch.Size([1, 200])
Targets[179] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
180th/2299 (179) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.3370)
-->   181th/ 2299
Training[180] shape: torch.Size([1, 200])
Targets[180] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
181th/2299 (180) timeStep of 2299 -  target: 1.4972458523193768 |    prediction: tensor(-0.0319)
-->   182th/ 2299
Training[181] shape: torch.Size([1, 200])
Targets[181] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
182th/2299 (181) timeStep of 2299 -  target: 1.8403046581848743 |    prediction: tensor(0.4223)
-->   183th/ 2299
Training[182] shape: torch.Size([1, 200])
Targets[182] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
183th/2299 (182) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-0.2196)
-->   184th/ 2299
Training[183] shape: torch.Size([1, 200])
Targets[183] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
184th/2299 (183) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(0.1165)
-->   185th/ 2299
Training[184] shape: torch.Size([1, 200])
Targets[184] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
185th/2299 (184) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-1.0736)
-->   186th/ 2299
Training[185] shape: torch.Size([1, 200])
Targets[185] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
186th/2299 (185) timeStep of 2299 -  target: -2.619459818066593 |    prediction: tensor(0.0958)
-->   187th/ 2299
Training[186] shape: torch.Size([1, 200])
Targets[186] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
187th/2299 (186) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.8388)
-->   188th/ 2299
Training[187] shape: torch.Size([1, 200])
Targets[187] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
188th/2299 (187) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(-1.2656)
-->   189th/ 2299
Training[188] shape: torch.Size([1, 200])
Targets[188] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
189th/2299 (188) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.0220)
-->   190th/ 2299
Training[189] shape: torch.Size([1, 200])
Targets[189] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
190th/2299 (189) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.2107)
-->   191th/ 2299
Training[190] shape: torch.Size([1, 200])
Targets[190] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
191th/2299 (190) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.5689)
-->   192th/ 2299
Training[191] shape: torch.Size([1, 200])
Targets[191] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
192th/2299 (191) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(0.4704)
-->   193th/ 2299
Training[192] shape: torch.Size([1, 200])
Targets[192] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
193th/2299 (192) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.1541)
-->   194th/ 2299
Training[193] shape: torch.Size([1, 200])
Targets[193] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
194th/2299 (193) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.1571)
-->   195th/ 2299
Training[194] shape: torch.Size([1, 200])
Targets[194] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
195th/2299 (194) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.3828)
-->   196th/ 2299
Training[195] shape: torch.Size([1, 200])
Targets[195] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
196th/2299 (195) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.3941)
-->   197th/ 2299
Training[196] shape: torch.Size([1, 200])
Targets[196] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
197th/2299 (196) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.1429)
-->   198th/ 2299
Training[197] shape: torch.Size([1, 200])
Targets[197] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
198th/2299 (197) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.7521)
-->   199th/ 2299
Training[198] shape: torch.Size([1, 200])
Targets[198] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
199th/2299 (198) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.0223)
-->   200th/ 2299
Training[199] shape: torch.Size([1, 200])
Targets[199] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
200th/2299 (199) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.5493)
-->   201th/ 2299
-->     1th/ 2299
Training[0] shape: torch.Size([1, 200])
Targets[0] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
1th/2299 (0) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.1020)
-->     2th/ 2299
Training[1] shape: torch.Size([1, 200])
Targets[1] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
2th/2299 (1) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.5251)
-->     3th/ 2299
Training[2] shape: torch.Size([1, 200])
Targets[2] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
3th/2299 (2) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.4736)
-->     4th/ 2299
Training[3] shape: torch.Size([1, 200])
Targets[3] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
4th/2299 (3) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.3294)
-->     5th/ 2299
Training[4] shape: torch.Size([1, 200])
Targets[4] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
5th/2299 (4) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.5430)
-->     6th/ 2299
Training[5] shape: torch.Size([1, 200])
Targets[5] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
6th/2299 (5) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.5769)
-->     7th/ 2299
Training[6] shape: torch.Size([1, 200])
Targets[6] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
7th/2299 (6) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(0.2405)
-->     8th/ 2299
Training[7] shape: torch.Size([1, 200])
Targets[7] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
8th/2299 (7) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.3822)
-->     9th/ 2299
Training[8] shape: torch.Size([1, 200])
Targets[8] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
9th/2299 (8) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(1.2911)
-->    10th/ 2299
Training[9] shape: torch.Size([1, 200])
Targets[9] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
10th/2299 (9) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2732)
-->    11th/ 2299
Training[10] shape: torch.Size([1, 200])
Targets[10] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
11th/2299 (10) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(1.1339)
-->    12th/ 2299
Training[11] shape: torch.Size([1, 200])
Targets[11] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
12th/2299 (11) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.8560)
-->    13th/ 2299
Training[12] shape: torch.Size([1, 200])
Targets[12] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
13th/2299 (12) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.9222)
-->    14th/ 2299
Training[13] shape: torch.Size([1, 200])
Targets[13] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
14th/2299 (13) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.2019)
-->    15th/ 2299
Training[14] shape: torch.Size([1, 200])
Targets[14] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
15th/2299 (14) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.2876)
-->    16th/ 2299
Training[15] shape: torch.Size([1, 200])
Targets[15] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
16th/2299 (15) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.5698)
-->    17th/ 2299
Training[16] shape: torch.Size([1, 200])
Targets[16] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
17th/2299 (16) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(0.1574)
-->    18th/ 2299
Training[17] shape: torch.Size([1, 200])
Targets[17] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
18th/2299 (17) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.3793)
-->    19th/ 2299
Training[18] shape: torch.Size([1, 200])
Targets[18] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
19th/2299 (18) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.1774)
-->    20th/ 2299
Training[19] shape: torch.Size([1, 200])
Targets[19] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
20th/2299 (19) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.5084)
-->    21th/ 2299
Training[20] shape: torch.Size([1, 200])
Targets[20] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
21th/2299 (20) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.0615)
-->    22th/ 2299
Training[21] shape: torch.Size([1, 200])
Targets[21] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
22th/2299 (21) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-1.1455)
-->    23th/ 2299
Training[22] shape: torch.Size([1, 200])
Targets[22] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
23th/2299 (22) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.1656)
-->    24th/ 2299
Training[23] shape: torch.Size([1, 200])
Targets[23] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
24th/2299 (23) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.4201)
-->    25th/ 2299
Training[24] shape: torch.Size([1, 200])
Targets[24] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
25th/2299 (24) timeStep of 2299 -  target: -2.8481656886435913 |    prediction: tensor(-1.5860)
-->    26th/ 2299
Training[25] shape: torch.Size([1, 200])
Targets[25] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
26th/2299 (25) timeStep of 2299 -  target: -4.44910678268258 |    prediction: tensor(-1.9602)
-->    27th/ 2299
Training[26] shape: torch.Size([1, 200])
Targets[26] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
27th/2299 (26) timeStep of 2299 -  target: -3.991695041528583 |    prediction: tensor(-2.2164)
-->    28th/ 2299
Training[27] shape: torch.Size([1, 200])
Targets[27] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
28th/2299 (27) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.4872)
-->    29th/ 2299
Training[28] shape: torch.Size([1, 200])
Targets[28] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
29th/2299 (28) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.2053)
-->    30th/ 2299
Training[29] shape: torch.Size([1, 200])
Targets[29] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
30th/2299 (29) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-2.4925)
-->    31th/ 2299
Training[30] shape: torch.Size([1, 200])
Targets[30] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
31th/2299 (30) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.9352)
-->    32th/ 2299
Training[31] shape: torch.Size([1, 200])
Targets[31] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
32th/2299 (31) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.7926)
-->    33th/ 2299
Training[32] shape: torch.Size([1, 200])
Targets[32] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
33th/2299 (32) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.1669)
-->    34th/ 2299
Training[33] shape: torch.Size([1, 200])
Targets[33] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
34th/2299 (33) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.1455)
-->    35th/ 2299
Training[34] shape: torch.Size([1, 200])
Targets[34] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
35th/2299 (34) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-1.3906)
-->    36th/ 2299
Training[35] shape: torch.Size([1, 200])
Targets[35] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
36th/2299 (35) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.5221)
-->    37th/ 2299
Training[36] shape: torch.Size([1, 200])
Targets[36] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
37th/2299 (36) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.6297)
-->    38th/ 2299
Training[37] shape: torch.Size([1, 200])
Targets[37] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
38th/2299 (37) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-1.2337)
-->    39th/ 2299
Training[38] shape: torch.Size([1, 200])
Targets[38] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
39th/2299 (38) timeStep of 2299 -  target: -3.191224494509089 |    prediction: tensor(-1.7564)
-->    40th/ 2299
Training[39] shape: torch.Size([1, 200])
Targets[39] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
40th/2299 (39) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.6793)
-->    41th/ 2299
Training[40] shape: torch.Size([1, 200])
Targets[40] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
41th/2299 (40) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.2813)
-->    42th/ 2299
Training[41] shape: torch.Size([1, 200])
Targets[41] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
42th/2299 (41) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.2043)
-->    43th/ 2299
Training[42] shape: torch.Size([1, 200])
Targets[42] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
43th/2299 (42) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.3140)
-->    44th/ 2299
Training[43] shape: torch.Size([1, 200])
Targets[43] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
44th/2299 (43) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-0.3397)
-->    45th/ 2299
Training[44] shape: torch.Size([1, 200])
Targets[44] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
45th/2299 (44) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.1129)
-->    46th/ 2299
Training[45] shape: torch.Size([1, 200])
Targets[45] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
46th/2299 (45) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(0.9373)
-->    47th/ 2299
Training[46] shape: torch.Size([1, 200])
Targets[46] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
47th/2299 (46) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.6239)
-->    48th/ 2299
Training[47] shape: torch.Size([1, 200])
Targets[47] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
48th/2299 (47) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.3197)
-->    49th/ 2299
Training[48] shape: torch.Size([1, 200])
Targets[48] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
49th/2299 (48) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2505)
-->    50th/ 2299
Training[49] shape: torch.Size([1, 200])
Targets[49] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
50th/2299 (49) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.7162)
-->    51th/ 2299
Training[50] shape: torch.Size([1, 200])
Targets[50] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
51th/2299 (50) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-1.3708)
-->    52th/ 2299
Training[51] shape: torch.Size([1, 200])
Targets[51] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
52th/2299 (51) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.0450)
-->    53th/ 2299
Training[52] shape: torch.Size([1, 200])
Targets[52] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
53th/2299 (52) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.8251)
-->    54th/ 2299
Training[53] shape: torch.Size([1, 200])
Targets[53] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
54th/2299 (53) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.4724)
-->    55th/ 2299
Training[54] shape: torch.Size([1, 200])
Targets[54] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
55th/2299 (54) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.3267)
-->    56th/ 2299
Training[55] shape: torch.Size([1, 200])
Targets[55] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
56th/2299 (55) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.0536)
-->    57th/ 2299
Training[56] shape: torch.Size([1, 200])
Targets[56] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
57th/2299 (56) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.9144)
-->    58th/ 2299
Training[57] shape: torch.Size([1, 200])
Targets[57] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
58th/2299 (57) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.4025)
-->    59th/ 2299
Training[58] shape: torch.Size([1, 200])
Targets[58] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
59th/2299 (58) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1463)
-->    60th/ 2299
Training[59] shape: torch.Size([1, 200])
Targets[59] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
60th/2299 (59) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.8130)
-->    61th/ 2299
Training[60] shape: torch.Size([1, 200])
Targets[60] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
61th/2299 (60) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.8773)
-->    62th/ 2299
Training[61] shape: torch.Size([1, 200])
Targets[61] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
62th/2299 (61) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-2.2162)
-->    63th/ 2299
Training[62] shape: torch.Size([1, 200])
Targets[62] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
63th/2299 (62) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(-0.8127)
-->    64th/ 2299
Training[63] shape: torch.Size([1, 200])
Targets[63] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
64th/2299 (63) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-1.0027)
-->    65th/ 2299
Training[64] shape: torch.Size([1, 200])
Targets[64] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
65th/2299 (64) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(1.3147)
-->    66th/ 2299
Training[65] shape: torch.Size([1, 200])
Targets[65] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
66th/2299 (65) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(-0.2623)
-->    67th/ 2299
Training[66] shape: torch.Size([1, 200])
Targets[66] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
67th/2299 (66) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.0401)
-->    68th/ 2299
Training[67] shape: torch.Size([1, 200])
Targets[67] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
68th/2299 (67) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.5275)
-->    69th/ 2299
Training[68] shape: torch.Size([1, 200])
Targets[68] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
69th/2299 (68) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(-0.3325)
-->    70th/ 2299
Training[69] shape: torch.Size([1, 200])
Targets[69] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
70th/2299 (69) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(1.0924)
-->    71th/ 2299
Training[70] shape: torch.Size([1, 200])
Targets[70] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
71th/2299 (70) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.4538)
-->    72th/ 2299
Training[71] shape: torch.Size([1, 200])
Targets[71] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
72th/2299 (71) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.0892)
-->    73th/ 2299
Training[72] shape: torch.Size([1, 200])
Targets[72] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
73th/2299 (72) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.9502)
-->    74th/ 2299
Training[73] shape: torch.Size([1, 200])
Targets[73] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
74th/2299 (73) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.4483)
-->    75th/ 2299
Training[74] shape: torch.Size([1, 200])
Targets[74] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
75th/2299 (74) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(1.8478)
-->    76th/ 2299
Training[75] shape: torch.Size([1, 200])
Targets[75] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
76th/2299 (75) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.0801)
-->    77th/ 2299
Training[76] shape: torch.Size([1, 200])
Targets[76] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
77th/2299 (76) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.2932)
-->    78th/ 2299
Training[77] shape: torch.Size([1, 200])
Targets[77] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
78th/2299 (77) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.3269)
-->    79th/ 2299
Training[78] shape: torch.Size([1, 200])
Targets[78] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
79th/2299 (78) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(0.2675)
-->    80th/ 2299
Training[79] shape: torch.Size([1, 200])
Targets[79] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
80th/2299 (79) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.8697)
-->    81th/ 2299
Training[80] shape: torch.Size([1, 200])
Targets[80] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
81th/2299 (80) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0894)
-->    82th/ 2299
Training[81] shape: torch.Size([1, 200])
Targets[81] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
82th/2299 (81) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.3759)
-->    83th/ 2299
Training[82] shape: torch.Size([1, 200])
Targets[82] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
83th/2299 (82) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.1155)
-->    84th/ 2299
Training[83] shape: torch.Size([1, 200])
Targets[83] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
84th/2299 (83) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.3965)
-->    85th/ 2299
Training[84] shape: torch.Size([1, 200])
Targets[84] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
85th/2299 (84) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.9309)
-->    86th/ 2299
Training[85] shape: torch.Size([1, 200])
Targets[85] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
86th/2299 (85) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.4354)
-->    87th/ 2299
Training[86] shape: torch.Size([1, 200])
Targets[86] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
87th/2299 (86) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(-0.1032)
-->    88th/ 2299
Training[87] shape: torch.Size([1, 200])
Targets[87] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
88th/2299 (87) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-1.6160)
-->    89th/ 2299
Training[88] shape: torch.Size([1, 200])
Targets[88] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
89th/2299 (88) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.2192)
-->    90th/ 2299
Training[89] shape: torch.Size([1, 200])
Targets[89] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
90th/2299 (89) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.8947)
-->    91th/ 2299
Training[90] shape: torch.Size([1, 200])
Targets[90] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
91th/2299 (90) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.6289)
-->    92th/ 2299
Training[91] shape: torch.Size([1, 200])
Targets[91] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
92th/2299 (91) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.7723)
-->    93th/ 2299
Training[92] shape: torch.Size([1, 200])
Targets[92] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
93th/2299 (92) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(1.3817)
-->    94th/ 2299
Training[93] shape: torch.Size([1, 200])
Targets[93] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
94th/2299 (93) timeStep of 2299 -  target: 2.0690105287618725 |    prediction: tensor(1.2990)
-->    95th/ 2299
Training[94] shape: torch.Size([1, 200])
Targets[94] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
95th/2299 (94) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.3716)
-->    96th/ 2299
Training[95] shape: torch.Size([1, 200])
Targets[95] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
96th/2299 (95) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.1703)
-->    97th/ 2299
Training[96] shape: torch.Size([1, 200])
Targets[96] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
97th/2299 (96) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(-0.1166)
-->    98th/ 2299
Training[97] shape: torch.Size([1, 200])
Targets[97] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
98th/2299 (97) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.3336)
-->    99th/ 2299
Training[98] shape: torch.Size([1, 200])
Targets[98] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
99th/2299 (98) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.6962)
-->   100th/ 2299
Training[99] shape: torch.Size([1, 200])
Targets[99] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
100th/2299 (99) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.1537)
-->   101th/ 2299
Training[100] shape: torch.Size([1, 200])
Targets[100] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
101th/2299 (100) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.6406)
-->   102th/ 2299
Training[101] shape: torch.Size([1, 200])
Targets[101] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
102th/2299 (101) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.7236)
-->   103th/ 2299
Training[102] shape: torch.Size([1, 200])
Targets[102] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
103th/2299 (102) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.2188)
-->   104th/ 2299
Training[103] shape: torch.Size([1, 200])
Targets[103] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
104th/2299 (103) timeStep of 2299 -  target: -2.7338127533550924 |    prediction: tensor(-2.3784)
-->   105th/ 2299
Training[104] shape: torch.Size([1, 200])
Targets[104] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
105th/2299 (104) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.8655)
-->   106th/ 2299
Training[105] shape: torch.Size([1, 200])
Targets[105] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
106th/2299 (105) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.7549)
-->   107th/ 2299
Training[106] shape: torch.Size([1, 200])
Targets[106] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
107th/2299 (106) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.0641)
-->   108th/ 2299
Training[107] shape: torch.Size([1, 200])
Targets[107] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
108th/2299 (107) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.6245)
-->   109th/ 2299
Training[108] shape: torch.Size([1, 200])
Targets[108] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
109th/2299 (108) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.2162)
-->   110th/ 2299
Training[109] shape: torch.Size([1, 200])
Targets[109] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
110th/2299 (109) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-2.0315)
-->   111th/ 2299
Training[110] shape: torch.Size([1, 200])
Targets[110] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
111th/2299 (110) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.1280)
-->   112th/ 2299
Training[111] shape: torch.Size([1, 200])
Targets[111] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
112th/2299 (111) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-1.1350)
-->   113th/ 2299
Training[112] shape: torch.Size([1, 200])
Targets[112] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
113th/2299 (112) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.6476)
-->   114th/ 2299
Training[113] shape: torch.Size([1, 200])
Targets[113] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
114th/2299 (113) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.6510)
-->   115th/ 2299
Training[114] shape: torch.Size([1, 200])
Targets[114] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
115th/2299 (114) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-1.5507)
-->   116th/ 2299
Training[115] shape: torch.Size([1, 200])
Targets[115] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
116th/2299 (115) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.3469)
-->   117th/ 2299
Training[116] shape: torch.Size([1, 200])
Targets[116] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
117th/2299 (116) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.8006)
-->   118th/ 2299
Training[117] shape: torch.Size([1, 200])
Targets[117] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
118th/2299 (117) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.3923)
-->   119th/ 2299
Training[118] shape: torch.Size([1, 200])
Targets[118] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
119th/2299 (118) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.4558)
-->   120th/ 2299
Training[119] shape: torch.Size([1, 200])
Targets[119] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
120th/2299 (119) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2633)
-->   121th/ 2299
Training[120] shape: torch.Size([1, 200])
Targets[120] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
121th/2299 (120) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.6034)
-->   122th/ 2299
Training[121] shape: torch.Size([1, 200])
Targets[121] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
122th/2299 (121) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.1714)
-->   123th/ 2299
Training[122] shape: torch.Size([1, 200])
Targets[122] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
123th/2299 (122) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.6291)
-->   124th/ 2299
Training[123] shape: torch.Size([1, 200])
Targets[123] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
124th/2299 (123) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.1879)
-->   125th/ 2299
Training[124] shape: torch.Size([1, 200])
Targets[124] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
125th/2299 (124) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.7560)
-->   126th/ 2299
Training[125] shape: torch.Size([1, 200])
Targets[125] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
126th/2299 (125) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.0132)
-->   127th/ 2299
Training[126] shape: torch.Size([1, 200])
Targets[126] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
127th/2299 (126) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.5520)
-->   128th/ 2299
Training[127] shape: torch.Size([1, 200])
Targets[127] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
128th/2299 (127) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.4336)
-->   129th/ 2299
Training[128] shape: torch.Size([1, 200])
Targets[128] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
129th/2299 (128) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.0933)
-->   130th/ 2299
Training[129] shape: torch.Size([1, 200])
Targets[129] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
130th/2299 (129) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.2506)
-->   131th/ 2299
Training[130] shape: torch.Size([1, 200])
Targets[130] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
131th/2299 (130) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.5657)
-->   132th/ 2299
Training[131] shape: torch.Size([1, 200])
Targets[131] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
132th/2299 (131) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.3586)
-->   133th/ 2299
Training[132] shape: torch.Size([1, 200])
Targets[132] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
133th/2299 (132) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.0625)
-->   134th/ 2299
Training[133] shape: torch.Size([1, 200])
Targets[133] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
134th/2299 (133) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.1169)
-->   135th/ 2299
Training[134] shape: torch.Size([1, 200])
Targets[134] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
135th/2299 (134) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.4116)
-->   136th/ 2299
Training[135] shape: torch.Size([1, 200])
Targets[135] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
136th/2299 (135) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(1.2742)
-->   137th/ 2299
Training[136] shape: torch.Size([1, 200])
Targets[136] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
137th/2299 (136) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(0.9053)
-->   138th/ 2299
Training[137] shape: torch.Size([1, 200])
Targets[137] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
138th/2299 (137) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(0.2627)
-->   139th/ 2299
Training[138] shape: torch.Size([1, 200])
Targets[138] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
139th/2299 (138) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.5043)
-->   140th/ 2299
Training[139] shape: torch.Size([1, 200])
Targets[139] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
140th/2299 (139) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(-0.1766)
-->   141th/ 2299
Training[140] shape: torch.Size([1, 200])
Targets[140] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
141th/2299 (140) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(1.0827)
-->   142th/ 2299
Training[141] shape: torch.Size([1, 200])
Targets[141] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
142th/2299 (141) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.6205)
-->   143th/ 2299
Training[142] shape: torch.Size([1, 200])
Targets[142] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
143th/2299 (142) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.2003)
-->   144th/ 2299
Training[143] shape: torch.Size([1, 200])
Targets[143] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
144th/2299 (143) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.3576)
-->   145th/ 2299
Training[144] shape: torch.Size([1, 200])
Targets[144] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
145th/2299 (144) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.6111)
-->   146th/ 2299
Training[145] shape: torch.Size([1, 200])
Targets[145] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
146th/2299 (145) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.7119)
-->   147th/ 2299
Training[146] shape: torch.Size([1, 200])
Targets[146] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
147th/2299 (146) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(0.0005)
-->   148th/ 2299
Training[147] shape: torch.Size([1, 200])
Targets[147] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
148th/2299 (147) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.8592)
-->   149th/ 2299
Training[148] shape: torch.Size([1, 200])
Targets[148] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
149th/2299 (148) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.4247)
-->   150th/ 2299
Training[149] shape: torch.Size([1, 200])
Targets[149] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
150th/2299 (149) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-0.3295)
-->   151th/ 2299
Training[150] shape: torch.Size([1, 200])
Targets[150] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
151th/2299 (150) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.2773)
-->   152th/ 2299
Training[151] shape: torch.Size([1, 200])
Targets[151] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
152th/2299 (151) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.7050)
-->   153th/ 2299
Training[152] shape: torch.Size([1, 200])
Targets[152] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
153th/2299 (152) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.3595)
-->   154th/ 2299
Training[153] shape: torch.Size([1, 200])
Targets[153] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
154th/2299 (153) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.0072)
-->   155th/ 2299
Training[154] shape: torch.Size([1, 200])
Targets[154] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
155th/2299 (154) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.5167)
-->   156th/ 2299
Training[155] shape: torch.Size([1, 200])
Targets[155] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
156th/2299 (155) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.4658)
-->   157th/ 2299
Training[156] shape: torch.Size([1, 200])
Targets[156] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
157th/2299 (156) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.1743)
-->   158th/ 2299
Training[157] shape: torch.Size([1, 200])
Targets[157] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
158th/2299 (157) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.1977)
-->   159th/ 2299
Training[158] shape: torch.Size([1, 200])
Targets[158] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
159th/2299 (158) timeStep of 2299 -  target: -1.933342206335598 |    prediction: tensor(-1.6276)
-->   160th/ 2299
Training[159] shape: torch.Size([1, 200])
Targets[159] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
160th/2299 (159) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.1133)
-->   161th/ 2299
Training[160] shape: torch.Size([1, 200])
Targets[160] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
161th/2299 (160) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.7232)
-->   162th/ 2299
Training[161] shape: torch.Size([1, 200])
Targets[161] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
162th/2299 (161) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(-0.7546)
-->   163th/ 2299
Training[162] shape: torch.Size([1, 200])
Targets[162] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
163th/2299 (162) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(0.7607)
-->   164th/ 2299
Training[163] shape: torch.Size([1, 200])
Targets[163] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
164th/2299 (163) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.1231)
-->   165th/ 2299
Training[164] shape: torch.Size([1, 200])
Targets[164] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
165th/2299 (164) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.2685)
-->   166th/ 2299
Training[165] shape: torch.Size([1, 200])
Targets[165] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
166th/2299 (165) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.6220)
-->   167th/ 2299
Training[166] shape: torch.Size([1, 200])
Targets[166] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
167th/2299 (166) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.1014)
-->   168th/ 2299
Training[167] shape: torch.Size([1, 200])
Targets[167] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
168th/2299 (167) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.2439)
-->   169th/ 2299
Training[168] shape: torch.Size([1, 200])
Targets[168] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
169th/2299 (168) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(0.2162)
-->   170th/ 2299
Training[169] shape: torch.Size([1, 200])
Targets[169] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
170th/2299 (169) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.4368)
-->   171th/ 2299
Training[170] shape: torch.Size([1, 200])
Targets[170] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
171th/2299 (170) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.6676)
-->   172th/ 2299
Training[171] shape: torch.Size([1, 200])
Targets[171] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
172th/2299 (171) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.2621)
-->   173th/ 2299
Training[172] shape: torch.Size([1, 200])
Targets[172] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
173th/2299 (172) timeStep of 2299 -  target: -2.0476951416240974 |    prediction: tensor(0.6791)
-->   174th/ 2299
Training[173] shape: torch.Size([1, 200])
Targets[173] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
174th/2299 (173) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.6818)
-->   175th/ 2299
Training[174] shape: torch.Size([1, 200])
Targets[174] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
175th/2299 (174) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-1.5570)
-->   176th/ 2299
Training[175] shape: torch.Size([1, 200])
Targets[175] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
176th/2299 (175) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-0.3741)
-->   177th/ 2299
Training[176] shape: torch.Size([1, 200])
Targets[176] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
177th/2299 (176) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.4470)
-->   178th/ 2299
Training[177] shape: torch.Size([1, 200])
Targets[177] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
178th/2299 (177) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.3292)
-->   179th/ 2299
Training[178] shape: torch.Size([1, 200])
Targets[178] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
179th/2299 (178) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.2740)
-->   180th/ 2299
Training[179] shape: torch.Size([1, 200])
Targets[179] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
180th/2299 (179) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.4673)
-->   181th/ 2299
Training[180] shape: torch.Size([1, 200])
Targets[180] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
181th/2299 (180) timeStep of 2299 -  target: 1.4972458523193768 |    prediction: tensor(0.3856)
-->   182th/ 2299
Training[181] shape: torch.Size([1, 200])
Targets[181] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
182th/2299 (181) timeStep of 2299 -  target: 1.8403046581848743 |    prediction: tensor(0.5609)
-->   183th/ 2299
Training[182] shape: torch.Size([1, 200])
Targets[182] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
183th/2299 (182) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-0.2977)
-->   184th/ 2299
Training[183] shape: torch.Size([1, 200])
Targets[183] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
184th/2299 (183) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(0.1477)
-->   185th/ 2299
Training[184] shape: torch.Size([1, 200])
Targets[184] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
185th/2299 (184) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-0.9436)
-->   186th/ 2299
Training[185] shape: torch.Size([1, 200])
Targets[185] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
186th/2299 (185) timeStep of 2299 -  target: -2.619459818066593 |    prediction: tensor(-0.1226)
-->   187th/ 2299
Training[186] shape: torch.Size([1, 200])
Targets[186] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
187th/2299 (186) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.7101)
-->   188th/ 2299
Training[187] shape: torch.Size([1, 200])
Targets[187] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
188th/2299 (187) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(-1.4043)
-->   189th/ 2299
Training[188] shape: torch.Size([1, 200])
Targets[188] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
189th/2299 (188) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.0052)
-->   190th/ 2299
Training[189] shape: torch.Size([1, 200])
Targets[189] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
190th/2299 (189) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.3896)
-->   191th/ 2299
Training[190] shape: torch.Size([1, 200])
Targets[190] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
191th/2299 (190) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.5279)
-->   192th/ 2299
Training[191] shape: torch.Size([1, 200])
Targets[191] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
192th/2299 (191) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(0.5326)
-->   193th/ 2299
Training[192] shape: torch.Size([1, 200])
Targets[192] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
193th/2299 (192) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.0569)
-->   194th/ 2299
Training[193] shape: torch.Size([1, 200])
Targets[193] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
194th/2299 (193) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.2778)
-->   195th/ 2299
Training[194] shape: torch.Size([1, 200])
Targets[194] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
195th/2299 (194) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.3584)
-->   196th/ 2299
Training[195] shape: torch.Size([1, 200])
Targets[195] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
196th/2299 (195) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.2962)
-->   197th/ 2299
Training[196] shape: torch.Size([1, 200])
Targets[196] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
197th/2299 (196) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0722)
-->   198th/ 2299
Training[197] shape: torch.Size([1, 200])
Targets[197] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
198th/2299 (197) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.7548)
-->   199th/ 2299
Training[198] shape: torch.Size([1, 200])
Targets[198] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
199th/2299 (198) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.0313)
-->   200th/ 2299
Training[199] shape: torch.Size([1, 200])
Targets[199] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
200th/2299 (199) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.5768)
-->   201th/ 2299
-->     1th/ 2299
Training[0] shape: torch.Size([1, 200])
Targets[0] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
1th/2299 (0) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.1131)
-->     2th/ 2299
Training[1] shape: torch.Size([1, 200])
Targets[1] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
2th/2299 (1) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.6028)
-->     3th/ 2299
Training[2] shape: torch.Size([1, 200])
Targets[2] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
3th/2299 (2) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.5352)
-->     4th/ 2299
Training[3] shape: torch.Size([1, 200])
Targets[3] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
4th/2299 (3) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.2431)
-->     5th/ 2299
Training[4] shape: torch.Size([1, 200])
Targets[4] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
5th/2299 (4) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.5753)
-->     6th/ 2299
Training[5] shape: torch.Size([1, 200])
Targets[5] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
6th/2299 (5) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.6577)
-->     7th/ 2299
Training[6] shape: torch.Size([1, 200])
Targets[6] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
7th/2299 (6) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(0.2027)
-->     8th/ 2299
Training[7] shape: torch.Size([1, 200])
Targets[7] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
8th/2299 (7) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.5017)
-->     9th/ 2299
Training[8] shape: torch.Size([1, 200])
Targets[8] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
9th/2299 (8) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(1.2854)
-->    10th/ 2299
Training[9] shape: torch.Size([1, 200])
Targets[9] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
10th/2299 (9) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.4423)
-->    11th/ 2299
Training[10] shape: torch.Size([1, 200])
Targets[10] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
11th/2299 (10) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(1.0086)
-->    12th/ 2299
Training[11] shape: torch.Size([1, 200])
Targets[11] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
12th/2299 (11) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.8991)
-->    13th/ 2299
Training[12] shape: torch.Size([1, 200])
Targets[12] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
13th/2299 (12) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.0167)
-->    14th/ 2299
Training[13] shape: torch.Size([1, 200])
Targets[13] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
14th/2299 (13) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.2910)
-->    15th/ 2299
Training[14] shape: torch.Size([1, 200])
Targets[14] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
15th/2299 (14) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.3791)
-->    16th/ 2299
Training[15] shape: torch.Size([1, 200])
Targets[15] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
16th/2299 (15) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.5664)
-->    17th/ 2299
Training[16] shape: torch.Size([1, 200])
Targets[16] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
17th/2299 (16) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(0.0678)
-->    18th/ 2299
Training[17] shape: torch.Size([1, 200])
Targets[17] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
18th/2299 (17) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.4373)
-->    19th/ 2299
Training[18] shape: torch.Size([1, 200])
Targets[18] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
19th/2299 (18) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.3075)
-->    20th/ 2299
Training[19] shape: torch.Size([1, 200])
Targets[19] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
20th/2299 (19) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.6029)
-->    21th/ 2299
Training[20] shape: torch.Size([1, 200])
Targets[20] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
21th/2299 (20) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.0648)
-->    22th/ 2299
Training[21] shape: torch.Size([1, 200])
Targets[21] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
22th/2299 (21) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.9186)
-->    23th/ 2299
Training[22] shape: torch.Size([1, 200])
Targets[22] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
23th/2299 (22) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.1762)
-->    24th/ 2299
Training[23] shape: torch.Size([1, 200])
Targets[23] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
24th/2299 (23) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.4022)
-->    25th/ 2299
Training[24] shape: torch.Size([1, 200])
Targets[24] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
25th/2299 (24) timeStep of 2299 -  target: -2.8481656886435913 |    prediction: tensor(-1.5099)
-->    26th/ 2299
Training[25] shape: torch.Size([1, 200])
Targets[25] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
26th/2299 (25) timeStep of 2299 -  target: -4.44910678268258 |    prediction: tensor(-1.8723)
-->    27th/ 2299
Training[26] shape: torch.Size([1, 200])
Targets[26] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
27th/2299 (26) timeStep of 2299 -  target: -3.991695041528583 |    prediction: tensor(-2.3905)
-->    28th/ 2299
Training[27] shape: torch.Size([1, 200])
Targets[27] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
28th/2299 (27) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.5156)
-->    29th/ 2299
Training[28] shape: torch.Size([1, 200])
Targets[28] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
29th/2299 (28) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.2039)
-->    30th/ 2299
Training[29] shape: torch.Size([1, 200])
Targets[29] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
30th/2299 (29) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-2.2143)
-->    31th/ 2299
Training[30] shape: torch.Size([1, 200])
Targets[30] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
31th/2299 (30) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-1.0036)
-->    32th/ 2299
Training[31] shape: torch.Size([1, 200])
Targets[31] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
32th/2299 (31) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.7496)
-->    33th/ 2299
Training[32] shape: torch.Size([1, 200])
Targets[32] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
33th/2299 (32) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.0469)
-->    34th/ 2299
Training[33] shape: torch.Size([1, 200])
Targets[33] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
34th/2299 (33) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.1557)
-->    35th/ 2299
Training[34] shape: torch.Size([1, 200])
Targets[34] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
35th/2299 (34) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-1.5742)
-->    36th/ 2299
Training[35] shape: torch.Size([1, 200])
Targets[35] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
36th/2299 (35) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.7097)
-->    37th/ 2299
Training[36] shape: torch.Size([1, 200])
Targets[36] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
37th/2299 (36) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.7212)
-->    38th/ 2299
Training[37] shape: torch.Size([1, 200])
Targets[37] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
38th/2299 (37) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-1.2480)
-->    39th/ 2299
Training[38] shape: torch.Size([1, 200])
Targets[38] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
39th/2299 (38) timeStep of 2299 -  target: -3.191224494509089 |    prediction: tensor(-1.7785)
-->    40th/ 2299
Training[39] shape: torch.Size([1, 200])
Targets[39] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
40th/2299 (39) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.7723)
-->    41th/ 2299
Training[40] shape: torch.Size([1, 200])
Targets[40] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
41th/2299 (40) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.2710)
-->    42th/ 2299
Training[41] shape: torch.Size([1, 200])
Targets[41] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
42th/2299 (41) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.4232)
-->    43th/ 2299
Training[42] shape: torch.Size([1, 200])
Targets[42] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
43th/2299 (42) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.2646)
-->    44th/ 2299
Training[43] shape: torch.Size([1, 200])
Targets[43] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
44th/2299 (43) timeStep of 2299 -  target: -2.1620480769125963 |    prediction: tensor(-0.4346)
-->    45th/ 2299
Training[44] shape: torch.Size([1, 200])
Targets[44] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
45th/2299 (44) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.2234)
-->    46th/ 2299
Training[45] shape: torch.Size([1, 200])
Targets[45] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
46th/2299 (45) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(1.1432)
-->    47th/ 2299
Training[46] shape: torch.Size([1, 200])
Targets[46] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
47th/2299 (46) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.6891)
-->    48th/ 2299
Training[47] shape: torch.Size([1, 200])
Targets[47] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
48th/2299 (47) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.3260)
-->    49th/ 2299
Training[48] shape: torch.Size([1, 200])
Targets[48] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
49th/2299 (48) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.1516)
-->    50th/ 2299
Training[49] shape: torch.Size([1, 200])
Targets[49] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
50th/2299 (49) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.7086)
-->    51th/ 2299
Training[50] shape: torch.Size([1, 200])
Targets[50] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
51th/2299 (50) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-1.4272)
-->    52th/ 2299
Training[51] shape: torch.Size([1, 200])
Targets[51] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
52th/2299 (51) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.0101)
-->    53th/ 2299
Training[52] shape: torch.Size([1, 200])
Targets[52] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
53th/2299 (52) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.7878)
-->    54th/ 2299
Training[53] shape: torch.Size([1, 200])
Targets[53] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
54th/2299 (53) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.4354)
-->    55th/ 2299
Training[54] shape: torch.Size([1, 200])
Targets[54] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
55th/2299 (54) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.3158)
-->    56th/ 2299
Training[55] shape: torch.Size([1, 200])
Targets[55] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
56th/2299 (55) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-0.0535)
-->    57th/ 2299
Training[56] shape: torch.Size([1, 200])
Targets[56] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
57th/2299 (56) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.8820)
-->    58th/ 2299
Training[57] shape: torch.Size([1, 200])
Targets[57] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
58th/2299 (57) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.2925)
-->    59th/ 2299
Training[58] shape: torch.Size([1, 200])
Targets[58] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
59th/2299 (58) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1166)
-->    60th/ 2299
Training[59] shape: torch.Size([1, 200])
Targets[59] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
60th/2299 (59) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.7972)
-->    61th/ 2299
Training[60] shape: torch.Size([1, 200])
Targets[60] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
61th/2299 (60) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.8447)
-->    62th/ 2299
Training[61] shape: torch.Size([1, 200])
Targets[61] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
62th/2299 (61) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-2.3373)
-->    63th/ 2299
Training[62] shape: torch.Size([1, 200])
Targets[62] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
63th/2299 (62) timeStep of 2299 -  target: -2.2764010122010956 |    prediction: tensor(-0.7987)
-->    64th/ 2299
Training[63] shape: torch.Size([1, 200])
Targets[63] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
64th/2299 (63) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.9030)
-->    65th/ 2299
Training[64] shape: torch.Size([1, 200])
Targets[64] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
65th/2299 (64) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(1.3535)
-->    66th/ 2299
Training[65] shape: torch.Size([1, 200])
Targets[65] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
66th/2299 (65) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(-0.2789)
-->    67th/ 2299
Training[66] shape: torch.Size([1, 200])
Targets[66] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
67th/2299 (66) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.1079)
-->    68th/ 2299
Training[67] shape: torch.Size([1, 200])
Targets[67] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
68th/2299 (67) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.6668)
-->    69th/ 2299
Training[68] shape: torch.Size([1, 200])
Targets[68] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
69th/2299 (68) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(-0.3280)
-->    70th/ 2299
Training[69] shape: torch.Size([1, 200])
Targets[69] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
70th/2299 (69) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(1.1063)
-->    71th/ 2299
Training[70] shape: torch.Size([1, 200])
Targets[70] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
71th/2299 (70) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.5652)
-->    72th/ 2299
Training[71] shape: torch.Size([1, 200])
Targets[71] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
72th/2299 (71) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.1245)
-->    73th/ 2299
Training[72] shape: torch.Size([1, 200])
Targets[72] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
73th/2299 (72) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.0001)
-->    74th/ 2299
Training[73] shape: torch.Size([1, 200])
Targets[73] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
74th/2299 (73) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.3826)
-->    75th/ 2299
Training[74] shape: torch.Size([1, 200])
Targets[74] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
75th/2299 (74) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(1.7950)
-->    76th/ 2299
Training[75] shape: torch.Size([1, 200])
Targets[75] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
76th/2299 (75) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.2752)
-->    77th/ 2299
Training[76] shape: torch.Size([1, 200])
Targets[76] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
77th/2299 (76) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.2466)
-->    78th/ 2299
Training[77] shape: torch.Size([1, 200])
Targets[77] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
78th/2299 (77) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.3204)
-->    79th/ 2299
Training[78] shape: torch.Size([1, 200])
Targets[78] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
79th/2299 (78) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(0.3850)
-->    80th/ 2299
Training[79] shape: torch.Size([1, 200])
Targets[79] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
80th/2299 (79) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.8756)
-->    81th/ 2299
Training[80] shape: torch.Size([1, 200])
Targets[80] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
81th/2299 (80) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0649)
-->    82th/ 2299
Training[81] shape: torch.Size([1, 200])
Targets[81] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
82th/2299 (81) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.4096)
-->    83th/ 2299
Training[82] shape: torch.Size([1, 200])
Targets[82] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
83th/2299 (82) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.1079)
-->    84th/ 2299
Training[83] shape: torch.Size([1, 200])
Targets[83] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
84th/2299 (83) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.3729)
-->    85th/ 2299
Training[84] shape: torch.Size([1, 200])
Targets[84] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
85th/2299 (84) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.9912)
-->    86th/ 2299
Training[85] shape: torch.Size([1, 200])
Targets[85] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
86th/2299 (85) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.4758)
-->    87th/ 2299
Training[86] shape: torch.Size([1, 200])
Targets[86] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
87th/2299 (86) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(-0.0916)
-->    88th/ 2299
Training[87] shape: torch.Size([1, 200])
Targets[87] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
88th/2299 (87) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-1.5430)
-->    89th/ 2299
Training[88] shape: torch.Size([1, 200])
Targets[88] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
89th/2299 (88) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(0.1387)
-->    90th/ 2299
Training[89] shape: torch.Size([1, 200])
Targets[89] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
90th/2299 (89) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.8368)
-->    91th/ 2299
Training[90] shape: torch.Size([1, 200])
Targets[90] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
91th/2299 (90) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.7575)
-->    92th/ 2299
Training[91] shape: torch.Size([1, 200])
Targets[91] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
92th/2299 (91) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.8300)
-->    93th/ 2299
Training[92] shape: torch.Size([1, 200])
Targets[92] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
93th/2299 (92) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(1.2665)
-->    94th/ 2299
Training[93] shape: torch.Size([1, 200])
Targets[93] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
94th/2299 (93) timeStep of 2299 -  target: 2.0690105287618725 |    prediction: tensor(1.2343)
-->    95th/ 2299
Training[94] shape: torch.Size([1, 200])
Targets[94] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
95th/2299 (94) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.3874)
-->    96th/ 2299
Training[95] shape: torch.Size([1, 200])
Targets[95] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
96th/2299 (95) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(0.1859)
-->    97th/ 2299
Training[96] shape: torch.Size([1, 200])
Targets[96] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
97th/2299 (96) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(-0.3328)
-->    98th/ 2299
Training[97] shape: torch.Size([1, 200])
Targets[97] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
98th/2299 (97) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(0.2783)
-->    99th/ 2299
Training[98] shape: torch.Size([1, 200])
Targets[98] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
99th/2299 (98) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.8312)
-->   100th/ 2299
Training[99] shape: torch.Size([1, 200])
Targets[99] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
100th/2299 (99) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.2121)
-->   101th/ 2299
Training[100] shape: torch.Size([1, 200])
Targets[100] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
101th/2299 (100) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(-0.6314)
-->   102th/ 2299
Training[101] shape: torch.Size([1, 200])
Targets[101] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
102th/2299 (101) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.7240)
-->   103th/ 2299
Training[102] shape: torch.Size([1, 200])
Targets[102] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
103th/2299 (102) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.2330)
-->   104th/ 2299
Training[103] shape: torch.Size([1, 200])
Targets[103] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
104th/2299 (103) timeStep of 2299 -  target: -2.7338127533550924 |    prediction: tensor(-2.5642)
-->   105th/ 2299
Training[104] shape: torch.Size([1, 200])
Targets[104] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
105th/2299 (104) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.8566)
-->   106th/ 2299
Training[105] shape: torch.Size([1, 200])
Targets[105] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
106th/2299 (105) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.9213)
-->   107th/ 2299
Training[106] shape: torch.Size([1, 200])
Targets[106] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
107th/2299 (106) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.0137)
-->   108th/ 2299
Training[107] shape: torch.Size([1, 200])
Targets[107] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
108th/2299 (107) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.5653)
-->   109th/ 2299
Training[108] shape: torch.Size([1, 200])
Targets[108] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
109th/2299 (108) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.2101)
-->   110th/ 2299
Training[109] shape: torch.Size([1, 200])
Targets[109] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
110th/2299 (109) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-2.0212)
-->   111th/ 2299
Training[110] shape: torch.Size([1, 200])
Targets[110] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
111th/2299 (110) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(-0.0102)
-->   112th/ 2299
Training[111] shape: torch.Size([1, 200])
Targets[111] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
112th/2299 (111) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-1.0811)
-->   113th/ 2299
Training[112] shape: torch.Size([1, 200])
Targets[112] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
113th/2299 (112) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.5792)
-->   114th/ 2299
Training[113] shape: torch.Size([1, 200])
Targets[113] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
114th/2299 (113) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-1.6890)
-->   115th/ 2299
Training[114] shape: torch.Size([1, 200])
Targets[114] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
115th/2299 (114) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-1.5000)
-->   116th/ 2299
Training[115] shape: torch.Size([1, 200])
Targets[115] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
116th/2299 (115) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(-0.3374)
-->   117th/ 2299
Training[116] shape: torch.Size([1, 200])
Targets[116] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
117th/2299 (116) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.8187)
-->   118th/ 2299
Training[117] shape: torch.Size([1, 200])
Targets[117] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
118th/2299 (117) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.5764)
-->   119th/ 2299
Training[118] shape: torch.Size([1, 200])
Targets[118] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
119th/2299 (118) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.4210)
-->   120th/ 2299
Training[119] shape: torch.Size([1, 200])
Targets[119] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
120th/2299 (119) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(-0.2783)
-->   121th/ 2299
Training[120] shape: torch.Size([1, 200])
Targets[120] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
121th/2299 (120) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.6029)
-->   122th/ 2299
Training[121] shape: torch.Size([1, 200])
Targets[121] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
122th/2299 (121) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.1187)
-->   123th/ 2299
Training[122] shape: torch.Size([1, 200])
Targets[122] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
123th/2299 (122) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.7227)
-->   124th/ 2299
Training[123] shape: torch.Size([1, 200])
Targets[123] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
124th/2299 (123) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(1.1928)
-->   125th/ 2299
Training[124] shape: torch.Size([1, 200])
Targets[124] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
125th/2299 (124) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(0.7425)
-->   126th/ 2299
Training[125] shape: torch.Size([1, 200])
Targets[125] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
126th/2299 (125) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.0786)
-->   127th/ 2299
Training[126] shape: torch.Size([1, 200])
Targets[126] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
127th/2299 (126) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.6296)
-->   128th/ 2299
Training[127] shape: torch.Size([1, 200])
Targets[127] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
128th/2299 (127) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(-0.3641)
-->   129th/ 2299
Training[128] shape: torch.Size([1, 200])
Targets[128] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
129th/2299 (128) timeStep of 2299 -  target: -1.0185187240276048 |    prediction: tensor(-0.0736)
-->   130th/ 2299
Training[129] shape: torch.Size([1, 200])
Targets[129] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
130th/2299 (129) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.1935)
-->   131th/ 2299
Training[130] shape: torch.Size([1, 200])
Targets[130] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
131th/2299 (130) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.5931)
-->   132th/ 2299
Training[131] shape: torch.Size([1, 200])
Targets[131] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
132th/2299 (131) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.3650)
-->   133th/ 2299
Training[132] shape: torch.Size([1, 200])
Targets[132] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
133th/2299 (132) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.1355)
-->   134th/ 2299
Training[133] shape: torch.Size([1, 200])
Targets[133] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
134th/2299 (133) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0785)
-->   135th/ 2299
Training[134] shape: torch.Size([1, 200])
Targets[134] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
135th/2299 (134) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(0.3765)
-->   136th/ 2299
Training[135] shape: torch.Size([1, 200])
Targets[135] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
136th/2299 (135) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(1.2370)
-->   137th/ 2299
Training[136] shape: torch.Size([1, 200])
Targets[136] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
137th/2299 (136) timeStep of 2299 -  target: 2.2977163993388707 |    prediction: tensor(0.8874)
-->   138th/ 2299
Training[137] shape: torch.Size([1, 200])
Targets[137] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
138th/2299 (137) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(0.2027)
-->   139th/ 2299
Training[138] shape: torch.Size([1, 200])
Targets[138] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
139th/2299 (138) timeStep of 2299 -  target: -1.5902834004701005 |    prediction: tensor(-0.5356)
-->   140th/ 2299
Training[139] shape: torch.Size([1, 200])
Targets[139] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
140th/2299 (139) timeStep of 2299 -  target: -0.1036952417196115 |    prediction: tensor(-0.1814)
-->   141th/ 2299
Training[140] shape: torch.Size([1, 200])
Targets[140] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
141th/2299 (140) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(1.1215)
-->   142th/ 2299
Training[141] shape: torch.Size([1, 200])
Targets[141] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
142th/2299 (141) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.5636)
-->   143th/ 2299
Training[142] shape: torch.Size([1, 200])
Targets[142] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
143th/2299 (142) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.1811)
-->   144th/ 2299
Training[143] shape: torch.Size([1, 200])
Targets[143] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
144th/2299 (143) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.3014)
-->   145th/ 2299
Training[144] shape: torch.Size([1, 200])
Targets[144] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
145th/2299 (144) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(0.6650)
-->   146th/ 2299
Training[145] shape: torch.Size([1, 200])
Targets[145] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
146th/2299 (145) timeStep of 2299 -  target: 0.4680694347228843 |    prediction: tensor(0.6818)
-->   147th/ 2299
Training[146] shape: torch.Size([1, 200])
Targets[146] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
147th/2299 (146) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(0.0020)
-->   148th/ 2299
Training[147] shape: torch.Size([1, 200])
Targets[147] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
148th/2299 (147) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.9969)
-->   149th/ 2299
Training[148] shape: torch.Size([1, 200])
Targets[148] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
149th/2299 (148) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.3698)
-->   150th/ 2299
Training[149] shape: torch.Size([1, 200])
Targets[149] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
150th/2299 (149) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-0.2708)
-->   151th/ 2299
Training[150] shape: torch.Size([1, 200])
Targets[150] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
151th/2299 (150) timeStep of 2299 -  target: 0.010657693568887659 |    prediction: tensor(-0.2196)
-->   152th/ 2299
Training[151] shape: torch.Size([1, 200])
Targets[151] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
152th/2299 (151) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(1.6126)
-->   153th/ 2299
Training[152] shape: torch.Size([1, 200])
Targets[152] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
153th/2299 (152) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.3043)
-->   154th/ 2299
Training[153] shape: torch.Size([1, 200])
Targets[153] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
154th/2299 (153) timeStep of 2299 -  target: 0.35371649943438516 |    prediction: tensor(0.0014)
-->   155th/ 2299
Training[154] shape: torch.Size([1, 200])
Targets[154] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
155th/2299 (154) timeStep of 2299 -  target: -1.132871659316104 |    prediction: tensor(-0.4617)
-->   156th/ 2299
Training[155] shape: torch.Size([1, 200])
Targets[155] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
156th/2299 (155) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(-0.5570)
-->   157th/ 2299
Training[156] shape: torch.Size([1, 200])
Targets[156] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
157th/2299 (156) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.2170)
-->   158th/ 2299
Training[157] shape: torch.Size([1, 200])
Targets[157] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
158th/2299 (157) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.2456)
-->   159th/ 2299
Training[158] shape: torch.Size([1, 200])
Targets[158] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
159th/2299 (158) timeStep of 2299 -  target: -1.933342206335598 |    prediction: tensor(-1.6271)
-->   160th/ 2299
Training[159] shape: torch.Size([1, 200])
Targets[159] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
160th/2299 (159) timeStep of 2299 -  target: -0.21804817700811066 |    prediction: tensor(-0.1486)
-->   161th/ 2299
Training[160] shape: torch.Size([1, 200])
Targets[160] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
161th/2299 (160) timeStep of 2299 -  target: -1.4759304651816014 |    prediction: tensor(-1.7801)
-->   162th/ 2299
Training[161] shape: torch.Size([1, 200])
Targets[161] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
162th/2299 (161) timeStep of 2299 -  target: 1.0398341111653802 |    prediction: tensor(-0.7380)
-->   163th/ 2299
Training[162] shape: torch.Size([1, 200])
Targets[162] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
163th/2299 (162) timeStep of 2299 -  target: 1.725951722896375 |    prediction: tensor(0.8692)
-->   164th/ 2299
Training[163] shape: torch.Size([1, 200])
Targets[163] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
164th/2299 (163) timeStep of 2299 -  target: 1.3828929170308777 |    prediction: tensor(0.2112)
-->   165th/ 2299
Training[164] shape: torch.Size([1, 200])
Targets[164] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
165th/2299 (164) timeStep of 2299 -  target: 1.611598787607876 |    prediction: tensor(0.2705)
-->   166th/ 2299
Training[165] shape: torch.Size([1, 200])
Targets[165] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
166th/2299 (165) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.5568)
-->   167th/ 2299
Training[166] shape: torch.Size([1, 200])
Targets[166] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
167th/2299 (166) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.1166)
-->   168th/ 2299
Training[167] shape: torch.Size([1, 200])
Targets[167] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
168th/2299 (167) timeStep of 2299 -  target: -0.446754047585109 |    prediction: tensor(0.2621)
-->   169th/ 2299
Training[168] shape: torch.Size([1, 200])
Targets[168] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
169th/2299 (168) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(0.2858)
-->   170th/ 2299
Training[169] shape: torch.Size([1, 200])
Targets[169] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
170th/2299 (169) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(-0.4803)
-->   171th/ 2299
Training[170] shape: torch.Size([1, 200])
Targets[170] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
171th/2299 (170) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(-0.6731)
-->   172th/ 2299
Training[171] shape: torch.Size([1, 200])
Targets[171] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
172th/2299 (171) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-1.1921)
-->   173th/ 2299
Training[172] shape: torch.Size([1, 200])
Targets[172] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
173th/2299 (172) timeStep of 2299 -  target: -2.0476951416240974 |    prediction: tensor(0.5580)
-->   174th/ 2299
Training[173] shape: torch.Size([1, 200])
Targets[173] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
174th/2299 (173) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(-0.7836)
-->   175th/ 2299
Training[174] shape: torch.Size([1, 200])
Targets[174] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
175th/2299 (174) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-1.5215)
-->   176th/ 2299
Training[175] shape: torch.Size([1, 200])
Targets[175] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
176th/2299 (175) timeStep of 2299 -  target: -1.3615775298931023 |    prediction: tensor(-0.3465)
-->   177th/ 2299
Training[176] shape: torch.Size([1, 200])
Targets[176] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
177th/2299 (176) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.4755)
-->   178th/ 2299
Training[177] shape: torch.Size([1, 200])
Targets[177] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
178th/2299 (177) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(-0.3156)
-->   179th/ 2299
Training[178] shape: torch.Size([1, 200])
Targets[178] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
179th/2299 (178) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.3116)
-->   180th/ 2299
Training[179] shape: torch.Size([1, 200])
Targets[179] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
180th/2299 (179) timeStep of 2299 -  target: -0.9041657887391056 |    prediction: tensor(-0.4809)
-->   181th/ 2299
Training[180] shape: torch.Size([1, 200])
Targets[180] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
181th/2299 (180) timeStep of 2299 -  target: 1.4972458523193768 |    prediction: tensor(0.5013)
-->   182th/ 2299
Training[181] shape: torch.Size([1, 200])
Targets[181] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
182th/2299 (181) timeStep of 2299 -  target: 1.8403046581848743 |    prediction: tensor(0.5949)
-->   183th/ 2299
Training[182] shape: torch.Size([1, 200])
Targets[182] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
183th/2299 (182) timeStep of 2299 -  target: 1.1541870464538793 |    prediction: tensor(-0.3056)
-->   184th/ 2299
Training[183] shape: torch.Size([1, 200])
Targets[183] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
184th/2299 (183) timeStep of 2299 -  target: -1.818989271047099 |    prediction: tensor(0.1495)
-->   185th/ 2299
Training[184] shape: torch.Size([1, 200])
Targets[184] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
185th/2299 (184) timeStep of 2299 -  target: -1.7046363357585999 |    prediction: tensor(-0.8930)
-->   186th/ 2299
Training[185] shape: torch.Size([1, 200])
Targets[185] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
186th/2299 (185) timeStep of 2299 -  target: -2.619459818066593 |    prediction: tensor(-0.1781)
-->   187th/ 2299
Training[186] shape: torch.Size([1, 200])
Targets[186] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
187th/2299 (186) timeStep of 2299 -  target: -0.7898128534506065 |    prediction: tensor(-0.6755)
-->   188th/ 2299
Training[187] shape: torch.Size([1, 200])
Targets[187] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
188th/2299 (187) timeStep of 2299 -  target: 0.925481175876881 |    prediction: tensor(-1.4264)
-->   189th/ 2299
Training[188] shape: torch.Size([1, 200])
Targets[188] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
189th/2299 (188) timeStep of 2299 -  target: -0.6754599181621073 |    prediction: tensor(0.0063)
-->   190th/ 2299
Training[189] shape: torch.Size([1, 200])
Targets[189] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
190th/2299 (189) timeStep of 2299 -  target: -1.2472245946046032 |    prediction: tensor(-0.4352)
-->   191th/ 2299
Training[190] shape: torch.Size([1, 200])
Targets[190] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
191th/2299 (190) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.5230)
-->   192th/ 2299
Training[191] shape: torch.Size([1, 200])
Targets[191] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
192th/2299 (191) timeStep of 2299 -  target: 0.8111282405883818 |    prediction: tensor(0.5476)
-->   193th/ 2299
Training[192] shape: torch.Size([1, 200])
Targets[192] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
193th/2299 (192) timeStep of 2299 -  target: -0.33240111229660985 |    prediction: tensor(0.0121)
-->   194th/ 2299
Training[193] shape: torch.Size([1, 200])
Targets[193] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
194th/2299 (193) timeStep of 2299 -  target: -0.5611069828736082 |    prediction: tensor(0.3107)
-->   195th/ 2299
Training[194] shape: torch.Size([1, 200])
Targets[194] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
195th/2299 (194) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.3567)
-->   196th/ 2299
Training[195] shape: torch.Size([1, 200])
Targets[195] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
196th/2299 (195) timeStep of 2299 -  target: 0.23936356414588597 |    prediction: tensor(0.2751)
-->   197th/ 2299
Training[196] shape: torch.Size([1, 200])
Targets[196] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
197th/2299 (196) timeStep of 2299 -  target: 0.5824223700113834 |    prediction: tensor(0.0490)
-->   198th/ 2299
Training[197] shape: torch.Size([1, 200])
Targets[197] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
198th/2299 (197) timeStep of 2299 -  target: 1.2685399817423784 |    prediction: tensor(0.7512)
-->   199th/ 2299
Training[198] shape: torch.Size([1, 200])
Targets[198] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
199th/2299 (198) timeStep of 2299 -  target: 0.1250106288573868 |    prediction: tensor(-0.0386)
-->   200th/ 2299
Training[199] shape: torch.Size([1, 200])
Targets[199] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 2301
ORELM:TRAIN:Features shape: torch.Size([1, 200])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 200])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 200])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 200])
Targets ~ torch.Size([1, 200])
Inputs ~ 200
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 200])
weights: torch.Size([25, 200])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 200])
---> Linear_recurrent
numSamples: 1
numInputs: 200
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 200])
NumInputs = (hidden, inputs): torch.Size([25, 200])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 200])
200th/2299 (199) timeStep of 2299 -  target: 0.6967753052998826 |    prediction: tensor(0.5803)
-->   201th/ 2299
