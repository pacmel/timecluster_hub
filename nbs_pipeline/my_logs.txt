--> LR_find
n_epoch: 3
cb: LRFinder
--> Fit
--> Create opt
---> opt_func 
self.model: ORELM_torch(
  (inputAE): FOSELM_torch()
  (hiddenAE): FOSELM_torch()
)
self.splitter(self.model): []
Learning rate: 0.001
OPT func: <function Adam at 0x7f8eaf262dd0>
Adam optimizer
Get cbs
decouple_wd: True
weight_decay <function weight_decay at 0x7f8eaf2627a0>
l2_reg <function l2_reg at 0x7f8eaf262830>
Cbs: [<function weight_decay at 0x7f8eaf2627a0>]
Add to cbs
average_sqr_grad<function average_sqr_grad at 0x7f8eaf262950>
step_stat<function step_stat at 0x7f8eaf262c20>
adam_step<function adam_step at 0x7f8eaf262d40>
partial(average_grad, dampening=True): functools.partial(<function average_grad at 0x7f8eaf2628c0>, dampening=True)
About to get optimizer
Get params
Get cbs
Get defaults
Get param list from params: []
Get hyperes
Set hypers
Set frozen idx
Return optimizer
-- opt_func -> 
Estoy aqui
--> bn_bias_state
--> norm bias params
Getting res
--> norm bias params
Getting res
Okay got res
About to return
--> norm bias params
Getting res
Okay got res
About to return
Okay got res
About to return
mapping var [tensor([[-0.5040,  0.3977, -0.2986,  0.4099,  0.5373, -0.8866, -0.5283, -0.0956,
          0.3371,  0.4291, -0.5562, -0.0354,  0.6489, -0.7505, -0.1940,  0.7543,
          0.7996,  0.4207,  0.0034, -0.1975, -0.7938,  0.0936, -0.1774,  0.7550,
          0.0565]], grad_fn=<SubBackward0>), tensor([[-0.0717,  0.3356,  0.4120, -0.4970, -0.8808,  0.8454,  0.4416, -0.6135,
          0.8051,  0.0723, -0.6930,  0.3070,  0.6031, -0.4744, -0.8249,  0.6204,
          0.8642,  0.6299, -0.6454,  0.1378,  0.0723,  0.7249,  0.7542, -0.4302,
          0.6675]], grad_fn=<SubBackward0>), tensor([[ 0.1672,  0.6357,  0.3414,  0.8804,  0.9681, -0.9522, -0.2547,  0.6516,
          0.3739,  0.6962, -0.2616,  0.1454, -0.8589,  0.9769, -0.3588,  0.4407,
         -0.3254, -0.4750,  0.2678,  0.2762, -0.2543, -0.9892, -0.6785,  0.0498,
         -0.7959]], grad_fn=<SubBackward0>)]
Returning
Got norm bias state
--> bn_bias_state
--> norm bias params
Getting res
--> norm bias params
Getting res
Okay got res
About to return
--> norm bias params
Getting res
Okay got res
About to return
Okay got res
About to return
mapping var []
Returning
Create opt -->
About to fit
Event: fit
Function: <bound method Learner._do_fit of <fastai.learner.Learner object at 0x7f8ce9e4ff70>>
--> _do_fit
epoch 0:
Event: epoch
Function: <bound method Learner._do_epoch of <fastai.learner.Learner object at 0x7f8ce9e4ff70>>
--> Do epoch
Event: train
Function: <bound method Learner.all_batches of <fastai.learner.Learner object at 0x7f8ce9e4ff70>>
Set the model to training mode
... Enabling Vs Code execution ...
--> Al batches
Event: batch
Function: <bound method Learner._do_one_batch of <fastai.learner.Learner object at 0x7f8ce9e4ff70>>
--> Do one batch
--> Forward
features ~ (num_samples, num_Inputs, num_steps - nwindows) = torch.Size([64, 1, 25])
--> Input AE
--> Foselm: Train
FOSELM Features & targets shape
Features ~torch.Size([64, 1, 25])
Targets ~torch.Size([64, 1, 25])
64 1
Traceback (most recent call last):
  File "/tmp/ipykernel_1263083/1119649501.py", line 16, in <module>
    lr_valley, lr_steep = learn.lr_find(suggest_funcs=[valley, steep])
  File "/home/macu/env/lib/python3.10/site-packages/fastai/callback/schedule.py", line 309, in lr_find
    with self.no_logging(): self.fit(n_epoch, cbs=cb)
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 316, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 214, in _with_events
    try: self(f'before_{event_type}');  f()
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 302, in _do_fit
    self._with_events(self._do_epoch, 'epoch', CancelEpochException)
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 214, in _with_events
    try: self(f'before_{event_type}');  f()
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 289, in _do_epoch
    self._do_epoch_train()
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 280, in _do_epoch_train
    self._with_events(self.all_batches, 'train', CancelTrainException)
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 214, in _with_events
    try: self(f'before_{event_type}');  f()
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 221, in all_batches
    for o in enumerate(self.dl): self.one_batch(*o)
  File "/home/macu/lib/tsai/tsai/learner.py", line 40, in one_batch
    self._with_events(self._do_one_batch, 'batch', CancelBatchException)
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 214, in _with_events
    try: self(f'before_{event_type}');  f()
  File "/home/macu/env/lib/python3.10/site-packages/fastai/learner.py", line 240, in _do_one_batch
    self.pred = self.model(*self.xb)
  File "/home/macu/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/macu/work/nbs/orelm/orelm_torch.py", line 276, in forward
    features = self.calculateHiddenLayerActivation(features, 3) #Revisar esto...
  File "/home/macu/work/nbs/orelm/orelm_torch.py", line 122, in calculateHiddenLayerActivation
    self.inputWeights = self.__calculateInputWeightsUsingAE(features)
  File "/home/macu/work/nbs/orelm/orelm_torch.py", line 103, in __calculateInputWeightsUsingAE
    self.inputAE.train_func(features=features,targets=features)
  File "/home/macu/work/nbs/orelm/foselm_torch.py", line 152, in train_func
    assert num_samples == num_vars, \
AssertionError: FOS_ELM:train: differs features 1 targets 64

