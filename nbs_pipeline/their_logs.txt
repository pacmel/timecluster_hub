-->     1th/  198
Training[2301] shape: torch.Size([1, 2301])
Targets[2301] shape: torch.Size([1, 1])
Features[2301] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    1th/  198 timeStep ( 2301)-  target:  -0.7898   |    prediction:  -0.6141 
-->     2th/  198
Training[2302] shape: torch.Size([1, 2301])
Targets[2302] shape: torch.Size([1, 1])
Features[2302] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    2th/  198 timeStep ( 2302)-  target:   0.8111   |    prediction:   0.2613 
-->     3th/  198
Training[2303] shape: torch.Size([1, 2301])
Targets[2303] shape: torch.Size([1, 1])
Features[2303] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    3th/  198 timeStep ( 2303)-  target:   1.6116   |    prediction:   0.8244 
-->     4th/  198
Training[2304] shape: torch.Size([1, 2301])
Targets[2304] shape: torch.Size([1, 1])
Features[2304] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    4th/  198 timeStep ( 2304)-  target:  -0.7898   |    prediction:  -0.0165 
-->     5th/  198
Training[2305] shape: torch.Size([1, 2301])
Targets[2305] shape: torch.Size([1, 1])
Features[2305] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    5th/  198 timeStep ( 2305)-  target:  -0.6755   |    prediction:  -0.0293 
-->     6th/  198
Training[2306] shape: torch.Size([1, 2301])
Targets[2306] shape: torch.Size([1, 1])
Features[2306] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    6th/  198 timeStep ( 2306)-  target:   0.8111   |    prediction:   0.1891 
-->     7th/  198
Training[2307] shape: torch.Size([1, 2301])
Targets[2307] shape: torch.Size([1, 1])
Features[2307] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    7th/  198 timeStep ( 2307)-  target:   1.2685   |    prediction:   0.3177 
-->     8th/  198
Training[2308] shape: torch.Size([1, 2301])
Targets[2308] shape: torch.Size([1, 1])
Features[2308] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    8th/  198 timeStep ( 2308)-  target:   0.3537   |    prediction:   0.4437 
-->     9th/  198
Training[2309] shape: torch.Size([1, 2301])
Targets[2309] shape: torch.Size([1, 1])
Features[2309] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
    9th/  198 timeStep ( 2309)-  target:  -1.0185   |    prediction:  -0.0640 
-->    10th/  198
Training[2310] shape: torch.Size([1, 2301])
Targets[2310] shape: torch.Size([1, 1])
Features[2310] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   10th/  198 timeStep ( 2310)-  target:  -0.5611   |    prediction:   0.0625 
-->    11th/  198
Training[2311] shape: torch.Size([1, 2301])
Targets[2311] shape: torch.Size([1, 1])
Features[2311] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   11th/  198 timeStep ( 2311)-  target:  -0.1037   |    prediction:   0.0456 
-->    12th/  198
Training[2312] shape: torch.Size([1, 2301])
Targets[2312] shape: torch.Size([1, 1])
Features[2312] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   12th/  198 timeStep ( 2312)-  target:  -2.1620   |    prediction:  -0.2812 
-->    13th/  198
Training[2313] shape: torch.Size([1, 2301])
Targets[2313] shape: torch.Size([1, 1])
Features[2313] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   13th/  198 timeStep ( 2313)-  target:  -1.9333   |    prediction:  -0.7358 
-->    14th/  198
Training[2314] shape: torch.Size([1, 2301])
Targets[2314] shape: torch.Size([1, 1])
Features[2314] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   14th/  198 timeStep ( 2314)-  target:  -1.8190   |    prediction:  -0.5693 
-->    15th/  198
Training[2315] shape: torch.Size([1, 2301])
Targets[2315] shape: torch.Size([1, 1])
Features[2315] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   15th/  198 timeStep ( 2315)-  target:  -0.7898   |    prediction:  -0.4807 
-->    16th/  198
Training[2316] shape: torch.Size([1, 2301])
Targets[2316] shape: torch.Size([1, 1])
Features[2316] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   16th/  198 timeStep ( 2316)-  target:  -2.7338   |    prediction:  -0.5297 
-->    17th/  198
Training[2317] shape: torch.Size([1, 2301])
Targets[2317] shape: torch.Size([1, 1])
Features[2317] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   17th/  198 timeStep ( 2317)-  target:  -2.8482   |    prediction:  -0.9108 
-->    18th/  198
Training[2318] shape: torch.Size([1, 2301])
Targets[2318] shape: torch.Size([1, 1])
Features[2318] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   18th/  198 timeStep ( 2318)-  target:  -0.4468   |    prediction:  -0.7057 
-->    19th/  198
Training[2319] shape: torch.Size([1, 2301])
Targets[2319] shape: torch.Size([1, 1])
Features[2319] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   19th/  198 timeStep ( 2319)-  target:  -0.1037   |    prediction:  -0.3505 
-->    20th/  198
Training[2320] shape: torch.Size([1, 2301])
Targets[2320] shape: torch.Size([1, 1])
Features[2320] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   20th/  198 timeStep ( 2320)-  target:   0.1250   |    prediction:  -0.2100 
-->    21th/  198
Training[2321] shape: torch.Size([1, 2301])
Targets[2321] shape: torch.Size([1, 1])
Features[2321] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   21th/  198 timeStep ( 2321)-  target:  -0.9042   |    prediction:  -0.7713 
-->    22th/  198
Training[2322] shape: torch.Size([1, 2301])
Targets[2322] shape: torch.Size([1, 1])
Features[2322] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   22th/  198 timeStep ( 2322)-  target:  -1.5903   |    prediction:  -0.4803 
-->    23th/  198
Training[2323] shape: torch.Size([1, 2301])
Targets[2323] shape: torch.Size([1, 1])
Features[2323] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   23th/  198 timeStep ( 2323)-  target:  -0.9042   |    prediction:  -0.2936 
-->    24th/  198
Training[2324] shape: torch.Size([1, 2301])
Targets[2324] shape: torch.Size([1, 1])
Features[2324] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   24th/  198 timeStep ( 2324)-  target:  -1.2472   |    prediction:  -0.7066 
-->    25th/  198
Training[2325] shape: torch.Size([1, 2301])
Targets[2325] shape: torch.Size([1, 1])
Features[2325] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   25th/  198 timeStep ( 2325)-  target:  -1.0185   |    prediction:  -0.6748 
-->    26th/  198
Training[2326] shape: torch.Size([1, 2301])
Targets[2326] shape: torch.Size([1, 1])
Features[2326] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   26th/  198 timeStep ( 2326)-  target:  -0.9042   |    prediction:  -0.2808 
-->    27th/  198
Training[2327] shape: torch.Size([1, 2301])
Targets[2327] shape: torch.Size([1, 1])
Features[2327] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   27th/  198 timeStep ( 2327)-  target:  -0.2180   |    prediction:  -0.8759 
-->    28th/  198
Training[2328] shape: torch.Size([1, 2301])
Targets[2328] shape: torch.Size([1, 1])
Features[2328] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   28th/  198 timeStep ( 2328)-  target:  -0.4468   |    prediction:  -0.2609 
-->    29th/  198
Training[2329] shape: torch.Size([1, 2301])
Targets[2329] shape: torch.Size([1, 1])
Features[2329] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   29th/  198 timeStep ( 2329)-  target:  -0.5611   |    prediction:  -0.7502 
-->    30th/  198
Training[2330] shape: torch.Size([1, 2301])
Targets[2330] shape: torch.Size([1, 1])
Features[2330] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   30th/  198 timeStep ( 2330)-  target:   0.1250   |    prediction:  -0.3109 
-->    31th/  198
Training[2331] shape: torch.Size([1, 2301])
Targets[2331] shape: torch.Size([1, 1])
Features[2331] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   31th/  198 timeStep ( 2331)-  target:   0.1250   |    prediction:   0.5394 
-->    32th/  198
Training[2332] shape: torch.Size([1, 2301])
Targets[2332] shape: torch.Size([1, 1])
Features[2332] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   32th/  198 timeStep ( 2332)-  target:   0.2394   |    prediction:  -0.1470 
-->    33th/  198
Training[2333] shape: torch.Size([1, 2301])
Targets[2333] shape: torch.Size([1, 1])
Features[2333] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   33th/  198 timeStep ( 2333)-  target:   1.0398   |    prediction:   0.5564 
-->    34th/  198
Training[2334] shape: torch.Size([1, 2301])
Targets[2334] shape: torch.Size([1, 1])
Features[2334] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   34th/  198 timeStep ( 2334)-  target:   1.2685   |    prediction:   0.2123 
-->    35th/  198
Training[2335] shape: torch.Size([1, 2301])
Targets[2335] shape: torch.Size([1, 1])
Features[2335] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   35th/  198 timeStep ( 2335)-  target:   1.2685   |    prediction:   0.0756 
-->    36th/  198
Training[2336] shape: torch.Size([1, 2301])
Targets[2336] shape: torch.Size([1, 1])
Features[2336] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   36th/  198 timeStep ( 2336)-  target:   1.0398   |    prediction:  -0.1040 
-->    37th/  198
Training[2337] shape: torch.Size([1, 2301])
Targets[2337] shape: torch.Size([1, 1])
Features[2337] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   37th/  198 timeStep ( 2337)-  target:   0.6968   |    prediction:   0.1876 
-->    38th/  198
Training[2338] shape: torch.Size([1, 2301])
Targets[2338] shape: torch.Size([1, 1])
Features[2338] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   38th/  198 timeStep ( 2338)-  target:   0.2394   |    prediction:   0.0064 
-->    39th/  198
Training[2339] shape: torch.Size([1, 2301])
Targets[2339] shape: torch.Size([1, 1])
Features[2339] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   39th/  198 timeStep ( 2339)-  target:   0.4681   |    prediction:   0.4345 
-->    40th/  198
Training[2340] shape: torch.Size([1, 2301])
Targets[2340] shape: torch.Size([1, 1])
Features[2340] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   40th/  198 timeStep ( 2340)-  target:  -0.2180   |    prediction:   0.1621 
-->    41th/  198
Training[2341] shape: torch.Size([1, 2301])
Targets[2341] shape: torch.Size([1, 1])
Features[2341] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   41th/  198 timeStep ( 2341)-  target:  -1.0185   |    prediction:  -1.0882 
-->    42th/  198
Training[2342] shape: torch.Size([1, 2301])
Targets[2342] shape: torch.Size([1, 1])
Features[2342] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   42th/  198 timeStep ( 2342)-  target:  -1.2472   |    prediction:  -0.6347 
-->    43th/  198
Training[2343] shape: torch.Size([1, 2301])
Targets[2343] shape: torch.Size([1, 1])
Features[2343] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   43th/  198 timeStep ( 2343)-  target:  -1.3616   |    prediction:  -0.2111 
-->    44th/  198
Training[2344] shape: torch.Size([1, 2301])
Targets[2344] shape: torch.Size([1, 1])
Features[2344] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   44th/  198 timeStep ( 2344)-  target:  -1.4759   |    prediction:   0.1814 
-->    45th/  198
Training[2345] shape: torch.Size([1, 2301])
Targets[2345] shape: torch.Size([1, 1])
Features[2345] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   45th/  198 timeStep ( 2345)-  target:  -0.7898   |    prediction:  -0.0585 
-->    46th/  198
Training[2346] shape: torch.Size([1, 2301])
Targets[2346] shape: torch.Size([1, 1])
Features[2346] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   46th/  198 timeStep ( 2346)-  target:   0.0107   |    prediction:  -0.6602 
-->    47th/  198
Training[2347] shape: torch.Size([1, 2301])
Targets[2347] shape: torch.Size([1, 1])
Features[2347] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   47th/  198 timeStep ( 2347)-  target:  -1.4759   |    prediction:  -0.6778 
-->    48th/  198
Training[2348] shape: torch.Size([1, 2301])
Targets[2348] shape: torch.Size([1, 1])
Features[2348] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   48th/  198 timeStep ( 2348)-  target:  -1.3616   |    prediction:  -0.2732 
-->    49th/  198
Training[2349] shape: torch.Size([1, 2301])
Targets[2349] shape: torch.Size([1, 1])
Features[2349] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   49th/  198 timeStep ( 2349)-  target:  -2.0477   |    prediction:  -1.1653 
-->    50th/  198
Training[2350] shape: torch.Size([1, 2301])
Targets[2350] shape: torch.Size([1, 1])
Features[2350] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   50th/  198 timeStep ( 2350)-  target:  -1.8190   |    prediction:  -1.1344 
-->    51th/  198
Training[2351] shape: torch.Size([1, 2301])
Targets[2351] shape: torch.Size([1, 1])
Features[2351] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   51th/  198 timeStep ( 2351)-  target:  -0.7898   |    prediction:  -1.2367 
-->    52th/  198
Training[2352] shape: torch.Size([1, 2301])
Targets[2352] shape: torch.Size([1, 1])
Features[2352] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   52th/  198 timeStep ( 2352)-  target:  -0.1037   |    prediction:   0.2782 
-->    53th/  198
Training[2353] shape: torch.Size([1, 2301])
Targets[2353] shape: torch.Size([1, 1])
Features[2353] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   53th/  198 timeStep ( 2353)-  target:  -0.2180   |    prediction:  -0.5054 
-->    54th/  198
Training[2354] shape: torch.Size([1, 2301])
Targets[2354] shape: torch.Size([1, 1])
Features[2354] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   54th/  198 timeStep ( 2354)-  target:   0.2394   |    prediction:  -0.2696 
-->    55th/  198
Training[2355] shape: torch.Size([1, 2301])
Targets[2355] shape: torch.Size([1, 1])
Features[2355] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   55th/  198 timeStep ( 2355)-  target:   0.3537   |    prediction:   0.0105 
-->    56th/  198
Training[2356] shape: torch.Size([1, 2301])
Targets[2356] shape: torch.Size([1, 1])
Features[2356] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   56th/  198 timeStep ( 2356)-  target:   0.5824   |    prediction:  -0.3730 
-->    57th/  198
Training[2357] shape: torch.Size([1, 2301])
Targets[2357] shape: torch.Size([1, 1])
Features[2357] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   57th/  198 timeStep ( 2357)-  target:  -0.2180   |    prediction:  -0.1957 
-->    58th/  198
Training[2358] shape: torch.Size([1, 2301])
Targets[2358] shape: torch.Size([1, 1])
Features[2358] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   58th/  198 timeStep ( 2358)-  target:  -1.2472   |    prediction:  -0.8136 
-->    59th/  198
Training[2359] shape: torch.Size([1, 2301])
Targets[2359] shape: torch.Size([1, 1])
Features[2359] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   59th/  198 timeStep ( 2359)-  target:  -1.0185   |    prediction:  -0.9269 
-->    60th/  198
Training[2360] shape: torch.Size([1, 2301])
Targets[2360] shape: torch.Size([1, 1])
Features[2360] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   60th/  198 timeStep ( 2360)-  target:  -0.9042   |    prediction:  -1.3939 
-->    61th/  198
Training[2361] shape: torch.Size([1, 2301])
Targets[2361] shape: torch.Size([1, 1])
Features[2361] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   61th/  198 timeStep ( 2361)-  target:   0.3537   |    prediction:  -1.0700 
-->    62th/  198
Training[2362] shape: torch.Size([1, 2301])
Targets[2362] shape: torch.Size([1, 1])
Features[2362] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   62th/  198 timeStep ( 2362)-  target:   0.0107   |    prediction:  -0.2867 
-->    63th/  198
Training[2363] shape: torch.Size([1, 2301])
Targets[2363] shape: torch.Size([1, 1])
Features[2363] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   63th/  198 timeStep ( 2363)-  target:   0.1250   |    prediction:   0.0303 
-->    64th/  198
Training[2364] shape: torch.Size([1, 2301])
Targets[2364] shape: torch.Size([1, 1])
Features[2364] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   64th/  198 timeStep ( 2364)-  target:   0.3537   |    prediction:  -0.2746 
-->    65th/  198
Training[2365] shape: torch.Size([1, 2301])
Targets[2365] shape: torch.Size([1, 1])
Features[2365] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   65th/  198 timeStep ( 2365)-  target:   0.9255   |    prediction:   0.4816 
-->    66th/  198
Training[2366] shape: torch.Size([1, 2301])
Targets[2366] shape: torch.Size([1, 1])
Features[2366] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   66th/  198 timeStep ( 2366)-  target:   0.0107   |    prediction:   0.2925 
-->    67th/  198
Training[2367] shape: torch.Size([1, 2301])
Targets[2367] shape: torch.Size([1, 1])
Features[2367] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   67th/  198 timeStep ( 2367)-  target:   0.5824   |    prediction:   0.2470 
-->    68th/  198
Training[2368] shape: torch.Size([1, 2301])
Targets[2368] shape: torch.Size([1, 1])
Features[2368] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   68th/  198 timeStep ( 2368)-  target:   0.6968   |    prediction:   0.3425 
-->    69th/  198
Training[2369] shape: torch.Size([1, 2301])
Targets[2369] shape: torch.Size([1, 1])
Features[2369] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   69th/  198 timeStep ( 2369)-  target:  -0.4468   |    prediction:   0.0427 
-->    70th/  198
Training[2370] shape: torch.Size([1, 2301])
Targets[2370] shape: torch.Size([1, 1])
Features[2370] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   70th/  198 timeStep ( 2370)-  target:   0.6968   |    prediction:   0.4575 
-->    71th/  198
Training[2371] shape: torch.Size([1, 2301])
Targets[2371] shape: torch.Size([1, 1])
Features[2371] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   71th/  198 timeStep ( 2371)-  target:   0.3537   |    prediction:   1.2104 
-->    72th/  198
Training[2372] shape: torch.Size([1, 2301])
Targets[2372] shape: torch.Size([1, 1])
Features[2372] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   72th/  198 timeStep ( 2372)-  target:  -0.1037   |    prediction:  -0.2164 
-->    73th/  198
Training[2373] shape: torch.Size([1, 2301])
Targets[2373] shape: torch.Size([1, 1])
Features[2373] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   73th/  198 timeStep ( 2373)-  target:   0.0107   |    prediction:   0.0720 
-->    74th/  198
Training[2374] shape: torch.Size([1, 2301])
Targets[2374] shape: torch.Size([1, 1])
Features[2374] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   74th/  198 timeStep ( 2374)-  target:  -0.6755   |    prediction:  -0.1473 
-->    75th/  198
Training[2375] shape: torch.Size([1, 2301])
Targets[2375] shape: torch.Size([1, 1])
Features[2375] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   75th/  198 timeStep ( 2375)-  target:   0.6968   |    prediction:  -0.4897 
-->    76th/  198
Training[2376] shape: torch.Size([1, 2301])
Targets[2376] shape: torch.Size([1, 1])
Features[2376] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   76th/  198 timeStep ( 2376)-  target:   0.1250   |    prediction:   0.1779 
-->    77th/  198
Training[2377] shape: torch.Size([1, 2301])
Targets[2377] shape: torch.Size([1, 1])
Features[2377] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   77th/  198 timeStep ( 2377)-  target:  -1.0185   |    prediction:  -0.3537 
-->    78th/  198
Training[2378] shape: torch.Size([1, 2301])
Targets[2378] shape: torch.Size([1, 1])
Features[2378] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   78th/  198 timeStep ( 2378)-  target:  -0.7898   |    prediction:  -0.1397 
-->    79th/  198
Training[2379] shape: torch.Size([1, 2301])
Targets[2379] shape: torch.Size([1, 1])
Features[2379] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   79th/  198 timeStep ( 2379)-  target:  -1.2472   |    prediction:  -1.0588 
-->    80th/  198
Training[2380] shape: torch.Size([1, 2301])
Targets[2380] shape: torch.Size([1, 1])
Features[2380] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   80th/  198 timeStep ( 2380)-  target:  -0.7898   |    prediction:  -0.8525 
-->    81th/  198
Training[2381] shape: torch.Size([1, 2301])
Targets[2381] shape: torch.Size([1, 1])
Features[2381] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   81th/  198 timeStep ( 2381)-  target:  -0.9042   |    prediction:  -0.9975 
-->    82th/  198
Training[2382] shape: torch.Size([1, 2301])
Targets[2382] shape: torch.Size([1, 1])
Features[2382] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   82th/  198 timeStep ( 2382)-  target:  -0.2180   |    prediction:  -0.1928 
-->    83th/  198
Training[2383] shape: torch.Size([1, 2301])
Targets[2383] shape: torch.Size([1, 1])
Features[2383] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   83th/  198 timeStep ( 2383)-  target:  -2.2764   |    prediction:  -0.7701 
-->    84th/  198
Training[2384] shape: torch.Size([1, 2301])
Targets[2384] shape: torch.Size([1, 1])
Features[2384] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   84th/  198 timeStep ( 2384)-  target:  -1.8190   |    prediction:  -1.5862 
-->    85th/  198
Training[2385] shape: torch.Size([1, 2301])
Targets[2385] shape: torch.Size([1, 1])
Features[2385] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   85th/  198 timeStep ( 2385)-  target:  -6.1644   |    prediction:  -3.3811 
-->    86th/  198
Training[2386] shape: torch.Size([1, 2301])
Targets[2386] shape: torch.Size([1, 1])
Features[2386] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   86th/  198 timeStep ( 2386)-  target:  -1.5903   |    prediction:  -0.7534 
-->    87th/  198
Training[2387] shape: torch.Size([1, 2301])
Targets[2387] shape: torch.Size([1, 1])
Features[2387] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   87th/  198 timeStep ( 2387)-  target:  -2.6195   |    prediction:  -1.7958 
-->    88th/  198
Training[2388] shape: torch.Size([1, 2301])
Targets[2388] shape: torch.Size([1, 1])
Features[2388] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   88th/  198 timeStep ( 2388)-  target:  -7.0792   |    prediction:  -2.1749 
-->    89th/  198
Training[2389] shape: torch.Size([1, 2301])
Targets[2389] shape: torch.Size([1, 1])
Features[2389] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   89th/  198 timeStep ( 2389)-  target:  -1.7046   |    prediction:  -1.6345 
-->    90th/  198
Training[2390] shape: torch.Size([1, 2301])
Targets[2390] shape: torch.Size([1, 1])
Features[2390] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   90th/  198 timeStep ( 2390)-  target:  -2.3908   |    prediction:  -1.2443 
-->    91th/  198
Training[2391] shape: torch.Size([1, 2301])
Targets[2391] shape: torch.Size([1, 1])
Features[2391] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   91th/  198 timeStep ( 2391)-  target:  -2.6195   |    prediction:  -3.0999 
-->    92th/  198
Training[2392] shape: torch.Size([1, 2301])
Targets[2392] shape: torch.Size([1, 1])
Features[2392] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   92th/  198 timeStep ( 2392)-  target:  -6.0500   |    prediction:  -3.7709 
-->    93th/  198
Training[2393] shape: torch.Size([1, 2301])
Targets[2393] shape: torch.Size([1, 1])
Features[2393] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   93th/  198 timeStep ( 2393)-  target:  -3.1912   |    prediction:  -1.4455 
-->    94th/  198
Training[2394] shape: torch.Size([1, 2301])
Targets[2394] shape: torch.Size([1, 1])
Features[2394] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   94th/  198 timeStep ( 2394)-  target:   0.4681   |    prediction:  -0.6593 
-->    95th/  198
Training[2395] shape: torch.Size([1, 2301])
Targets[2395] shape: torch.Size([1, 1])
Features[2395] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   95th/  198 timeStep ( 2395)-  target:  -0.2180   |    prediction:  -1.1051 
-->    96th/  198
Training[2396] shape: torch.Size([1, 2301])
Targets[2396] shape: torch.Size([1, 1])
Features[2396] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   96th/  198 timeStep ( 2396)-  target:  -1.5903   |    prediction:  -1.9496 
-->    97th/  198
Training[2397] shape: torch.Size([1, 2301])
Targets[2397] shape: torch.Size([1, 1])
Features[2397] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   97th/  198 timeStep ( 2397)-  target:  -0.4468   |    prediction:   0.1879 
-->    98th/  198
Training[2398] shape: torch.Size([1, 2301])
Targets[2398] shape: torch.Size([1, 1])
Features[2398] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   98th/  198 timeStep ( 2398)-  target:   0.8111   |    prediction:   1.0023 
-->    99th/  198
Training[2399] shape: torch.Size([1, 2301])
Targets[2399] shape: torch.Size([1, 1])
Features[2399] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
   99th/  198 timeStep ( 2399)-  target:   0.8111   |    prediction:   0.1646 
-->   100th/  198
Training[2400] shape: torch.Size([1, 2301])
Targets[2400] shape: torch.Size([1, 1])
Features[2400] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  100th/  198 timeStep ( 2400)-  target:   0.8111   |    prediction:   0.8130 
-->   101th/  198
Training[2401] shape: torch.Size([1, 2301])
Targets[2401] shape: torch.Size([1, 1])
Features[2401] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  101th/  198 timeStep ( 2401)-  target:   0.5824   |    prediction:   0.6887 
-->   102th/  198
Training[2402] shape: torch.Size([1, 2301])
Targets[2402] shape: torch.Size([1, 1])
Features[2402] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  102th/  198 timeStep ( 2402)-  target:  -0.1037   |    prediction:   0.0012 
-->   103th/  198
Training[2403] shape: torch.Size([1, 2301])
Targets[2403] shape: torch.Size([1, 1])
Features[2403] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  103th/  198 timeStep ( 2403)-  target:   0.0107   |    prediction:   0.8290 
-->   104th/  198
Training[2404] shape: torch.Size([1, 2301])
Targets[2404] shape: torch.Size([1, 1])
Features[2404] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  104th/  198 timeStep ( 2404)-  target:   0.0107   |    prediction:   0.4640 
-->   105th/  198
Training[2405] shape: torch.Size([1, 2301])
Targets[2405] shape: torch.Size([1, 1])
Features[2405] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  105th/  198 timeStep ( 2405)-  target:  -1.8190   |    prediction:  -0.5486 
-->   106th/  198
Training[2406] shape: torch.Size([1, 2301])
Targets[2406] shape: torch.Size([1, 1])
Features[2406] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  106th/  198 timeStep ( 2406)-  target:  -3.3056   |    prediction:  -1.6155 
-->   107th/  198
Training[2407] shape: torch.Size([1, 2301])
Targets[2407] shape: torch.Size([1, 1])
Features[2407] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  107th/  198 timeStep ( 2407)-  target:  -1.4759   |    prediction:  -1.9104 
-->   108th/  198
Training[2408] shape: torch.Size([1, 2301])
Targets[2408] shape: torch.Size([1, 1])
Features[2408] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  108th/  198 timeStep ( 2408)-  target:  -1.2472   |    prediction:  -3.7885 
-->   109th/  198
Training[2409] shape: torch.Size([1, 2301])
Targets[2409] shape: torch.Size([1, 1])
Features[2409] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  109th/  198 timeStep ( 2409)-  target:  -3.3056   |    prediction:  -3.4168 
-->   110th/  198
Training[2410] shape: torch.Size([1, 2301])
Targets[2410] shape: torch.Size([1, 1])
Features[2410] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  110th/  198 timeStep ( 2410)-  target:  -1.3616   |    prediction:  -1.5890 
-->   111th/  198
Training[2411] shape: torch.Size([1, 2301])
Targets[2411] shape: torch.Size([1, 1])
Features[2411] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  111th/  198 timeStep ( 2411)-  target:  -1.1329   |    prediction:  -2.2486 
-->   112th/  198
Training[2412] shape: torch.Size([1, 2301])
Targets[2412] shape: torch.Size([1, 1])
Features[2412] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  112th/  198 timeStep ( 2412)-  target:  -0.7898   |    prediction:  -0.7929 
-->   113th/  198
Training[2413] shape: torch.Size([1, 2301])
Targets[2413] shape: torch.Size([1, 1])
Features[2413] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  113th/  198 timeStep ( 2413)-  target:  -0.9042   |    prediction:  -1.1959 
-->   114th/  198
Training[2414] shape: torch.Size([1, 2301])
Targets[2414] shape: torch.Size([1, 1])
Features[2414] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  114th/  198 timeStep ( 2414)-  target:   0.5824   |    prediction:   0.6091 
-->   115th/  198
Training[2415] shape: torch.Size([1, 2301])
Targets[2415] shape: torch.Size([1, 1])
Features[2415] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  115th/  198 timeStep ( 2415)-  target:  -1.3616   |    prediction:  -1.3305 
-->   116th/  198
Training[2416] shape: torch.Size([1, 2301])
Targets[2416] shape: torch.Size([1, 1])
Features[2416] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  116th/  198 timeStep ( 2416)-  target:  -0.5611   |    prediction:   0.1767 
-->   117th/  198
Training[2417] shape: torch.Size([1, 2301])
Targets[2417] shape: torch.Size([1, 1])
Features[2417] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  117th/  198 timeStep ( 2417)-  target:  -1.0185   |    prediction:  -0.7738 
-->   118th/  198
Training[2418] shape: torch.Size([1, 2301])
Targets[2418] shape: torch.Size([1, 1])
Features[2418] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  118th/  198 timeStep ( 2418)-  target:  -1.3616   |    prediction:  -1.1684 
-->   119th/  198
Training[2419] shape: torch.Size([1, 2301])
Targets[2419] shape: torch.Size([1, 1])
Features[2419] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  119th/  198 timeStep ( 2419)-  target:  -2.0477   |    prediction:  -1.4634 
-->   120th/  198
Training[2420] shape: torch.Size([1, 2301])
Targets[2420] shape: torch.Size([1, 1])
Features[2420] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  120th/  198 timeStep ( 2420)-  target:  -1.5903   |    prediction:  -1.0194 
-->   121th/  198
Training[2421] shape: torch.Size([1, 2301])
Targets[2421] shape: torch.Size([1, 1])
Features[2421] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  121th/  198 timeStep ( 2421)-  target:   0.3537   |    prediction:  -0.7573 
-->   122th/  198
Training[2422] shape: torch.Size([1, 2301])
Targets[2422] shape: torch.Size([1, 1])
Features[2422] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  122th/  198 timeStep ( 2422)-  target:  -1.3616   |    prediction:  -0.4935 
-->   123th/  198
Training[2423] shape: torch.Size([1, 2301])
Targets[2423] shape: torch.Size([1, 1])
Features[2423] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  123th/  198 timeStep ( 2423)-  target:  -1.8190   |    prediction:  -1.2963 
-->   124th/  198
Training[2424] shape: torch.Size([1, 2301])
Targets[2424] shape: torch.Size([1, 1])
Features[2424] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  124th/  198 timeStep ( 2424)-  target:  -0.2180   |    prediction:  -0.5093 
-->   125th/  198
Training[2425] shape: torch.Size([1, 2301])
Targets[2425] shape: torch.Size([1, 1])
Features[2425] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  125th/  198 timeStep ( 2425)-  target:  -0.7898   |    prediction:  -0.5997 
-->   126th/  198
Training[2426] shape: torch.Size([1, 2301])
Targets[2426] shape: torch.Size([1, 1])
Features[2426] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  126th/  198 timeStep ( 2426)-  target:  -0.9042   |    prediction:  -0.4226 
-->   127th/  198
Training[2427] shape: torch.Size([1, 2301])
Targets[2427] shape: torch.Size([1, 1])
Features[2427] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  127th/  198 timeStep ( 2427)-  target:  -1.0185   |    prediction:  -0.6229 
-->   128th/  198
Training[2428] shape: torch.Size([1, 2301])
Targets[2428] shape: torch.Size([1, 1])
Features[2428] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  128th/  198 timeStep ( 2428)-  target:  -1.7046   |    prediction:  -0.9083 
-->   129th/  198
Training[2429] shape: torch.Size([1, 2301])
Targets[2429] shape: torch.Size([1, 1])
Features[2429] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  129th/  198 timeStep ( 2429)-  target:  -1.9333   |    prediction:  -1.6788 
-->   130th/  198
Training[2430] shape: torch.Size([1, 2301])
Targets[2430] shape: torch.Size([1, 1])
Features[2430] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  130th/  198 timeStep ( 2430)-  target:  -0.3324   |    prediction:  -0.7681 
-->   131th/  198
Training[2431] shape: torch.Size([1, 2301])
Targets[2431] shape: torch.Size([1, 1])
Features[2431] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  131th/  198 timeStep ( 2431)-  target:  -0.4468   |    prediction:  -0.3734 
-->   132th/  198
Training[2432] shape: torch.Size([1, 2301])
Targets[2432] shape: torch.Size([1, 1])
Features[2432] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  132th/  198 timeStep ( 2432)-  target:  -0.6755   |    prediction:  -0.9792 
-->   133th/  198
Training[2433] shape: torch.Size([1, 2301])
Targets[2433] shape: torch.Size([1, 1])
Features[2433] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  133th/  198 timeStep ( 2433)-  target:   1.0398   |    prediction:  -0.2464 
-->   134th/  198
Training[2434] shape: torch.Size([1, 2301])
Targets[2434] shape: torch.Size([1, 1])
Features[2434] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  134th/  198 timeStep ( 2434)-  target:   0.5824   |    prediction:   0.9141 
-->   135th/  198
Training[2435] shape: torch.Size([1, 2301])
Targets[2435] shape: torch.Size([1, 1])
Features[2435] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  135th/  198 timeStep ( 2435)-  target:   0.0107   |    prediction:  -0.0035 
-->   136th/  198
Training[2436] shape: torch.Size([1, 2301])
Targets[2436] shape: torch.Size([1, 1])
Features[2436] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  136th/  198 timeStep ( 2436)-  target:   1.1542   |    prediction:   0.3385 
-->   137th/  198
Training[2437] shape: torch.Size([1, 2301])
Targets[2437] shape: torch.Size([1, 1])
Features[2437] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  137th/  198 timeStep ( 2437)-  target:   0.1250   |    prediction:   0.5379 
-->   138th/  198
Training[2438] shape: torch.Size([1, 2301])
Targets[2438] shape: torch.Size([1, 1])
Features[2438] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  138th/  198 timeStep ( 2438)-  target:   0.0107   |    prediction:   0.1207 
-->   139th/  198
Training[2439] shape: torch.Size([1, 2301])
Targets[2439] shape: torch.Size([1, 1])
Features[2439] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  139th/  198 timeStep ( 2439)-  target:   0.1250   |    prediction:   0.0742 
-->   140th/  198
Training[2440] shape: torch.Size([1, 2301])
Targets[2440] shape: torch.Size([1, 1])
Features[2440] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  140th/  198 timeStep ( 2440)-  target:  -1.7046   |    prediction:  -0.6241 
-->   141th/  198
Training[2441] shape: torch.Size([1, 2301])
Targets[2441] shape: torch.Size([1, 1])
Features[2441] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  141th/  198 timeStep ( 2441)-  target:   0.8111   |    prediction:  -0.5968 
-->   142th/  198
Training[2442] shape: torch.Size([1, 2301])
Targets[2442] shape: torch.Size([1, 1])
Features[2442] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  142th/  198 timeStep ( 2442)-  target:  -0.2180   |    prediction:  -0.2795 
-->   143th/  198
Training[2443] shape: torch.Size([1, 2301])
Targets[2443] shape: torch.Size([1, 1])
Features[2443] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  143th/  198 timeStep ( 2443)-  target:  -0.3324   |    prediction:   0.4680 
-->   144th/  198
Training[2444] shape: torch.Size([1, 2301])
Targets[2444] shape: torch.Size([1, 1])
Features[2444] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  144th/  198 timeStep ( 2444)-  target:   0.5824   |    prediction:   0.2254 
-->   145th/  198
Training[2445] shape: torch.Size([1, 2301])
Targets[2445] shape: torch.Size([1, 1])
Features[2445] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  145th/  198 timeStep ( 2445)-  target:   0.5824   |    prediction:  -0.3496 
-->   146th/  198
Training[2446] shape: torch.Size([1, 2301])
Targets[2446] shape: torch.Size([1, 1])
Features[2446] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  146th/  198 timeStep ( 2446)-  target:  -0.5611   |    prediction:  -0.2789 
-->   147th/  198
Training[2447] shape: torch.Size([1, 2301])
Targets[2447] shape: torch.Size([1, 1])
Features[2447] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  147th/  198 timeStep ( 2447)-  target:  -0.2180   |    prediction:   0.2332 
-->   148th/  198
Training[2448] shape: torch.Size([1, 2301])
Targets[2448] shape: torch.Size([1, 1])
Features[2448] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  148th/  198 timeStep ( 2448)-  target:   0.2394   |    prediction:   0.2804 
-->   149th/  198
Training[2449] shape: torch.Size([1, 2301])
Targets[2449] shape: torch.Size([1, 1])
Features[2449] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  149th/  198 timeStep ( 2449)-  target:   0.9255   |    prediction:   0.8436 
-->   150th/  198
Training[2450] shape: torch.Size([1, 2301])
Targets[2450] shape: torch.Size([1, 1])
Features[2450] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  150th/  198 timeStep ( 2450)-  target:   0.5824   |    prediction:   0.1633 
-->   151th/  198
Training[2451] shape: torch.Size([1, 2301])
Targets[2451] shape: torch.Size([1, 1])
Features[2451] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  151th/  198 timeStep ( 2451)-  target:   0.0107   |    prediction:   0.3052 
-->   152th/  198
Training[2452] shape: torch.Size([1, 2301])
Targets[2452] shape: torch.Size([1, 1])
Features[2452] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  152th/  198 timeStep ( 2452)-  target:   0.1250   |    prediction:   0.3421 
-->   153th/  198
Training[2453] shape: torch.Size([1, 2301])
Targets[2453] shape: torch.Size([1, 1])
Features[2453] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  153th/  198 timeStep ( 2453)-  target:  -0.5611   |    prediction:  -0.4124 
-->   154th/  198
Training[2454] shape: torch.Size([1, 2301])
Targets[2454] shape: torch.Size([1, 1])
Features[2454] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  154th/  198 timeStep ( 2454)-  target:   0.4681   |    prediction:   0.5411 
-->   155th/  198
Training[2455] shape: torch.Size([1, 2301])
Targets[2455] shape: torch.Size([1, 1])
Features[2455] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  155th/  198 timeStep ( 2455)-  target:   1.7260   |    prediction:   1.1556 
-->   156th/  198
Training[2456] shape: torch.Size([1, 2301])
Targets[2456] shape: torch.Size([1, 1])
Features[2456] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  156th/  198 timeStep ( 2456)-  target:   0.5824   |    prediction:   0.1029 
-->   157th/  198
Training[2457] shape: torch.Size([1, 2301])
Targets[2457] shape: torch.Size([1, 1])
Features[2457] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  157th/  198 timeStep ( 2457)-  target:   1.0398   |    prediction:   1.0685 
-->   158th/  198
Training[2458] shape: torch.Size([1, 2301])
Targets[2458] shape: torch.Size([1, 1])
Features[2458] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  158th/  198 timeStep ( 2458)-  target:  -0.7898   |    prediction:   0.5825 
-->   159th/  198
Training[2459] shape: torch.Size([1, 2301])
Targets[2459] shape: torch.Size([1, 1])
Features[2459] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  159th/  198 timeStep ( 2459)-  target:   0.8111   |    prediction:   0.6625 
-->   160th/  198
Training[2460] shape: torch.Size([1, 2301])
Targets[2460] shape: torch.Size([1, 1])
Features[2460] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  160th/  198 timeStep ( 2460)-  target:  -0.5611   |    prediction:   0.1049 
-->   161th/  198
Training[2461] shape: torch.Size([1, 2301])
Targets[2461] shape: torch.Size([1, 1])
Features[2461] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  161th/  198 timeStep ( 2461)-  target:  -0.7898   |    prediction:  -0.0657 
-->   162th/  198
Training[2462] shape: torch.Size([1, 2301])
Targets[2462] shape: torch.Size([1, 1])
Features[2462] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  162th/  198 timeStep ( 2462)-  target:   0.1250   |    prediction:  -0.3801 
-->   163th/  198
Training[2463] shape: torch.Size([1, 2301])
Targets[2463] shape: torch.Size([1, 1])
Features[2463] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  163th/  198 timeStep ( 2463)-  target:   0.3537   |    prediction:   0.2011 
-->   164th/  198
Training[2464] shape: torch.Size([1, 2301])
Targets[2464] shape: torch.Size([1, 1])
Features[2464] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  164th/  198 timeStep ( 2464)-  target:   0.1250   |    prediction:   0.3235 
-->   165th/  198
Training[2465] shape: torch.Size([1, 2301])
Targets[2465] shape: torch.Size([1, 1])
Features[2465] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  165th/  198 timeStep ( 2465)-  target:  -0.5611   |    prediction:  -0.2840 
-->   166th/  198
Training[2466] shape: torch.Size([1, 2301])
Targets[2466] shape: torch.Size([1, 1])
Features[2466] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  166th/  198 timeStep ( 2466)-  target:  -0.7898   |    prediction:  -0.3875 
-->   167th/  198
Training[2467] shape: torch.Size([1, 2301])
Targets[2467] shape: torch.Size([1, 1])
Features[2467] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  167th/  198 timeStep ( 2467)-  target:  -1.1329   |    prediction:  -0.7493 
-->   168th/  198
Training[2468] shape: torch.Size([1, 2301])
Targets[2468] shape: torch.Size([1, 1])
Features[2468] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  168th/  198 timeStep ( 2468)-  target:  -0.3324   |    prediction:  -0.3786 
-->   169th/  198
Training[2469] shape: torch.Size([1, 2301])
Targets[2469] shape: torch.Size([1, 1])
Features[2469] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  169th/  198 timeStep ( 2469)-  target:   0.2394   |    prediction:  -0.3427 
-->   170th/  198
Training[2470] shape: torch.Size([1, 2301])
Targets[2470] shape: torch.Size([1, 1])
Features[2470] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  170th/  198 timeStep ( 2470)-  target:  -1.2472   |    prediction:  -0.9681 
-->   171th/  198
Training[2471] shape: torch.Size([1, 2301])
Targets[2471] shape: torch.Size([1, 1])
Features[2471] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  171th/  198 timeStep ( 2471)-  target:  -0.2180   |    prediction:  -0.3540 
-->   172th/  198
Training[2472] shape: torch.Size([1, 2301])
Targets[2472] shape: torch.Size([1, 1])
Features[2472] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  172th/  198 timeStep ( 2472)-  target:  -1.2472   |    prediction:  -0.8265 
-->   173th/  198
Training[2473] shape: torch.Size([1, 2301])
Targets[2473] shape: torch.Size([1, 1])
Features[2473] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  173th/  198 timeStep ( 2473)-  target:  -0.3324   |    prediction:  -0.1134 
-->   174th/  198
Training[2474] shape: torch.Size([1, 2301])
Targets[2474] shape: torch.Size([1, 1])
Features[2474] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  174th/  198 timeStep ( 2474)-  target:   0.1250   |    prediction:  -0.0391 
-->   175th/  198
Training[2475] shape: torch.Size([1, 2301])
Targets[2475] shape: torch.Size([1, 1])
Features[2475] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  175th/  198 timeStep ( 2475)-  target:   0.6968   |    prediction:   0.0155 
-->   176th/  198
Training[2476] shape: torch.Size([1, 2301])
Targets[2476] shape: torch.Size([1, 1])
Features[2476] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  176th/  198 timeStep ( 2476)-  target:  -0.4468   |    prediction:  -0.0147 
-->   177th/  198
Training[2477] shape: torch.Size([1, 2301])
Targets[2477] shape: torch.Size([1, 1])
Features[2477] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  177th/  198 timeStep ( 2477)-  target:   1.7260   |    prediction:   1.3212 
-->   178th/  198
Training[2478] shape: torch.Size([1, 2301])
Targets[2478] shape: torch.Size([1, 1])
Features[2478] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  178th/  198 timeStep ( 2478)-  target:  -0.1037   |    prediction:   0.2429 
-->   179th/  198
Training[2479] shape: torch.Size([1, 2301])
Targets[2479] shape: torch.Size([1, 1])
Features[2479] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  179th/  198 timeStep ( 2479)-  target:   1.2685   |    prediction:   0.8115 
-->   180th/  198
Training[2480] shape: torch.Size([1, 2301])
Targets[2480] shape: torch.Size([1, 1])
Features[2480] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  180th/  198 timeStep ( 2480)-  target:  -0.5611   |    prediction:   0.6902 
-->   181th/  198
Training[2481] shape: torch.Size([1, 2301])
Targets[2481] shape: torch.Size([1, 1])
Features[2481] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  181th/  198 timeStep ( 2481)-  target:  -0.1037   |    prediction:  -0.6384 
-->   182th/  198
Training[2482] shape: torch.Size([1, 2301])
Targets[2482] shape: torch.Size([1, 1])
Features[2482] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  182th/  198 timeStep ( 2482)-  target:  -0.9042   |    prediction:  -0.0859 
-->   183th/  198
Training[2483] shape: torch.Size([1, 2301])
Targets[2483] shape: torch.Size([1, 1])
Features[2483] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  183th/  198 timeStep ( 2483)-  target:   0.9255   |    prediction:   0.0087 
-->   184th/  198
Training[2484] shape: torch.Size([1, 2301])
Targets[2484] shape: torch.Size([1, 1])
Features[2484] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  184th/  198 timeStep ( 2484)-  target:  -0.5611   |    prediction:  -0.5903 
-->   185th/  198
Training[2485] shape: torch.Size([1, 2301])
Targets[2485] shape: torch.Size([1, 1])
Features[2485] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  185th/  198 timeStep ( 2485)-  target:  -0.2180   |    prediction:   0.1474 
-->   186th/  198
Training[2486] shape: torch.Size([1, 2301])
Targets[2486] shape: torch.Size([1, 1])
Features[2486] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  186th/  198 timeStep ( 2486)-  target:   0.6968   |    prediction:   0.3892 
-->   187th/  198
Training[2487] shape: torch.Size([1, 2301])
Targets[2487] shape: torch.Size([1, 1])
Features[2487] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  187th/  198 timeStep ( 2487)-  target:   0.2394   |    prediction:  -0.5693 
-->   188th/  198
Training[2488] shape: torch.Size([1, 2301])
Targets[2488] shape: torch.Size([1, 1])
Features[2488] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  188th/  198 timeStep ( 2488)-  target:  -0.4468   |    prediction:  -0.2891 
-->   189th/  198
Training[2489] shape: torch.Size([1, 2301])
Targets[2489] shape: torch.Size([1, 1])
Features[2489] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  189th/  198 timeStep ( 2489)-  target:   1.0398   |    prediction:   0.3067 
-->   190th/  198
Training[2490] shape: torch.Size([1, 2301])
Targets[2490] shape: torch.Size([1, 1])
Features[2490] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  190th/  198 timeStep ( 2490)-  target:   0.1250   |    prediction:   0.0875 
-->   191th/  198
Training[2491] shape: torch.Size([1, 2301])
Targets[2491] shape: torch.Size([1, 1])
Features[2491] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  191th/  198 timeStep ( 2491)-  target:  -0.2180   |    prediction:  -0.4309 
-->   192th/  198
Training[2492] shape: torch.Size([1, 2301])
Targets[2492] shape: torch.Size([1, 1])
Features[2492] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  192th/  198 timeStep ( 2492)-  target:  -0.5611   |    prediction:  -0.3592 
-->   193th/  198
Training[2493] shape: torch.Size([1, 2301])
Targets[2493] shape: torch.Size([1, 1])
Features[2493] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  193th/  198 timeStep ( 2493)-  target:   0.0107   |    prediction:   0.1795 
-->   194th/  198
Training[2494] shape: torch.Size([1, 2301])
Targets[2494] shape: torch.Size([1, 1])
Features[2494] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  194th/  198 timeStep ( 2494)-  target:  -0.1037   |    prediction:  -0.2157 
-->   195th/  198
Training[2495] shape: torch.Size([1, 2301])
Targets[2495] shape: torch.Size([1, 1])
Features[2495] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  195th/  198 timeStep ( 2495)-  target:   0.8111   |    prediction:   0.3723 
-->   196th/  198
Training[2496] shape: torch.Size([1, 2301])
Targets[2496] shape: torch.Size([1, 1])
Features[2496] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  196th/  198 timeStep ( 2496)-  target:   0.5824   |    prediction:   0.2830 
-->   197th/  198
Training[2497] shape: torch.Size([1, 2301])
Targets[2497] shape: torch.Size([1, 1])
Features[2497] shape: torch.Size([1, 2301])
ORELM:TRAIN:samples = weights: 1 | outputs: 1
ORELM:TRAIN:Features shape: torch.Size([1, 2301])=> Columns: 1
ORELM:TRAIN:Weights number: 1 = 1
--> Calculate Hidden Activation 1
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 1: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 1-->
Calculate Hidden Activation 1 -->
--> Calculate Hidden Activation 3
Features ~ torch.Size([1, 2301])
--> Input AE
--> Foselm: Train
targets shape torch.Size([1, 2301])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 2301])
Targets ~ torch.Size([1, 2301])
Inputs ~ 2301
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 2301])
weights: torch.Size([25, 2301])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Input AE -->
--> Hidden AE
--> Foselm: Train
targets shape torch.Size([1, 25])
FOSELM:TRAIN:2SHAPED
Dimensions ok
Features ~ torch.Size([1, 25])
Targets ~ torch.Size([1, 25])
Inputs ~ 25
1 1
--> Train func (single)
Foselm - Calculate Hidden layer activation
Features: torch.Size([1, 25])
weights: torch.Size([25, 25])
Foselm - Layer normalizatison
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
FOSELM: Calculate hidden layer activation -->
non RLS
Train func (single) -->
FOSELM:Train:END -->
Hidden AE -->
Before LR 2: torch.Size([1, 2301])
---> Linear_recurrent
numSamples: 1
numInputs: 2301
numHiddenNeuron: 25
Features = (samples, inputs): torch.Size([1, 2301])
NumInputs = (hidden, inputs): torch.Size([25, 2301])
Linear_recurrent --->
--> SigmoidActFunc V ~ torch.Size([1, 25])
SigmoidActFunc -->
ORELM: calculate hidden layer activation 2-->
Get prediction
Calculate Hidden Activation 3 --> Features ~ torch.Size([1, 2301])
  197th/  198 timeStep ( 2497)-  target:   0.0107   |    prediction:   0.1956 
