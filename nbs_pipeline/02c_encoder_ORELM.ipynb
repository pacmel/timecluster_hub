{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import nbs_pipeline.utils.vscode  as vs\n",
    "vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# OR-ELM: Online Recurrent Extreme Learning Machine for time-series prediction\n",
    "\n",
    "> This notebook applies visual analytics to [OR_ELM](https://github.com/chickenbestlover/Online-Recurrent-Extreme-Learning-Machine) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tsai.all import *\n",
    "except:\n",
    "    from tsai.all import * # TODO: Weird error when loading tsai!from tchub.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from fastcore.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.schedule import *\n",
    "from dvats.all import *\n",
    "import nbs.orelm.orelm_torch as orelm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "Before running this notebook, make sure you have the `$WANDB_API_KEY` environment varibale defined with your API_KEY (run in a terminal `echo $WANDB_API_KEY` to see it). If not, run in a terminal `wandb login [API_KEY]`. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/02c-encoder_orelm.yaml\n",
      "... About to replace includes with content\n",
      "Before configuration reading \n",
      "-include: None\n",
      "-user_preferences:\n",
      "\t-use_wandb: False\n",
      "\t-wdb:\n",
      "\t\t-user: mi-santamaria\n",
      "\t\t-project_name: test-project\n",
      "\t\t-version: 0\n",
      "\t\t-mode: offline\n",
      "\t\t-artifacts_path: ./data/wandb_artifacts\n",
      "\t-data:\n",
      "\t\t-folder: ~/data/\n",
      "\t\t-fname: speed_6005\n",
      "\t\t-ftype: .csv\n",
      "\t\t-cols: [1]\n",
      "\t\t-freq: 1s\n",
      "\t-artifact:\n",
      "\t\t-alias: TiltABP\n",
      "\t-directories:\n",
      "\t\t-tmp: tmp\n",
      "\t\t-data: ~/data/speed_6005.csv\n",
      "-data:\n",
      "\t-name: speed_6005\n",
      "\t-path: ~/data/speed_6005.csv\n",
      "\t-alias: TiltABP\n",
      "\t-cols: [1]\n",
      "\t-csv_config:\n",
      "\t-date_offset: None\n",
      "\t-date_format: %Y-%m-%d %H:%M:%S\n",
      "\t-freq: 1s\n",
      "\t-joining_train_test: False\n",
      "\t-missing_values:\n",
      "\t\t-technique: None\n",
      "\t\t-constant: None\n",
      "\t-normalize_training: False\n",
      "\t-range_training: None\n",
      "\t-range_testing: None\n",
      "\t-resampling_freq: None\n",
      "\t-start_date: None\n",
      "\t-test_split: None\n",
      "\t-time_col: None\n",
      "-wandb:\n",
      "\t-user: mi-santamaria\n",
      "\t-dir: ~/test-project\n",
      "\t-enabled: False\n",
      "\t-group: None\n",
      "\t-log_learner: False\n",
      "\t-mode: offline\n",
      "\t-project: test-project\n",
      "\t-version: 0\n",
      "\t-artifacts_path: ./data/wandb_artifacts\n",
      "-configuration:\n",
      "\t-job_type: encoder_ORELM\n",
      "\t-alias: TiltABP\n",
      "\t-wandb:\n",
      "\t\t-use: False\n",
      "\t\t-entity: mi-santamaria\n",
      "\t\t-group: None\n",
      "\t\t-project: test-project\n",
      "\t-artifacts:\n",
      "\t\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t\t-valid:\n",
      "\t\t\t-data: None\n",
      "\t\t\t-size: 0.1\n",
      "\t-specifications:\n",
      "\t\t-algorithm: OSELM\n",
      "\t\t-n_epoch: 200\n",
      "\t\t-random_seed: 6\n",
      "\t\t-numHiddenNeurons: 25\n",
      "\t\t-activationFunction: sig\n",
      "\t\t-LN: True\n",
      "\t\t-AE: True\n",
      "\t\t-ORTH: True\n",
      "\t\t-lamb: 0.0001\n",
      "\t\t-weight_forgetting_factors:\n",
      "\t\t\t-input: 1\n",
      "\t\t\t-output: 0.92\n",
      "\t\t-sliding_windows:\n",
      "\t\t\t-stride: 1\n",
      "\t\t\t-size: 200\n",
      "After reading config\n",
      "-job_type: encoder_ORELM\n",
      "-alias: TiltABP\n",
      "-wandb:\n",
      "\t-use: False\n",
      "\t-entity: mi-santamaria\n",
      "\t-group: None\n",
      "\t-project: test-project\n",
      "-artifacts:\n",
      "\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t-valid:\n",
      "\t\t-data: None\n",
      "\t\t-size: 0.1\n",
      "-specifications:\n",
      "\t-algorithm: OSELM\n",
      "\t-n_epoch: 200\n",
      "\t-random_seed: 6\n",
      "\t-numHiddenNeurons: 25\n",
      "\t-activationFunction: sig\n",
      "\t-LN: True\n",
      "\t-AE: True\n",
      "\t-ORTH: True\n",
      "\t-lamb: 0.0001\n",
      "\t-weight_forgetting_factors:\n",
      "\t\t-input: 1\n",
      "\t\t-output: 0.92\n",
      "\t-sliding_windows:\n",
      "\t\t-stride: 1\n",
      "\t\t-size: 200\n"
     ]
    }
   ],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "config, job_type, dataSet = cfg.get_artifact_config_ORELM(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: test-project\n"
     ]
    }
   ],
   "source": [
    "print(\"Project: \"+config.wandb_project)\n",
    "run = wandb.init(\n",
    "    entity          = config.wandb_entity,\n",
    "    project         = config.wandb_project,\n",
    "    group           = config.wandb_group,\n",
    "    job_type        = job_type,\n",
    "    allow_val_change= True,\n",
    "    mode            = 'online' if config.use_wandb else 'disabled',\n",
    "    config          = config,\n",
    "    resume          = False\n",
    ")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dataSet:\n",
      "-folder: ~/data/\n",
      "-fname: speed_6005\n",
      "-ftype: .csv\n",
      "-cols: [1]\n",
      "-freq: 1s\n"
     ]
    }
   ],
   "source": [
    "print(\"Used dataSet:\")\n",
    "cfg.recursive_print_attrdict(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is a $w \\times s \\times t$ matrix. The first step consists in slicing the original multivariate time series into slices of shape ($w \\times d$), as shown in this figure from the paper.\n",
    "<img src=\"https://i.imgur.com/R9Fx8uO.png\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of this sliding window approach are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLIDING WINDOW --\n",
      "Len: 200\n",
      "Stride: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"--- SLIDING WINDOW --\")\n",
    "print(\"Len: \" + str(config.w))\n",
    "print(\"Stride: \" + str(config.stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>2015-08-31 18:22:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>2015-08-31 18:32:00</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>2015-08-31 18:57:00</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>2015-08-31 19:07:00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>2015-08-31 19:12:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               timestamp  value\n",
       "1970-01-01 00:00:00  2015-08-31 18:22:00     90\n",
       "1970-01-01 00:00:01  2015-08-31 18:32:00     80\n",
       "1970-01-01 00:00:02  2015-08-31 18:57:00     84\n",
       "1970-01-01 00:00:03  2015-08-31 19:07:00     94\n",
       "1970-01-01 00:00:04  2015-08-31 19:12:00     90"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get artiffact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "#convert to pandas dataset\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. variables: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of variables\n",
    "if dataSet.cols:\n",
    "    df_train = df_train.iloc[:, dataSet.cols]\n",
    "print(f'Num. variables: {len(df_train.columns)}')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:35</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:36</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:37</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:38</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:39</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90\n",
       "...                    ...\n",
       "1970-01-01 00:41:35     81\n",
       "1970-01-01 00:41:36     89\n",
       "1970-01-01 00:41:37     87\n",
       "1970-01-01 00:41:38     82\n",
       "1970-01-01 00:41:39     83\n",
       "\n",
       "[2500 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.9068\n",
      "8.744856417346142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize data by subtracting mean and dividing by std\n",
    "meanSeq     = np.mean(df_train['value'])\n",
    "print(meanSeq)\n",
    "stdSeq      = np.std(df_train['value'])\n",
    "print(stdSeq)\n",
    "df_train['value'] = (df_train['value'] - meanSeq)/stdSeq\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset shape</td>\n",
       "      <td>(2500, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Sliding windows</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sliding window shape</td>\n",
       "      <td>(1, 200)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Description      Value\n",
       "0              Dataset shape  (2500, 1)\n",
       "1  Number of Sliding windows       2301\n",
       "2       Sliding window shape   (1, 200)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup Training windows\n",
    "X_train, _ = sw(df_train) #Windows\n",
    "data = {\n",
    "    \"Description\": [\n",
    "        \"Dataset shape\", \n",
    "        \"Number of Sliding windows\", \n",
    "        \"Sliding window shape\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(df_train.shape), \n",
    "        str(X_train.shape[0]), \n",
    "        f\"({X_train.shape[1]}, {X_train.shape[2]})\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "training_info = pd.DataFrame(data)\n",
    "training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No validation artifact. Random items to get: 0.1\n"
     ]
    }
   ],
   "source": [
    "if config.valid_artifact:\n",
    "    valid_artifact = artifacts_gettr(config.valid_artifact)\n",
    "    df_val = valid_artifact.to_df()\n",
    "    X_valid, _ = sw(df_val)\n",
    "    df_val.shape, X_valid.shape\n",
    "    print(\"valid_artifact\")\n",
    "    print(valid_artifact)\n",
    "    print(\"df_val\")\n",
    "    print(df_val)\n",
    "    print(\"X_valid\")\n",
    "    print(X_valid)\n",
    "    print(\"df_val.shape\")\n",
    "    print(df_val.shape)\n",
    "    print(\"X_valid.shape\")\n",
    "    print(X_valid.shape)\n",
    "else:\n",
    "    print(\"No validation artifact. Random items to get:\", config.valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: METER EXPLICACIÓN DE OR-ELM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: AQUI VA LA EXPLICACIÓN CON EL EJEMPLO QUE SE META EN EL PAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZcAAABmCAYAAAC3Bq+HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdoUlEQVR4nO3de1xUdf7H8fegwwCKuCgwkAJilpZIi5bZ5RflLV21sizXy8Juqa2hYbqlWYmF5uJaZsW27dZiF1dtV23TfViUl2yxcl1JJWWtQG0FTcsLXgDh/P5wmRy5zZGZAeT1fDzm0cw53/P9fr7n8p3Dx9N3LIZhGAIAAAAAAAAAwASfhg4AAAAAAAAAAND0kFwGAAAAAAAAAJhGchkAAAAAAAAAYBrJZQAAAAAAAACAaSSXAQAAAAAAAACmkVwGAAAAAAAAAJhGchkAAAAAAAAAYBrJZQAAAAAAAACAaSSXAQAAAAAAAACmkVwGAAD4n88++0x33XWXIiMjZbPZFBYWpj59+mjq1KkXVV9BQYEsFosyMzMdyzIzM2WxWFRQUOBYtmTJEi1cuLB+wUuKjo5WUlKS4/OGDRtksVi0YcMGU/VkZGQ4xeyK6tpKSkpS69atTdVTl+zsbKWmpuro0aNV1iUkJCghIcGt7QEAAACoGcllAAAASWvWrNENN9yg48ePKz09XR988IFeeOEF3XjjjVq2bJnb2vnZz36mzZs3Kzw83LHMXcnlC8XHx2vz5s2Kj483td3FJJcvti2zsrOzNXv27GqTyxkZGcrIyPBo+wAAAAB+1LKhAwAAAGgM0tPT1alTJ73//vtq2fLHW6SRI0cqPT3dbe2EhIQoJCTEbfXVpk2bNrr++us92kZZWZksFotX2qrLVVdd1aDtAwAAAM0NTy4DAABIOnLkiNq3b++UWK7k4+N8yxQdHa0hQ4Zo5cqV6tGjh/z8/BQTE6NFixbV2c6F02IkJCRozZo12rt3rywWi+NVm7KyMj366KOy2+0KCAjQTTfdpM8//7xKueqmqvjmm280cuRIRUREOKb+6Nu3r3Jychx9y83N1caNGx2xREdHO9X35ptvaurUqbrssstks9n01Vdf1ToFR25urvr27atWrVopJCREycnJOnXqlGN9ddOHVLJYLEpNTZUkpaam6je/+Y0kqVOnTo74KtusblqM77//XhMnTtRll10mX19fxcTEaObMmSopKanSTnJyst58801169ZNAQEBiouL0+rVq2s+EAAAAEAzx5PLAAAAkvr06aM//elPmjx5skaPHq34+HhZrdYay+fk5CglJUWpqamy2+16++239fDDD6u0tFTTpk1zud2MjAyNHz9eX3/9tVauXOnSNuPGjdMbb7yhadOmqX///tq5c6eGDx+uEydO1Lnt4MGDVV5ervT0dEVGRurw4cPKzs52TDOxcuVK3XPPPQoKCnJMMWGz2ZzqmDFjhvr06aNXXnlFPj4+Cg0NVVFRUbXtlZWVafDgwZowYYKmT5+u7OxspaWlae/evXrvvfdc6m+lBx54QN9//71efPFFrVixwjG1SE1PLJ85c0a33nqrvv76a82ePVs9evTQpk2b9OyzzyonJ0dr1qxxKr9mzRpt2bJFTz/9tFq3bq309HTdddddysvLU0xMjKlYAQAAgOaA5DIAAICkefPmaffu3XrxxRf14osvymq16tprr9XQoUOVnJxc5YfpDhw4oG3btikuLk6SNGjQIB06dEjPPPOMJk6cqICAAJfaveqqq9S2bVvZbDaXppXYvXu3Fi9erClTpjim6+jfv7/CwsI0evToWrc9cuSI8vLytHDhQo0ZM8axfPjw4Y73P/3pT+Xv71/rNBedO3fWO++840r3VFpaqqlTp2ry5MmOWK1Wq2bOnKl//vOfuvHGG12qR5I6dOigyMhIR5yVT1TXZPHixdq+fbuWL1+uESNGONpv3bq1HnvsMWVlZal///6O8qdPn9aHH36owMBASefmkY6IiNDy5cs1ffp0l+MEAAAAmgumxQAAAJDUrl07bdq0SVu2bNG8efN0xx136D//+Y9mzJih2NhYHT582Kn81Vdf7UgsVxo1apSOHz+uf//73x6Lc/369ZJUJZF87733Vjulx/mCg4PVuXNnzZ8/X88995y2bdumiooK0zHcfffdpspfGOuoUaMk/dgXT1m3bp1atWqle+65x2l5UlKSJOmjjz5yWn7rrbc6EsuSFBYWptDQUO3du9ejcQIAAABNFcllAACA8/Tq1UuPPfaY3nnnHR04cEBTpkxRQUFBlR/1s9vtVbatXHbkyBGPxVdZ94Xtt2zZUu3atat1W4vFoo8++kgDBw5Uenq64uPjFRISosmTJ7s0pUalyukoXFFdXN7YT5X12+32KnNYh4aGqmXLllXar27/2Ww2nT592qNxAgAAAE0VyWUAAIAaWK1WzZo1S5K0c+dOp3XVzTFcuayuJG99VNZ9Yftnz551KVkbFRWl1157TUVFRcrLy9OUKVOUkZHh+KE8V9T1g4N1xXXhfvLz85OkKj+yV9/kc7t27XTw4EEZhuG0/NChQzp79qzat29fr/oBAACA5o7kMgAAgKTCwsJql+/atUuSFBER4bQ8NzdXX3zxhdOyJUuWKDAwUPHx8abaNvN0bEJCgiTp7bffdlq+fPlynT171lS7V1xxhZ544gnFxsY6TeXh7qd1L4x1yZIlkn7sS1hYmPz8/LR9+3ancu+++26Vuip/XNCV+Pr27avi4mKtWrXKafkbb7zhWA8AAADg4vGDfgAAAJIGDhyoDh06aOjQoeratasqKiqUk5OjBQsWqHXr1nr44YedykdERGjYsGFKTU1VeHi43nrrLWVlZem3v/2tyz/mVyk2NlYrVqzQ73//e/Xs2VM+Pj7q1atXtWW7deumMWPGaOHChbJarerXr5927typ3/3ud2rTpk2t7Wzfvl3JyckaMWKEunTpIl9fX61bt07bt293+sG62NhYLV26VMuWLVNMTIz8/PwUGxtrqk+VfH19tWDBAhUXF+vaa69Vdna20tLSNGjQIN10002Szj0JPWbMGL3++uvq3Lmz4uLi9PnnnzuS0BfuK0l64YUXlJiYKKvVqiuvvNJpruRKv/jFL/Tyyy8rMTFRBQUFio2N1SeffKK5c+dq8ODB6tev30X1CQAAAMA5JJcBAAAkPfHEE3r33Xf1/PPPq7CwUCUlJQoPD1e/fv00Y8YMdevWzan8Nddco1/+8peaNWuW9uzZo4iICD333HOaMmWK6bYffvhh5ebm6vHHH9exY8dkGEaVqRzO99prryksLEyZmZlatGiRrrnmGv3tb3/TyJEja23Hbrerc+fOysjI0P79+2WxWBQTE6MFCxZo0qRJjnKzZ89WYWGhxo0bpxMnTigqKkoFBQWm+yWdm1pk9erVmjx5stLS0uTv769x48Zp/vz5TuUWLFggSUpPT1dxcbFuu+02rV69WtHR0U7lEhISNGPGDC1evFh//OMfVVFRofXr1zuegj6fn5+f1q9fr5kzZ2r+/Pn67rvvdNlll2natGmO6U4AAAAAXDyLUdtfLgAAAKgiOjpa3bt31+rVqxs6FAAAAABoMMy5DAAAAAAAAAAwjeQyAAAAAAAAAMA0psUAAAAAAAAAAJjGk8sAAAAAAAAAANNILgMAAAAAAAAATCO5DAAAAAAAAAAwraW3G6yoqNCBAwcUGBgoi8Xi7eYBAAAAAACAJs0wDJ04cUIRERHy8eHZUTQcryeXDxw4oI4dO3q7WQAAAAAAAOCSsn//fnXo0KGhw0Az5vV/2ggMDPzfu/2K2xgn6ZjTK25jXLXL63qdv01t27tad13lXF1/MX2pb+zeqNtMeU/E7cl9UVs79Tl/atrWXX1xZ/3uOr6uXpc1bdvQ57wnznMz58bF7mt37pv6xOvt4+WpY9tY++nOY1pd+cawjzz53dSYz4sL978rx88dY/3F9r8h95u7+uDqtp68Rmvry8VeC+48L9z9HeTp+x9PHaeajltjGT/qs2+8cX/f0N8vnriX8sZ3t5n13upHdd9Vnjq+dR03b5xTF17rF/a3oca0i/muMHvuNJWchrvaNbsf3dEnV//muvB87/6P7pLOz7MBDcPrTy7/OBVGG7Vo3UJSG6f155apyvK6nF9XdfVWV87V+uqz3tX2XOHOuupbt5nynojbk/uitnbqc/7UtK27+uLO+t11fF29LmveVqa2McOVeDxxnps5N8y04amxpj7xupO7j0VD9MEVnorL7LXo6evPVZ78bvLE9u5y4f535fi5Y6y/2P435H5zVx9c3daz16hUU18u9lpw53nh7u8gT9//eEL1+0Zy9z2/uzTG+/uG/n7xxL2UN767zaz3Vj+q/66S0zJ3qfu4ub/NmmJw/m8l940B9blu6/s3haf/XnV3XZ5q1+x+dEefXP2bq8p11+rcZ6acRUNjUhYAAAAAAAAAgGkklwEAAAAAAAAAppFcBgAAAAAAAACY5vU5lwEAAAAAAADAE8rLy1VWVtbQYTRZLVq0UMuWLV2ez5vkMgAAAAAAAIAmr7i4WN9++60Mw2joUJq0gIAAhYeHy9fXt86yJJcBAAAAAAAANGnl5eX69ttvFRAQoJCQEJefvMWPDMNQaWmpvvvuO+Xn56tLly7y8al9VmWSywAAAAAAAACatLKyMhmGoZCQEPn7+zd0OE2Wv7+/rFar9u7dq9LSUvn5+dVanh/0AwAAAAAAAHBJ4Inl+qvraWWnsh6MAwAAAAAAAABwiSK5DAAAAAAAAAAwjeQyAAAAAAAAAFwiEhISlJKS4pW2+EE/AAAAAAAAAJckb0/BbBiul61rfujExERlZmaajmHFihWyWq2mt7sYpp9c/vjjjzV06FBFRETIYrFo1apVHggLAAAAAAAAAC5dhYWFjtfChQvVpk0bp2UvvPCCU/mysjKX6g0ODlZgYKAnQq7CdHL55MmTiouL00svveSJeAAAAAAAAADgkme32x2voKAgWSwWx+czZ86obdu2Wr58uRISEuTn56e33npLR44c0c9//nN16NBBAQEBio2N1V/+8henei+cFiM6Olpz587Vr371KwUGBioyMlKvvvqqW/pgOrk8aNAgpaWlafjw4W4JAAAAAAAAAABQ1WOPPabJkydr165dGjhwoM6cOaOePXtq9erV2rlzp8aPH6+xY8fqs88+q7WeBQsWqFevXtq2bZsmTpyoX//619q9e3e94/P4nMslJSUqKSlxfD5+/LinmwQAAAAAAACAJi8lJaXKQ77Tpk1zvJ80aZLWrl2rd955R717966xnsGDB2vixImSziWsn3/+eW3YsEFdu3atV3ymn1w269lnn1VQUJDj1bFjR083CQAAAAAAAABNXq9evZw+l5eXa86cOerRo4fatWun1q1b64MPPtC+fftqradHjx6O95XTbxw6dKje8Xk8uTxjxgwdO3bM8dq/f7+nmwQAAAAAAACAJq9Vq1ZOnxcsWKDnn39ejz76qNatW6ecnBwNHDhQpaWltdZjtVqdPlssFlVUVNQ7Po9Pi2Gz2WSz2TzdDAAAAAAAAABc0jZt2qQ77rhDY8aMkSRVVFRoz5496tatW4PE4/EnlwEAAAAAAAAA9Xf55ZcrKytL2dnZ2rVrlyZMmKCioqIGi8f0k8vFxcX66quvHJ/z8/OVk5Oj4OBgRUZGujU4AAAAAAAAALhYhtHQEbjXk08+qfz8fA0cOFABAQEaP3687rzzTh07dqxB4jGdXP7Xv/6lW2+91fH5kUcekSQlJiYqMzPTbYEBAAAAAAAAQHOQlJSkpKQkx+fo6GgZ1WTGg4ODtWrVqlrr2rBhg9PngoKCKmVycnLMB1kN08nlhISEajsGAAAAAAAAAGg+mHMZAAAAAAAAAGAayWUAAAAAAAAAgGkklwEAAAAAAAAAppFcBgAAAAAAAACYRnIZAAAAAAAAAGAayWUAAAAAAAAAgGkklwEAAAAAAAAAppFcBgAAAAAAAACYRnIZAAAAAAAAAGBay4YOAAAAAAAAAAA8oee/e3q1va3xW10ua7FYal2fmJiozMzMi4ojOjpaKSkpSklJuajtXUVyGQAAAAAAAAC8rLCw0PF+2bJleuqpp5SXl+dY5u/v3xBhmeL15LJhGP97d1zlxeWSjjutP7dMVZbX5fy6qqu3unKu1lef9a625wp31lXfus2U90TcntwXtbVTn/Onpm3d1Rd31u+u4+vqdVnztjK1jRmuxOOJ89zMuWGmDU+NNfWJ153cfSwaog+u8FRcZq9FT19/rvLkd5MntneXC/e/K8fPHWP9xfa/Ifebu/rg6raevUalmvpysdeCO88Ld38Hefr+xxOq3zeSu+/53aUx3t839PeLJ+6lvPHdbWa9t/pR/XeVnJa5S93Hzf1t1hSD838ruW8MqM91W9+/KTz996q76/JUu2b3ozv65OrfXFWuu5PnPv+YZ0NTZLfbHe+DgoJksViclr333ntKTU1Vbm6uIiIilJiYqJkzZ6ply3Mp3dTUVL3++us6ePCg2rVrp3vuuUeLFi1SQkKC9u7dqylTpmjKlCmSPHeuWAwvn4XffPONOnfu7M0mAQAAAAAAgEvO/v371aFDh4YOo1E4c+aM8vPz1alTJ/n5+TmWN+ZpMc6XmZmplJQUHT16VJL0/vvv695779WiRYt088036+uvv9b48eOVlJSkWbNm6a9//avuv/9+LV26VFdffbWKior0xRdfaNy4cfr+++8VFxen8ePHa9y4cZKcE9l1qWlfVsfrTy4HBwdLkvbt26egoCBvNw+giTl+/Lg6duyo/fv3q02bNg0dDoBGjjEDgFmMGwDMYMxAY2EYhk6cOKGIiIiGDgUeMmfOHE2fPl2JiYmSpJiYGD3zzDN69NFHNWvWLO3bt092u139+vWT1WpVZGSkrrvuOknn8q8tWrRQYGCgqaTyxfB6ctnHx0fSuUe9GYgBuKpNmzaMGQBcxpgBwCzGDQBmMGagMeChzUvb1q1btWXLFs2ZM8exrLy8XGfOnNGpU6c0YsQILVy4UDExMbr99ts1ePBgDR061DFlhrfwg34AAAAAAAAA0IhUVFRo9uzZGj58eJV1fn5+6tixo/Ly8pSVlaUPP/xQEydO1Pz587Vx40ZZrVavxUlyGQAAAAAAAAAakfj4eOXl5enyyy+vsYy/v7+GDRumYcOG6aGHHlLXrl21Y8cOxcfHy9fXV+Xl5TVu6y5eTy7bbDbNmjVLNpvN200DaIIYMwCYwZgBwCzGDQBmMGYA8JannnpKQ4YMUceOHTVixAj5+Pho+/bt2rFjh9LS0pSZmany8nL17t1bAQEBevPNN+Xv76+oqChJUnR0tD7++GONHDlSNptN7du390icFsMwDI/UDAAAAAAAAABecObMGeXn56tTp07y8/Nr6HBMy8zMVEpKio4ePepY9v777+vpp5/Wtm3bZLVa1bVrVz3wwAMaN26cVq1apXnz5mnXrl0qLy9XbGys0tLS1LdvX0nSp59+qgkTJigvL08lJSUykwI2sy9JLgMAAAAAAABo0pp6crkxMbMvfbwUEwAAAAAAAADgEkJyGQAAAAAAAABgGsllAAAAAAAAAIBpJJcBAAAAAAAAAKZ5NbmckZHhmAi6Z8+e2rRpkzebB9BIpKamymKxOL3sdrtjvWEYSk1NVUREhPz9/ZWQkKDc3FynOkpKSjRp0iS1b99erVq10rBhw/Ttt996uysAPODjjz/W0KFDFRERIYvFolWrVjmtd9cY8cMPP2js2LEKCgpSUFCQxo4d6/TLzACajrrGjaSkpCr3Htdff71TGcYNoPl49tlnde211yowMFChoaG68847lZeX51SG+w2g6TIMo6FDaPLM7EOvJZeXLVumlJQUzZw5U9u2bdPNN9+sQYMGad++fd4KAUAjcvXVV6uwsNDx2rFjh2Ndenq6nnvuOb300kvasmWL7Ha7+vfvrxMnTjjKpKSkaOXKlVq6dKk++eQTFRcXa8iQISovL2+I7gBwo5MnTyouLk4vvfRStevdNUaMGjVKOTk5Wrt2rdauXaucnByNHTvW4/0D4H51jRuSdPvttzvde/zjH/9wWs+4ATQfGzdu1EMPPaRPP/1UWVlZOnv2rAYMGKCTJ086ynC/ATQ9LVq0kCSVlpY2cCRN36lTpyRJVqu17sKGl1x33XXGgw8+6LSsa9euxvTp070VAoBGYtasWUZcXFy16yoqKgy73W7MmzfPsezMmTNGUFCQ8corrxiGYRhHjx41rFarsXTpUkeZ//73v4aPj4+xdu1aj8YOwLskGStXrnR8dtcY8eWXXxqSjE8//dRRZvPmzYYkY/fu3R7uFQBPunDcMAzDSExMNO64444at2HcAJq3Q4cOGZKMjRs3GobB/QbQVFVUVBgFBQXGnj17jJMnTxqnT5/mZfJ16tQp4/Dhw8aXX35pHDhwwKX93tIz+W1npaWl2rp1q6ZPn+60fMCAAcrOzvZGCAAamT179igiIkI2m029e/fW3LlzFRMTo/z8fBUVFWnAgAGOsjabTbfccouys7M1YcIEbd26VWVlZU5lIiIi1L17d2VnZ2vgwIEN0SUAXuCuMWLz5s0KCgpS7969HWWuv/56BQUFKTs7W1deeaVX+wXA8zZs2KDQ0FC1bdtWt9xyi+bMmaPQ0FBJYtwAmrljx45JkoKDgyVxvwE0VRaLReHh4crPz9fevXsbOpwmrW3btk7Tl9bGK8nlw4cPq7y8XGFhYU7Lw8LCVFRU5I0QADQivXv31htvvKErrrhCBw8eVFpamm644Qbl5uY6xoTqxovKL4eioiL5+vrqJz/5SZUyjCnApc1dY0RRUZEjqXS+0NBQxhHgEjRo0CCNGDFCUVFRys/P15NPPqnbbrtNW7dulc1mY9wAmjHDMPTII4/opptuUvfu3SVxvwE0Zb6+vurSpQtTY9SD1Wp1TDHiCq8klytZLBanz4ZhVFkG4NI3aNAgx/vY2Fj16dNHnTt31uLFix0/rnMx4wVjCtB8uGOMqK484whwabrvvvsc77t3765evXopKipKa9as0fDhw2vcjnEDuPQlJydr+/bt+uSTT6qs434DaJp8fHzk5+fX0GE0G175Qb/27durRYsWVf5l7tChQ1X+JRBA89OqVSvFxsZqz549jv/torbxwm63q7S0VD/88EONZQBcmtw1Rtjtdh08eLBK/d999x3jCNAMhIeHKyoqSnv27JHEuAE0V5MmTdLf//53rV+/Xh06dHAs534DAFznleSyr6+vevbsqaysLKflWVlZuuGGG7wRAoBGrKSkRLt27VJ4eLg6deoku93uNF6UlpZq48aNjvGiZ8+eslqtTmUKCwu1c+dOxhTgEueuMaJPnz46duyYPv/8c0eZzz77TMeOHWMcAZqBI0eOaP/+/QoPD5fEuAE0N4ZhKDk5WStWrNC6devUqVMnp/XcbwCA67w2LcYjjzyisWPHqlevXurTp49effVV7du3Tw8++KC3QgDQSEybNk1Dhw5VZGSkDh06pLS0NB0/flyJiYmyWCxKSUnR3Llz1aVLF3Xp0kVz585VQECARo0aJUkKCgrS/fffr6lTp6pdu3YKDg7WtGnTFBsbq379+jVw7wDUV3Fxsb766ivH5/z8fOXk5Cg4OFiRkZFuGSO6deum22+/XePGjdMf/vAHSdL48eM1ZMgQflwHaIJqGzeCg4OVmpqqu+++W+Hh4SooKNDjjz+u9u3b66677pLEuAE0Nw899JCWLFmid999V4GBgY4nlIOCguTv7++2v0kYNwA0C4YXvfzyy0ZUVJTh6+trxMfHGxs3bvRm8wAaifvuu88IDw83rFarERERYQwfPtzIzc11rK+oqDBmzZpl2O12w2azGf/3f/9n7Nixw6mO06dPG8nJyUZwcLDh7+9vDBkyxNi3b5+3uwLAA9avX29IqvJKTEw0DMN9Y8SRI0eM0aNHG4GBgUZgYKAxevRo44cffvBSLwG4U23jxqlTp4wBAwYYISEhhtVqNSIjI43ExMQqYwLjBtB8VDdeSDL+/Oc/O8pwvwEArrEYhmF4P6UNAAAAAAAAAGjKvDLnMgAAAAAAAADg0kJyGQAAAAAAAABgGsllAAAAAAAAAIBpJJcBAAAAAAAAAKaRXAYAAAAAAAAAmEZyGQAAAAAAAABgGsllAAAAAAAAAIBpJJcBAAAAAAAAAKaRXAYAAAAAAAAAmEZyGQAAAAAAAABgGsllAAAAAAAAAIBp/w9ITbwRI4zkoQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2301, 1, 200)\n",
      "y.shape: (2301, 1, 200)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset\n",
    "random.seed = config.random_seed\n",
    "if config.valid_artifact:\n",
    "    X, y, splits  = combine_split_data(xs=[X_train, X_valid], ys=[X_train, X_valid])\n",
    "else:\n",
    "    X = X_train\n",
    "    y = X_train\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size)\n",
    "splits\n",
    "print(\"X.shape: \"+str(X.shape))\n",
    "print(\"y.shape: \"+str(y.shape))\n",
    "#print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the model\n",
    "#features = pd.DataFrame(dls.dataset[0][0])\n",
    "#targets = pd.DataFrame(dls.dataset[0][1]) #1\n",
    "\n",
    "#print(\"dls len: \" + str(len(dls.dataset)))\n",
    "\n",
    "#print(\"Features shape: \" + str(features.shape))\n",
    "#print(\"Targets shape: \" + str(features.shape))\n",
    "\n",
    "#dls.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLags         = X_train.shape[0] #config.epochs\n",
    "nDimInput       = numLags\n",
    "nDimOutput      = 1 #targets.shape[1] #1\n",
    "numNeurons      = config.numHiddenNeurons #nDimInput  #config.numHiddenNeurons\n",
    "algorithm       = config.algorithm\n",
    "LN              = config.LN \n",
    "AE              = config.AE\n",
    "InWeightFF      = config.inputWeightForgettingFactor #1.0\n",
    "OutWeightFF     = config.outputWeightForgettingFactor #0.92\n",
    "HiddenWeightFF  = config.inputWeightForgettingFactor #1.0\n",
    "lamb            = config.lamb\n",
    "predictionStep  = config.stride #5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   Description           Value\n",
       "0               Dataset shape       (2500, 1)\n",
       "1   Number of Sliding windows            2301\n",
       "2        Sliding window shape        (1, 200)\n",
       "3      inputs/Charasteristics            2301\n",
       "4               Targets shape  (2301, 1, 200)\n",
       "5               X_train shape  (2301, 1, 200)\n",
       "6               Input Weights      (25, 2301)\n",
       "7              Hidden Weights        (25, 25)\n",
       "8                    Hidden A         (1, 25)\n",
       "9                        Bias         (1, 25)\n",
       "10                   Features       (1, 2301)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_to_append = {\n",
    "    \"Description\": [\n",
    "        \"inputs/Charasteristics\", \n",
    "        \"Targets shape\", \n",
    "        \"X_train shape\", \n",
    "        \"Input Weights\", \n",
    "        \"Hidden Weights\", \n",
    "        \"Hidden A\", \n",
    "        \"Bias\", \n",
    "        \"Features\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(nDimInput),\n",
    "        str(y.shape),\n",
    "        str(X_train.shape),\n",
    "        f\"({numNeurons}, {nDimInput})\",\n",
    "        f\"({numNeurons}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {nDimInput})\"\n",
    "    ]\n",
    "}\n",
    "data_to_append = pd.DataFrame(data_to_append)\n",
    "training_info = training_info.append(data_to_append, ignore_index = True)\n",
    "training_info.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with fastai Learner class, to abstract from Pytorch's training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To track the performance of this model fit, go to the project dashboard in Weights & Biases. The link is provided at the beginning of this notebook, after the execution of the function `wandb.init()'' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, log the learner to be used by the next notebook in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "200\n",
      "outputs\n",
      "1\n",
      "numNeurons\n",
      "25\n",
      "Out weight FF\n",
      "0.92\n",
      "(25, 200)\n",
      "--> Initialize_Phase: Input Weights initialized. Shape: (25, 200)\n",
      "ORELM_torch(\n",
      "  (inputAE): FOSELM_torch()\n",
      "  (hiddenAE): FOSELM_torch()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = orelm.ORELM_torch(\n",
    "    inputs                      =   X_train.shape[2], #nDimInput,\n",
    "    outputs                     =   nDimOutput,\n",
    "    numHiddenNeurons            =   config.numHiddenNeurons,\n",
    "    activationFunction          =   config.activationFunction,\n",
    "    LN                          =   config.LN,\n",
    "    AE                          =   config.AE,\n",
    "    ORTH                        =   config.ORTH,\n",
    "    inputWeightForgettingFactor =   config.inputWeightForgettingFactor,\n",
    "    outputWeightForgettingFactor=   config.outputWeightForgettingFactor\n",
    ")\n",
    "m.initializePhase(lamb=0.0001)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n"
     ]
    }
   ],
   "source": [
    "tfms = [ToFloat(), ToFloat()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape[0]: 2301\n",
      "X.shape: (2301, 1, 200)\n",
      "y.shape: (2301, 1, 200)\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "dls.shape: (2301, 1, 200)\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "<class 'tsai.data.core.TSDataLoaders'>\n",
      "<class 'nbs.orelm.orelm_torch.ORELM_torch'>\n"
     ]
    }
   ],
   "source": [
    "tfms = [ToFloat(), ToFloat()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "#DataLoader\n",
    "print(\"X_train shape[0]: \" + str(X_train.shape[0]))\n",
    "print(\"X.shape: \"+str(X.shape))\n",
    "print(\"y.shape: \"+str(y.shape))\n",
    "\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "print(\"dls.shape: \"+str(X.shape))\n",
    "learn =  Learner(\n",
    "    dls         = dls, \n",
    "    model       = m, \n",
    "    loss_func   = nn.MSELoss(), #\n",
    "    opt_func    = Adam, #Creates an optimizer\n",
    "    cbs         = [WandbCallback(log_preds=False)] #List of callbacks\n",
    ")\n",
    "\n",
    "print(type(dls))\n",
    "print(type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORELM_torch(\n",
      "  (inputAE): FOSELM_torch()\n",
      "  (hiddenAE): FOSELM_torch()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### Prueba comprobar tamaños para m \"en pequeño\"\\nstep = 0\\npredictions = []\\ntarget = []\\nmaxStep = X.shape[0]\\nfor i in range(maxStep-1):\\n    training_dataset = X[i]\\n    targets = y[i]\\n    features = X[i+1] \\n    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\\n    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\\n    m.train(training_dataset, targets)\\n    Y = m.predict(features)\\n    predictions.append(Y[0][0])\\n    target.append(y[i+1][0])\\n    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#### Prueba comprobar tamaños para m \"en pequeño\"\n",
    "step = 0\n",
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]\n",
    "for i in range(maxStep-1):\n",
    "    training_dataset = X[i]\n",
    "    targets = y[i]\n",
    "    features = X[i+1] \n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    m.train(training_dataset, targets)\n",
    "    Y = m.predict(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(y[i+1][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epoch: 4\n",
      "cb: LRFinder\n",
      "--> Fit\n",
      "About to return type: <class 'map'>\n",
      "--> Create opt\n",
      "---> opt_func \n",
      "self.model: ORELM_torch(\n",
      "  (inputAE): FOSELM_torch()\n",
      "  (hiddenAE): FOSELM_torch()\n",
      ")\n",
      "self.splitter(self.model): []\n",
      "Learning rate: 0.001\n",
      "OPT func: <function Adam at 0x7f1e2f3b9900>\n",
      "Adam optimizer\n",
      "Get cbs\n",
      "decouple_wd: True\n",
      "weight_decay <function weight_decay at 0x7f1e2f3b92d0>\n",
      "l2_reg <function l2_reg at 0x7f1e2f3b9360>\n",
      "Cbs: [<function weight_decay at 0x7f1e2f3b92d0>]\n",
      "Add to cbs\n",
      "average_sqr_grad<function average_sqr_grad at 0x7f1e2f3b9480>\n",
      "step_stat<function step_stat at 0x7f1e2f3b9750>\n",
      "adam_step<function adam_step at 0x7f1e2f3b9870>\n",
      "partial(average_grad, dampening=True): functools.partial(<function average_grad at 0x7f1e2f3b93f0>, dampening=True)\n",
      "About to get optimizer\n",
      "Get params\n",
      "Get cbs\n",
      "Get defaults\n",
      "About to return type: <class 'map'>\n",
      "Get param list from params: []\n",
      "Get hyperes\n",
      "Set hypers\n",
      "Set frozen idx\n",
      "Return optimizer\n",
      "-- opt_func -> \n",
      "Estoy aqui\n",
      "--> bn_bias_state\n",
      "--> norm bias params\n",
      "Getting res\n",
      "About to return type: <class 'map'>\n",
      "--> norm bias params\n",
      "Getting res\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "Okay got res\n",
      "About to return\n",
      "About to return type: <class 'map'>\n",
      "Okay got res\n",
      "About to return\n",
      "mapping var [array([[ 0.05971276,  0.24327163,  0.11142815,  0.19737328, -0.57425234,\n",
      "        -0.60555226,  0.44133665, -0.72387224,  0.79307422,  0.52211996,\n",
      "        -0.28582328, -0.76096593, -0.04575164,  0.43189454,  0.09443508,\n",
      "         0.51752528, -0.98341838, -0.96909312,  0.87717575,  0.97417925,\n",
      "         0.68676279, -0.81915041,  0.93829526, -0.35638761, -0.22616368]]), array([[ 0.7777381 , -0.87364425,  0.88858732, -0.49398518,  0.41724152,\n",
      "         0.57843798, -0.4751912 ,  0.73657632, -0.62192541,  0.27429778,\n",
      "        -0.10566162, -0.43467939, -0.68541522,  0.60224464, -0.35411414,\n",
      "        -0.81616828, -0.35865168,  0.63051852,  0.1786613 ,  0.71829576,\n",
      "        -0.66895644, -0.87266537,  0.8548843 , -0.47949452, -0.25867806]]), array([[-0.30813155,  0.17943749,  0.10830442,  0.77494005, -0.71961003,\n",
      "        -0.65814966,  0.84990462,  0.59260052, -0.81627318, -0.16147934,\n",
      "         0.01925786, -0.29493183, -0.51845487,  0.14231499,  0.78616423,\n",
      "        -0.34293291,  0.20443664,  0.49559287, -0.69545034,  0.78947857,\n",
      "        -0.24503905,  0.97480166, -0.88819759,  0.83529827,  0.5970993 ]])]\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb Celda 37\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#print(\"self.dls shape: \" + str(learn.dls.train.shape))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#print(\"self.dls.train \" + str(len(learn.dls.train)))\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m lr_valley, lr_steep \u001b[39m=\u001b[39m   learn\u001b[39m.\u001b[39;49mlr_find(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                             suggest_funcs\u001b[39m=\u001b[39;49m[valley, steep]                        )\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/callback/schedule.py:308\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mn_epoch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(n_epoch))\n\u001b[1;32m    306\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcb: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cb))\n\u001b[0;32m--> 308\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_logging(): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m suggest_funcs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBefore tensor\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/learner.py:271\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    269\u001b[0m     cbs \u001b[39m=\u001b[39m L(cbs) \u001b[39m+\u001b[39m SkipToEpoch(start_epoch)\n\u001b[1;32m    270\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madded_cbs(cbs):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mif\u001b[39;00m reset_opt \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_opt()\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m wd \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: wd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwd\n\u001b[1;32m    273\u001b[0m     \u001b[39mif\u001b[39;00m wd \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(wd\u001b[39m=\u001b[39mwd)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner.create_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwd_bn_bias:\n\u001b[1;32m    200\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEstoy aqui\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bn_bias_state(\u001b[39mTrue\u001b[39;49;00m ): p[\u001b[39m'\u001b[39m\u001b[39mdo_wd\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGot norm bias state\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_bn:\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/learner.py:182\u001b[0m, in \u001b[0;36mLearner._bn_bias_state\u001b[0;34m(self, with_bias)\u001b[0m\n\u001b[1;32m    180\u001b[0m var \u001b[39m=\u001b[39m norm_bias_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, with_bias)\n\u001b[1;32m    181\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmapping var \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(var)) \n\u001b[0;32m--> 182\u001b[0m mapped \u001b[39m=\u001b[39m var\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt\u001b[39m.\u001b[39;49mstate)\n\u001b[1;32m    183\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mReturning\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastcore/foundation.py:156\u001b[0m, in \u001b[0;36mL.map\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(map_ex(\u001b[39mself\u001b[39;49m, f, \u001b[39m*\u001b[39;49margs, gen\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastcore/basics.py:841\u001b[0m, in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m gen: \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m    840\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAbout to return type: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(res)))\n\u001b[0;32m--> 841\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(res)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "#print(\"self.dls shape: \" + str(learn.dls.train.shape))\n",
    "#print(\"self.dls.train \" + str(len(learn.dls.train)))\n",
    "\n",
    "lr_valley, lr_steep =   learn.lr_find(\n",
    "                            suggest_funcs=[valley, steep]                        )\n",
    "#lr_valley, lr_steep = learn.lr_finsd(suggest_funcs=[valley, steep]) --> original\n",
    "#learn.fit_one_cycle(1, lr_max=lr_valley)\n",
    "#learn.fit_one_cycle(config.epochs, lr_max=lr_valley)\n",
    "#learn.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([X[w][0] for w in range(X_train.shape[0])]).T\n",
    "T = np.array([y[w][0] for w in range(X_train.shape[0])]).T   \n",
    "print('Input shape: ', str(X.shape))\n",
    "print('Target shape: ', str(T.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]-predictionStep-1\n",
    "print(\"Num steps: \" + str(maxStep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "for i in range(maxStep):\n",
    "    training_dataset = X[[i],:]\n",
    "    targets = T[[i],:]\n",
    "    features = X[[i+1],:]\n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    m.train(training_dataset, targets)\n",
    "    Y = m.predict(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(T[i][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Calculate total Normalizedd Root Mean Square Error (NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct original value\n",
    "predictions = np.array(predictions)\n",
    "target = np.array(target)\n",
    "predictions = predictions * stdSeq + meanSeq\n",
    "target = target * stdSeq + meanSeq\n",
    "  \n",
    "def computeSquareDeviation(predictions, truth):\n",
    "  squareDeviation = np.square(predictions-truth)\n",
    "  return squareDeviation\n",
    "\n",
    "# Calculate NRMSE from skip_eval to the end\n",
    "skip_eval=100\n",
    "squareDeviation = computeSquareDeviation(predictions, target)\n",
    "squareDeviation[:skip_eval] = None\n",
    "nrmse = np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions)\n",
    "print(\"NRMSE {}\".format(nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target len: \" + str(len(target)) + str(target))\n",
    "print(\"Prediction len: \" + str(len(predictions))+str(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "algorithm = config.algorithm\n",
    "print(algorithm)\n",
    "print(config.job_type)\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "targetPlot,=plt.plot(target,label='target',color='red',marker='.',linestyle='-')\n",
    "predictedPlot,=plt.plot(predictions,label='predicted',color='blue',marker='.',linestyle=':')\n",
    "plt.xlim([0, 200])\n",
    "plt.ylim([60, 100])\n",
    "plt.ylabel('value',fontsize=15)\n",
    "plt.xlabel('time',fontsize=15)\n",
    "plt.ion()\n",
    "plt.grid()\n",
    "plt.legend(handles=[targetPlot, predictedPlot])\n",
    "plt.title('Time-series Prediction of '+ config.job_type + ' algorithm: ' + algorithm +' on '+dataSet.fname+' dataset' ,fontsize=20,fontweight=40)\n",
    "plot_path = './predictionPlot.png'\n",
    "#plt.savefig(plot_path,plot_pathbbox_inches='tight')\n",
    "plt.savefig(plot_path,bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.pause(0)\n",
    "print('Prediction plot is saved to'+plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning and prediction of OR-ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
