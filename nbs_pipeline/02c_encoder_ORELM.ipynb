{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import nbs_pipeline.utils.vscode  as vs\n",
    "vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# OR-ELM: Online Recurrent Extreme Learning Machine for time-series prediction\n",
    "\n",
    "> This notebook applies visual analytics to [OR_ELM](https://github.com/chickenbestlover/Online-Recurrent-Extreme-Learning-Machine) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/macu/lib/orelm/\n",
      "El directorio existe: /home/macu/lib/orelm/\n",
      "['/home/macu/work/nbs_pipeline', '/home/macu/env/lib/python310.zip', '/home/macu/env/lib/python3.10', '/home/macu/env/lib/python3.10/lib-dynload', '', '/home/macu/env/lib/python3.10/site-packages', '/home/macu/env/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg', '/home/macu/lib/tsai', '/home/macu/work', '/home/macu/work']\n",
      "['/home/macu/work/nbs_pipeline', '/home/macu/env/lib/python310.zip', '/home/macu/env/lib/python3.10', '/home/macu/env/lib/python3.10/lib-dynload', '', '/home/macu/env/lib/python3.10/site-packages', '/home/macu/env/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg', '/home/macu/lib/tsai', '/home/macu/work', '/home/macu/work', '/home/macu/lib/orelm/']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tsai.all import *\n",
    "except:\n",
    "    from tsai.all import * # TODO: Weird error when loading tsai!from tchub.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from fastcore.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.schedule import *\n",
    "from dvats.all import *\n",
    "import nbs.orelm.orelm_torch as orelm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "Before running this notebook, make sure you have the `$WANDB_API_KEY` environment varibale defined with your API_KEY (run in a terminal `echo $WANDB_API_KEY` to see it). If not, run in a terminal `wandb login [API_KEY]`. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/02c-encoder_orelm.yaml\n",
      "... About to replace includes with content\n",
      "Before configuration reading \n",
      "-include: None\n",
      "-user_preferences:\n",
      "\t-use_wandb: False\n",
      "\t-wdb:\n",
      "\t\t-user: mi-santamaria\n",
      "\t\t-project_name: test-project\n",
      "\t\t-version: 0\n",
      "\t\t-mode: offline\n",
      "\t\t-artifacts_path: ./data/wandb_artifacts\n",
      "\t-data:\n",
      "\t\t-folder: ~/data/\n",
      "\t\t-fname: speed_6005\n",
      "\t\t-ftype: .csv\n",
      "\t\t-cols: [1]\n",
      "\t\t-freq: 1s\n",
      "\t-artifact:\n",
      "\t\t-alias: TiltABP\n",
      "\t-directories:\n",
      "\t\t-tmp: tmp\n",
      "\t\t-data: ~/data/speed_6005.csv\n",
      "-data:\n",
      "\t-name: speed_6005\n",
      "\t-path: ~/data/speed_6005.csv\n",
      "\t-alias: TiltABP\n",
      "\t-cols: [1]\n",
      "\t-csv_config:\n",
      "\t-date_offset: None\n",
      "\t-date_format: %Y-%m-%d %H:%M:%S\n",
      "\t-freq: 1s\n",
      "\t-joining_train_test: False\n",
      "\t-missing_values:\n",
      "\t\t-technique: None\n",
      "\t\t-constant: None\n",
      "\t-normalize_training: False\n",
      "\t-range_training: None\n",
      "\t-range_testing: None\n",
      "\t-resampling_freq: None\n",
      "\t-start_date: None\n",
      "\t-test_split: None\n",
      "\t-time_col: None\n",
      "-wandb:\n",
      "\t-user: mi-santamaria\n",
      "\t-dir: ~/test-project\n",
      "\t-enabled: False\n",
      "\t-group: None\n",
      "\t-log_learner: False\n",
      "\t-mode: offline\n",
      "\t-project: test-project\n",
      "\t-version: 0\n",
      "\t-artifacts_path: ./data/wandb_artifacts\n",
      "-configuration:\n",
      "\t-job_type: encoder_ORELM\n",
      "\t-alias: TiltABP\n",
      "\t-wandb:\n",
      "\t\t-use: False\n",
      "\t\t-entity: mi-santamaria\n",
      "\t\t-group: None\n",
      "\t\t-project: test-project\n",
      "\t-artifacts:\n",
      "\t\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t\t-valid:\n",
      "\t\t\t-data: None\n",
      "\t\t\t-size: 0.1\n",
      "\t-specifications:\n",
      "\t\t-algorithm: OSELM\n",
      "\t\t-n_epoch: 200\n",
      "\t\t-random_seed: 6\n",
      "\t\t-numHiddenNeurons: 25\n",
      "\t\t-activationFunction: sig\n",
      "\t\t-LN: True\n",
      "\t\t-AE: True\n",
      "\t\t-ORTH: True\n",
      "\t\t-lamb: 0.0001\n",
      "\t\t-weight_forgetting_factors:\n",
      "\t\t\t-input: 1\n",
      "\t\t\t-output: 0.92\n",
      "\t\t-sliding_windows:\n",
      "\t\t\t-stride: 1\n",
      "\t\t\t-size: 200\n",
      "After reading config\n",
      "-job_type: encoder_ORELM\n",
      "-alias: TiltABP\n",
      "-wandb:\n",
      "\t-use: False\n",
      "\t-entity: mi-santamaria\n",
      "\t-group: None\n",
      "\t-project: test-project\n",
      "-artifacts:\n",
      "\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t-valid:\n",
      "\t\t-data: None\n",
      "\t\t-size: 0.1\n",
      "-specifications:\n",
      "\t-algorithm: OSELM\n",
      "\t-n_epoch: 200\n",
      "\t-random_seed: 6\n",
      "\t-numHiddenNeurons: 25\n",
      "\t-activationFunction: sig\n",
      "\t-LN: True\n",
      "\t-AE: True\n",
      "\t-ORTH: True\n",
      "\t-lamb: 0.0001\n",
      "\t-weight_forgetting_factors:\n",
      "\t\t-input: 1\n",
      "\t\t-output: 0.92\n",
      "\t-sliding_windows:\n",
      "\t\t-stride: 1\n",
      "\t\t-size: 200\n"
     ]
    }
   ],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "config, job_type, dataSet = cfg.get_artifact_config_ORELM(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: test-project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "print(\"Project: \"+config.wandb_project)\n",
    "run = wandb.init(\n",
    "    entity          = config.wandb_entity,\n",
    "    project         = config.wandb_project,\n",
    "    group           = config.wandb_group,\n",
    "    job_type        = job_type,\n",
    "    allow_val_change= True,\n",
    "    mode            = 'online' if config.use_wandb else 'disabled',\n",
    "    config          = config,\n",
    "    resume          = False\n",
    ")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dataSet:\n",
      "-folder: ~/data/\n",
      "-fname: speed_6005\n",
      "-ftype: .csv\n",
      "-cols: [1]\n",
      "-freq: 1s\n"
     ]
    }
   ],
   "source": [
    "print(\"Used dataSet:\")\n",
    "cfg.recursive_print_attrdict(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is a $w \\times s \\times t$ matrix. The first step consists in slicing the original multivariate time series into slices of shape ($w \\times d$), as shown in this figure from the paper.\n",
    "<img src=\"https://i.imgur.com/R9Fx8uO.png\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of this sliding window approach are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLIDING WINDOW --\n",
      "Len: 200\n",
      "Stride: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"--- SLIDING WINDOW --\")\n",
    "print(\"Len: \" + str(config.w))\n",
    "print(\"Stride: \" + str(config.stride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>2015-08-31 18:22:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>2015-08-31 18:32:00</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>2015-08-31 18:57:00</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>2015-08-31 19:07:00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>2015-08-31 19:12:00</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               timestamp  value\n",
       "1970-01-01 00:00:00  2015-08-31 18:22:00     90\n",
       "1970-01-01 00:00:01  2015-08-31 18:32:00     80\n",
       "1970-01-01 00:00:02  2015-08-31 18:57:00     84\n",
       "1970-01-01 00:00:03  2015-08-31 19:07:00     94\n",
       "1970-01-01 00:00:04  2015-08-31 19:12:00     90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get artiffact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "#convert to pandas dataset\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. variables: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of variables\n",
    "if dataSet.cols:\n",
    "    df_train = df_train.iloc[:, dataSet.cols]\n",
    "print(f'Num. variables: {len(df_train.columns)}')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:35</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:36</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:37</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:38</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:41:39</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90\n",
       "...                    ...\n",
       "1970-01-01 00:41:35     81\n",
       "1970-01-01 00:41:36     89\n",
       "1970-01-01 00:41:37     87\n",
       "1970-01-01 00:41:38     82\n",
       "1970-01-01 00:41:39     83\n",
       "\n",
       "[2500 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.9068\n",
      "8.744856417346142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize data by subtracting mean and dividing by std\n",
    "meanSeq     = np.mean(df_train['value'])\n",
    "print(meanSeq)\n",
    "stdSeq      = np.std(df_train['value'])\n",
    "print(stdSeq)\n",
    "df_train['value'] = (df_train['value'] - meanSeq)/stdSeq\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset shape</td>\n",
       "      <td>(2500, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of Sliding windows</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sliding window shape</td>\n",
       "      <td>(1, 200)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Description      Value\n",
       "0              Dataset shape  (2500, 1)\n",
       "1  Number of Sliding windows       2301\n",
       "2       Sliding window shape   (1, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup Training windows\n",
    "X_train, _ = sw(df_train) #Windows\n",
    "data = {\n",
    "    \"Description\": [\n",
    "        \"Dataset shape\", \n",
    "        \"Number of Sliding windows\", \n",
    "        \"Sliding window shape\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(df_train.shape), \n",
    "        str(X_train.shape[0]), \n",
    "        f\"({X_train.shape[1]}, {X_train.shape[2]})\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "training_info = pd.DataFrame(data)\n",
    "training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>-0.218048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.239364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>1.382893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.925481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "1970-01-01 00:00:00  0.925481\n",
       "1970-01-01 00:00:01 -0.218048\n",
       "1970-01-01 00:00:02  0.239364\n",
       "1970-01-01 00:00:03  1.382893\n",
       "1970-01-01 00:00:04  0.925481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No validation artifact. Random items to get: 0.1\n"
     ]
    }
   ],
   "source": [
    "if config.valid_artifact:\n",
    "    valid_artifact = artifacts_gettr(config.valid_artifact)\n",
    "    df_val = valid_artifact.to_df()\n",
    "    X_valid, _ = sw(df_val)\n",
    "    df_val.shape, X_valid.shape\n",
    "    print(\"valid_artifact\")\n",
    "    print(valid_artifact)\n",
    "    print(\"df_val\")\n",
    "    print(df_val)\n",
    "    print(\"X_valid\")\n",
    "    print(X_valid)\n",
    "    print(\"df_val.shape\")\n",
    "    print(df_val.shape)\n",
    "    print(\"X_valid.shape\")\n",
    "    print(X_valid.shape)\n",
    "else:\n",
    "    print(\"No validation artifact. Random items to get:\", config.valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: METER EXPLICACIÓN DE OR-ELM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: AQUI VA LA EXPLICACIÓN CON EL EJEMPLO QUE SE META EN EL PAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2301, 1, 200)\n",
      "y.shape: (2301, 1, 200)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset\n",
    "random.seed = config.random_seed\n",
    "if config.valid_artifact:\n",
    "    X, y, splits  = combine_split_data(xs=[X_train, X_valid], ys=[X_train, X_valid])\n",
    "else:\n",
    "    X = X_train\n",
    "    y = X_train\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size)\n",
    "splits\n",
    "print(\"X.shape: \"+str(X.shape))\n",
    "print(\"y.shape: \"+str(y.shape))\n",
    "#print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the model\n",
    "#features = pd.DataFrame(dls.dataset[0][0])\n",
    "#targets = pd.DataFrame(dls.dataset[0][1]) #1\n",
    "\n",
    "#print(\"dls len: \" + str(len(dls.dataset)))\n",
    "\n",
    "#print(\"Features shape: \" + str(features.shape))\n",
    "#print(\"Targets shape: \" + str(features.shape))\n",
    "\n",
    "#dls.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numLags         = X_train.shape[0] #config.epochs\n",
    "nDimInput       = numLags\n",
    "nDimOutput      = 1 #targets.shape[1] #1\n",
    "numNeurons      = config.numHiddenNeurons #nDimInput  #config.numHiddenNeurons\n",
    "algorithm       = config.algorithm\n",
    "LN              = config.LN \n",
    "AE              = config.AE\n",
    "InWeightFF      = config.inputWeightForgettingFactor #1.0\n",
    "OutWeightFF     = config.outputWeightForgettingFactor #0.92\n",
    "HiddenWeightFF  = config.inputWeightForgettingFactor #1.0\n",
    "lamb            = config.lamb\n",
    "predictionStep  = config.stride #5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   Description           Value\n",
       "0               Dataset shape       (2500, 1)\n",
       "1   Number of Sliding windows            2301\n",
       "2        Sliding window shape        (1, 200)\n",
       "3      inputs/Charasteristics            2301\n",
       "4               Targets shape  (2301, 1, 200)\n",
       "5               X_train shape  (2301, 1, 200)\n",
       "6               Input Weights      (25, 2301)\n",
       "7              Hidden Weights        (25, 25)\n",
       "8                    Hidden A         (1, 25)\n",
       "9                        Bias         (1, 25)\n",
       "10                   Features       (1, 2301)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_to_append = {\n",
    "    \"Description\": [\n",
    "        \"inputs/Charasteristics\", \n",
    "        \"Targets shape\", \n",
    "        \"X_train shape\", \n",
    "        \"Input Weights\", \n",
    "        \"Hidden Weights\", \n",
    "        \"Hidden A\", \n",
    "        \"Bias\", \n",
    "        \"Features\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        str(nDimInput),\n",
    "        str(y.shape),\n",
    "        str(X_train.shape),\n",
    "        f\"({numNeurons}, {nDimInput})\",\n",
    "        f\"({numNeurons}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {numNeurons})\",\n",
    "        f\"({nDimOutput}, {nDimInput})\"\n",
    "    ]\n",
    "}\n",
    "data_to_append = pd.DataFrame(data_to_append)\n",
    "training_info = training_info.append(data_to_append, ignore_index = True)\n",
    "training_info.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with fastai Learner class, to abstract from Pytorch's training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To track the performance of this model fit, go to the project dashboard in Weights & Biases. The link is provided at the beginning of this notebook, after the execution of the function `wandb.init()'' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, log the learner to be used by the next notebook in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "200\n",
      "outputs\n",
      "1\n",
      "numNeurons\n",
      "25\n",
      "Out weight FF\n",
      "0.92\n",
      "(25, 200)\n",
      "--> Initialize_Phase: Input Weights initialized. Shape: (25, 200)\n",
      "ORELM_torch()\n"
     ]
    }
   ],
   "source": [
    "m = orelm.ORELM_torch(\n",
    "    inputs                      =   X_train.shape[2], #nDimInput,\n",
    "    outputs                     =   nDimOutput,\n",
    "    numHiddenNeurons            =   config.numHiddenNeurons,\n",
    "    activationFunction          =   config.activationFunction,\n",
    "    LN                          =   config.LN,\n",
    "    AE                          =   config.AE,\n",
    "    ORTH                        =   config.ORTH,\n",
    "    inputWeightForgettingFactor =   config.inputWeightForgettingFactor,\n",
    "    outputWeightForgettingFactor=   config.outputWeightForgettingFactor\n",
    ")\n",
    "m.initializePhase(lamb=0.0001)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n"
     ]
    }
   ],
   "source": [
    "tfms = [ToFloat(), ToFloat()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape[0]: 2301\n",
      "X.shape: (2301, 1, 200)\n",
      "y.shape: (2301, 1, 200)\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "dls.shape: (2301, 1, 200)\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "<class 'tsai.data.core.TSDataLoaders'>\n",
      "<class 'nbs.orelm_torch.ORELM_torch'>\n"
     ]
    }
   ],
   "source": [
    "tfms = [ToFloat(), ToFloat()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "#DataLoader\n",
    "print(\"X_train shape[0]: \" + str(X_train.shape[0]))\n",
    "print(\"X.shape: \"+str(X.shape))\n",
    "print(\"y.shape: \"+str(y.shape))\n",
    "\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "print(\"dls.shape: \"+str(X.shape))\n",
    "learn =  Learner(\n",
    "    dls         = dls, \n",
    "    model       = m, \n",
    "    loss_func   = nn.MSELoss(), #\n",
    "    opt_func    = Adam, #Creates an optimizer\n",
    "    cbs         = [WandbCallback(log_preds=False)] #List of callbacks\n",
    ")\n",
    "\n",
    "print(type(dls))\n",
    "print(type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORELM_torch()\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### Prueba comprobar tamaños para m \"en pequeño\"\\nstep = 0\\npredictions = []\\ntarget = []\\nmaxStep = X.shape[0]\\nfor i in range(maxStep-1):\\n    training_dataset = X[i]\\n    targets = y[i]\\n    features = X[i+1] \\n    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\\n    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\\n    m.train(training_dataset, targets)\\n    Y = m.predict(features)\\n    predictions.append(Y[0][0])\\n    target.append(y[i+1][0])\\n    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#### Prueba comprobar tamaños para m \"en pequeño\"\n",
    "step = 0\n",
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]\n",
    "for i in range(maxStep-1):\n",
    "    training_dataset = X[i]\n",
    "    targets = y[i]\n",
    "    features = X[i+1] \n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    m.train(training_dataset, targets)\n",
    "    Y = m.predict(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(y[i+1][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epoch: 4\n",
      "cb: LRFinder\n",
      "--> Fit\n",
      "About to return type: <class 'map'>\n",
      "--> Create opt\n",
      "---> opt_func \n",
      "self.model: ORELM_torch()\n",
      "self.splitter(self.model): []\n",
      "Learning rate: 0.001\n",
      "OPT func: <function Adam at 0x7f4ac57a5900>\n",
      "Adam optimizer\n",
      "Get cbs\n",
      "decouple_wd: True\n",
      "weight_decay <function weight_decay at 0x7f4ac57a52d0>\n",
      "l2_reg <function l2_reg at 0x7f4ac57a5360>\n",
      "Cbs: [<function weight_decay at 0x7f4ac57a52d0>]\n",
      "Add to cbs\n",
      "average_sqr_grad<function average_sqr_grad at 0x7f4ac57a5480>\n",
      "step_stat<function step_stat at 0x7f4ac57a5750>\n",
      "adam_step<function adam_step at 0x7f4ac57a5870>\n",
      "partial(average_grad, dampening=True): functools.partial(<function average_grad at 0x7f4ac57a53f0>, dampening=True)\n",
      "About to get optimizer\n",
      "Get params\n",
      "Get cbs\n",
      "Get defaults\n",
      "About to return type: <class 'map'>\n",
      "Get param list from params: []\n",
      "Get hyperes\n",
      "Set hypers\n",
      "Set frozen idx\n",
      "Return optimizer\n",
      "-- opt_func -> \n",
      "Estoy aqui\n",
      "--> bn_bias_state\n",
      "--> norm bias params\n",
      "Getting res\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n",
      "Okay got res\n",
      "About to return\n",
      "mapping var [array([[ 0.44953077, -0.561693  , -0.07599009, -0.56099342, -0.43538704,\n",
      "        -0.50422894, -0.88073734,  0.1448887 ,  0.76199988, -0.70746054,\n",
      "        -0.62382644,  0.35533132,  0.90134541,  0.07534413,  0.52123535,\n",
      "        -0.85939042,  0.57068155, -0.12083857, -0.38054984, -0.92215116,\n",
      "         0.08124622, -0.49703427,  0.8905551 , -0.05580866, -0.09650483]])]\n",
      "About to return type: <class 'map'>\n",
      "About to return type: <class 'map'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb Celda 37\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#print(\"self.dls shape: \" + str(learn.dls.train.shape))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#print(\"self.dls.train \" + str(len(learn.dls.train)))\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m lr_valley, lr_steep \u001b[39m=\u001b[39m   learn\u001b[39m.\u001b[39;49mlr_find(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64766174732d6a7570797465722d31222c2273657474696e6773223a7b22686f7374223a227373683a2f2f67342e6574736973692e75706d2e6573227d7d/home/macu/work/nbs_pipeline/02c_encoder_ORELM.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                             suggest_funcs\u001b[39m=\u001b[39;49m[valley, steep]                        )\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/callback/schedule.py:308\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mn_epoch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(n_epoch))\n\u001b[1;32m    306\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcb: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cb))\n\u001b[0;32m--> 308\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_logging(): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m suggest_funcs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBefore tensor\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/learner.py:271\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    269\u001b[0m     cbs \u001b[39m=\u001b[39m L(cbs) \u001b[39m+\u001b[39m SkipToEpoch(start_epoch)\n\u001b[1;32m    270\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madded_cbs(cbs):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mif\u001b[39;00m reset_opt \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_opt()\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m wd \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: wd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwd\n\u001b[1;32m    273\u001b[0m     \u001b[39mif\u001b[39;00m wd \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(wd\u001b[39m=\u001b[39mwd)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/learner.py:201\u001b[0m, in \u001b[0;36mLearner.create_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwd_bn_bias:\n\u001b[1;32m    200\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEstoy aqui\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bn_bias_state(\u001b[39mTrue\u001b[39;49;00m ): p[\u001b[39m'\u001b[39m\u001b[39mdo_wd\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGot norm bias state\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_bn:\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastai/learner.py:182\u001b[0m, in \u001b[0;36mLearner._bn_bias_state\u001b[0;34m(self, with_bias)\u001b[0m\n\u001b[1;32m    180\u001b[0m var \u001b[39m=\u001b[39m norm_bias_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, with_bias)\n\u001b[1;32m    181\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmapping var \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(var)) \n\u001b[0;32m--> 182\u001b[0m mapped \u001b[39m=\u001b[39m var\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt\u001b[39m.\u001b[39;49mstate)\n\u001b[1;32m    183\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mReturning\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastcore/foundation.py:156\u001b[0m, in \u001b[0;36mL.map\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(map_ex(\u001b[39mself\u001b[39;49m, f, \u001b[39m*\u001b[39;49margs, gen\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/fastcore/basics.py:841\u001b[0m, in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m gen: \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m    840\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAbout to return type: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(res)))\n\u001b[0;32m--> 841\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(res)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "#print(\"self.dls shape: \" + str(learn.dls.train.shape))\n",
    "#print(\"self.dls.train \" + str(len(learn.dls.train)))\n",
    "\n",
    "lr_valley, lr_steep =   learn.lr_find(\n",
    "                            suggest_funcs=[valley, steep]                        )\n",
    "#lr_valley, lr_steep = learn.lr_find(suggest_funcs=[valley, steep]) --> original\n",
    "#learn.fit_one_cycle(1, lr_max=lr_valley)\n",
    "#learn.fit_one_cycle(config.epochs, lr_max=lr_valley)\n",
    "#learn.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([X[w][0] for w in range(X_train.shape[0])]).T\n",
    "T = np.array([y[w][0] for w in range(X_train.shape[0])]).T   \n",
    "print('Input shape: ', str(X.shape))\n",
    "print('Target shape: ', str(T.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "target = []\n",
    "maxStep = X.shape[0]-predictionStep-1\n",
    "print(\"Num steps: \" + str(maxStep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "for i in range(maxStep):\n",
    "    training_dataset = X[[i],:]\n",
    "    targets = T[[i],:]\n",
    "    features = X[[i+1],:]\n",
    "    print(\"Training[\"+str(i)+\"] shape: \" + str(training_dataset.shape))\n",
    "    print(\"Targets[\"+str(i)+\"] shape: \" + str(targets.shape))\n",
    "    m.train(training_dataset, targets)\n",
    "    Y = m.predict(features)\n",
    "    predictions.append(Y[0][0])\n",
    "    target.append(T[i][0])\n",
    "    print (str(step)+\"th/\"+str(maxStep)+\" (\"+str(i)+\") timeStep of \"+str(maxStep) +\" -  target: \"+str(target[i]) + \" |    prediction: \"+str(predictions[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Calculate total Normalizedd Root Mean Square Error (NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct original value\n",
    "predictions = np.array(predictions)\n",
    "target = np.array(target)\n",
    "predictions = predictions * stdSeq + meanSeq\n",
    "target = target * stdSeq + meanSeq\n",
    "  \n",
    "def computeSquareDeviation(predictions, truth):\n",
    "  squareDeviation = np.square(predictions-truth)\n",
    "  return squareDeviation\n",
    "\n",
    "# Calculate NRMSE from skip_eval to the end\n",
    "skip_eval=100\n",
    "squareDeviation = computeSquareDeviation(predictions, target)\n",
    "squareDeviation[:skip_eval] = None\n",
    "nrmse = np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions)\n",
    "print(\"NRMSE {}\".format(nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target len: \" + str(len(target)) + str(target))\n",
    "print(\"Prediction len: \" + str(len(predictions))+str(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "algorithm = config.algorithm\n",
    "print(algorithm)\n",
    "print(config.job_type)\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "targetPlot,=plt.plot(target,label='target',color='red',marker='.',linestyle='-')\n",
    "predictedPlot,=plt.plot(predictions,label='predicted',color='blue',marker='.',linestyle=':')\n",
    "plt.xlim([0, 200])\n",
    "plt.ylim([60, 100])\n",
    "plt.ylabel('value',fontsize=15)\n",
    "plt.xlabel('time',fontsize=15)\n",
    "plt.ion()\n",
    "plt.grid()\n",
    "plt.legend(handles=[targetPlot, predictedPlot])\n",
    "plt.title('Time-series Prediction of '+ config.job_type + ' algorithm: ' + algorithm +' on '+dataSet.fname+' dataset' ,fontsize=20,fontweight=40)\n",
    "plot_path = './predictionPlot.png'\n",
    "#plt.savefig(plot_path,plot_pathbbox_inches='tight')\n",
    "plt.savefig(plot_path,bbox_inches='tight')\n",
    "plt.draw()\n",
    "plt.show()\n",
    "plt.pause(0)\n",
    "print('Prediction plot is saved to'+plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online learning and prediction of OR-ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
