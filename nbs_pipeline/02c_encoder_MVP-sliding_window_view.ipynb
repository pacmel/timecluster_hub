{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b6c9b7-dd2a-4d74-bf5a-cedadcc9347f",
   "metadata": {},
   "source": [
    "# Encoder - MVP\n",
    "\n",
    "Self-supervised learning Masked Value Prediction (MVP) as a way to create the embeddings.\n",
    "Based on tsai's MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4844a-ef9f-48f8-a575-254bd0aa04fe",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Initial notebook setup and specific debugging and pre-configured cases selection.\n",
    "### VsCode update patch\n",
    "Initial notebook setup when using VSCode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185023c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import sys\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    import nbs_pipeline.utils.vscode  as vs\n",
    "    vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b767ea2-3eaf-4233-b144-926264ec1c25",
   "metadata": {},
   "source": [
    "### Debugging variables\n",
    "\n",
    "- `print_flag`. If `True` it adds debbuging messages in those functions that allows so.\n",
    "- `reset_kernel`. If `True` it resets the kernel by the end of the execution. Use only in case that memory management is needed.\n",
    "- `check_memory_usage`. If `True`, it adds some lines for checking the GPU memmory ussage along the execution.\n",
    "- `time_flag`. If `True` it get the execution time along the notebook as well as inside those functions that allows so.\n",
    "- `window_size_percentage`. If `True`, MVP will be used directly with the proposed windows sizes. Otherwise, it will be asumed that they have been taken as absolute values and execution will be take that into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bed3a6-eaea-4f74-9411-ea4bea5bfa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flag = True\n",
    "reset_kernel = True\n",
    "check_memory_usage = True\n",
    "time_flag = True\n",
    "window_size_percentage = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1162273-f25b-4040-934e-943389baaca6",
   "metadata": {},
   "source": [
    "## Preconfigurated cases selection\n",
    "- `pre_configured_case`. If `True`, a preconfigured case will be selected, forcing the artifact to get the expected configuration based on the information in `config\\*.yml` and `utils\\config.py`.\n",
    "- `case_id`. If `preconfigured_case` is `True`, it forces to select the configuration of the `case_id` preconfigured samples. The available preconfigured samples are shown in the next cell.\n",
    "- `frequency_factor`. If `pre_configured_case` is `True`, frequency will be resampled by `config.freq*frequency_factor`\n",
    "  `frequency_factor_change_alias`. If `pre_configured_case` is `True` and `frequency_factor != 1` then the dataset alias will be modified for adding the new frequency as suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0e189a-1cc3-4e40-93d9-86d56cee23a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "import utils.config as cfg_\n",
    "cfg_.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a05e15-80e7-44fd-91b3-637a0d2e7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_configured_case = True\n",
    "case_id = 1\n",
    "frequency_factor = 150\n",
    "frequency_factor_change_alias = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bafe60-84e9-440a-ae92-29562567df86",
   "metadata": {},
   "source": [
    "## Main code\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a511d12-df7f-420e-b570-f37bc13d1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "from tsai.data.preparation import prepare_forecasting_data\n",
    "from tsai.data.validation import get_long_term_forecasting_splits, get_forecasting_splits #TODO: Quitar 1 cuando esté decidida la opción\n",
    "import wandb\n",
    "if check_memory_usage: \n",
    "    import nbs_pipeline.utils.memory as mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2deef3-db00-430a-b426-49d7e58e22c0",
   "metadata": {},
   "source": [
    "### Initialize and Configurate Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be090327-2eda-44be-9a71-89e20242dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961dbf47-71de-4471-80d5-2fdabbd6e360",
   "metadata": {},
   "source": [
    "#### Setup CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb164924-13e2-4099-ba35-06e675035d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_device = int(1)\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.device_count()\n",
    "\n",
    "#torch.cuda.set_device(device)\n",
    "#if check_memory_usage:\n",
    " #   gpu_device = torch.cuda.current_device()\n",
    "  #  mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb7848-0ac0-4f55-a6e6-49478d7cac25",
   "metadata": {},
   "source": [
    "#### Get configutation from yml\n",
    "> This file used the configuration files './config/base.yml' and './config/02b_encoder_MVP.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b845205-b133-4ee1-baaf-acc2ddd6533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias: solar_4_seconds\n",
      "fname: solar_4_seconds_dataset\n",
      "ftype: .tsf\n",
      "freq: 4s\n",
      "cols: []\n",
      "time_col: None\n",
      "mvp: {'batch_size': 512, 'n_epoch': 100, 'ws': [450, 900], 'stride': 450}\n",
      "dcae: {'batch_size': 512, 'n_epoch': 100, 'stride': 48, 'w': 224, 'delta': 60, 'nfs': [64, 32, 16], 'kss': [10, 5, 5], 'output_filter_size': 10, 'top_k': [2, 2, 4], 'pool_szs': [2, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP_SWV(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.show_config(case_id)\n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71052bbf-f65b-45ea-aa8f-e3ee665f27ba",
   "metadata": {},
   "source": [
    "### Setup W&B artiffact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30caa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 02c_encoder_MVP-sliding_window_view\n"
     ]
    }
   ],
   "source": [
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"02c_encoder_MVP-sliding_window_view\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b51e78-7bb2-4bbc-a1d6-a4c4bee1a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias: solar_4_seconds\n",
      "analysis_mode: online\n",
      "batch_size: 512\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [450, 900]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 450\n",
      "train_artifact: mi-santamaria/deepvats/solar_4_seconds-10m:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 900\n",
      "wandb_group: None\n",
      "artifact_name: solar_4_seconds-10m\n",
      "data_cols: []\n",
      "freq: 4s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "resampling_freq: 10T\n",
      "norm_use_by_single_batch: (False,)\n"
     ]
    }
   ],
   "source": [
    "if print_flag: cfg_.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4411368-d772-4381-9cc0-5c9b7ea5361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mi-santamaria. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20240111_182517-jqupequ7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/jqupequ7' target=\"_blank\">02c_encoder_MVP-sliding_window_view</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/jqupequ7' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/jqupequ7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'stream.Stream' object attribute 'write' is read-only\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', resume=False,\n",
    "    name = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0515d-4f2a-4ba6-8c41-a6f480ff6f4b",
   "metadata": {},
   "source": [
    "### Split data using Sliding Window & Get training artiffact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a82ad4-45ca-4c9e-8d87-aa56f4d2fdd2",
   "metadata": {},
   "source": [
    "#### Get W&B train artifact\n",
    "##### Build artifact selector\n",
    "Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebeba46-eb67-405c-9de7-c1acb8e4085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias: solar_4_seconds\n",
      "analysis_mode: online\n",
      "batch_size: 512\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [450, 900]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 450\n",
      "train_artifact: mi-santamaria/deepvats/solar_4_seconds-10m:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 900\n",
      "wandb_group: None\n",
      "artifact_name: solar_4_seconds-10m\n",
      "data_cols: []\n",
      "freq: 4s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "resampling_freq: 10T\n",
      "norm_use_by_single_batch: [False]\n"
     ]
    }
   ],
   "source": [
    "config = run.config  # Object for storing hyperparameters\n",
    "if print_flag: cfg_.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cd3daa2-d550-424a-9113-df1d9c7bef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78dced3c-8280-460e-bd11-8188495bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_artifact = artifacts_gettr(config.train_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8acf714f-0fe1-4aed-8b57-23ccd31b22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                0            1            2            3  \\\n",
       "2002-01-01 00:00:00  5931.372266  3440.111713  4147.990158  1005.964135   \n",
       "2002-01-01 00:10:00  5715.572874  3547.763803  3874.365954  1040.995599   \n",
       "2002-01-01 00:20:00  6556.910663  3880.651585  4446.102240  1171.973044   \n",
       "2002-01-01 00:30:00  5942.032149  3748.438673  4268.350097  1215.260650   \n",
       "2002-01-01 00:40:00  6107.060523  3901.220754  4184.055746  1234.619848   \n",
       "...                          ...          ...          ...          ...   \n",
       "2002-01-11 17:20:00          NaN          NaN  5059.323853          NaN   \n",
       "2002-01-11 17:30:00          NaN          NaN  4663.700689          NaN   \n",
       "2002-01-11 17:40:00          NaN          NaN  5197.783968          NaN   \n",
       "2002-01-11 17:50:00          NaN          NaN  4503.084537          NaN   \n",
       "2002-01-11 18:00:00          NaN          NaN  4816.115863          NaN   \n",
       "\n",
       "                              4  \n",
       "2002-01-01 00:00:00  390.220627  \n",
       "2002-01-01 00:10:00  371.706241  \n",
       "2002-01-01 00:20:00  408.820509  \n",
       "2002-01-01 00:30:00  385.392171  \n",
       "2002-01-01 00:40:00  430.877752  \n",
       "...                         ...  \n",
       "2002-01-11 17:20:00         NaN  \n",
       "2002-01-11 17:30:00         NaN  \n",
       "2002-01-11 17:40:00         NaN  \n",
       "2002-01-11 17:50:00         NaN  \n",
       "2002-01-11 18:00:00         NaN  \n",
       "\n",
       "[1549 rows x 5 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = train_artifact.to_df()\n",
    "if print_flag:\n",
    "    print(df_train.shape)\n",
    "    display(df_train.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e58744-f25a-4e25-baad-07013879e89f",
   "metadata": {},
   "source": [
    "### Get training set\n",
    "Use `prepare_forecasting_data` from tsai. Must take into account it uses the following variables:\n",
    "> | Variable         | Definition                                           | Default Value | Value Utilised   |\n",
    "> |------------------|------------------------------------------------------|---------------|------------------|\n",
    "> | `df`             | Time series DataFrame.                               | -             | `df_train`       |\n",
    "> | `fcst_history`   | Input historical steps. Window size.                 | -             | `config.w`       |\n",
    "> | `fcst_horizon`   | Future predicted steps.                              | `1`           | - (no forecasts) |\n",
    "> | `x_vars`         | Input variables.                                     | `None`        | - (all columns)  |\n",
    "> | `y_vars`         | Output variables.                                    | `None`        | -                |\n",
    "> | `dtype`          | Output datatype (for example, `'float32'`).          | `None`        | -                |\n",
    "> | `unique_id_cols` | None or unique identifier column id.                 | -             | -                |\n",
    "> \n",
    "> For more information, visit [tsai - data - preparation - prepare_forecasting_data](https://timeseriesai.github.io/tsai/data.preparation.html#prepare_forecasting_data)recasting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca6f7fd-ca88-449a-81db-9ebcce6beb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train ~  (1549, 5)\n",
      "window_sizes =  [450, 900]\n",
      "wlen =  900\n"
     ]
    }
   ],
   "source": [
    "if print_flag: \n",
    "    print(\"df_train ~ \", df_train.shape)\n",
    "    print(\"window_sizes = \", config.mvp_ws)\n",
    "    print(\"wlen = \", config.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "973a9e71-2e00-4cbd-a93b-2824e2f45c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = prepare_forecasting_data(df_train, fcst_history = config.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3deacf2c-348f-414c-8cdd-2de61c49733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ~ (649, 5, 900)\n",
      "stride ~ 450\n"
     ]
    }
   ],
   "source": [
    "if print_flag:\n",
    "    print(\"X ~\", X_train.shape)\n",
    "    print(\"stride ~\", config.stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d9653-82e7-42a1-a659-b61b13708dcf",
   "metadata": {},
   "source": [
    "#### Apply strides\n",
    "Once we have build the windows, we can apply strides in order to check have the same structure as when used via sliding window\n",
    "> <span style=\"color:red\"> TODO: Check if it is the same to set fcst_horizon = stride </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ff39cfd-bab8-4b9e-96c4-7a8600652afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_strided = X_train[::config.stride]\n",
    "X = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565617e-74e5-4727-91ba-fd5470e864fc",
   "metadata": {},
   "source": [
    "- df_train ~ (num_samples, num_vars)\n",
    "- X_train ~ (num_samples - window_size, num_vars, window_size)\n",
    "- X_train_strided ~ ((num_samples - window_size)/stride, num_vars, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d25ab5a-b1e6-4eb7-8542-e4dc87f2a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ~  (649, 5, 900)\n",
      "X_strided ~  (2, 5, 900)\n"
     ]
    }
   ],
   "source": [
    "print(\"X ~ \", X.shape)\n",
    "print(\"X_strided ~ \", X_strided.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e726d-a175-4629-8024-0156cdfe599a",
   "metadata": {},
   "source": [
    "### Split Training Set into Training and Test Dataset\n",
    "\n",
    "> Use the `get_forecasting_splits` function from tsai to split your time series data. Understand and adapt the parameters to suit your needs:\n",
    ">\n",
    "> | Variable               | Definition                                             | Default Value | Value Utilised     |\n",
    "> |------------------------|--------------------------------------------------------|---------------|--------------------|\n",
    "> | `df`                   | DataFrame containing a sorted time series.             | -             | `df_train`         |\n",
    "> | `fcst_history`         | Number of historical steps used as input.              | -             | `config.w`         |\n",
    "> | `fcst_horizon`         | Number of steps forecasted into the future.            | `1`           | 1 (no forecasts)   |\n",
    "> | `stride`               | Strides of the sliding windows (input and target).     | `1`           | `config.stride`    |\n",
    "> | `valid_size`           | Size of the training set (based on datetimes).         | `0.0`         | `config.valid_size`|\n",
    "> | `test_size`            | Size of the test set (based on datetimes).             | `0.2`         | `0.2`              |\n",
    "> | `valid_cutoff_datetime`| First prediction datetime of validation dataset.       | `None`        | -                  |\n",
    "> | `test_cutoff_datetime` | First prediction datetime of test dataset.             | `None`        | -                  |\n",
    "> | `datetime_col`         | Column with the datetime values.                       | `None`        | `config.time_col   |\n",
    "> | `use_index`            | Flag to indicate if datetime is in the index.          | `False`       | `True`             |\n",
    "> | `unique_id_cols`       | Column/s with the unique identifier/s for each entity. | `None`        | -                  |\n",
    "> | `show_plot`            | Flag to indicate if splits should be plotted.          | `True`        | `True`             |\n",
    ">\n",
    "> For more information, visit [tsai - Splitting data - get_forecasting_splits](https://timeseriesai.github.io/tsai/data.validation.html#get_forecasting_splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "854c7680-e590-449a-a454-6b6a7595b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "539d98ef-0953-446c-8a47-7c3278a929fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AssertionError'>",
     "evalue": "you need to modify test_size due to lack of data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39manalysis_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m'\u001b[39m: \n\u001b[0;32m----> 2\u001b[0m     splits \u001b[38;5;241m=\u001b[39m get_forecasting_splits(\n\u001b[1;32m      3\u001b[0m         df \u001b[38;5;241m=\u001b[39m df_train, \n\u001b[1;32m      4\u001b[0m         fcst_history \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mw,\n\u001b[1;32m      5\u001b[0m         fcst_horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m         stride \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mstride, \n\u001b[1;32m      7\u001b[0m         test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      8\u001b[0m         show_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#    splits = TimeSplitter(valid_size=0.2, show_plot=True)(X)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39manalysis_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/tsai/data/validation.py:615\u001b[0m, in \u001b[0;36mget_forecasting_splits\u001b[0;34m(df, fcst_history, fcst_horizon, stride, valid_size, test_size, valid_cutoff_datetime, test_cutoff_datetime, datetime_col, use_index, unique_id_cols, show_plot)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m use_test:\n\u001b[1;32m    614\u001b[0m     train_end \u001b[38;5;241m=\u001b[39m test_start \u001b[38;5;241m-\u001b[39m (fcst_horizon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m stride\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m train_end \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou need to modify test_size due to lack of data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m     train_idxs \u001b[38;5;241m=\u001b[39m usable_np_idxs[usable_step_codes \u001b[38;5;241m<\u001b[39m train_end]\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: you need to modify test_size due to lack of data"
     ]
    }
   ],
   "source": [
    "if config.analysis_mode == 'online': \n",
    "    splits = get_forecasting_splits(\n",
    "        df = df_train, \n",
    "        fcst_history = config.w,\n",
    "        fcst_horizon = 1,\n",
    "        stride = config.stride, \n",
    "        test_size = 0.2,\n",
    "        show_plot = True\n",
    "    )\n",
    "    #    splits = TimeSplitter(valid_size=0.2, show_plot=True)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    splits = get_splits(np.arange(len(X_strided)), valid_size=config.valid_size)\n",
    "\n",
    "if print_flag:\n",
    "    display(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb702b4-8b10-4164-8755-456ffd2759f9",
   "metadata": {},
   "source": [
    "## MVP - Encoder training\n",
    "Train MVP with optional adaptable window sizes, to allow for inference with different\n",
    "window sizes, to provide an easier exploration of the embedding space through different\n",
    "ways of sliding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156687d8-27b4-451c-b4ae-d5e6859fce25",
   "metadata": {},
   "source": [
    "### Set callback list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = L(WandbCallback(log_preds=False)) if config.use_wandb else L()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31668027-6769-405d-8223-09699a4f1b7f",
   "metadata": {},
   "source": [
    "### Set transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97038fe-116f-4d6c-8569-e9a9c015a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [ToFloat(), None]\n",
    "batch_tfms = [TSStandardize(by_sample=config.norm_by_sample, \n",
    "               use_single_batch=config.norm_use_single_batch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ae849-6b83-4298-9132-b68746b982f8",
   "metadata": {},
   "source": [
    "### Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_flag: print(X.shape)\n",
    "dls = get_ts_dls(X, splits=splits, tfms=tfms, bs=config.batch_size, batch_tfms=batch_tfms)\n",
    "if print_flag: display(dls.show_at(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7824ad8e-868d-4840-a985-00627f538439",
   "metadata": {},
   "source": [
    "#### Check dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0746c-7d67-474b-85db-f65e5fe147b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_flag:\n",
    "    print(\"X ~\", X.shape) \n",
    "    print(\"dls batch size\", dls.bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b997218-945b-49df-b48e-e83eff7f3463",
   "metadata": {},
   "source": [
    "#### Build MVP TS Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e4f21-d911-446d-8df0-d8c6fc4e112c",
   "metadata": {},
   "source": [
    "##### Auxiliar functions for ensuring absolute/percentage window size management and checking the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68800c87-ba6e-4097-bfb0-6862a0fb1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not window_size_percentage):\n",
    "    from copy import deepcopy\n",
    "    def ensure_expected_window_size(expected_window_size, print_flag: bool = False):\n",
    "        window_size = deepcopy(expected_window_size)\n",
    "        if print_flag: print(window_size)\n",
    "        window_size[0] = window_size[0] / window_size[1]\n",
    "        if print_flag: \n",
    "            print(window_size)\n",
    "            print(int(round(window_size[0]*window_size[1])))\n",
    "        return window_size\n",
    "    def check_expected_window_size(learn, expected_window_size, print_flag: bool = False):\n",
    "        # Find MVP calback\n",
    "        obtained_window_size = deepcopy(learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0].window_size)\n",
    "        if print_flag: print(\"obtained percentage\", obtained_window_size)\n",
    "        obtained_window_size[0] = int(round(obtained_window_size[0]*obtained_window_size[1]))\n",
    "        if print_flag: print(\"obtained absolute\", obtained_window_size)\n",
    "        return obtained_window_size == expected_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291d3f9-ab4a-4233-9fe7-2febc19e80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not window_size_percentage:\n",
    "    window_size = ensure_expected_window_size(config.mvp_ws)\n",
    "else:\n",
    "    window_size = config.mvp_ws\n",
    "window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45a7c5-6670-4098-8112-fe57d6e51e21",
   "metadata": {},
   "source": [
    "##### Initialize learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2b562-c1d8-4b01-aa69-6aa974ee959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgc = ShowGraphCallback2()\n",
    "learn = ts_learner(dls, \n",
    "                   InceptionTimePlus, \n",
    "                   cbs= cbs + sgc + MVP(\n",
    "                       r = config.r, \n",
    "                       window_size=window_size, \n",
    "                       future_mask = config.mask_future, \n",
    "                       target_dir='./models', \n",
    "                       sync = config.mask_sync, \n",
    "                       stateful = config.mask_stateful,\n",
    "                       fname=f'encoder_MVP',\n",
    "                       verbose=False\n",
    "                    ), y_range=[X.min(), X.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf260d-9df4-48c6-9f9a-191d5b956631",
   "metadata": {},
   "source": [
    "#### Check learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deaf33e-2d3d-4fac-a10f-21704a2cca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not window_size_percentage:\n",
    "    check_expected_window_size(learn, config.mvp_ws, print_flag = print_flag)\n",
    "    if print_flag:\n",
    "        print(\"learn dls.bs\",  learn.dls.bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675240ed-a3b9-4a8d-b5cb-41c48b68909c",
   "metadata": {},
   "source": [
    "#### Example mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c923f-31e8-49f2-b3d9-8b1fe370bcc6",
   "metadata": {},
   "source": [
    "##### Create mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dd304-6691-49b7-9ffc-f004757f3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mask_future:\n",
    "    example_mask = create_future_mask(torch.from_numpy(X[0]), config.r, sync=config.mask_sync)\n",
    "else:\n",
    "    example_mask = create_subsequence_mask(torch.from_numpy(X[0]), config.r, stateful=config.mask_stateful, sync=config.mask_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d81f4-2d4a-484c-bf9b-88ccab1cd4d6",
   "metadata": {},
   "source": [
    "##### Show mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563efbd4-bc93-4969-b7e8-bed4b191291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "plt.pcolormesh(example_mask[0], cmap=colors.ListedColormap(['whitesmoke', 'orchid']))\n",
    "plt.title(f'r={config.r},  future={config.mask_future},  stateful={config.mask_stateful},  sync={config.mask_sync}')\n",
    "ax.set_ylabel('variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb64be-3389-4f2b-997d-a8799e1a5469",
   "metadata": {},
   "source": [
    " #### Check window size configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63c043-6d89-47f6-a579-2f028980237e",
   "metadata": {},
   "source": [
    "##### Check config attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d5cc8-fac5-4f9d-bbd9-4083c2c60d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_window_size = config.mvp_ws\n",
    "if print_flag:\n",
    "    print(\"w\", config.w, \"mvp_ws\", config.mvp_ws)\n",
    "    print(\"expected \", expected_window_size)\n",
    "    print(*config.mvp_ws)\n",
    "np.random.randint(*config.mvp_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e5d4c-84de-440c-9572-8688951c2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "obtained_window_size = deepcopy(learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0].window_size)\n",
    "if print_flag: print(\"obtained \", obtained_window_size)\n",
    "obtained_window_size[0] = int(round(obtained_window_size[0]*obtained_window_size[1]))\n",
    "if print_flag: print(\"obtained \", obtained_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a3112-ba6b-4756-9ce1-e15e4c2af1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (expected_window_size != obtained_window_size):\n",
    "    raise ValueError(\"Obtained window_size for MVP training different from expected window size. Check size, ws1 & ws2 parameters in '02b-encoder_MVP.yaml'\")\n",
    "else: \n",
    "    print(\"Obtained window size tuple is the expected one. Continue!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc784e8-59a1-45e9-8af1-b61ba01a9fc6",
   "metadata": {},
   "source": [
    "##### Check w1 < w2 for MVP random window size selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272a132-9026-419c-81b0-d16d03894f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (obtained_window_size[1] < obtained_window_size[0]):\n",
    "    raise ValueError(\"Ws2 must be greater than Ws1 as they are the maximun and minimum window size respectively. Please ensure w2 > w1\")\n",
    "else: \n",
    "    print(obtained_window_size)\n",
    "    ws = np.random.randint(*obtained_window_size)\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05917f56-5e62-4e45-b546-5996a72106bd",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10238a-f7f2-4fa2-9497-1b59f83cc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obtained_window_size = deepcopy(learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0].window_size)\n",
    "if print_flag: print(\"obtained \", obtained_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4402b8e-a0e3-40ac-b208-8172d9ba0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4870d10-dcd3-4cfc-937e-3db61ed57f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_valley, lr_steep = learn.lr_find(suggest_funcs=(valley, steep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f53b3-5c75-4d9b-94c9-0385f65dd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obtained_window_size = deepcopy(learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0].window_size)\n",
    "if print_flag: print(\"obtained \", obtained_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a6e2e-6b3b-44f4-9f8a-7585931b2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not window_size_percentage:\n",
    "    if not check_expected_window_size(learn=learn, expected_window_size=config.mvp_ws, print_flag=True):\n",
    "        learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0].window_size = ensure_expected_window_size(config.mvp_ws, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26833f1-ba03-470e-b209-b20ddebc7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dd97f-1cb2-4364-9748-db882ac6162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(n_epoch=config.epochs, lr_max=lr_valley,  cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.000001, patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b920f-09d3-4bdc-9dbe-0d0ecf673138",
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae82aae-70dd-40de-baf8-22a2bf3d99c0",
   "metadata": {},
   "source": [
    "#### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab4815-050b-475e-b0e7-7278fbae4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not window_size_percentage:\n",
    "    if not check_expected_window_size(learn=learn, expected_window_size=config.mvp_ws, print_flag=True):\n",
    "        learn.cbs.filter(lambda cb: isinstance(cb, MVP))[0].window_size = ensure_expected_window_size(config.mvp_ws, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db4834-1e28-4251-8f58-662cdf5f24bf",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf3667-a698-451a-9900-0ac1d6fa0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.MVP.show_preds(sharey=True, nrows=2) # error with nwors=1 or ncols=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4ff29-1d59-4c1d-8499-a8e2b0b6c012",
   "metadata": {},
   "source": [
    "## Save artifact to W&B\n",
    "> Remove extra information and saving the learner object as an weight and biases artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bf350-4f52-4a18-ad19-9d260bd060d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the ShowGraphCallback2 callback to avoid errors in the frontend (TODO)\n",
    "learn.remove_cb(sgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0de64-aced-433e-9c10-28fbcf4f9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the learner without the datasets\n",
    "aux_learn = learn.export_and_get()\n",
    "if config.use_wandb: \n",
    "    run.log_artifact(\n",
    "        ReferenceArtifact(\n",
    "            aux_learn, \n",
    "            f'mvp-SWV', \n",
    "            type='learner', \n",
    "            metadata=dict(run.config)\n",
    "        ), \n",
    "        aliases=config.alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97de068-dc91-4cfc-b0a0-2a52b52a9f80",
   "metadata": {},
   "source": [
    "## Close W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe12cd-6e5f-40eb-8f84-12d2db7a355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253c2fa-520a-4c55-a972-7fa9f4b0e250",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Execution ended\")\n",
    "beep(1)\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
