{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create artifact from time series dataframe\n",
    "Gets a .tsf or .csv with a time serie, convert int to np.dataframe and loads it to weights and biases (W&B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Initial notebook setup and specific debugging and pre-configured cases selection\n",
    "### VsCode update patch\n",
    "Initial notebook setup when using VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    import nbs_pipeline.utils.vscode  as vs\n",
    "    vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging variables\n",
    "- `print_flag`. If `True` it adds debbuging messages in those functions that allows so (eg. `get_enc_embeddings`)\n",
    "- `reset_kernel`. If `True` it resets the kernel by the end of the execution. Use only in case that memory management is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flag = True\n",
    "reset_kernel=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "import utils.config as cfg\n",
    "cfg.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_configured_case = True\n",
    "case_id = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "from dvats.load import TSArtifact, infer_or_inject_freq\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tsai.data.external import convert_tsf_to_dataframe\n",
    "from tsai.utils import stack_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and Artiffact configurattions\n",
    "This notebook gets configuration from `config\\base.yaml` and `config\\01-dataset_artifact.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting  monash_solar_10_minutes_0\n",
      "normalize_training: False\u001b[0m\n",
      "wandb_artifacts_path: ./data/wandb_artifacts\u001b[0m\n",
      "\u001b[94mfreq: 1h\u001b[0m -> 10min\u001b[0m\n",
      "range_testing: None\u001b[0m\n",
      "time_col: None\u001b[0m\n",
      "range_training: None\u001b[0m\n",
      "missing_values_technique: None\u001b[0m\n",
      "use_wandb: True\u001b[0m\n",
      "date_offset: None\u001b[0m\n",
      "missing_values_constant: None\u001b[0m\n",
      "test_split: None\u001b[0m\n",
      "joining_train_test: False\u001b[0m\n",
      "\u001b[94mdata_fpath: ~/data/australian_electricity_demand_dataset.tsf\u001b[0m -> ~/data/solar_10_minutes_dataset.tsf\u001b[0m\n",
      "resampling_freq: None\u001b[0m\n",
      "csv_config: {}\u001b[0m\n",
      "data_cols: [0]\u001b[0m\n",
      "\u001b[94martifact_name: Monash-Australian_electricity_demand\u001b[0m -> Monash-Solar_10_minutes\u001b[0m\n",
      "start_date: None\u001b[0m\n",
      "date_format: %Y-%m-%d %H:%M:%S\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = cfg.get_artifact_config_sd2a(print_flag = False)\n",
    "if pre_configured_case: \n",
    "    cfg.force_artifact_config_sd2a(config, case_id, print_flag = print_flag, both = print_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is assumed to come as a dataframe, either as a binarized  picke file or\n",
    "as a csv file. It can also come as a `.tsf` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check file content (if wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/macu/data/solar_10_minutes_dataset.tsf\n",
      "# Dataset Information\n",
      "# The original solar dataset contains approximately 6000 simulated time series representing 5-minute solar power and hourly day-ahead forecasts of photovoltaic (PV) power plants in United States in 2006.\n",
      "# This file contains the aggregated version of a subset of the original dataset used by Lai et al. (2017).\n",
      "# This contains 137 time series representing the solar power production recorded per every 10 minutes in Alabama state in 2006.\n",
      "#\n",
      "# For more details, please refer to\n",
      "# National Renewable Energy Laboratory, 2020. Solar power data for integration studies. Accessed:  2020-04-30. URL https://www.nrel.gov/grid/solar-power-data.html\n",
      "# Lai, G., 2017. multivariate-time-series-data. https://github.com/laiguokun/multivariate-time-series-data, accessed:  2020-05-04\n",
      "# Lai, G., Chang, W., Yang, Y., Liu, H., 2017. Modeling long and short-term temporal patterns with deep neural networks. CoRR abs/1703.07015.URL http://arxiv.org/abs/1703.07015\n",
      "#\n",
      "@relation Solar\n",
      "@attribute series_name string\n",
      "@attribute start_timestamp date\n",
      "Timestamp 0     2006-01-01 00:00:01\n",
      "1     2006-01-01 00:00:01\n",
      "2     2006-01-01 00:00:01\n",
      "3     2006-01-01 00:00:01\n",
      "4     2006-01-01 00:00:01\n",
      "              ...        \n",
      "132   2006-01-01 00:00:01\n",
      "133   2006-01-01 00:00:01\n",
      "134   2006-01-01 00:00:01\n",
      "135   2006-01-01 00:00:01\n",
      "136   2006-01-01 00:00:01\n",
      "Name: start_timestamp, Length: 137, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "if print_flag:\n",
    "    fpath=os.path.expanduser(config.data_fpath)\n",
    "    print(fpath)\n",
    "    try: \n",
    "        with open(fpath, 'r') as file:\n",
    "            for _ in range(13):\n",
    "                line = file.readline()\n",
    "                print(line, end='')\n",
    "        data, _, _, _, _ = convert_tsf_to_dataframe(fpath)\n",
    "        print(\"Timestamp\", data.start_timestamp)\n",
    "    except Exception as e:\n",
    "        print(\"Error while converting file. Maybe not a tsf: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = str(config.data_fpath).split('.')[-1]\n",
    "\n",
    "if ext == 'pickle':\n",
    "    df = pd.read_pickle(config.data_fpath)\n",
    "    \n",
    "elif ext in ['csv','txt']:\n",
    "    df = pd.read_csv(config.data_fpath, **config.csv_config)\n",
    "    \n",
    "elif ext == 'tsf':\n",
    "    data, _, _, _, _ = convert_tsf_to_dataframe(os.path.expanduser(config.data_fpath))\n",
    "    config.update({'start_date': data.start_timestamp[0]}, allow_val_change=True)\n",
    "    date_format = config.date_format\n",
    "    df = pd.DataFrame(stack_pad(data.series_value).T)\n",
    "    \n",
    "else:\n",
    "    raise Exception('The data file path has an unsupported extension')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully\n",
      "(52560, 137)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  127  128  129  130  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   131  132  133  134  135  136  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if print_flag:\n",
    "    print(f'File loaded successfully')\n",
    "    print(df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the time column (if any) as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  127  128  129  130  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   131  132  133  134  135  136  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config.time_col is not None:\n",
    "    if print_flag: print(\"time_col: \"+str(config.time_col))\n",
    "    \n",
    "    if isinstance(config.time_col, int): \n",
    "        if print_flag: print(\"Op 1: time_col int\")\n",
    "        datetime = df.iloc[:, config.time_col]\n",
    "    \n",
    "    elif isinstance(config.time_col, list): \n",
    "        if print_flag: print(\"Op 2: time_col list\")\n",
    "        datetime = df.iloc[:, config.time_col].apply(lambda x: x.astype(str).str.cat(sep='-'), axis=1)\n",
    "    \n",
    "    index = pd.DatetimeIndex(datetime)\n",
    "    \n",
    "    if config.date_offset:\n",
    "        index += config.date_offset\n",
    "    \n",
    "    df = df.set_index(index, drop=False)   \n",
    "    \n",
    "    #Delete Timestamp col\n",
    "    col_name = df.columns[config.time_col]\n",
    "    \n",
    "    if print_flag: print(\"... drop Timestamp col \" + str(col_name))\n",
    "    \n",
    "    df = df.drop(col_name, axis=1)\n",
    "    \n",
    "if print_flag: display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataframe frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<10 * Minutes>\n"
     ]
    }
   ],
   "source": [
    "df = infer_or_inject_freq(\n",
    "    df, \n",
    "    injected_freq=config.freq, \n",
    "    start_date=config.start_date, \n",
    "    format=config.date_format\n",
    ")\n",
    "if print_flag: print(df.index.freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_cols:  [0]\n",
      "Num. variables: 1\n"
     ]
    }
   ],
   "source": [
    "# Subset of variables\n",
    "if config.data_cols:\n",
    "    if print_flag: print(\"data_cols: \", config.data_cols)\n",
    "    df = df.iloc[:, config.data_cols]\n",
    "\n",
    "if print_flag: print(f'Num. variables: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape before dropping duplicates (52560, 1)\n",
      "df shape after dropping duplicates (52560, 1)\n"
     ]
    }
   ],
   "source": [
    "#Duplicated rows\n",
    "if print_flag: print(\"df shape before dropping duplicates\", df.shape)\n",
    "df.drop_duplicates()\n",
    "if print_flag: print(\"df shape after dropping duplicates\", df.shape)\n",
    "# Verificar si hay duplicados en el índice del dataframe\n",
    "if df.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the default missing values by np.NaN\n",
    "if config.missing_values_constant:\n",
    "    df.replace(config.missing_values_constant, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_time_serie_flag = False\n",
    "if show_time_serie_flag:\n",
    "    # Show time series plot\n",
    "    fig, ax = plt.subplots(1, figsize=(15,5), )\n",
    "    cmap = matplotlib.colormaps.get_cmap('viridis')\n",
    "    #df.plot(color=cmap(0.05), ax=ax) # or use colormap=cmap\n",
    "    df.plot(colormap=cmap, ax=ax) # or use colormap=cmap\n",
    "    # rect = Rectangle((5000, -4.2), 3000, 8.4, facecolor='lightgrey', alpha=0.5)\n",
    "    # ax.add_patch(rect)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    display(plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Handle Missing Values, Resample and Normalize__\n",
    "\n",
    "> In this second part, Time Series Artifact (TSArtifact) object can be created and missing values handling techniques, resampling and normalization can be applied.\n",
    "> \n",
    "> This techniques should be applied on the three subsets that must be previously created: training, validation and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = config.range_training\n",
    "\n",
    "if isinstance(rg, list):\n",
    "    rg_training = rg\n",
    "    \n",
    "elif isinstance(rg, dict):\n",
    "    rg_training = pd.date_range(rg['start'], rg['end'], freq=rg['freq'])\n",
    "    \n",
    "elif config.test_split:\n",
    "    rg_training = df.index[:math.ceil(len(df) * (1-config.test_split))]\n",
    "\n",
    "else:\n",
    "    rg_training = None\n",
    "    \n",
    "df_training = df[df.index.isin(rg_training)] if rg_training is not None else df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build training artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to write df to  /home/macu/data/wandb_artifacts/-3784109434391932832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TS': {'sd': '2006-01-01 00:00:01',\n",
       "  'ed': '2006-12-31 23:50:01',\n",
       "  'created': 'from-df',\n",
       "  'n_vars': 1,\n",
       "  'handle_missing_values_technique': 'None',\n",
       "  'has_missing_values': 'False',\n",
       "  'n_samples': 52560,\n",
       "  'freq': '<10 * Minutes>',\n",
       "  'vars': [0],\n",
       "  'hash': '-3784109434391932832'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_artifact = TSArtifact.from_df(\n",
    "    df_training, \n",
    "    name=config.artifact_name, \n",
    "    missing_values_technique=config.missing_values_technique,\n",
    "    resampling_freq=config.resampling_freq, \n",
    "    normalize=config.normalize_training, \n",
    "    path=str(Path.home()/config.wandb_artifacts_path)\n",
    ")\n",
    "if print_flag: display(training_artifact.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging \n",
    "if df_training.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe & artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg None | test_split None\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "rg = config.range_testing\n",
    "\n",
    "if rg or config.test_split:\n",
    "    \n",
    "    if isinstance(rg, list):\n",
    "        rg_testing = rg\n",
    "\n",
    "    elif isinstance(rg, dict):\n",
    "        rg_testing = pd.date_range(rg['start'], rg['end'], freq=rg['freq'])\n",
    "\n",
    "    elif config.test_split:\n",
    "        rg_testing = df.index[math.ceil(len(df) * (1 - config.test_split)):]\n",
    "\n",
    "    else:\n",
    "        rg_testing = None\n",
    "    \n",
    "    df_testing = df[df.index.isin(rg_testing)]\n",
    "    testing_artifact = TSArtifact.from_df(df_testing,\n",
    "                                          name=config.artifact_name, \n",
    "                                          missing_values_technique=config.missing_values_technique,\n",
    "                                          resampling_freq=config.resampling_freq, \n",
    "                                          normalize=False,\n",
    "                                          path=str(Path.home()/config.wandb_artifacts_path))\n",
    "    display(testing_artifact.metadata)\n",
    "    if df_testing.index.duplicated().any():\n",
    "        print(\"Hay valores duplicados en el índice del dataframe.\")\n",
    "    else:\n",
    "        print(\"No hay valores duplicados en el índice del dataframe.\")\n",
    "else:\n",
    "    print(\"rg \"+ str(rg) + \" | test_split \"+ str(config.test_split))\n",
    "    testing_artifact = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training + Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe & artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training + Testing data\n",
    "if(config.joining_train_test):\n",
    "    print(\"joining_train_test: \"+ str(config.joining_train_test))\n",
    "    df_train_test = pd.concat([df_training, df_testing])\n",
    "    train_test_artifact = TSArtifact.from_df(df_train_test,\n",
    "                                           name=config.artifact_name, \n",
    "                                           missing_values_technique=config.missing_values_technique,\n",
    "                                           resampling_freq=config.resampling_freq, \n",
    "                                           normalize=False,\n",
    "                                           path=str(Path.home()/config.wandb_artifacts_path))\n",
    "    if df_train_test.index.duplicated().any():\n",
    "        print(\"Hay valores duplicados en el índice del dataframe.\")\n",
    "    else:\n",
    "        print(\"No hay valores duplicados en el índice del dataframe.\")\n",
    "    display(train_test_artifact.metadata)\n",
    "else:\n",
    "    train_test_artifact = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "> \n",
    "Before running this notebook part, make sure you have the `$WANDB_API_KEY`, `$WANDB_ENTITY` and `$WANDB_PROJECT` environment varibales defined with your API_KEY and your ENTITY and PROJECT names (run in a terminal `echo $WANDB_API_KEY` to see it, same with the other variables). If not, run in a terminal `wandb login [API_KEY]` to set the first one. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account. Run in a terminal `export WANDB_ENTITY=entity_name` and/or `export WANDB_PROJECT=project_name` to set the other two\n",
    "> \n",
    "> <span style=\"color:red\"> TODO: Modify config.ipynb so it gets wandb config from base.yml </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 01_dataset_artifact\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"01_dataset_artifact\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mi-santamaria. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20231220_102459-oj2w9stn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/oj2w9stn' target=\"_blank\">01_dataset_artifact</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/oj2w9stn' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/oj2w9stn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'stream.Stream' object attribute 'write' is read-only\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc244eaa3214b1aad70b0cbda1ad0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">01_dataset_artifact</strong> at: <a href='https://wandb.ai/mi-santamaria/deepvats/runs/oj2w9stn' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/oj2w9stn</a><br/>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/macu/work/wandb/run-20231220_102459-oj2w9stn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode = 'online' if config.use_wandb else 'disabled'\n",
    "\n",
    "# Make the run that will produce the artifact\n",
    "with wandb.init(job_type='create_dataset', resume=True, mode=mode, config=config, name=runname) as run:\n",
    "    if testing_artifact: \n",
    "        run.log_artifact(training_artifact, aliases=['train'])\n",
    "        run.log_artifact(testing_artifact, aliases=['test'])\n",
    "        \n",
    "        if train_test_artifact:\n",
    "            run.log_artifact(train_test_artifact, aliases=['all'])\n",
    "    \n",
    "    else:\n",
    "        run.log_artifact(training_artifact, aliases=['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ended\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dvats.imports import beep\n",
    "print(\"Execution ended\")\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
