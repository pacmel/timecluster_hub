{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create artifact from time series dataframe\n",
    "Gets a .tsf or .csv with a time serie, convert int to np.dataframe and loads it to weights and biases (W&B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Initial notebook setup and specific debugging and pre-configured cases selection\n",
    "### VsCode update patch\n",
    "Initial notebook setup when using VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '--vscode' in sys.argv:\n",
    "    print(\"Executing inside vscode\")\n",
    "    import nbs_pipeline.utils.vscode  as vs\n",
    "    vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging variables\n",
    "- `print_flag`. If `True` it adds debbuging messages in those functions that allows so (eg. `get_enc_embeddings`)\n",
    "- `reset_kernel`. If `True` it resets the kernel by the end of the execution. Use only in case that memory management is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_flag = True\n",
    "reset_kernel=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfigurated cases selection\n",
    "- `pre_configured_case`. If `True`, a preconfigured case will be selected, forcing the artifact to get the expected configuration based on the information in `config\\*.yml` and `utils\\config.py`.\n",
    "- `case_id`. If `preconfigured_case` is `True`, it forces to select the configuration of the `case_id` preconfigured samples. The available preconfigured samples are shown in the next cell.\n",
    "- `frequency_factor`. If `pre_configured_case` is `True`, frequency will be resampled by `config.freq*frequency_factor`\n",
    "  `frequency_factor_change_alias`. If `pre_configured_case` is `True` and `frequency_factor != 1` then the dataset alias will be modified for adding the new frequency as suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "import utils.config as cfg_\n",
    "cfg_.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_configured_case = True\n",
    "case_id = 1\n",
    "frequency_factor = 150\n",
    "frequency_factor_change_alias = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "from dvats.load import TSArtifact, infer_or_inject_freq\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tsai.data.external import convert_tsf_to_dataframe\n",
    "from tsai.utils import stack_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and Artiffact configurattions\n",
    "This notebook gets configuration from `config\\base.yaml` and `config\\01-dataset_artifact.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting  monash_solar_4_seconds_0\n",
      "--> Frequency factor config\n",
      "Freq factor:  150\n",
      "frequency_factor_change_alias:  True\n",
      "--> Frequency factor resampling frequency\n",
      "Freq factor:  150\n",
      "freq_original:  4s\n",
      "freq_new:  0 days 00:10:00\n",
      "suffix:  10m\n",
      "resampling_freq:  10T\n",
      "Frequency factor resampling frequency -->\n",
      "resampling_freq:  4s\n",
      "name:  solar_4_seconds-10m\n",
      "path:  ~/data/australian_electricity_demand_dataset.tsf\n",
      "Frequency factor config -->\n",
      "use_wandb: True\u001b[0m\n",
      "\u001b[94mdata_cols: [0]\u001b[0m -> []\u001b[0m\n",
      "range_testing: None\u001b[0m\n",
      "date_format: %Y-%m-%d %H:%M:%S\u001b[0m\n",
      "joining_train_test: False\u001b[0m\n",
      "missing_values_constant: None\u001b[0m\n",
      "start_date: None\u001b[0m\n",
      "range_training: None\u001b[0m\n",
      "wandb_artifacts_path: ./data/wandb_artifacts\u001b[0m\n",
      "\u001b[94mfreq: 1h\u001b[0m -> 4s\u001b[0m\n",
      "time_col: None\u001b[0m\n",
      "data_fpath: ~/data/australian_electricity_demand_dataset.tsf\u001b[0m\n",
      "\u001b[94mresampling_freq: None\u001b[0m -> 10T\u001b[0m\n",
      "test_split: None\u001b[0m\n",
      "\u001b[94martifact_name: Monash-Australian_electricity_demand\u001b[0m -> solar_4_seconds-10m\u001b[0m\n",
      "csv_config: {}\u001b[0m\n",
      "missing_values_technique: None\u001b[0m\n",
      "normalize_training: False\u001b[0m\n",
      "date_offset: None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = cfg_.get_artifact_config_sd2a(print_flag = False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_sd2a(\n",
    "        config = config, \n",
    "        id = case_id, \n",
    "        print_flag = print_flag, \n",
    "        both = print_flag, \n",
    "        frequency_factor = frequency_factor, \n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is assumed to come as a dataframe, either as a binarized  picke file or\n",
    "as a csv file. It can also come as a `.tsf` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check file content (if wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/macu/data/australian_electricity_demand_dataset.tsf\n",
      "# Dataset Information\n",
      "# This dataset contains five time series representing the half hourly electricity demand of five states in Australia: Victoria, New South Wales, Queensland, Tasmania and South Australia.\n",
      "# It was extracted from R tsibbledata package.\n",
      "#\n",
      "# For more details, please refer to\n",
      "# O'Hara-Wild, M., Hyndman, R., Wang, E., 2021. tsibbledata: Diverse Datasets for 'tsibble'. R package version 0.3.0. https://CRAN.R-project.org/package=tsibbledata\n",
      "#\n",
      "@relation Aus_Electricity_Demand\n",
      "@attribute series_name string\n",
      "@attribute state string\n",
      "@attribute start_timestamp date\n",
      "@frequency half_hourly\n",
      "@missing false\n",
      "Timestamp 0   2002-01-01\n",
      "1   2002-01-01\n",
      "2   2002-01-01\n",
      "3   2002-01-01\n",
      "4   2002-01-01\n",
      "Name: start_timestamp, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "if print_flag:\n",
    "    fpath=os.path.expanduser(config.data_fpath)\n",
    "    print(fpath)\n",
    "    try: \n",
    "        with open(fpath, 'r') as file:\n",
    "            for _ in range(13):\n",
    "                line = file.readline()\n",
    "                print(line, end='')\n",
    "        data, _, _, _, _ = convert_tsf_to_dataframe(fpath)\n",
    "        print(\"Timestamp\", data.start_timestamp)\n",
    "    except Exception as e:\n",
    "        print(\"Error while converting file. Maybe not a tsf: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = str(config.data_fpath).split('.')[-1]\n",
    "\n",
    "if ext == 'pickle':\n",
    "    df = pd.read_pickle(config.data_fpath)\n",
    "    \n",
    "elif ext in ['csv','txt']:\n",
    "    df = pd.read_csv(config.data_fpath, **config.csv_config)\n",
    "    \n",
    "elif ext == 'tsf':\n",
    "    data, _, _, _, _ = convert_tsf_to_dataframe(os.path.expanduser(config.data_fpath))\n",
    "    config.update({'start_date': data.start_timestamp[0]}, allow_val_change=True)\n",
    "    date_format = config.date_format\n",
    "    df = pd.DataFrame(stack_pad(data.series_value).T)\n",
    "    \n",
    "else:\n",
    "    raise Exception('The data file path has an unsupported extension')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully\n",
      "(232272, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5714.045004</td>\n",
       "      <td>3535.867064</td>\n",
       "      <td>3382.041342</td>\n",
       "      <td>1191.078014</td>\n",
       "      <td>315.915504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5360.189078</td>\n",
       "      <td>3383.499028</td>\n",
       "      <td>3288.315794</td>\n",
       "      <td>1219.589472</td>\n",
       "      <td>306.245864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5014.835118</td>\n",
       "      <td>3655.527552</td>\n",
       "      <td>3172.329022</td>\n",
       "      <td>1119.173498</td>\n",
       "      <td>305.762576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4602.755516</td>\n",
       "      <td>3510.446636</td>\n",
       "      <td>3020.312986</td>\n",
       "      <td>1016.407248</td>\n",
       "      <td>295.602196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4285.179828</td>\n",
       "      <td>3294.697156</td>\n",
       "      <td>2918.082882</td>\n",
       "      <td>923.499578</td>\n",
       "      <td>290.447070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3           4\n",
       "0  5714.045004  3535.867064  3382.041342  1191.078014  315.915504\n",
       "1  5360.189078  3383.499028  3288.315794  1219.589472  306.245864\n",
       "2  5014.835118  3655.527552  3172.329022  1119.173498  305.762576\n",
       "3  4602.755516  3510.446636  3020.312986  1016.407248  295.602196\n",
       "4  4285.179828  3294.697156  2918.082882   923.499578  290.447070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if print_flag:\n",
    "    print(f'File loaded successfully')\n",
    "    print(df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the time column (if any) as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5714.045004</td>\n",
       "      <td>3535.867064</td>\n",
       "      <td>3382.041342</td>\n",
       "      <td>1191.078014</td>\n",
       "      <td>315.915504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5360.189078</td>\n",
       "      <td>3383.499028</td>\n",
       "      <td>3288.315794</td>\n",
       "      <td>1219.589472</td>\n",
       "      <td>306.245864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5014.835118</td>\n",
       "      <td>3655.527552</td>\n",
       "      <td>3172.329022</td>\n",
       "      <td>1119.173498</td>\n",
       "      <td>305.762576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4602.755516</td>\n",
       "      <td>3510.446636</td>\n",
       "      <td>3020.312986</td>\n",
       "      <td>1016.407248</td>\n",
       "      <td>295.602196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4285.179828</td>\n",
       "      <td>3294.697156</td>\n",
       "      <td>2918.082882</td>\n",
       "      <td>923.499578</td>\n",
       "      <td>290.447070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3           4\n",
       "0  5714.045004  3535.867064  3382.041342  1191.078014  315.915504\n",
       "1  5360.189078  3383.499028  3288.315794  1219.589472  306.245864\n",
       "2  5014.835118  3655.527552  3172.329022  1119.173498  305.762576\n",
       "3  4602.755516  3510.446636  3020.312986  1016.407248  295.602196\n",
       "4  4285.179828  3294.697156  2918.082882   923.499578  290.447070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config.time_col is not None:\n",
    "    if print_flag: print(\"time_col: \"+str(config.time_col))\n",
    "    \n",
    "    if isinstance(config.time_col, int): \n",
    "        if print_flag: print(\"Op 1: time_col int\")\n",
    "        datetime = df.iloc[:, config.time_col]\n",
    "    \n",
    "    elif isinstance(config.time_col, list): \n",
    "        if print_flag: print(\"Op 2: time_col list\")\n",
    "        datetime = df.iloc[:, config.time_col].apply(lambda x: x.astype(str).str.cat(sep='-'), axis=1)\n",
    "    \n",
    "    index = pd.DatetimeIndex(datetime)\n",
    "    \n",
    "    if config.date_offset:\n",
    "        index += config.date_offset\n",
    "    \n",
    "    df = df.set_index(index, drop=False)   \n",
    "    \n",
    "    #Delete Timestamp col\n",
    "    col_name = df.columns[config.time_col]\n",
    "    \n",
    "    if print_flag: print(\"... drop Timestamp col \" + str(col_name))\n",
    "    \n",
    "    df = df.drop(col_name, axis=1)\n",
    "    \n",
    "if print_flag: display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataframe frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<4 * Seconds>\n"
     ]
    }
   ],
   "source": [
    "df = infer_or_inject_freq(\n",
    "    df, \n",
    "    injected_freq=config.freq, \n",
    "    start_date=config.start_date, \n",
    "    format=config.date_format\n",
    ")\n",
    "if print_flag: print(df.index.freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. variables: 5\n"
     ]
    }
   ],
   "source": [
    "# Subset of variables\n",
    "if config.data_cols:\n",
    "    if print_flag: print(\"data_cols: \", config.data_cols)\n",
    "    df = df.iloc[:, config.data_cols]\n",
    "\n",
    "if print_flag: print(f'Num. variables: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape before dropping duplicates (232272, 5)\n",
      "df shape after dropping duplicates (232272, 5)\n"
     ]
    }
   ],
   "source": [
    "#Duplicated rows\n",
    "if print_flag: print(\"df shape before dropping duplicates\", df.shape)\n",
    "df.drop_duplicates()\n",
    "if print_flag: print(\"df shape after dropping duplicates\", df.shape)\n",
    "# Verificar si hay duplicados en el índice del dataframe\n",
    "if df.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the default missing values by np.NaN\n",
    "if config.missing_values_constant:\n",
    "    df.replace(config.missing_values_constant, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_time_serie_flag = False\n",
    "if show_time_serie_flag:\n",
    "    # Show time series plot\n",
    "    fig, ax = plt.subplots(1, figsize=(15,5), )\n",
    "    cmap = matplotlib.colormaps.get_cmap('viridis')\n",
    "    #df.plot(color=cmap(0.05), ax=ax) # or use colormap=cmap\n",
    "    df.plot(colormap=cmap, ax=ax) # or use colormap=cmap\n",
    "    # rect = Rectangle((5000, -4.2), 3000, 8.4, facecolor='lightgrey', alpha=0.5)\n",
    "    # ax.add_patch(rect)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    display(plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Handle Missing Values, Resample and Normalize__\n",
    "\n",
    "> In this second part, Time Series Artifact (TSArtifact) object can be created and missing values handling techniques, resampling and normalization can be applied.\n",
    "> \n",
    "> This techniques should be applied on the three subsets that must be previously created: training, validation and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = config.range_training\n",
    "\n",
    "if isinstance(rg, list):\n",
    "    rg_training = rg\n",
    "    \n",
    "elif isinstance(rg, dict):\n",
    "    rg_training = pd.date_range(rg['start'], rg['end'], freq=rg['freq'])\n",
    "    \n",
    "elif config.test_split:\n",
    "    rg_training = df.index[:math.ceil(len(df) * (1-config.test_split))]\n",
    "\n",
    "else:\n",
    "    rg_training = None\n",
    "    \n",
    "df_training = df[df.index.isin(rg_training)] if rg_training is not None else df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build training artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to write df to  /home/macu/data/wandb_artifacts/3931547514932272730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TS': {'sd': '2002-01-01 00:00:00',\n",
       "  'ed': '2002-01-11 18:04:44',\n",
       "  'created': 'from-df',\n",
       "  'n_vars': 5,\n",
       "  'handle_missing_values_technique': 'None',\n",
       "  'has_missing_values': 'True',\n",
       "  'n_samples': 1549,\n",
       "  'freq': '<10 * Minutes>',\n",
       "  'vars': [0, 1, 2, 3, 4],\n",
       "  'hash': '3931547514932272730'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_artifact = TSArtifact.from_df(\n",
    "    df_training, \n",
    "    name=config.artifact_name, \n",
    "    missing_values_technique=config.missing_values_technique,\n",
    "    resampling_freq=config.resampling_freq, \n",
    "    normalize=config.normalize_training, \n",
    "    path=str(Path.home()/config.wandb_artifacts_path)\n",
    ")\n",
    "if print_flag: display(training_artifact.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging \n",
    "if df_training.index.duplicated().any():\n",
    "    raise ValueError(\"Duplicated index names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe & artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg None | test_split None\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "rg = config.range_testing\n",
    "\n",
    "if rg or config.test_split:\n",
    "    \n",
    "    if isinstance(rg, list):\n",
    "        rg_testing = rg\n",
    "\n",
    "    elif isinstance(rg, dict):\n",
    "        rg_testing = pd.date_range(rg['start'], rg['end'], freq=rg['freq'])\n",
    "\n",
    "    elif config.test_split:\n",
    "        rg_testing = df.index[math.ceil(len(df) * (1 - config.test_split)):]\n",
    "\n",
    "    else:\n",
    "        rg_testing = None\n",
    "    \n",
    "    df_testing = df[df.index.isin(rg_testing)]\n",
    "    testing_artifact = TSArtifact.from_df(df_testing,\n",
    "                                          name=config.artifact_name, \n",
    "                                          missing_values_technique=config.missing_values_technique,\n",
    "                                          resampling_freq=config.resampling_freq, \n",
    "                                          normalize=False,\n",
    "                                          path=str(Path.home()/config.wandb_artifacts_path))\n",
    "    display(testing_artifact.metadata)\n",
    "    if df_testing.index.duplicated().any():\n",
    "        print(\"Hay valores duplicados en el índice del dataframe.\")\n",
    "    else:\n",
    "        print(\"No hay valores duplicados en el índice del dataframe.\")\n",
    "else:\n",
    "    print(\"rg \"+ str(rg) + \" | test_split \"+ str(config.test_split))\n",
    "    testing_artifact = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training + Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dataframe & artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training + Testing data\n",
    "if(config.joining_train_test):\n",
    "    print(\"joining_train_test: \"+ str(config.joining_train_test))\n",
    "    df_train_test = pd.concat([df_training, df_testing])\n",
    "    train_test_artifact = TSArtifact.from_df(df_train_test,\n",
    "                                           name=config.artifact_name, \n",
    "                                           missing_values_technique=config.missing_values_technique,\n",
    "                                           resampling_freq=config.resampling_freq, \n",
    "                                           normalize=False,\n",
    "                                           path=str(Path.home()/config.wandb_artifacts_path))\n",
    "    if df_train_test.index.duplicated().any():\n",
    "        print(\"Hay valores duplicados en el índice del dataframe.\")\n",
    "    else:\n",
    "        print(\"No hay valores duplicados en el índice del dataframe.\")\n",
    "    display(train_test_artifact.metadata)\n",
    "else:\n",
    "    train_test_artifact = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "> \n",
    "Before running this notebook part, make sure you have the `$WANDB_API_KEY`, `$WANDB_ENTITY` and `$WANDB_PROJECT` environment varibales defined with your API_KEY and your ENTITY and PROJECT names (run in a terminal `echo $WANDB_API_KEY` to see it, same with the other variables). If not, run in a terminal `wandb login [API_KEY]` to set the first one. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account. Run in a terminal `export WANDB_ENTITY=entity_name` and/or `export WANDB_PROJECT=project_name` to set the other two\n",
    "> \n",
    "> <span style=\"color:red\"> TODO: Modify config.ipynb so it gets wandb config from base.yml </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 01_dataset_artifact\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"01_dataset_artifact\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20240111_181552-wfpaqv5b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/wfpaqv5b' target=\"_blank\">01_dataset_artifact</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/wfpaqv5b' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/wfpaqv5b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47eb5e489aa440a6a4f720ab8087f45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.079 MB of 0.079 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">01_dataset_artifact</strong> at: <a href='https://wandb.ai/mi-santamaria/deepvats/runs/wfpaqv5b' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/wfpaqv5b</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/macu/work/wandb/run-20240111_181552-wfpaqv5b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode = 'online' if config.use_wandb else 'disabled'\n",
    "\n",
    "# Make the run that will produce the artifact\n",
    "with wandb.init(job_type='create_dataset', resume=True, mode=mode, config=config, name=runname) as run:\n",
    "    if testing_artifact: \n",
    "        run.log_artifact(training_artifact, aliases=['train'])\n",
    "        run.log_artifact(testing_artifact, aliases=['test'])\n",
    "        \n",
    "        if train_test_artifact:\n",
    "            run.log_artifact(train_test_artifact, aliases=['all'])\n",
    "    \n",
    "    else:\n",
    "        run.log_artifact(training_artifact, aliases=['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ended\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dvats.imports import beep\n",
    "print(\"Execution ended\")\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
