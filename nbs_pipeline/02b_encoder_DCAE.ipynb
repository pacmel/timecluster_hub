{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed if the notebook is run in VSCode\n",
    "import nbs_pipeline.utils.vscode  as vs\n",
    "vs.DisplayHandle.update = vs.update_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DCAE: Deep Convolutional Autoencoder\n",
    "\n",
    "> This notebook encodes the data using the autoencoder described in [TimeCluster](https://link.springer.com/article/10.1007/s00371-019-01673-y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize loss function\n",
      "Initialize loss function\n",
      "Initialize loss function\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tsai.all import *\n",
    "except:\n",
    "    from tsai.all import * # TODO: Weird error when loading tsai!from tchub.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from fastcore.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.schedule import *\n",
    "from dvats.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. \n",
    "\n",
    "Before running this notebook, make sure you have the `$WANDB_API_KEY` environment varibale defined with your API_KEY (run in a terminal `echo $WANDB_API_KEY` to see it). If not, run in a terminal `wandb login [API_KEY]`. You can see your API_KEY [here](https://wandb.ai/authorize) or in the settings of your W&B account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/02b-encoder_dcae.yaml\n",
      "... About to replace includes with content\n",
      "Before configuration reading \n",
      "-include: None\n",
      "-user_preferences:\n",
      "\t-use_wandb: False\n",
      "\t-wdb:\n",
      "\t\t-user: mi-santamaria\n",
      "\t\t-project_name: test-project\n",
      "\t\t-version: 0\n",
      "\t\t-mode: offline\n",
      "\t\t-artifacts_path: ./data/wandb_artifacts\n",
      "\t-data:\n",
      "\t\t-folder: ~/data/\n",
      "\t\t-fname: speed_6005\n",
      "\t\t-ftype: .csv\n",
      "\t\t-cols: [1]\n",
      "\t\t-freq: 1s\n",
      "\t-artifact:\n",
      "\t\t-alias: TiltABP\n",
      "\t-directories:\n",
      "\t\t-tmp: tmp\n",
      "\t\t-data: ~/data/speed_6005.csv\n",
      "-data:\n",
      "\t-name: speed_6005\n",
      "\t-path: ~/data/speed_6005.csv\n",
      "\t-alias: TiltABP\n",
      "\t-cols: [1]\n",
      "\t-csv_config:\n",
      "\t-date_offset: None\n",
      "\t-date_format: %Y-%m-%d %H:%M:%S\n",
      "\t-freq: 1s\n",
      "\t-joining_train_test: False\n",
      "\t-missing_values:\n",
      "\t\t-technique: None\n",
      "\t\t-constant: None\n",
      "\t-normalize_training: False\n",
      "\t-range_training: None\n",
      "\t-range_testing: None\n",
      "\t-resampling_freq: None\n",
      "\t-start_date: None\n",
      "\t-test_split: None\n",
      "\t-time_col: None\n",
      "-wandb:\n",
      "\t-user: mi-santamaria\n",
      "\t-dir: ~/test-project\n",
      "\t-enabled: False\n",
      "\t-group: None\n",
      "\t-log_learner: False\n",
      "\t-mode: offline\n",
      "\t-project: test-project\n",
      "\t-version: 0\n",
      "\t-artifacts_path: ./data/wandb_artifacts\n",
      "-configuration:\n",
      "\t-job_type: encoder_DCAE\n",
      "\t-alias: TiltABP\n",
      "\t-wandb:\n",
      "\t\t-use: False\n",
      "\t\t-entity: mi-santamaria\n",
      "\t\t-group: None\n",
      "\t\t-project: test-project\n",
      "\t-artifacts:\n",
      "\t\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t\t-valid:\n",
      "\t\t\t-data: None\n",
      "\t\t\t-size: 0.1\n",
      "\t-specifications:\n",
      "\t\t-batch_size: 64\n",
      "\t\t-n_epoch: 200\n",
      "\t\t-pool_szs: [2, 2, 4]\n",
      "\t\t-top_k: 3\n",
      "\t\t-sliding_windows:\n",
      "\t\t\t-stride: 1\n",
      "\t\t\t-size: 32\n",
      "\t\t-autoencoder:\n",
      "\t\t\t-delta: 60\n",
      "\t\t\t-filters:\n",
      "\t\t\t\t-nfs: [64, 32, 16]\n",
      "\t\t\t\t-kss: [10, 5, 5]\n",
      "\t\t\t\t-output_size: 10\n",
      "After reading config\n",
      "-job_type: encoder_DCAE\n",
      "-alias: TiltABP\n",
      "-wandb:\n",
      "\t-use: False\n",
      "\t-entity: mi-santamaria\n",
      "\t-group: None\n",
      "\t-project: test-project\n",
      "-artifacts:\n",
      "\t-train: mi-santamaria/test-project/speed_6005:v0\n",
      "\t-valid:\n",
      "\t\t-data: None\n",
      "\t\t-size: 0.1\n",
      "-specifications:\n",
      "\t-batch_size: 64\n",
      "\t-n_epoch: 200\n",
      "\t-pool_szs: [2, 2, 4]\n",
      "\t-top_k: 3\n",
      "\t-sliding_windows:\n",
      "\t\t-stride: 1\n",
      "\t\t-size: 32\n",
      "\t-autoencoder:\n",
      "\t\t-delta: 60\n",
      "\t\t-filters:\n",
      "\t\t\t-nfs: [64, 32, 16]\n",
      "\t\t\t-kss: [10, 5, 5]\n",
      "\t\t\t-output_size: 10\n"
     ]
    }
   ],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "config, job_type, dataSet = cfg.get_artifact_config_DCAE(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: test-project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "print(\"Project: \"+config.wandb_project)\n",
    "run = wandb.init(\n",
    "    entity          = config.wandb_entity,\n",
    "    project         = config.wandb_project,\n",
    "    group           = config.wandb_group,\n",
    "    job_type        = job_type,\n",
    "    allow_val_change= True,\n",
    "    mode            = 'online' if config.use_wandb else 'disabled',\n",
    "    config          = config,\n",
    "    resume          = False\n",
    ")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets\n",
    "\n",
    "To load the dataset we will download a specific dataset artifact from the collection of artifacts\n",
    "stored in the weights and biases (wandb) project associated to this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a continuous multivariate time-series data $D$ of dimension $d$ with $n$ time-steps, $D = X_1,X_2,\\dots,X_n$ , where each $X_i = \\{x_i^1,\\dots,x_i^d\\}$ . Let $w$ be the window width, $s$ the stride, and $t$ the start time of a sliding window in the data.\n",
    "\n",
    "Define a new matrix $Z_k$ where each row is a vector of size $w$ of data extracted from the $k^{th}$ dimension.\n",
    "\n",
    "\\begin{aligned}&Z_k(w,s,t)\\\\&\\quad =\\begin{bmatrix} x_{t}^k&\\quad x_{t+1}^k&\\quad \\dots&\\quad x_{t+w-1}^k \\\\ x_{t+s}^k&\\quad x_{t+s+1}^k&\\quad \\dots&\\quad x_{t+s+w-1}^k \\\\ \\vdots&\\quad \\vdots&\\quad \\ddots&\\quad \\vdots \\\\ x_{t+(r-1)s}^k&\\quad x_{t+(r-1)s+1}^k&\\quad \\dots&\\quad x_{t+(r-1)s+w-1}^k \\end{bmatrix} \\end{aligned}\n",
    "\n",
    "where $r$ is the number of desired rows, and $t+(r-1)s+w-1 \\le n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is a $w \\times s \\times t$ matrix. The first step consists in slicing the original multivariate time series into slices of shape ($w \\times d$), as shown in this figure from the paper.\n",
    "<img src=\"https://i.imgur.com/R9Fx8uO.png\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of this sliding window approach are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. variables: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value\n",
       "1970-01-01 00:00:00     90\n",
       "1970-01-01 00:00:01     80\n",
       "1970-01-01 00:00:02     84\n",
       "1970-01-01 00:00:03     94\n",
       "1970-01-01 00:00:04     90"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "df_train = train_artifact.to_df()\n",
    "# Subset of variables\n",
    "if dataSet.cols:\n",
    "    df_train = df_train.iloc[:, dataSet.cols]\n",
    "print(f'Num. variables: {len(df_train.columns)}')\n",
    "df_train.head(5)\n",
    "\n",
    "X_train, _ = sw(df_train)\n",
    "df_train.shape, X_train.shape\n",
    "df_train.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.valid_artifact:\n",
    "    valid_artifact = artifacts_gettr(config.valid_artifact)\n",
    "    df_val = valid_artifact.to_df()\n",
    "    X_valid, _ = sw(df_val)\n",
    "    df_val.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract important features from the multivariate time series data through Deep Convolutional Autoencoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Convolutional Auto Encoders (DCAE) is a powerful method for learning high-level and mid-level abstractions from low-level raw data. It has the ability to extract features from complex and large time-series in an unsupervised manner. This is useful to overcome the complexity of multivariate time-series.\n",
    "\n",
    "Compared to the conventional auto-encoder, DCAE has fewer parameters than the conventional auto-encoder which means less training time. Also, DCAE uses local information to reconstruct the signal while conventional auto-encoders utilize fully connected layers to globally do the reconstruction. DCAE is an unsupervised model for representation learning which maps inputs into a new representation space. It has two main parts which are the encoding part that is used to project the data into a set of feature spaces and the decoding part that reconstructs the original data. The latent space representation is the space where the data lie in the bottleneck layers.\n",
    "\n",
    "The loss function of the DCAE is defined as the error between the input and the output. DCAE aims to find a code for each input by minimizing the mean squared error (MSE) between its input (original data) and output (reconstructed data). The MSE is used which assists to minimize the loss; thus, the network is forced to learn a low-dimensional representation of the input.\n",
    "\n",
    "We will implement the DCAE of the paper [TimeCluster](https://link.springer.com/article/10.1007/s00371-019-01673-y), whose architecture is shown in the table below:\n",
    "\n",
    "![](https://i.imgur.com/3EjuAfQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in the paper, the input shape is $60 \\times 3$, due to multivariate time series has 3 variables and the window size is 60. Generally, the size of the input/output of the autoencoder will depend on the shape of each slice obtained in the previos step. The number of latent features to be discovered is $60$ in the table above, but we can consider this as a free hyperparameter $\\delta$. Also, according to the paper: \"*The number of feature maps, size of filter and depth of the model are set based on the reconstruction error on validation set.*\". Thus, we must provide flexibility in the creation of the DCAE in terms of these hyperparameters.º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are not using a config file, you can also uncomment the following cell and define the hyperparameters in the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equal([len(x) for x in [config.nfs, config.kss, config.pool_szs]], \n",
    "          np.repeat(len(config.nfs), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "The implementation of the DCAE is done using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCAE_torch(\n",
      "  (downsample): Sequential(\n",
      "    (0): SameConv1d(\n",
      "      (conv1d_same): Conv1d(1, 64, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(32, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (5): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (latent_in): Linear(in_features=32, out_features=60, bias=True)\n",
      "    (latent_out): Linear(in_features=60, out_features=32, bias=True)\n",
      "    (reshape): Reshape(bs, 16, 2)\n",
      "  )\n",
      "  (upsample): Sequential(\n",
      "    (0): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): Upsample(scale_factor=4.0, mode=nearest)\n",
      "    (2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (4): SameConv1d(\n",
      "      (conv1d_same): Conv1d(32, 64, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (6): SameConv1d(\n",
      "      (conv1d_same): Conv1d(64, 1, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 32]), torch.Size([1, 1, 32]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DCAE_torch(c_in=X_train.shape[1], seq_len=config.w, delta=config.delta, \n",
    "               pool_szs=config.pool_szs, nfs=config.nfs)\n",
    "print(m)\n",
    "foo = torch.rand(1, X_train.shape[1], config.w)\n",
    "foo.shape, m(foo).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with fastai Learner class, to abstract from Pytorch's training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#2223) [1118,476,567,2078,1099,289,1915,897,950,464...],\n",
       " (#246) [119,1404,1431,2419,1804,1113,1966,477,1769,728...])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.valid_artifact:\n",
    "    X, y, splits  = combine_split_data(xs=[X_train, X_valid], ys=[X_train, X_valid])\n",
    "else:\n",
    "    X = X_train\n",
    "    y = X_train\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Axes: >, <Axes: >)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBRElEQVR4nO3deXhc5Xk+/vvMqpE02ndbluRFxsZAAAPGQGw2h80lkIUlBTs0/JJC0zqBLJSkcUODE5JQWkhJmyZAICRpm5Bv2GLMYoNjAzYQ8L5KlixL1r5r9vP748x7ZiRrmdGcbUb357p0JZZGMwd5PHrmed/nfiVZlmUQERERUdqzmX0BRERERKQNFnZEREREGYKFHREREVGGYGFHRERElCFY2BERERFlCBZ2RERERBmChR0RERFRhmBhR0RERJQhHGZfwHREIhGcOHECXq8XkiSZfTlEREREupFlGQMDA6iqqoLNNnlPLi0LuxMnTqC6utrsyyAiIiIyTHNzM2bPnj3pbdKysPN6vQCU/8C8vDyTr4aIiIhIP/39/aiurlbrn8mkZWEnll/z8vJY2BEREdGMkMj2Mw5PEBEREWWIpAu7N998E6tXr0ZVVRUkScIf/vCHUV+XZRnr169HVVUVPB4PVq5ciT179oy6jd/vx5e//GWUlJQgJycHf/VXf4Xjx4+n9B9CRERENNMlXdgNDQ3hrLPOwmOPPTbu1x966CE8/PDDeOyxx7Bjxw5UVFTgyiuvxMDAgHqbdevW4bnnnsNvfvMbbN26FYODg7juuusQDoen/19CRERENMNJsizL0/5mScJzzz2HT37ykwCUbl1VVRXWrVuHb3zjGwCU7lx5eTl+8IMf4Itf/CL6+vpQWlqKp59+GjfddBOA2JTrSy+9hE984hNTPm5/fz/y8/PR19fHPXZERESU0ZKpezTdY9fQ0IC2tjasWrVK/Zzb7caKFSuwbds2AMB7772HYDA46jZVVVVYsmSJehsiIiIiSp6mU7FtbW0AgPLy8lGfLy8vx7Fjx9TbuFwuFBYWnnIb8f1j+f1++P1+9c/9/f1aXjYRERFRRtBlKnbsOK4sy1OO6E52mw0bNiA/P1/9YDgxERER0ak0LewqKioA4JTOW3t7u9rFq6ioQCAQQE9Pz4S3Geu+++5DX1+f+tHc3KzlZRMRERFlBE0Lu7q6OlRUVGDTpk3q5wKBALZs2YLly5cDAM4991w4nc5Rt2ltbcXu3bvV24zldrvVMGKGEhMRERGNL+k9doODgzh8+LD654aGBvzlL39BUVER5syZg3Xr1uHBBx/EggULsGDBAjz44IPIzs7GrbfeCgDIz8/H3/zN3+Cee+5BcXExioqKcO+99+KMM87AFVdcod1/GREREdEMk3Rht3PnTlx66aXqn7/61a8CANasWYMnn3wSX//61zEyMoK77roLPT09uOCCC/DKK6+MOt/sX//1X+FwOPDZz34WIyMjuPzyy/Hkk0/Cbrdr8J9ERERENDOllGNnFubYERER0UxhWo4dEREREZmHhR0RERFRhmBhR0RERJQhWNiRofac6MM/P78HvcMBsy+FiIgo47CwI0P9x+YjeOLPjXj+wxNmXwoREVHGYWFHhuroV8787RjwT3FLIiIiShYLOzJUd3QJtptLsURERJpjYUeG6hkKRP83aPKVEBERZR4WdmSYSERGj+jYDbFjR0REpDUWdmSYfl8Qkeg5Jz1ciiUiItIcCzsyTHyXjh07IiIi7bGwI8PEd+l6hgNIw2OKiYiILI2FHRmmO25gIhiWMegPmXg1REREmYeFHRmmZ8zyKydjiYiItMXCjgwzNruOWXZERETaYmFHhjm1Y8fCjoiISEss7MgwYydhORlLRESkLRZ2ZJix2XXMsiMiItIWCzsyjOjQzSrwjPozERERaYOFHRmmZ1iZgp1bmhP9Mws7IiIiLbGwI8OIDt280txRfyYiIiJtsLAjQ4TCEfSNKB27eWVKYcccOyIiIm2xsCND9EaLOkkC6oqVpVjm2BEREWmLhR0ZQmTWFXicKPG6Rn2OiIiItMHCjgwh9tMV5rhQlB0t7IYDiERkMy+LiIgoo7CwI0OICdiibBcKooVdRAb6fdxnR0REpBUWdmSI7uigRGGOCy6HDV63I/p5LscSERFphYUdGSK+YwcoBV7854mIiCh1LOzIEPF77OL/t5uRJ0RERJphYUeGEBOwRTlO5X+znaM+T0RERKljYUeGEJl1hWOWYpllR0REpB0WdmSIWMdOKejUyBN27IiIiDTDwo4MoXbsTtljx8KOiIhIKyzsyBDiXFjRqSviVCwREZHmWNiR7vyhMAb9IQBxHbtsduyIiIi0xsKOdNc7rHTr7DYJeVlKMHGsY8e4EyIiIq2wsCPdqRl22S5IkgQgFnvCjh0REZF2WNiR7sZm2AGxpdi+kSBC4Ygp10VERJRpWNiR7sZm2AFAvseJaPMOvSNcjiUiItICCzvS3dgMOwBw2G3I9/D0CSIiIi2xsCPdifNgC+MKOyAWfcJ9dkRERNpgYUe6E1l1RdmjC7tCZtkRERFpioUd6U6dih3TsYtl2XGPHRERkRZ0KewGBgawbt061NTUwOPxYPny5dixY4f69bVr10KSpFEfy5Yt0+NSyALUjl3cVGz8n9mxIyIi0oZDjzv9whe+gN27d+Ppp59GVVUVnnnmGVxxxRXYu3cvZs2aBQC46qqr8MQTT6jf43K5Jro7SnPxOXbxeF4sERGRtjTv2I2MjOB3v/sdHnroIXz84x/H/PnzsX79etTV1eHxxx9Xb+d2u1FRUaF+FBUVaX0pZBHjTcUCsT13nIolIiLShuaFXSgUQjgcRlZW1qjPezwebN26Vf3z5s2bUVZWhvr6etx5551ob2+f8D79fj/6+/tHfVD6GC/HDojr2HEploiISBOaF3ZerxcXXnghHnjgAZw4cQLhcBjPPPMM3nnnHbS2tgIArr76avzqV7/C66+/jh//+MfYsWMHLrvsMvj9/nHvc8OGDcjPz1c/qqurtb5s0slIIAxfUDlZgh07IiIifekyPPH0009DlmXMmjULbrcb//7v/45bb70VdrsdAHDTTTfh2muvxZIlS7B69Wq8/PLLOHjwIF588cVx7+++++5DX1+f+tHc3KzHZZMORDfO5bAh22Uf9TV27IiIiLSly/DEvHnzsGXLFgwNDaG/vx+VlZW46aabUFdXN+7tKysrUVNTg0OHDo37dbfbDbfbrcelks7U/XXZLkjiDLEo0cHrYdwJERGRJnTNscvJyUFlZSV6enqwceNGXH/99ePerqurC83NzaisrNTzcsgEE2XYAbGl2EF/CP5Q2NDrIiIiykS6FHYbN27En/70JzQ0NGDTpk249NJLsXDhQnz+85/H4OAg7r33Xmzfvh2NjY3YvHkzVq9ejZKSEtxwww16XA6ZaKIMOwDwZjlgtyldvN5hdu2IiIhSpUth19fXh7vvvhunnXYabr/9dlx88cV45ZVX4HQ6YbfbsWvXLlx//fWor6/HmjVrUF9fj+3bt8Pr9epxOWSiiTLsAMBmk1CY7Rx1OyIiIpo+XfbYffazn8VnP/vZcb/m8XiwceNGPR6WLGiiDDuhMNuFzsEAJ2OJiIg0wLNiSVcTZdgJnIwlIiLSDgs70pWYeJ2oY8csOyIiIu2wsCNdTTYVG//5bkaeEBERpYyFHelKnYqdYClWTMv2cCmWiIgoZSzsSFexjt2pcSdAbO8dp2KJiIhSx8KOdCPLclyO3UQdu+geO3bsiIiIUsbCjnQz6A8hGJYBJDAVy44dERFRyljYkW7ERGy2y44sp33c23AqloiISDss7Eg3U2XYAbGlWObYERERpY6FHelmqlMngNhSrC8YwUggbMh1ERERZSoWdqSbqTLsACDHZYfLrjwN2bUjIiJKDQs70k0sw278qBMAkCRJjULhPjsiIqLUsLAj3STSsQOYZUdERKQVFnakm6lOnRCYZUc0MwXDEbMvgSjjsLAj3STcsWOWHdGM8z87mnH6dzbijQPtZl8KUUZhYUe6ETl2k03FAsyyI5qJXt/fjkAogu1Husy+FKKMwsKOdJNIjh0Q17HjUizRjNHUPQwAONnvM/lKiDILCzvSTSI5dkBsalZ0+Igos8myjGYWdkS6YGFHuohEZHUYQsSZTIR77Ihmlt7hIAb8IQBAe7/f5Kshyiws7EgX/b4gIrLy/6daiuVULNHMIpZhAXbsiLTGwo50Ibpv3iwHnPbJn2bMsSOaWeILu6FAGIPR7h0RpY6FHelCzbCbYn9d/G16hgOQZVnX6yIi8zX3DI/6czu7dkSaYWFHuuiODkJMtQwbf5tgWOY7d6IZoLl7dGF3kvvsiDTDwo50kehELAB4XHZ4nPbo93EylijTNY0p7NoH2LEj0goLO9JFohl2QhGz7IhmDFHYzS70AOAABZGWWNiRLmIdu8mjTgQRicLTJ4gyWzAcwYlepZBbWlMIgEuxRFpiYUe6SPScWIGTsUQzQ2uvD+GIDLfDhiWz8gGwY0ekJRZ2pAt1KjbJpVhm2RFlNrEMW12UjYr8LAAMKSbSEgs70gU7dkQ0HhF1Ul3oQXmeUtid5PAEkWZY2JEueoaV6dZEpmLjb8eOHVFmEx27OUXZKPdGC7t+HzMsiTTCwo50oXbsElyK5XmxRDND/FJsWZ4bAOALRtSzY4koNSzsSHOhcAR9I0l27KIFIHPsiDJbc1zHLstpR75HmYjn6RNE2mBhR5rrjRZ1kgT1RXsqIu6EOXZEmU1dii3OBgCUR7t2jDwh0gYLO9KcyKIr8Dhht0kJfY+6x45LsUQZq98XRG90/211oSjsYvvsiCh1LOxIc8lOxAJxS7HDAUQi3ERNlInEMmxxjgs5bgcAoNTLjh2RlljYkeaSzbADgILobSOy8q6eiDJPc9zghMCOHZG2WNiR5rqjAxDJdOxcDhu80XfwnIwlykzxUSdCebRj184sOyJNsLAjzU2nYwfECkFm2RFlpnELO7Vjx6VYIi2wsCPNTWePXfztuxl5QpSRmrpHAIwu7Mq4FEukKRZ2pDkx2VqUk1jUiVCU7Rz1/USUWcbfYyeWYv08fYJIAyzsSHMiiy7RUycEtWPHpViijBOOyDjeMzrDDohNxQZCsWBzIpo+FnakuVjHLrnCLnb6BAs7okxzst+HYFiG0y6hIrr8CgBuh119reA+O6LUsbAjzakdu2nvsWNhR5RpxODErALPKcHlZWqWHffZEaVKl8JuYGAA69atQ01NDTweD5YvX44dO3aoX5dlGevXr0dVVRU8Hg9WrlyJPXv26HEpZAJx3muyU7FFnIolylhN4+yvEzhAQaQdXQq7L3zhC9i0aROefvpp7Nq1C6tWrcIVV1yBlpYWAMBDDz2Ehx9+GI899hh27NiBiooKXHnllRgYGNDjcshA/lAYg/4QgGl07LLZsSPKVM3jRJ0IsSw7LsUSpUrzwm5kZAS/+93v8NBDD+HjH/845s+fj/Xr16Ourg6PP/44ZFnGI488gvvvvx833ngjlixZgqeeegrDw8N49tlntb4cMpg4B9Juk5CX5Ujqe2MdO26gJso042XYCTx9gkg7mhd2oVAI4XAYWVlZoz7v8XiwdetWNDQ0oK2tDatWrVK/5na7sWLFCmzbtm3c+/T7/ejv7x/1QdakZthluyBJ0hS3Hk3Eo7BjR+ns3YZufOGpHWjqGjb7Uixl8sKOe+yItKJ5Yef1enHhhRfigQcewIkTJxAOh/HMM8/gnXfeQWtrK9ra2gAA5eXlo76vvLxc/dpYGzZsQH5+vvpRXV2t9WWTRqabYQfElmL7RoIIhSOaXheREUYCYaz7zQd4dV87fvLGYbMvx1LGy7ATynj6BJFmdNlj9/TTT0OWZcyaNQtutxv//u//jltvvRV2u129zdhujizLE3Z47rvvPvT19akfzc3Nelw2aWC6GXYAkO9xQjwFeplnRWnoZ28dxYk+pev08u5WBEJ8gwIAw4EQOgeV14bxCjuxFNvBPXZEKdOlsJs3bx62bNmCwcFBNDc3491330UwGERdXR0qKioA4JTuXHt7+yldPMHtdiMvL2/UB1nTdDPsAMBhtyHfw9MnKD219fnw+OYjAACnXUK/L4S3DnWYfFXW0Bw9Sizf41T/jceLnT7hQyTC0yeIUqFrjl1OTg4qKyvR09ODjRs34vrrr1eLu02bNqm3CwQC2LJlC5YvX67n5ZABxDmvyU7ECkWcjKU09YM/7cdIMIylNYX43AU1AIDnPzxh8lVZw2T76wCgJNcNSQKCYZlxR0QpSm5sMUEbN26ELMtYuHAhDh8+jK997WtYuHAhPv/5z0OSJKxbtw4PPvggFixYgAULFuDBBx9EdnY2br31Vj0uhwwkXpSTzbATCnNcQOcQX9wprXzQ1IPnPlDinP5p9WKEIjKe3NaITXtPYiQQhsdln+IeMttUhZ3TbkNxjhudg36c7PejONdt5OURZRRdCru+vj7cd999OH78OIqKivCpT30K3/ve9+B0Ki34r3/96xgZGcFdd92Fnp4eXHDBBXjllVfg9Xr1uBwykDoVO82OXSzLjnvsKD3IsozvvrAXAPDpc2fjzNkFyh7jAg9aekfwxoF2XHNGpclXaa7JBieEMm+0sBvwYTG43YZounRZiv3sZz+LI0eOwO/3o7W1FY899hjy8/PVr0uShPXr16O1tRU+nw9btmzBkiVL9LgUMpjasZvGVGz897FjR+ni//3lBD5o6kW2y46vfWIhAOU1bvVZVQC4HAtM3bED4vbZMfKEKCU8K5Y0FZ9jNx08L5bSyXAghO+/vB8AcPel89XpTgBYfZbSpXt9fzsGfDO7A51YYcfIEyItsLAjTaUyFQvE9uZxKpbSwX9uOYq2fh9mFXjwNxfXjfra4so8zC3NgT8Uwav7Tpp0heaTZTluKdYz4e14XiyRNljYkaZSybED4jp2XIolizvRO4L/fFOJN/nHaxYhyzl6QEKSJKw+UyzHthp+fVbRMeCHPxSBTQKqCiYu7GKnT7BjR5QKFnakmZFAGL6gEsjKjh1luh/8aT98wQjOry3CNWdUjHsbsRz75sEO9M7QNytiGbaqwAOnfeJfOeVeEVLMjh1RKljYkWZEl83lsCF7mvEO7NhROnjvWA/+319OQJKUeJOJTs2ZX+bFoso8hCIy/rR7/CMTM10i++sA7rEj0goLO9KMur8u2zXhL7qpiE5fD+NOyKIiERnffX4PAOCz51Zjyaz8SW8vunbPfzQzp2MTL+yUpdiOQT/CPH2CaNpY2JFmUs2wA2JLsYP+EPyhsCbXRaSl5z5owYfH+5DrduCeT9RPeXuxz277kS60z8BlxqYEMuwAoDjXDZsEhCMyuobYtSOaLhZ2pJlUM+wAwJvlgN2mdPt6h9m1I2sZ8ofw0MZYvEmZN2uK71AKmo9VFyAiAy/vmnnLscej58RO1bGz2ySU5IosOxZ2RNPFwo40k2qGHQDYbBIKs52j7o/IKn665QhO9vsxpygbd1xcm/D3zeSw4kQ7dkD8PruZ19kk0goLO9JMqhl2QiEnY8mCjvcM47/ePAoA+MdrToPbkfiA0LVnVEKSgJ3HetDSO6LXJVqOLxhGW7RIm6pjBzDyhEgLLOxIM6lm2AmcjCUr+v7L++EPRbBsbhE+cfr48SYTqcjPwvm1RQCAF2fQEMXxHqWIzXU71E78ZBhSTJQ6FnakGTHJmmrHjll2ZDU7GrvxwketSrzJdadPa+o7thw7c8KKm+OWYRP5mYksu5k4ZEKkFRZ2pBktpmLjv7+bkSdkAUq8yV4AwM3nVWNxVd607ufqJRWw2yTsaulDQ+eQlpdoWbGok4lPnIgnlmI5PEE0fSzsSDPqVGyKS7FiqraHS7FkAb97/zh2tfTB63bgnlULp30/xbluXDS/BADwwgwZokg0w05QhyfYsZsxOgf9M/ZUFr2wsCPNxDp20487AWJ79DgVS2Yb9Ifw0MYDAIAvXz5fjeOYrtVnzqyw4uYkC7syDk/MKP2+IK565C1c9+hWhlJriIUdaUKW5bgcu1Q7dtE9dnwXRyb7jzcOo2PAj9ribKxdXpfy/a06vQIuuw0HTw7iQNuABldobaJjNzvRwi66x65z0I9QOKLbdZE1bNpzEp2DfhzvGeG+Sg2xsCNNDPpDCIaVd1yaTcWyY0cmau4exn9vbQAA/OM1i+BypP5yme9xYsXCUgCZn2kny3LSHbviHBfsNgmyDHQO8t9/povvXJ+YQTFAemNhR5oQE7HZLjuynInne42HU7FkBRte3odAKIKL5hfjysXlmt2vOh370QnIcuYuP3UPBTAUCEOSgFkFiQ1P2GwSyrxiOZYdnEzWPRTA1kOd6p9P9PLvWyss7EgTWmXYAbGlWObYkVnePtqFl3a1wSYB375u8bTiTSZyxaIyeJx2HOsaxq6WPs3u12rEMmxFXlZSb/aYZTcz/Gl3G0Jx++pa+9ix0woLO9KEVqdOALGlWF8wgpFAOOX7I0pGOCLjgReUeJNbzp+D0yqmF28ykWyXA5cvKgOQ2cuxyRwlFq9cdOwGOECRycRz35vlAMCOnZZY2JEmtMqwA4Aclx0uu/LUZNeOjPZ/7zVjz4l+eLMc+OqV9bo8hliOfeGjVkQydBow2f11gog8aWfHLmO19/vwdkMXAODWC+YA4B47LbGwI03EMuxSizoBAEmS1MgU7rMjIw34gvhhNN7kHy5fgOIU400msqK+FF63A619PrzX1KPLY5ituVv5RZ18YceQ4kz34q5WyDJwbk0hzqtRjtpr7WMhrxUWdqQJLTt2ALPsyBw/eeMIOgcDmFuSg9svrNXtcbKcdqyKnjebqcuxsaXYxAYnhDKGFGc88ZxffWYlKguUv2927LTDwo40odWpEwKz7Mhox7qG8ItovMn912oTbzKZ1WcpYcUv7WrNyMy2ZE+dENTTJ9ixy0jN3cN4v6kXNgm45sxKVOUrhX/XUAC+IPdUa8Fh9gWY7Y8fnkBDhzbnNhbmOHHTedVwO1KL+0hHmnfsmGVHBgqFI3jghX0IhCO4ZEEJLjutTPfHvGh+CQqznegcDODto924eEGJ7o9plEAook45Jjs8IeJO0n2P3dZDnchy2rC0tsjsS7GUF3e1AgCWzS1GmTcLsizD47RjJBhGW58PtSU5Jl9h+pvRhd3ulj78/a8/0PQ+c1wOfOrc2ZreZzoQOXZaTMUCzLIj42w/0oV/fn4P9rcNwG6TNI83mYjTbsPVZ1Ti2Xea8PyHJzKqsDvRO4KIDGQ5bShNcp+i6Nh1DQUQCEV075zq4XD7AG77xTtwO2zY+a0rkeue0b9qR1GXYaMDRJIkobIgC0c7hnCid4SFnQZm9LPtz4eVcMS5JTlYNq84pfv6S1Mv9rb248DJzD8maDxa5tgBcR07LsWSTo73DOPBl/bhpV1tAJRTIb6zejHqy72GXcPqM6vw7DtNeHl3Kx745JK0LGLGE78Mm2yRXJjthNMuIRiW0THoTzjc2Eqe2nYMsqxENv35cCc+Ed1POdMd6RjEnhP9cNgkXBX3M6nK9yiFHQcoNDGjC7t3GroBKOPWX7hkbkr39dS2Rnznj3vQ0KnNsm660TLHDohN14pOIJFWRgJhPL7lCP5zyxH4QxHYJOU14J4rF2q2lSBR59cVoczrRvuAH28d6sDli7Q74cJMzT3T218HKB2cMm8WWnpHcLLfl3aFXd9IEL97/7j6580H2lnYRb3wobIMe8mCklH/1qqiAxStHKDQxIwt7MIRGTuihd0Fdal16wCo7eNjXTOvsItEZHXIQcSUpIp77EhrsizjhY9aseGlfWpnYNncInxn9elYVKltCHGi7DYJ155ZiSf+3IjnPzyRMYXddMOJhfI8N1p6R9Jyn93/7mzGcCCs7hvbfKADsiwbsrxvZbIs448ftgCILcMKldEBihM8fUITmdH3n4Z9rf0Y8IfgdTuwuCr1F/W6YlHYDWds4OhE+n1BiP9krZZiORVLWtpzog83/dfb+PKvP8CJPqUL9B+fOwe/vnOZaUWdIH7Jbdp7MmNOWhHhxNWF0y3s0nMyNhyR8cvtxwAAX/vEQmQ5bWjt8+HgyUGTr8x8+9sGcKRjCC6H7ZSzl6vUyJP0K+StaMYWdm8fVVKvl9YWwm5L/Z1UVUEWHDYJ/lAErWn4LjMVoqvmzXLAadfmKcUcO9JC16Af//jcLqx+dCvebehGltOGr1xRj9fuWYFrzqi0RBfl7OoCzCrwYCgQxhsH2s2+HE1MN+pEUE+fSLMsuzf2t6Opexj5HiduPr8aF85VVoMy5e81FWJo4rKFZfBmjV7ZqYout/O8WG3M2MLuXbEMOzf1ZVgAcNht6ovYsRm2z07NsNNwf1J8x06WZ1YHlFIXDEfwi60NuPRHm/HsO02IyMB1Z1bitXtW4h+uWJDUofR6kyRJ7dplSlhxU1e0sCueXmFXFj19It06dk9uawQA3HxeNbJdDqxcqMTmbJ7hhZ0sy3j+o9HTsPHUpVh27DQxIwu7SETGu41KYXd+nXYZQ2KfXcMM22fXHR1w0GoZNv6+gmEZg/6QZvdLme+tQx245t/ewndf2It+XwiLK/PwP1+8EI/deo5lN+KLsOLX97djwJfeA0N9w0H0+5R/s9Ndii3ziqXY9PlFf+jkALYe7oRNAv56WQ0A4NJoYbezsSft/15T8eHxPjR3jyDbZR83I1IsxQ76Q+ifwT8nrczIwu5g+wB6h4PIdtlxxqx8ze63JvrutHGmdew0nogFAI/LDk+0q8LJWErEsa4h3PnLnbjt5+/iUPsginJcePCGM/D8ly/W9A2cHhZX5mFuaQ78oQhe3XfS7MtJiViGLfW64XFNrzOajufFim7dlYvL1aGROcXZmFuSg1BEVuO1ZiLRib5ycfm4z4lslwMF0SSEVnbtUjYjC7t3jirdunNrCjXbEwYAdaJj1zms2X2mA60z7IQiZtlRAob8ITz0p/248uE3sWnvSdhtEj5/US3euGclbr1gjiZ7aPUmSRJWnymWY1tNvprUpBJ1IpSn2XmxfcNB/P59ZeJz7fK6UV9bsbAUALD5QIfh12UFkYiMF8Qy7JmnLsMKseVY7rNL1YyMO3mnQRmcuEDjd/G1xTMz8iTWsdMm6kQozHGipXdE99Mn3m/qwTNvH8M3rzpNPYCc9CPLMr7/p/3Ye6Jfk/vb3zaAjgGls3PJghL803WLscDAkGGtrD6rCv/22iG8ebADvcMBFGj8RskoqQ5OAEB5dCm2dzgIXzBsqT2R4/mfnc0YCYZxWoUXy+aO/r1y6cIyPPHnxhkbe7KjsRsn+/3Iy3LgkvqJT1epys/CvtZ+Rp5oYMYVdrIsaz44IaiFXbcSeWJLg06BFrQ+J1YwajL20dcO4Y0DHTi9Kh9/c3Hd1N9AKTnSMYT/3HJU0/ucU5SNb127CFcuLk/bX5zzy3KxuDIPe1v78afdbbj5/DlmX9K0qBl2hdPfz5jnccDtsMEfiqBjwD/tPDwjhCMyntreCABYu7z2lOff+XVF8DjtaOv3YX/bgOnxOkYTQxNXLamY9Bx1dTKWS7Epm3GF3ZGOQXQOBuB22HDmbO321wHKBlCnXUIgFMGJvhHMnubG4XSjTsXqtBSrd5bd7mjnqGswffbzpDOxVFdd5MFXr6xP+f6yXQ6sqC+1fFcnEavPqsLe1n48/9GJtC3smlMMJwaUpenyvCw0dQ/jZL/P0oXda/tO4njPCAqynfjk2bNO+XqW044L5xXj9f3t2HygY0YVdqFwRD2yb7xp2HiVapYdO3apmnGFnThG7Jw5hZO+e5gOh92G6qJsHO0YwrGu4RlT2KVzx659wKcu4zEM2RgtPcoL98LyPNxw9myTr8ZarjuzEj/4035sP9KF9gGfOh2aTrRYigWUAQqlsLP2Gy4xNHHL+XMmfHNx6cJSvL6/HW8caMffrpxn4NWZa9uRLnQPBVCc41Iz/SZSxdMnNDPjhifE4IReU3LiBIqZdGZsz7AytarlVGz8/elZcO2J2+fFMGRjHI8WdrNTWKrLVNVF2Th7TgEiMvBytNORTkLhiFq4TzfDTihLg5DiA20D2HakC3abpEacjEfk2b13rGdGxXmIadhrzqiEY4pBxVhIsXX/vtPFjCrsZFmODU7M1aewq4kWdjMp8kTt2Gm8FGvEebHxG/gZq2KMll4WdpOJTcemX1hxa58PoYgMl92mDkBMV7nX+seKiW7dJ04vnzQjsbooG3NLcxCOyPjzoZkRe+IPhfGnPYktwwJAZb7y993a65txx3JqbUYVdse6lLa+y27DOXMKdXmMupJoll3XzIg8CYUj6BvRqWMXLRT1LLj2nOhT/z9jVYxxPLrHzqphwWa79sxKSBKw81iPWgSnC7F/cnaRJ+XhsTI1y86aHZze4QCe++A4gFMjTsYjwopnyvFiWw50YMAXQkVeFpbWTP37tiI/C5IEBMIRdHH1JCUzqrAT3bqzqvN122gtTp9onCGRJ73Rok6SgHyP9nEngL4F155RHTu+mBihRV2KnRl7UJNVnpelRjG9+FF6de2aNdpfB8RCiq2aZffbHc3wBSNYXJmH82qnLlxWRvPsthzsmBHHJD7/kZLHeN2ZlQkV+U67DWVe5e+cZ8amRvPCLhQK4Vvf+hbq6urg8Xgwd+5cfPe730UkElFvs3btWkiSNOpj2bJlWl/KKcT+ugvqtI05iSciT5q6hhGeAe1kUQwVeJyaB8Gqe+x0Krj6fUEci+us9gwHuASgM18wjPbosMosLsVOKHZ2bHqFFceiTjQo7Cy8FBsKR/DL7ccAAGsvOjXiZDwi9uRkvx/7Wgf0vkRTDQdCeHWvcoJKIsuwAkOKtaF5YfeDH/wAP/3pT/HYY49h3759eOihh/DDH/4Qjz766KjbXXXVVWhtbVU/XnrpJa0v5RTvqPl1+h0vVFXggctuQyAcmRHvOvSaiAXilmJ1Krj2Rbt1pdF3iREZM2pjsxnExuhslx2F2dp2eDPJ1UsqYbdJ2NXSl1aDWE3d0cEJDTp2YnjCiufFvrqvHS29IyjKceGvEixc3A47LpqvNBUyfTn2tX3tGAmGMacoO6lYsSo18sR6f+fpRPPCbvv27bj++utx7bXXora2Fp/+9KexatUq7Ny5c9Tt3G43Kioq1I+iIn3PcmzuHkZL7wgcNgnnJrDeP112m4TqIuVdR+MMOFpMrww7AGryfkSGuo9PS2IZ9qzZBfC6leQfTsbqK35/XboGCRuhKMeFi+crKf0vpNEQRZMGGXaCWIod8IUwHAilfH9aenJbAwDglvOrk9rWsyK6z25Lhh8vJgZ/Vp9VmdS/cxF5MhOaInrSvLC7+OKL8dprr+HgwYMAgA8//BBbt27FNddcM+p2mzdvRllZGerr63HnnXeivX3idzB+vx/9/f2jPpIlTps4Y3Y+sl36xveJ5diGGbDPrjs62KBHx87lsMUKLh322e1tVZ5Hp1flqdfPLDt9tTDqJGFiCesPf2lJmy0CWu6xy3U7kB09ML7dQsux+1r78fbR7ikjTsazsl7ZZ/deU48ub1atoN8XVM/FTWYZFgAqC8RSLDt2qdC8sPvGN76BW265BaeddhqcTifOPvtsrFu3Drfccot6m6uvvhq/+tWv8Prrr+PHP/4xduzYgcsuuwx+//j/eDds2ID8/Hz1o7q6OunrEoMTeuXXxRMDFMfSaAlluvTs2AGxglGPfXaiY7c4rrDrZuSJrsSUJ/fXTW3V6eXIdTtwpGMIv/+gxezLmdKgP6R2vMWqRSrE6ROAtZZjn4pGnFy1pELdE5ao6qJszC/LRTgiY2uGxp68suckAuEIFpTlYmGSZzZXRSNPGFKcGs0Lu9/+9rd45pln8Oyzz+L999/HU089hR/96Ed46qmn1NvcdNNNuPbaa7FkyRKsXr0aL7/8Mg4ePIgXX3xx3Pu877770NfXp340NzcnfV1if90yHQcnhJk0GavnHrv4+9V6idQfCuPQSWUD8+lVeSiK7vfiZKy+RDjxrAJOxE4lL8uJL182HwDw0J/2Y8hvreXIsUS3rijHBW+WNvsnxZSkGLgxW89QAM9Fi+zPL6+d1n2Irt3mDN1nF1uGrUp6uwXPi9WG5oXd1772NXzzm9/EzTffjDPOOAO33XYbvvKVr2DDhg0Tfk9lZSVqampw6NChcb/udruRl5c36iMZbX0+HOsahk0CliYwlp6q2mjiejptep4uUQgV5eizEV4tuDReIj10chChiIx8jxOzCjyxApJLsbriUmxy1l5Ui5ribLQP+PH45iNmX86ktNxfJ1itY/ebHc3whyJYMitv2nu1Lz1N2We3OQNjT7qHAth6WOlEXndmZdLfL86LPTngQzAcmeLWNBHNC7vh4WHYbKPv1m63j4o7GaurqwvNzc2orEz+iZAIsQx7elW+Zu8kJyP22DV3j2R85IkohLQ+dULQa4lUBBOfXpUHSZLiwpBZ2OlJHZ5gYZcQt8OOf7xmEQDgv946qnbFrKhZjTrR7u/WSh27UDiCp7c3AlACiac7/LO0thDZLjs6BvyjcjQzwcu7WxGOyFgyKw9zS3OT/v6SHDecdgmybJ1iPh1pXtitXr0a3/ve9/Diiy+isbERzz33HB5++GHccMMNAIDBwUHce++92L59OxobG7F582asXr0aJSUl6m209raaX6f//jpgdORJpufxxDp2+hR28ZEnWhIvqKdXKd1fI44vm+mC4Qjaoi/W7NglbtXiciyfV4xAKILvv7zf7MuZUJOGgxOClTp2m/aexIk+H4pzXNPqRgluhx3L5ykTz1sOZtZ0rLoMe2ZyQxOCzSap+xZ5Zuz0aV7YPfroo/j0pz+Nu+66C4sWLcK9996LL37xi3jggQcAKN27Xbt24frrr0d9fT3WrFmD+vp6bN++HV5vchstExU7H1b//XXAmMiTDN9np3bs0myPXaywUzKWijgVq7u2Ph8isjLtXJLjNvty0oYkSfj2dYthk4AXd7WqE/5Wo0dhJ44Vs0Jh90R0aOLWC+akfHLRpacp++ze2J85++xO9vvUvezXplD4ijNjM70poifNcz+8Xi8eeeQRPPLII+N+3ePxYOPGjVo/7ITaB3w42jEESQLOrzWmYwcAdSU5ONIxhMauYVyywLCHNZw4x1WvqVg9Tp8IR2Tsax3Tsctmx05vYnBidkHq54jONIsq83Dz+XPw7DtN+O4Le/DHuy+23M9Qz46d2XEne0704d2GbjhsEj53QXIRJ+NZGc2ze7+pB33DQeRnQFj3ix+1QpaBc2sKUzousIqRJynL+LNidzT0AAAWlnsN/ccj9tk1ZvAAhT8UxmB0Uk+3jl229kMNjV1DGA6EkeW0qftAYh07xp3ohfvrUnPPlfXwuh3Y3dKP/3vvuNmXM0okIquFeyYOT4iIk6vPqERFtKOUilkFHiwoy0VEBt46nBnLsc9/JJZhU9srL06fYEjx9GV8YSeWYZcZtAwr1JRkfmHXGy2C7DYJeVn6hD7r0bHbG12GPa0iTz3fVkz1smOnHzXDroCF3XQU57rx95cr7f+HNh5Q31RZQfuAH4FQBA6bpC6laUEMTwwFwqb993YPBfCHvyhFy9ppRpyMR0zHvrE//Qu75u5hfNDUC5sEXJNiYcfzYlOX+YWdwYMTQl1x5mfZqRl22S7djofSo+AaOzgBxDqDfSNBhDhmrwtGnaRuzfJa1JXkoHPQj5+8cdjsy1GJZdhZhR447Nr9WslxO9TTZ8zq2v363SYEQhGcOTsf58wp0Ox+RZ7dloMdaXOyyERe+KgVgNJAKfOmVtjzvNjUZXRh1z0UwIFoCK0RJ07Eqy1RliMyOfJE7ww7IFZw9ftCmuUaiaiTxXGFXb7HCVGb9mboUT9mU8OJWdhNm8thw/3R+JOfv9WApi5rxJ+oGXYp7K2aiBigMGOfXTAcwTNvHwOgdOu0fAO7tLYIOS47Ogf96vGG6So+lDhVakgxl2KnLaMLOzE9tqAsF8W5xk7hVeZnfuSJ3hl2wJiCS4P9b7Isq0uxYiIWABx2G/I9PH1CT2IpNpWN1QRcvqgMF88vQSAcwYaX95l9OQD0CScW1AGKAeM7OK/sOYnWPh9Kct0pTXqOx+Ww4aL5SuxJOk/HHm4fxN7WfjhsEq46vSLl+xNLsT3DQYwEwinf30yU0YVdLObE2G4doOw7mxM9gSJTl2P1zrADxhRcGgxQnOz3o2soALtNwmkVo+N1ijgZq5twRFbf4HCPXWri409e3t2Gt492mX1JajixlhOxgthnZ8ZS7JPbGgAAn7tgDtyO1CJOxiOmYzencZ7dC9GhiUsWlGgyRJeX5UCOS/lZ88zY6cnswk7dX2fs4ISQ6ZOx4jQIvSZihSINs+zEMuy80pxTsqgKmWWnm/YBH0IRGQ5b7GB3mr6FFV41duOfn99r+nYPPaJOhNhkrLFLsbtb+rCjsQdOu4TPXTBHl8dYuVDZZ/dBUw960/B1R5ZlTZdhAeWNC8+MTU3GFnZ9I0Hsa1OW3IwenBBiZ8ZaYx+M1kQBpFeGnaDlcV9jg4njxbLsuMdOa2J/XWVBljqJTKn5ypX1yMtyYF9rP/53Z7Op16Jrx86kyJMn/twIALj2jEr1GrRWVeDBwnIvIjLw5qFOXR5DT/taB3CkYwguhw1XLi7X7H4rCzgZm4qMLex2NnZDlpWgYL3+UU6lNhp5cixDl2LVqVidO3bq6RMavKONPyN2LDEEwo6d9sRELJdhtVOU48I/XFEPAPjRKwcw4DPnDclIIKye5apPx8744YnOQb/aiVp7UZ2ujyW6dpsPpN8+O5Fdd9nCMk3PYa8Sp09wKXZaMrawE0ebmNWtA5SiEgAaMrSwUzt2Ok7FAvp07BaPU9jxvFj9cHBCH7dfWIO5pTnoHAzgsdfNiT8RwdN5WQ5dQuDVpVgDhyd+/U4TAuEIPlZdgI9VF+j6WCuihd2baRZ7oscyrMCl2NRkbmF31LzBCaGmWESeDGdkNlp8jp2eYgVXah2JvuGguiR4euWpS7FaFpA0mnrqBDt2mnLabfj2tYsBAL/4c4Mp+3n1nIgFgHJvbClWlvUvfILhCJ6ORpx8/qJa3R9vaU0Rct0OdA4GsDu6opAO/tLci+M9I8h22XFZNGxZK5Xs2KUkIwu7QX8Iu0+I/XXmDE4AQFW+By6HDcGwnJFhi0ZMxSr3r80SqciKml3oGbezoOWSL412nOHEulm5sBQfry9FMCzjwZeMjz/Rc3ACiOXY+YIR9Pv0P33i5d1taB/wo9TrxtVLtI04GY8Se6L8ntp8IH2mY5//UAklvnJxOTwubSeGq7jHLiUZWdjtbOxGOCKjusijPkHMYLNJqCnK3MgTI3Ls4u8/1SVSNZi48tRlWIAdOz21MJxYN5Ik4dvXLoLdJuGVvSex7bCxm/D1LuyynHY18qjDgOXYJ/+sRJz89QU1cDmM+RWpxp6kyT67cERWY05Wn6ntMiwQH1JsTJc202RkYRfbX2det06oydCjxUYCYfiCyvKy/h07bWJIxgsmjpepHbtthzuxz8Rke1mW1T12epxMQMCCci9uW6bEn3z3hb2Gbv1o1nkpFojPstN3gOLD5l6839QLp13CrTpFnIxHjT1p7k2LN5Y7GrvRPuBHXpYDl9SXaH7/Yil2OBBGH08CSlpmFnZif52JgxNCXYmIPMmswk4UPy6HDdkat+HH0mqoYbwzYuOpBWQGxZ2c6B3BX//8Haz5xbumvfPtGPTDH4rAJgEVGh4QT6P9w+ULkO9xYn/bAH5rYPxJc7dStOvVsQPis+z07dj973vKz+26M6tQ6jXutKLKfA9Oq/BCloE3D1l/OfaX2xsBAJ84vUKX4OYsp119Pc7EbUx6y7jCbiQQxkfHlSW3ZXPN79jFIk8yK8tO3V+X7dL0/MTxaLFE6guGcbhjEABw+qzJl2IH/SH4Q5lxlM3ulj5EZKB9wI+OQePP2gRiy7DleVlwanhAPI1WmOPCV65YAAD48SsHDel0yLKs+1IsENtnp3fHbvsRpSlw9ZLUj8ZK1go19sTahd07R7vw0q422CTgjov1i4KpKlCKeZ4Zm7yMe5V9v6kHoYiMyvwsS2zUrsvQ0yeMyrCLf4yhQBi+4PQKrgNtAwhHZBTluFAxQa6hN8uhhudqcS6tFRw8OaD+/yPt5jwHOThhnM8tq8H8slx0DwXw6GuHdH+8zsEARoJh2CToup/ZiI5dx4AfRzqGIEnA+Sas9lwa3Wdn5diTcETGd1/YCwC4+fw5WDTBfmUtiDNjOUCRvIwr7OKXYfXuJCWiJtqxa8qwyBOjMuwAJR8r1YIrfhl2oueFzSahMDotmylZdgdODqr//0jH4CS31E8Lz4g1jNNuw7euXQQAeHJbI47q/HcuunWV0QQAvZRHl0XbdRye2NGo7M1eWO5Fgc4DYeM5t6YQXrcDXUMB7GqxZuzJ7947jj0n+uHNcuCeK+t1faxYSDGXYpOVcYXd22JwwgLLsABQmZcFt8OGUCSzIk+MyrADlKm/VCdj1YnYCfbXCYUZNhl7sC2uY2dWYdfDcGIjrVxYhksXliIU0T/+JDY4oW/RbsR5saIpYNYWHqfdhovmK4MIb1hwOnbAF8RDGw8AUPZzFufquwcxFlLMjl2yMqqw8wXD+EtzLwBrDE4A0cgTcWZsBk3GGpVhJ6SaZTfZGbHxMmkyNhCKjCrmjnSYtRQbDSfmUqxh7r92MRw2Ca/ua8dbOm7GN2J/HWDMebFWOK3o0tOsu8/uJ28cQeegH3UlObj9wlrdHy92XmzmNESMklGF3V+aexEIRVDqdavHeVlBTQbuszMqw05IpWMXjsjY3zb5RKyQSVl2jV1DCMXt1TnSbu5SLPfYGWd+WS5uu1CJP3lAx/iTZoMKu/jzYvWY7u4ZCmB/tLttxv46YUW9ss/uw+O9ltoO0tQ1jF9sVfL97r9mkSH5fjwvdvoyqrB752jsHZcV9tcJosjMpCw7EQliXMdu+ll2DZ2D8AUj8DjtqC2evODX6vgyKzgQ/UUlnn8tvSMYCRg77SvLsjo8wT12xlp3eT0Ks504eHIQv363SZfH0Ps4MUFEjwTCEV2mfd+N7q+bX5ar+xLjZCrys2KxJwet07V78KV9CIQjuGRBCS5fpO3xYRMRS7En+30IW3SYxKoyqrB7t1GcD2uN/XVCbSZ27Aycio1/nOm8ixXLsIsqveoQxkS0Or7MCkRht2xusToUcrTT2K5d73AQw9Fi0sxTYGai/Gwnvhrd4P7wpoPo02HS26iOndthV5/Deuyzi28KmO3S06x1CsX2I1340x4l3uRb1y42rGlS5nXDJgHBsIxOk6Ka0lXGFHaBUATvHesBYI1/nPFqi8WxYpmTZadOxRq0FJvKEmmi++sA7Y4vs4ID0aiTheW5mFeaC8D4fXaiW1fqdSPLqW+QNZ3qlvPnoL48Fz3DQTzy2kFN79sfCqM1uudN744doG/kyTsN1mkKrKxX9tm9eajT9E5VfLzJ5y6owcIKr2GP7bDb1GgqRp4kJ2MKu10tvfAFIyjKcWFBWa7ZlzOKCCluzqDIk1jHTv+4E+VxxFBD8l0HMRE71f46QLvjy6xAZNjVV3hjhZ3B++xaeqODE+zWmcJht+Hb1y0GADy9/RgOxeUapqqlZwSyDGS77Cg2oHOv1wBF30gQe6NH7i2zQFPgnGjsSfdQAB8d7zX1Wv5nZzP2tfYjL8uBr+gcbzKeyrgzYylxGVPYvR1tpZ9fa639dQBQERd50pIB7zxkWY7LsTN4KjbJTposy8l17DQ6vsxsw4GQuv9pYbkX88qUNxdGR54wnNh8lywoxRWLyhCKyPji0++hV6M3LfETsUa85say7LRdlnvvWDdkWdmLWjZBeLmRnHabev6qmdOx/b4gfiTiTa6oN+y1Pp44M5Ydu+RkTGGnjqrPNf8d11ijIk8yYJ/doD+EYFhZIrD6VOyJPh96h4Nw2CTUV0zdyc2UqdjD7YOQZaAk14XiXLfpS7GMOjHXgzeegVkFHhztHML/9/R7mhyZ12zQ4ISg11KslfbXCSuj07GbTRyg+Mnrh9E1FMDc0hzcHp2wNtosRp5MS0YUdqFwBO81in+c5u+RGI8YoMiEM2PFRGy2y27YvqnpLpHuiSa4zy/LTeiw6qIMybETgxP15cqeGFHYHe0YNPS4oljUCcOJzVTmzcIv1p4Hr9uBdxu6cd/vdqUcG9IcLdr1HpwQytXzYrX9Jf+2BZsC4tzYj473osuEwYHGziH84s9KvMm3r11s2hnPomPH82KTkxGF3e4T/RgKhJHvceI0Azd3JkNETmRCx87oDLv4x+oeCiT1CymZZVggthTrC0YMjwbRkrq/LlrYzS70wGW3wR+KGLodQF2K5R470y2s8OInnzsHdpuE33/Qgn9/7XBK99fUZcxErFCmw+kTg/4Qdkff/J1voaZAeV4WFlfmKbEnOgZMT+R7L+1DMCxjRX2pOqVrhlhIMQu7ZGREYSeOgjmvtgi2KeIszKKGFGdAlp3Rp07EP5Y/FMFIMPGCK/6M2ETkuOxwRd+dpnPXTpwRK6bYHHYbakuUX8BG7rNr4akTlvLx+lL8yyeXAAD+9dWDeO6D49O+L6NOnRDEUmy7hh279471IByRMbvQY7kBn5ULzTmF4s+HO7Fp70nYbZJ67rBZ1KVYDk8kJSMKu3ejrfRlFmqljyV+qWbCUqzRGXaAsuwr0s6T2We3LzrtNtUZsYIkSeqkbzrvszs4ZikWgOH77Pp9QfT7QgA4FWslt5w/B19cMRcA8I3/26W+MU6GLMuGnRMriKXYjkG/ZtsJxH+7FbfwiE7ZloMdhsWehMIRPBCNN7ltWQ0WlJu7AiaWYjsG/JrsC50p0r6wC0dkNTXczKNgplKXQZEnsQw7Y6JOAKXgig02JBZ50jMUUJcdEy3sgPTPsusbDqIt2tWoL48NjMQKO2M6di3RZdjCbCdy3A5DHpMS841PnIarl1QgEI7gi8+8h6NJPid6h4MY8CtFu1H7J0ty3ZCigbVaxRFZeeju7OoC5GU50DscxIcGxZ78Zkcz9rcNIN/jxLorFhjymJMpynHBHX1Df7KPIcWJSvvCbl9rPwZ8IeS6HVhcmfgvb6OVe2ORJ2LfUboyo2MX/3iJLpGKbKo5RdnIy0q8CE33LLuD7Uq3blaBB964/2418sSgLLtY1AkHJ6zGZpPwrzd9DB+rLkDvcBCff3JHUm9kxDJseZ5xwdNOu03Ny9Nin91IIKzmxC2zYMfOYbfhkgXGLcf2jQTx8CYlxPorVyxAgYF7qCciSZJ6Yg3PjE1c2hd24h3X0tpCOEya3EmEzSbFjhZL8312Rp86ISSbZZdMMHG8dM+yi03Ejo53MXopVt1fx2VYS8py2vGz25didqEHx7qG8f/9cid8Ce5fNXp/nVDmjQ5QDKS+5+qDph4EwzIq87MMW05OVmyfnf7Hiz362iF0DwUwvywXn1tmTrzJeDgZmzzrVkIJsvIeibHEPrt0PzPWtI5dkkukyQ5OCOmeZRd/4kS8udHCrnPQr8u5oWPFok6s+UuTlKPenlh7HrxZDuw81oOv/d9HCe1fa+4xNsNOEPvstBigUGNO6qwXai/EYk/60KFxMHO8ox2DeHJbIwDg29eZF28ynsp8Ztklyzp/e9MQidtfZ8U9EmPFOnbGDFC88NEJXP/YVhzWeOlN7HEzOok82SXSZKNOhGSXfK1GdOwWjtn4nOt2qGcvHunUfzmW4cTpYUG5Fz/963PhsEl4/sMT+NdXpz5Tttmkjl25hpEnalPAAufDTqTMm6W+MX188xHdBgi+9+I+hCIyLl1YihXRs2qtYlYBT59IVloXdoc7BtA7HES2y44zZiX3y9sM4sxYo5ZiH3v9MD483odHEnihToYZOXbxj5dIx24kEFY3hCffsRNLvvp3tbQmy/IpGXbxjNxnJzp2XIq1vovml+DBG84AADz6+mH8787mSW9v2lKsRqdP+IJhfNDcC8DaQ3cAcOM5swEAv/hzA1b965vYtPdkyuHS8d482IHX9rfDYZPwrei5wlbC82KTl9aF3XvHegAA59YUWqp1PBG1Y2fAUuyJ3hHsj3ZuXt7dpun+BDNy7OIfL5GO3b62fkRkZZIu2fMf03mPXcegHz3DQdgk5bSNsYzcZ8fhifTy2fOqcfel8wAA9/1+F7Yd7pzwtk0GHycmxE6fSK1j92FzLwKhCEpy3ZgbfcNtVXdcVIuHP3sWyrxuHOsaxp2/3Inbf/EuDkeHpFIRCkfwLy8q8Sa3X1irvj5YCc+LTZ71q6FJ7GxQCrvza639jksQe+yae0YQ1DnyZEvcGYPhiIxfvd2kyf1GIrGoAZH3ZpRkCq7p7q8D0nsq9mCb0omrLc4Zd1rRqMiT4UBI/XviUmz6uOfKhVh9VhVCERlfeua9cYuHYDii7ncyfCk2OjzRnuLwRHzMiVX31wmSJOHGc2bj9XtX4ksr5sFlt+GtQ5246pG38N3n96JvZPorC8++24SDJwdRmO3EP1xufrzJeGbx9ImkpXdhd0z847TuHol45d4sZDltCEdkNeNLL2KK6szZyhL1s+82JTzxNpl+XxBib7XRS7HJ5NjtTaGwS+ccuwOTLMMCxhV24vntzXIg32PsGwCaPptNwg8/fSbOrSlEvy+Ezz+5A51jzipt7fUhHJHhdthQmus29Ppip0+k1rF7p0HZX7fM4suw8XLdDnzz6tPwylc+jisWlSMUkfGLPzfgsh9txq/fbUo6xLhvOBZv8tUr65FvYC5pMsRSbL8vhMFodiJNLq0Lu66hINwOG86qtv7+OmB05EmDjvvsAqEIth5SllH++a9OR1V+FrqHAnj+wxMp37codrxZDsOXv0WHMJGhhr3RqJNkgomF+I6dlntZjKCeODHBmclij11T17CuXePj3F+XtrKcdvzXbeeipjgbzd0juHNMDEr8RKzRRziWxZ0+Md3TGAKhiLqNJ12aAvFqS3Lw32uW4qk7zse80hx0DQVw3+934a8e24od0WHCRDzy2kH0DgdRX56LW86fo+MVpybX7YA3Swk4b2XXLiFpXdgBwNlzCuB2GBOQqYWaYv0jT3Ye68ZQIIySXBfOml2A2y6sBQA8ua0x5UJFzbAzeH9d/GP2DE1ecIXCEXV/YbITsUCsYxcMy2n3DlF07MZOxAoVeVnIdtkRisi6Hm/H/XXprTjXjV+sPQ/5Hic+aOrFPf/zoRqDYtbgBAAU57hgk5TtJV1D0+va7Wrpgy8YQVGOCwvG2YeaLlbUl+JP6z6Ob1+3GN4sB/ac6Mdnfrodf//rD6bcU324fRBPbz8GQIk3sXIGLMAzY5Ol+d9mKBTCt771LdTV1cHj8WDu3Ln47ne/i0gk1h2QZRnr169HVVUVPB4PVq5ciT179kzr8dIhvy6emIzV85fqlmhK+Yr6MthsEm4+rxpuhw17TvRjZ/Sd6nR1R5dBjV6GjX/MUERWjzMaz5GOIfhDEeS6HaiZxi8fj8sOT3R/WjpNxkYiMg6Jwq5i/F9YkiQZshzb0sMMu3Q3rzQX/3nbuXDaJby4qxU/fOUAAHMLO4fdhpJckWU3vcJOLMOeX2v9/XVTcdpt+JuL6/DGvStxy/nVkCTgjx+ewGU/2oJHXzs04fab7724F6GIjCsWlamnW1iZGlLMjl1CNC/sfvCDH+CnP/0pHnvsMezbtw8PPfQQfvjDH+LRRx9Vb/PQQw/h4YcfxmOPPYYdO3agoqICV155JQYGkp/ySYf8unh1YilWx47dG9H9dSK1vDDHhRvOngUAePLPjSndt1kTsYCyRJTtEgXXxMux4sSJRZXeaS8VFaVhll1L7wiGAmG47DbUFE886TevNBp5omdhx6XYjLBsbjF+8KkzASg5ar95t8m0iVihPMXIk3eOWv9s8WSV5Lqx4cYz8fzfXYylNYUYCYbx400HccXDW/DyrtZRKxybD7TjjQMdcNol3H+t9eJNxlPJAYqkaF7Ybd++Hddffz2uvfZa1NbW4tOf/jRWrVqFnTt3AlC6dY888gjuv/9+3HjjjViyZAmeeuopDA8P49lnn03qsZx2G86ZU6j1f4KuanQ+VqyldwQHTw7CJgGXLChRP79meS0A4E972lL6x2FWhp2QyGDDdIOJRz1OkseXWYHIr5tbmjPp/ke1Y9eu35uL49F9WOzYpb8bz5mtTkze/4fd2H5E6XhVm/R3m0rkSSgcwc40CrVP1pJZ+fjfL12If7v5Y6jIy8LxnhH87a/ex60/ewf72/oRDEfwwAtKvMna5bWos3jUi8Cl2ORoXthdfPHFeO2113DwoDJt8+GHH2Lr1q245pprAAANDQ1oa2vDqlWr1O9xu91YsWIFtm3bltRjnTErz7ADqLUi/iEd1ynyREzDnjOncNQhzosq87BsbhHCERnPvH1s2vcf69iZM0GVSBTJnhQGJ4R0nIxV99dNMDghzCszbimWUSeZYd0VC3DD2bMQjsjqv4k5xeZ07FIJKd5zoh9DgTDyshw4rWL6rw9WJkkSrv/YLLx+7wp8+bL5cDls2H60C9f821v43M/ewZGOIRTluPB3l1kz3mQ8PC8W6huSRGhe2H3jG9/ALbfcgtNOOw1OpxNnn3021q1bh1tuuQUA0NbWBgAoLy8f9X3l5eXq18by+/3o7+8f9QEowcTppjzPDY/TjnBEVjeYa2lzdH+dWIaNt3Z5HQDg1ylEn5h1TqwQy7Ibf++bLMspRZ0I6Zhlp07ETjA4IcTvsdNj6tcXDKM9eq4lhycygyRJ+P6nzhiVGVpt0t9tKll26v66uiLYDZ7oNVq2y4F7Vi3Ea19dgatOr0BEhnoE5z2r6tMqhmimnxc7Egjj73/9QcK317yw++1vf4tnnnkGzz77LN5//3089dRT+NGPfoSnnnpq1O3GblqVZXnCjawbNmxAfn6++lFdXQ0AWJomwcTxJEnSbTLWHwqrafErF5ad8vUrFpVhVoEHPcNB/PEv04s+UadiTVqKjR33NX7BdbxnBP2+EJx2CQvKJi9wJpOeHTulAzfRRKxQU5wNmwQM+ELoGNT+YHFx9I/HaUehRbOxKHluhx3/edu5WDa3CJ8+dzZy3A5TriOVpVixvy7dhu5SUV2UjZ/edi6e/cIFOLemEFedXoGbz7NuvMl44kOK0y2CSgt/+EsL+n2JJzRoXth97Wtfwze/+U3cfPPNOOOMM3DbbbfhK1/5CjZs2AAAqKioAIBTunPt7e2ndPGE++67D319fepHc7NyjuF5aVjYAbGjxbQeoNjZ2IOhQBilXjcWV57arXLYbbj9whoAwBPTjD6xTMdugk6a2F9XX+6FyzH9p3e6dexC4Yh6/utUS7FZTru68V2PfXbx++vSfeqQRivMceE3/9+F+NFnzjLtGkSWXbIdu3BEVjtWmbi/birL55fgd3+7HD+97dy061aW5yt/5/5QBD3D6ZNUoAVZlpMeetS8sBseHobNNvpu7Xa7GndSV1eHiooKbNq0Sf16IBDAli1bsHz58nHv0+12Iy8vb9QHgJR+cZspFnmi7S9Vsb9uRX3phNOgN51XjSynDfta+/FuQ+Jr9oL4R2XGVCwQf/rE+AWXGkw8TmGbjHQ7L7axaxiBcATZLntCk6h6Rp5wfx3pqcwr9tgl17Hb39aPAV8IuW5Hyq8PZCy3w67G3My0ydjtR7tw4OQAspyJ1zuaV0arV6/G9773Pbz44otobGzEc889h4cffhg33HADAGUpct26dXjwwQfx3HPPYffu3Vi7di2ys7Nx6623an05llQXPTO2QeMsu8n21wkF2S7ccPZsAEpgcbLUjp1ZU7FTFFypnBEbL5njy6xATMQuKE8s4kXPyBMRdcKJWNKDiDvpHPQjlMQAmliGXVpbaPlAXjrVrALl732mFXaiW3f9x6oS/h7NN0k8+uij+Pa3v4277roL7e3tqKqqwhe/+EX80z/9k3qbr3/96xgZGcFdd92Fnp4eXHDBBXjllVfg9U5/T1Q6USNPNFyKPd4zjEPtg7DbJFwyf/LAybXLa/Hrd5uwcU8bWnpHEs4aC4Uj6oHTpnXsplgiVQu7WakdM5fM8WVWcKBNnDiRWJJ+rGOnx1KsyLDj4ARprzjHBbtNQjgio3MwgIroxORU4gcnKP1U5nvw4fE+dQ/vTNDcPYxX950EANx6/hz8KMHv0/xti9frxSOPPIJjx45hZGQER44cwb/8y7/A5YoVApIkYf369WhtbYXP58OWLVuwZMkSrS/FsmKRJ8MIhLSJPBHdunPmFEx5mPPCCi+WzytGRIZ6rEwieqNFnSTBtImqyYYaugb9aOv3QZKUeJdUxB9flg5Ex26qiVhBjTxp51IspRebTUKZVwxQJPZLPhKR1a0nM2lwIpNUzsCO3dNvH0NEVjJp5yUxDMh+tAnKvErkSUSObTRPVWwZ9tRp2PGsjQYW/2ZHE0YCiUWfiCKnwOM0bfNtrGN36hKp6NbVFucgN8WJPXUpdjignpFpZYlm2AmiY9fSO5Lw33+iGE5Meks2y+5Q+yB6hoPwOO04c3Zq3Xwyx0wLKR4OhPCbd5sAxH5fJ4qFnQlGRZ5oMEDhD4Wx7YiIOUns3L/LF5VjdqEHvcNB/L+/tCT0PWZPxCqPrXQKe4cDCI8puERhl0owsSDCnSMy0O+z9j47XzCsLutPFXUiFOW41CiSo53ade2C4Qjaor9sZ/M4MdJJuejYDSQ2QCGWYc+tKZz0VBayLpFlN1POi33uAyXipKY4G5cm2LAR+Aw3iViObexMvWO3o6EHw4EwyiaIORmP3SZhzYW1AJQhikSiT8zOsANiS7ERGegfGV1wiRMnUh2cAJSJa2+062f1ydgjHYOIyEBBthOl0V94idBjn11bnw8RWfn5iSk2Iq2JAYr2BDt2sfw67q9LVzNpKTY+4uT2C2uTPvOchZ1JROSJFh07EXOycmFpUrlhn11aDY/Tjv1tA3j76NTRJ+K0BzM7dk67Dd6saME1ZrBhrwZnxMYrTJMsu/j9dcn8/cfOjNWuYxcbnPAk/WJElKhYSPHUhZ0sy3hH7K+by/116UosxZ4c8J+yWpNpth3pwqH2QWS77PjM0tlJfz8LO5PURpditQgpfkMt7JJr1+ZnO3HjObMAAE9ua5jy9lbo2AHjDzYM+UNoiBbJWmVUTXV8mVUcaEvsxImx5pVpH3nC/XVkhDL1WLGpl2KPdg6hc9APl8OGs6q5vy5dleS64YhOQ0/nOLl08kS0W/fpc2cjLyv5QUUWdiYRp08cSzHLrrl7GEc6hmC3SbhofknS3y82ZW7aexLN3ZNfixX22AHjT8bub+uHLCuDKcksR05mquPLrELt2CU4OCHosRQrMuwSjdAhmo6yJI4VE8uwZ1cXwO2w63pdpB+7TVKX4DN5Obapaxiv7VciTm6PbpdKFgs7k2gVebL5oDINe25N4bQiSBaUe3Hx/BJEZOCZtyePPhEFTlGOued/jpdlp1Uwcbypji+ziliG3fQKu6Mdg5pN/rb0sLAj/SWzx04MTnAZNv3FzozN3I7dL7c3QpaBj9eXYn5ZYrmkY7GwM0mp141slxJ50pxC5Mnm/bH9ddMluna/frcJw4GJDxoWBY5Zp04IsY5dbIl0T4u2++uAqY8vs4IBX1DtktUnGE4szC70wGW3wR+KqPeRKrHHbnYRCzvSjyjsuoYCk74xlmVZ7dgt4+BE2hMDFK19mdmxG/KH8NudzQCAzycZcRKPhZ1JlMiT1M6M9QXD2HZEeTe6sj65/XXxLj2tDHOKstHvC+EPH5yY8Haxjp3Ze+yiS6TxHbtW7SZihXQ4L/ZQdPChPM+tRrQkymG3oTZ6vJ1W++xiS7E8dYL0U5jthNOuDOd0DE68HNvUPYy2fh+cdglnzyk06vJIJyLyJFM7dr//oAUDvhBqi7Oxon76zRoWdiZSz4ydZuTJjsZujATDKM9zY1Hl9I9js9sk3H5hDQBliGKi6BO1Y2f2HrsxBVcwHMHB6ACBph27NJiKPdiW3IkTY2m5zy4ckdW9LxyeID1JkqQOUEw2GSu6dWfNLoDHxf116S6Tz4tVIk6UIcY1y5OPOInHws5EqZ4Z+8b+6GkT9WVJxVyM5zNLq5HtsuPgyUFsj3YBx+qJLn2aPhU7Zon00MlBBMIReLMcqNZwCXCy48usQj1xIuXCLvWOXfuAD6GIDEfcJmcivYjIk8n22b2t7q/jMmwmUEOKM/D0ia2HO3GkYwg5Ljs+fW7yESfxWNiZqK44tSy7zQdT318n5Huc+NQ5ypPpF9FR63j+UBiDfmX/nWU6dtFOmggmXlyZl3KBG2+y48usYroTsYIaeaJBlp3YX1dZkGXakXM0c5Srx4pNvBTL82EzSyaHFItA4s8srYZ3GhEn8VjYmSiVkOKmrmEc7RiCwybhogXJx5yMZ81yZTn2tf0n0TQmhqU3WtzYbRLyslI7hzVVY3Ps9mgcTBx7HOUfl6U7dtPMsBO0XIrlRCwZqXyK82JbekdwvGcEdpuEc2u4vy4TiNeWrqEAfEFtz7g2U2PnEF6P5tGKbVGpYGFnIhFS3NIzknTkiejWnVtTOK0Aw/HML/PikgUlkGVl5DqemmGX7dK0KzYdY5dI9+oQdRL/OH0jQYTC04+k0UvXoB+d0Y3jC5KciBXmRgu7zkE/+lLsTHJwgowk8ionCil+56iyDLtkVj5y3Oa+GSVt5Huc8DiVvZJtGbQc+8vtxyDLyuqbeE1OBQs7E5V63ciZZuTJ5gPR/XVJnjYxlc9fVAsA+O3OZgz5Y9EnVsmwU65BKbj6fSEEQhHsbY0WdrO0LezyPU6IGrZ3xHrLsQdPKt26OUXZyHZN7xdXrtuBimjn40hnasuxPHWCjDRVx44xJ5lHkqSMW44d9Ifwv9GIk7UpRJzEY2FnovjIk2QGKJSYk04AwKWnpb6/Lt7K+jLUFGdjwBfC7z9oUT9vlQw7YHTBtaulF4P+EFwOm7qsqBWH3aaGPlsxyy7+jNhUaLXPTj0nloUdGSA2PDFBx46DExlJDSnOkI7d798/jgF/CHNLcvDxBdr8PmdhZ7JaNfIk8cLunYZu+IIRVORlTXtv1URsNglroseYPPnnWPSJVTLsAGWfX0G04HrrkFLgLiz3wmnX/ulcZOHJWHUitiK1glarfXZijx07dmQEtWM3zrmhJ/t9aOwahk0CltaysMsklfnRkOIM6NhFIjKe3NYIIPWIk3gs7Ew2nTNjNx+ITcPqsd/t00tnI8dlx5GOIWw9rBRO4pQHsydiBXEdW6OFndb768Y+jhWz7FLNsBO0iDyRZVndYzebe+zIAOXRHLve4eApG+nfju6vW1yVp9keZLIGNaQ4A06feOtwJ452DCHX7cCnUow4icfCzmTTmYzVa3+dkJflVHN0xAi2KGzMzrATxHV80NwLQMfCbpzjy6xAluW4jp35hV3HoB/+UAQ2CajIZ4Yd6S/P44DbofwK6xgzQPEOY04yViadFysCiT+zdDZyNRzwYWFnMtGxS3Qp9ljXEBo6ozEn8/V70bo9uonz9QPtaOwcik3FWqxjF44eXr9Y46gTYbzjy6ygrd+HAV8IDpuEuSUpLsVG99g1dQ0jOM3pX7EMW56XBZeDLyukP0mSJhygiOXXcRk202TK8ERD5xDeONABSYK6/UkrfAU2mdhjd6J3BP7Q1Lk8olu3tLYw5RDDycwrzcWK+tJo9MmxWMfOAlOxwOjOoSQhpSPVJmPV82IPRJdh60pyUi6kKvKykOOyIxSRk9oSEO84M+zIBGKAIj6kuHPQj8PRQaDzuL8u42TK6RNPRffWXbqwTF250woLO5OV5sZFnnRP/Q7kjej+ukt1WoaNtzYaffK/O5vVX9xWmIoFRncO55bkTDvuYypjjy+zilRPnIgnSRLmlaW2HNvCM2LJBOOdFyu6dadVeC2zwkDaqYp27Ab9IfT7rLVFJlEDviD+773jALSLOInHws5kyUSe+IJh9RxXvfbXxVuxoBR1JTkY8IfUpWIrTMUCozuHWp84EW/s8WVWkeqJE2Olus+uhVEnZIKyvFNDikUwMZdhM1O2y4GCbOX1P12XY3/33nEM+kOYV5qDSzQ6OSoeCzsLqEtwgOLto13whyKozM9C/TRPGkiGEn0y+ngTy3Ts4q5Dr8EJIA06dpoVdiLLbnqRJ7FwYk7EknHEHrv2uI6dOjgxl4MTmUpdjk3DAYpIRMZT248BULp1eiRbsLCzALHPbqrCLn4a1qhjvT517uhpHet07GLXsVjHws6KHbtwRMahdm0mYoWUO3a93GNHxlP32EWz7HqGAtgf3X96Pjt2GWuWGKBIw8iTLYc60NA5BG+WAzeeo13ESTwWdhZQqy7FTr5xPT6/zijeuOgTl8OGbJfdsMeeTPzeGT2XYkUB2WOhuJPm7mH4ghG4HTbMKdKmQxa/x06EUidKlmV1Dyb32JGRytU9dspS7LuNSrduflkuSnLdpl0X6UvNskvDpVgRIXbT0mrdzjBmYWcBYiJmssiThs4hNHYNw2mXcNF87dfkJ/P5i2qR63bgzFn5hnUKp1JXnAO3w4bFlXm6dhHFUuygP5TQ1LIRRH7dgvJc2DVKKq8pzoZNAgZ8IXQMjn9E00R6h4MYDig/myp27MhAZWPiTsT5sNxfl9lE5Em6LcUe6RjEloNKxMntGkecxNOnXKSkiI7diT4l8sTtOLUrJrp159UWaRpkmIia4hy8fu8K5Og0eTodhTkuvPn1S3XvIHqzHLDbJIQjMnqHgyjPM79jqdWJE/HcDjvmFGWjsWsYR9qH1GnDRIhuXUmuG1lO838+NHOIpdgBXwjDgRDebRTnw3J/XSaLnRebXh27X0YjTi4/rRxzivXbj8yOnQWU5LqQ63ZAlpVltvHE9tcZtwwbr8ybpVvbeLrK87J0zfIDlAGSwugEllWy7NQTJzQ+J3i6++xaesXgBLt1ZKxct0N9c3ekfQh7T/QDYMcu08WWYtOnY9cfF3Hy+WiUmF5Y2FmAEnmiVO8N4+yzGwmE1bMPjYg5odEKLTYZq2WGXbzpZtkdZ9QJmST+9IkXdp1ARAZqi7PVz1FmqoweW9jW50MkktyeYLP8387jGAqEsaAsF8vn6dtRZmFnEWKf3bFxJmNFzMmsAg8WlOkfc0KjWWkyNhCK4GiH8hzRvmMXjTzpSC7yhIMTZKZSr7Ic+8KHrQB4PuxMUJGfBUkCAuEIuizyhnsySsRJIwAl+F/vveos7CyibpIzY8X+uhULSy0zvDCTWCnLrqFzCKGIDK/bob5r1Yq6FNue7FJstLDj4ASZQHTnxPPwgrlchs10TrsNZdGCPh0mYzcfbMexrmHkZTlww9mzdH88FnYWIZZix2bZybKMN8T+unpz9tfNdLHzYs2PPDkQtwyrdZEvCruW3hGMBBKfAI517BhOTMYr946ONeHgxMwgJvBb02CA4oloxMnN58/R7fjLeCzsLEI9fWLMHruGziE0dZsTc0IKcXxZjwWWYvWYiBUKc1xqdMzRzsS7di3RUye4x47MEL+fbnahhyHZM0RVmgxQHG4fwFuHOmGTgNuW1Uz9DRpgYWcRYo/dib4R+IKxbomYhj2/rshyU6kzhRiesMJUbGwiVp+9lsnus+v3BdHvCwHgqRNkDnFeLMD9dTOJ2Ipi9aXYp7Ypx4ddsagc1RoFyk+FhZ1FFOeMH3my+aBS2F3KaVjTqKdPWKFjp9NErJDsPruW6DJsYbaTbzzIFPEdO+6vmzliS7HW7dj1jQTxu/eViJO1OkecxGNhZxGSJMWdGasUdqNjTri/ziyxPXbmFnbDgRCaokW/1hOxQrJZdow6IbONKuyYXzdjVKXBebHPvX8cw4EwFpZ7caGBez/5FttCaotzsLulH43RydjtRzsRiMaciF+4ZDyrTMUebh+ELCuB1sU6nYM5ryy5pVixv252AQcnyBxzirJx8fwSeLMcmp2dTNaXDufFftTSBwC47sxKQxMtWNhZiDharCE6GfvG/ugy7GmMOTFTkUVy7A7oODghiDcQRzsGEYnIsE1xFq2ImGDHjsxit0l45gsXmH0ZZDCxFNs+4EcwHIHTbr0FSLGtSuyhN4r1fhIzWHxIsSzL2HxQya9bWc/9dWYSS7G+YCSpGBCtqfvrdCzsZhdmw2W3wR+KqEXbZBhOTERmKM5xwWW3QZaBk/3W3Gcnts4Y3UlmYWchdWKPXecwjnYOobl7BC67Dcvnc9LLTDkuO1zRd4Nmdu0OnFT2vS3UaXACULofInonkX12aseOE7FEZCCbTUKFOhlrvcLOFwzjZL8fAAu7Ga2mOBZ58qfdbQCUKS8jAg1pYpIkoVBk2Zm4z07PDLt4yeyz4/AEEZlFDFBYMaT4eHT/sdftQEG209DHZmFnIcU5LnijkSfPvtMEAFjB0yYswewsu77hINqiyw31OmXYCYlOxg4HQurPg6dOEJHRrBxSLJZhZxdlG75HXvPCrrZWOeB27Mfdd98NAFi7du0pX1u2bJnWl5GWlMgTpVsilrhWMr/OEszOsjvYrnTrZhV44M3S991foll2IsPO63Yg32PsO1IiosoC64YUN3WJ/XXGr2Zovsa3Y8cOhMOxDea7d+/GlVdeic985jPq56666io88cQT6p9dLpfWl5G2aoqzsSs6Il1d5FFPAiBzmZ1lF5uI1T/2Jtaxm3wp9jgnYonIRFY+L7Y5+sbXjAgezQu70tLRS4ff//73MW/ePKxYsUL9nNvtRkVFhdYPnRHq4saiV9aXMebEIszOstP7xIl4c6NvJjoH/egbDiJ/gv0hnIglIjOlw1KsGYWdrnvsAoEAnnnmGdxxxx2jCpTNmzejrKwM9fX1uPPOO9He3q7nZaQVkWUH8LQJKyk0OctOdOz0OnEiXo7boZ7DeKRz4uXYFrWw4/46IjJepYVPnxAZdkadDxtP18LuD3/4A3p7e7F27Vr1c1dffTV+9atf4fXXX8ePf/xj7NixA5dddhn8fv+E9+P3+9Hf3z/qI1OJPXYuhw0XzmPMiVUUZYup2KDhjy3LsiEZdvES2WfHqBMiMpNYiu0dDpqaMTqWLMumdux0zdH4+c9/jquvvhpVVVXq52666Sb1/y9ZsgRLly5FTU0NXnzxRdx4443j3s+GDRvwz//8z3peqmWcXV2AOy6qQ315LmNOLMTMPXYdg370DAdhk4D5ZcYcLTevNAdbD3dOus9OjPNzjx0RmSEvy4lctwOD/hBO9I1Y5ujNrqEAhgNhSJI5r4+6deyOHTuGV199FV/4whcmvV1lZSVqampw6NChCW9z3333oa+vT/1obm7W+nItw2aT8E+rF+Pm8+eYfSkUx8yp2INtStestjgHWU67IY85r2zqyJMW7rEjIpNV5ltvMlZ06yrysuB2GPOaHU+3ltATTzyBsrIyXHvttZPerqurC83NzaisrJzwNm63G263PoeeEyXCzBy7AwYvwwJTZ9n5gmG0DyjbJ7gUS0RmqSrw4FD7IFotNEBh5v46QKeOXSQSwRNPPIE1a9bA4YjVjoODg7j33nuxfft2NDY2YvPmzVi9ejVKSkpwww036HEpRJqI79jJsmzoY6snThgwESuIwq6paxjBcOSUr7f2KS+iHqdd/dkQERmtyoIDFM0m7q8DdCrsXn31VTQ1NeGOO+4Y9Xm73Y5du3bh+uuvR319PdasWYP6+nps374dXq9xv7SIkiU6dsGwjEF/yNDHFh07IyZihfI8N3JcdoQiMo5Fgzbjxe+vYyQPEZmlUo08sU5hZ+bgBKDTUuyqVavG7Wp4PB5s3LhRj4ck0pXHZYfHacdIMIyeoaDupz8IkYiMQ6KwqzBuY7AkSZhXlouPjvfhSMfgKUMb3F9HRFYQCym2zlKs2YUdz4olSlCRCVl2Lb0jGAqE4bLbUFNs7Ckkk+2zY9QJEVlBlQWHJ5q7lWvJqD12RJmoMEdk2RlX2In8urmlOXDajf3nKo6zO9J+auSJOHWCUSdEZKbKgtjpE0bvfx5PIBRR9/tVm3BOLMDCjihhZkzGqvvrDBycECbt2PHUCSKyABF3MhIMo2/E+AD5sVp6RyDLQJbThtJcc9I8WNgRJciMLDt1ItbAwQkhPstu7DthdXiCS7FEZKIspx3F0ddmK5wZGz8Ra9ZgGQs7ogSZ07FTumVGTsQKNcXZsEnAgC+EjsHYkX/BcARt/coLaDWXYonIZOqZsRbYZ2f24ATAwo4oYUZ37ELhiHpWqxlLsW6HXX1xit9n19bnQ0QGXHYbSkxaaiAiEqryxWSs+YWd2eHEAAs7ooQZfV5sY9cwAuEIsl1205Y8x9tnFz84YbMxw46IzCUiT05YIPKEHTuiNFIUXYrtGTJmg66YiF1Q7jWtgBrvzFjuryMiK7HSebEs7IjSiIg7MSrH7kCbOHHCuGDisdTIk47YUqzIsGM4MRFZgRpSbPLwhCzLaOriUixR2lD32Bm0FCs6dmZMxArqUmx7rGMnok7YsSMiK7DKebF9I0EMRI+crDYxCoqFHVGC1KXY4QAiEf2DMM3MsBNEYdfSO4KRQBgAw4mJyFrEebFtfT6EDXhtnog4caLU64bHZTftOljYESWoIFrYRWSg36fvPjtfMIzGTmX504yoE6Ewx6V2Ko92Kl272FIsw4mJyHxlXjfsNgmhiIzOuGgmo1lhfx3Awo4oYS6HDV63A4D+k7FHOgYRkYGCbCdKveZGisTvswtHZHWDMjt2RGQFDrsN5dHXSTMHKFjYEaWhQoOy7OL315mVXi7E77NrH/AhFJHhsEnqCykRkdniz4w1S5MFMuwAFnZESYll2em7FHugzbwTJ8aKz7IT++sq8rPgsPPlg4isQZ2MNXGAQg0nNnk1g6/MREkoylYiT/SejN3X2g8AqDdxcEKYVxZbihUTsYw6ISIrEa9JjV1DU9xSP1yKJUpDasdO56XYPSeUwu70qjxdHycRomN3tGNQfeGaVcDBCSKyjvpo3ufBk4NT3FIfoXBE3d83p5iFHVHaiJ0+oV9h197vQ+egHzYJWFRhfmE3uzAbLrsN/lAEOxq7AXBwgoisReR9Hjw5AFk2PvKktU/Zf+yy21DuzTL88eOxsCNKghHnxYpu3dzSXFOzkAS7TUJdibIc+06DUthxKZaIrGReaS5sEtA7HETHgPGRJ2J/3ewi88/QZmFHlIQiA6Zi95zoA2CNZVhB7LMLhCIAgNk8dYKILCTLaUdt9A2oCHc3klX21wEs7IiSUpitf8dub3RwYnGlhQq70tHn1TKcmIisRqQIiHO2jcTCjihNxTp2+sWdxAYn8nV7jGTFF3aSpMSdEBFZSfw+O6OpGXYWeNPLwo4oCUU5StyJXh27fl8Qx7qUFwhLLcXGFXYVeVlwOfjSQUTWIs7VPmDCZGyzRcKJARZ2REkRS7F9I0GEwhHN739ftFtXlZ+lDmpYwdzosWIAMIv764jIgkTH7tDJAUQixk7GNkczPrkUS5Rm8j1OiBO+eke0X44Vy7CLLbQMCwA5bgcqo8uvjDohIiuqLVaimYYDYbQYeGbsgC+oruJUF5n/+sjCjigJDrsN+R79Tp+wUjDxWGI5llEnRGRFDrsN88qU1ykjByiau5UisijHBW+W07DHnQgLO6IkFek4GWvFqBPhE0sq4HHaccmCUrMvhYhoXAujJ1AYGXnSZKH9dQDgMPsCiNJNYY4L6BzSPMvOHwrjcLuy6ff0WdZaigWA25bV4Nbz58BucvgmEdFExPnaRk7GNlso6gRgx44oabEsO2332B1sG0QoIqMg24kqi8aJsKgjIiszI8suFnVijW0qLOyIkiQiT7Tu2MUvw0oSCygiomSJydijHUMI6pBcMB4rhRMDLOyIkqbXebFWPHGCiCidzCrwIMdlRyAcwbGuIUMes7mHhR1RWhPDE1pPxVrxxAkionRis0lYoC7H6h9UHInIOB6dirXK8AQLO6IkqR07DZdiwxEZ+1qtG3VCRJQu1H12BgxQnBzwIRCOwGGT1KxPs7GwI0qSHh27xq4hDAfCyHLaMDfu+C4iIkqOOhlrwABFU/QIyFmFHjjs1iiprHEVRGlEj46dWIY9rSKPk6dERCkQHTsjIk9iE7HWWIYFWNgRJa0oR3TstIs7sXIwMRFROqmvUFY9GruG4AuGdX2sZouFEwMs7IiSJpZiB/0h+EPavGjs5eAEEZEmSnPdKMx2IiJDDX3XS3OPMjhhlYlYgIUdUdK8WQ51ubR3OPWunSzLlj4jlogonUiSpObZ6b0ca7UMO4CFHVHSbDYJhdlKSLEWWXZt/T50DwVgt0lYGN30S0RE0ydeS/WejGVhR5QhCjWcjN3TonTr5pfmIstpT/n+iIhmOrVjp+Nk7EggjI4BPwAWdkRpT8vJWPXECS7DEhFpQnTsDp7Ub4+dOHEiL8uB/OgqjhWwsCOaBi2z7DgRS0SkrfoypbBr6R3BgE+7BIN4IsPOShOxAAs7ommJnReb+guGGJxgx46ISBv52U5U5CknQejVtbPi/jpAh8KutrYWkiSd8nH33XcDUCYA169fj6qqKng8HqxcuRJ79uzR+jKIdFWUo7Tde1Jciu0bDuJ4dFz+9EpGnRARaUU9gUKnAQqxFJvxhd2OHTvQ2tqqfmzatAkA8JnPfAYA8NBDD+Hhhx/GY489hh07dqCiogJXXnklBgb0T4gm0ooYnkh1KnZPq7IMO7vQY6k9GkRE6W5huRJUfECnAQorhhMDOhR2paWlqKioUD9eeOEFzJs3DytWrIAsy3jkkUdw//3348Ybb8SSJUvw1FNPYXh4GM8++6zWl0KkG/X0iRQ7dnuZX0dEpAu9s+xmzFJsvEAggGeeeQZ33HEHJElCQ0MD2trasGrVKvU2brcbK1aswLZt2/S8FCJNxfbYpdix44kTRES6WKjjUqwsy5Yt7Bx63vkf/vAH9Pb2Yu3atQCAtrY2AEB5efmo25WXl+PYsWMT3o/f74ff71f/3N/fr/3FEiVBq6lYTsQSEeljflkuJAnoHAygc9CPkly3ZvfdMeiHLxiBJAFVBR7N7lcLunbsfv7zn+Pqq69GVVXVqM9LkjTqz7Isn/K5eBs2bEB+fr76UV1drcv1EiWqSIMcO18wjCMdQwDYsSMi0lq2y6F207Tu2on9dVX5Hrgc1goY0e1qjh07hldffRVf+MIX1M9VVFQAiHXuhPb29lO6ePHuu+8+9PX1qR/Nzc36XDRRgsRSrC8YwUggPK372N82gHBERnGOC+V52r2TJCIihV4nUDSpgxPW6tYBOhZ2TzzxBMrKynDttdeqn6urq0NFRYU6KQso+/C2bNmC5cuXT3hfbrcbeXl5oz6IzJTjssNlV/75TLdrtzcuv26yjjUREU3PwnJxZqy2WXbN3UpMldX21wE6FXaRSARPPPEE1qxZA4cjto1PkiSsW7cODz74IJ577jns3r0ba9euRXZ2Nm699VY9LoVIF5IkoVBk2U1zn53YX8dgYiIifeiVZWfVwQlAp+GJV199FU1NTbjjjjtO+drXv/51jIyM4K677kJPTw8uuOACvPLKK/B6vXpcCpFuCrNdONnvn/ZkLCdiiYj0tTBuKXaq/fzJaLJohh2gU2G3atUqyLI87tckScL69euxfv16PR6ayDCpZNmFIzL2tzHDjohIT3UlOXDYJAz4Q2jt82k2wdps4Y6dtUY5iNJIKll2RzsG4QtGkO2yo644R+tLIyIiAC6HDXNLldfYAxotx/qCYbT1+wBYs2PHwo5omlLJshPLsIsq82CzcXCCiEgvWk/GtvSOQJaBbJcdxdE3+FbCwo5omgpTyLJjMDERkTFik7HaFHbxy7BWTDRgYUc0TUXZYio2mPT37uEZsUREhtB6MrbZwoMTAAs7ommb7h47WZY5EUtEZBDRsTt0chDhyPiDncmwctQJwMKOaNqmOxV7os+HvpEgHDYJC8pz9bg0IiKKqi7KRpbTBn8oohZlqWBhR5ShCrOn17Hb06Lsr5tflgu3w675dRERUYzdJmFBWXSfnQYDFE0WPnUCYGFHNG3xHbuJchvHw2VYIiJjqZOxKe6zk2U5bo+d9c6JBVjYEU2b6NgFwzIG/aGEv4+DE0RExlpYoWx7SXUytmc4qL7ezy5kx44oo3hcdnicylJqMpOxexl1QkRkKK2y7ES3rjzPjSynNbfSsLAjSkFRkll2PUMBnOhTEssXs7AjIjLEwmjkSUPnEPyh8LTvx+qDEwALO6KUFOaILLvECjuxDFtTnA1vllO36yIiopiKvCx4sxwIRWQ0dA5N+36aLJ5hB7CwI0pJspOxPHGCiMh4kiTFTqBIYTm2mR07osyWbJYdJ2KJiMyhxQkUasfOooMTAAs7opRMt2PH/XVERMaKdewGp30f6h67YhZ2RBkpmY7dcCCEo9G9HVyKJSIyVqpZdsFwBCd6rR1ODLCwI0pJMufF7m8bgCwDJblulHmz9L40IiKKUx89wrGpexjDgcSzR4XWXh8iMuB22FCa69b68jTDwo4oBUXRpdhEcuwYTExEZJ7iXDdKogXZoZPJL8fGT8TabJKm16YlFnZEKRBxJ4nk2DGYmIjIXKmcQJEOGXYACzuilKh77BJYiuVELBGRuVI5gYKFHdEMoC7FDgcQicgT3i4YjmB/9IWEHTsiInOok7HT6NiJDLvZhR5Nr0lrLOyIUlAQLewiMtDvm3if3ZGOQQRCEeS6HZZ/t0dElKlSybJjx45oBnA5bPC6HQAmn4zd06Iswy6uzLP0plsiokwmlmJP9vvRm2CwvNDcY/0MO4CFHVHKChPIshP76xhMTERknly3Q11KPZjEZGzfSBC9w8qqjJVPnQBY2BGlLJZlN/FSLM+IJSKyhunssxP760pyXciJrtJYFQs7ohQVZSuRJxNNxsqyjL2tnIglIrICdZ9dEpOxzXEZdlbHwo4oRWrHboKl2OM9IxjwheC0S5hflmvkpRER0RjT6dily+AEwMKOKGWx0yfGL+zEMmx9uRcuB//JERGZKf7MWFmeOKYqnnrqhMX31wEs7IhSNtV5sTxKjIjIOuaW5sBuk9A7HETHgD+h72HHjmgGKZpiKpYnThARWUeW047aaGRJosuxx3tGAHCPHdGMUJg9VceOE7FERFayMDpAcSCBAYpwRMbxNMmwA1jYEaUs1rE7Ne6kc9CPk/1+SBKwqJKFHRGRFcTvs5tKW78PwbAMp11CRV6W3peWMhZ2RCkqylHiTsbr2Ill2LriHMtnHxERzRSxydipQ4qbusQZsdmwp8HJQSzsiFIklmL7RoIIhSOjviaWYXniBBGRdYgsu0MnBxCJTD4ZKzLsxIkVVsfCjihF+R4npOibuN6R0cuxHJwgIrKemqJsuBw2DAfCaOkdmfS26TQRC7CwI0qZw25Dvmf80yf2MeqEiMhyHHYb5pcqgfFTDVA097CwI5pxisaZjB3yh9DQNQSAS7FERFajTsZOMUDBjh3RDFQ4TpbdvtZ+yDJQnudGSa7brEsjIqJxJDoZm07nxAIs7Ig0Ecuyi+2x4/46IiLrWlgx9VLskD+EzkHlDXs6ZNgBLOyINCEiT+I7dgwmJiKyLtGxO9oxhOCYRANB7K8ryHYiL8tp2LWlgoUdkQbGOy+WZ8QSEVnXrAIPclx2BMIRHIvuhx5LZNhVF6ZHtw5gYUekCTE8IaZiA6GIum+DS7FERNYjSZKaZ7d/guXYdBucAFjYEWlC7dhFl2IPtQ8gGJaRl+VIm1BLIqKZRpxAcXCCwu54j5Jxly6DE4BOhV1LSwv++q//GsXFxcjOzsbHPvYxvPfee+rX165dC0mSRn0sW7ZMj0shMsTYjp1Yhl1clQdJsv4RNEREM1F9+eSRJ+nYsdP88Mqenh5cdNFFuPTSS/Hyyy+jrKwMR44cQUFBwajbXXXVVXjiiSfUP7tcLq0vhcgwYzt2ezkRS0RkeSLL7uAEZ8aysAPwgx/8ANXV1aOKttra2lNu53a7UVFRofXDE5miSOTYReNO9nJwgojI8kTHrrFrCL5gGFlOu/q1SERWM+zSqbDTfCn2j3/8I5YuXYrPfOYzKCsrw9lnn42f/exnp9xu8+bNKCsrQ319Pe688060t7dPeJ9+vx/9/f2jPoisRCzFDvpD8AXD2NsaW4olIiJrKsl1oSjHBVkGDreP7tp1DPrhD0Vgk4DKgiyTrjB5mhd2R48exeOPP44FCxZg48aN+NKXvoS///u/xy9/+Uv1NldffTV+9atf4fXXX8ePf/xj7NixA5dddhn8fv+497lhwwbk5+erH9XV1VpfNlFKvFkO2G3KXroPm3sx6A/B5bBhXvQsQiIish5JklBfPn5QsViGrSrwwGlPn1lTzZdiI5EIli5digcffBAAcPbZZ2PPnj14/PHHcfvttwMAbrrpJvX2S5YswdKlS1FTU4MXX3wRN9544yn3ed999+GrX/2q+uf+/n4Wd2QpNpuEwmwnOgcD2Hq4EwBwWoU3rV4MiIhmooXlXrx9tPuUo8VEhl06LcMCOnTsKisrsXjx4lGfW7RoEZqamib9npqaGhw6dGjcr7vdbuTl5Y36ILIacazYW4eUwo7764iIrE9k2Y2djBWnTsz4wu6iiy7CgQMHRn3u4MGDqKmpmfB7urq60NzcjMrKSq0vh8gwYjL2o+O9AIDFnIglIrK8ibLsxFJsOmXYAToUdl/5ylfw9ttv48EHH8Thw4fx7LPP4r/+679w9913AwAGBwdx7733Yvv27WhsbMTmzZuxevVqlJSU4IYbbtD6cogMIwYoIrLyZ3bsiIisb0G0sDvR50O/L6h+Ph0nYgEdCrvzzjsPzz33HH79619jyZIleOCBB/DII4/gc5/7HADAbrdj165duP7661FfX481a9agvr4e27dvh9fr1fpyiAwjOnYAYJOARRUs7IiIrC7f40RlvjL1eihuOTYdM+wAHYYnAOC6667DddddN+7XPB4PNm7cqMfDEpmqKMep/v+5pbnwuOyT3JqIiKyivtyL1j4fDrQN4tyaIviCYZzsV5I6ZvxSLNFMJYYnAC7DEhGlk9gJFErH7nh0cCLX7UBhtnPC77MiFnZEGinKYWFHRJSO1DNjowMUzd0jAJRuXbqd983Cjkgj8XvsFldyIpaIKF2ok7HRjl1sf53HtGuaLhZ2RBop4lIsEVFaml+WC0kCuoYC6Bz0p+3gBMDCjkgzdaU58GY5cNbs/FHdOyIisjaPy46aaBF3sG0grQs7XaZiiWaivCwntn7jMmQ5+X6JiCjd1Jd70dg1jAMnB9QMu3SbiAXYsSPSVL7HCbeDMSdEROlGTMYeiOvYsbAjIiIiSkNiMnb70S4MB8KQJGBWAYcniIiIiNKO6Ngd61K6dRV5Wchypt8KDAs7IiIimvFqi3PgtMcy69JxGRZgYUdEREQEl8OGuSW56p/TcSIWYGFHREREBACojy7HAizsiIiIiNLawvJYx646DU+dAFjYEREREQGITcYC7NgRERERpbWFcUux6To8wZMniIiIiABUF2bjikXlsNuA0ly32ZczLSzsiIiIiADYbBL+e81Ssy8jJVyKJSIiIsoQLOyIiIiIMgQLOyIiIqIMwcKOiIiIKEOwsCMiIiLKECzsiIiIiDIECzsiIiKiDMHCjoiIiChDsLAjIiIiyhAs7IiIiIgyBAs7IiIiogzBwo6IiIgoQ7CwIyIiIsoQLOyIiIiIMgQLOyIiIqIMwcKOiIiIKEM4zL6A6ZBlGQDQ399v8pUQERER6UvUO6L+mUxaFnZdXV0AgOrqapOvhIiIiMgYAwMDyM/Pn/Q2aVnYFRUVAQCampqm/A8kbfT396O6uhrNzc3Iy8sz+3IyHn/exuPP3Fj8eRuPP3NjafnzlmUZAwMDqKqqmvK2aVnY2WzK1sD8/Hw+OQ2Wl5fHn7mB+PM2Hn/mxuLP23j8mRtLq593oo0sDk8QERERZQgWdkREREQZIi0LO7fbje985ztwu91mX8qMwZ+5sfjzNh5/5sbiz9t4/Jkby6yftyQnMjtLRERERJaXlh07IiIiIjoVCzsiIiKiDMHCjoiIiChDsLAjIiIiyhBpWdj9x3/8B+rq6pCVlYVzzz0Xb731ltmXlJHWr18PSZJGfVRUVJh9WRnlzTffxOrVq1FVVQVJkvCHP/xh1NdlWcb69etRVVUFj8eDlStXYs+ePeZcbIaY6me+du3aU573y5YtM+diM8CGDRtw3nnnwev1oqysDJ/85Cdx4MCBUbfh81w7ify8+RzX1uOPP44zzzxTDSK+8MIL8fLLL6tfN/r5nXaF3W9/+1usW7cO999/Pz744ANccskluPrqq9HU1GT2pWWk008/Ha2trerHrl27zL6kjDI0NISzzjoLjz322Lhff+ihh/Dwww/jsccew44dO1BRUYErr7wSAwMDBl9p5pjqZw4AV1111ajn/UsvvWTgFWaWLVu24O6778bbb7+NTZs2IRQKYdWqVRgaGlJvw+e5dhL5eQN8jmtp9uzZ+P73v4+dO3di586duOyyy3D99derxZvhz285zZx//vnyl770pVGfO+200+RvfvObJl1R5vrOd74jn3XWWWZfxowBQH7uuefUP0ciEbmiokL+/ve/r37O5/PJ+fn58k9/+lMTrjDzjP2Zy7Isr1mzRr7++utNuZ6ZoL29XQYgb9myRZZlPs/1NvbnLct8jhuhsLBQ/u///m9Tnt9p1bELBAJ47733sGrVqlGfX7VqFbZt22bSVWW2Q4cOoaqqCnV1dbj55ptx9OhRsy9pxmhoaEBbW9uo57vb7caKFSv4fNfZ5s2bUVZWhvr6etx5551ob283+5IyRl9fHwCgqKgIAJ/nehv78xb4HNdHOBzGb37zGwwNDeHCCy805fmdVoVdZ2cnwuEwysvLR32+vLwcbW1tJl1V5rrgggvwy1/+Ehs3bsTPfvYztLW1Yfny5ejq6jL70mYE8Zzm891YV199NX71q1/h9ddfx49//GPs2LEDl112Gfx+v9mXlvZkWcZXv/pVXHzxxViyZAkAPs/1NN7PG+BzXA+7du1Cbm4u3G43vvSlL+G5557D4sWLTXl+O3S5V51JkjTqz7Isn/I5St3VV1+t/v8zzjgDF154IebNm4ennnoKX/3qV028spmFz3dj3XTTTer/X7JkCZYuXYqamhq8+OKLuPHGG028svT3d3/3d/joo4+wdevWU77G57n2Jvp58zmuvYULF+Ivf/kLent78bvf/Q5r1qzBli1b1K8b+fxOq45dSUkJ7Hb7KVVue3v7KdUwaS8nJwdnnHEGDh06ZPalzAhiApnPd3NVVlaipqaGz/sUffnLX8Yf//hHvPHGG5g9e7b6eT7P9THRz3s8fI6nzuVyYf78+Vi6dCk2bNiAs846C//2b/9myvM7rQo7l8uFc889F5s2bRr1+U2bNmH58uUmXdXM4ff7sW/fPlRWVpp9KTNCXV0dKioqRj3fA4EAtmzZwue7gbq6utDc3Mzn/TTJsoy/+7u/w+9//3u8/vrrqKurG/V1Ps+1NdXPezx8jmtPlmX4/X5znt+6jGTo6De/+Y3sdDrln//85/LevXvldevWyTk5OXJjY6PZl5Zx7rnnHnnz5s3y0aNH5bffflu+7rrrZK/Xy5+1hgYGBuQPPvhA/uCDD2QA8sMPPyx/8MEH8rFjx2RZluXvf//7cn5+vvz73/9e3rVrl3zLLbfIlZWVcn9/v8lXnr4m+5kPDAzI99xzj7xt2za5oaFBfuONN+QLL7xQnjVrFn/m0/S3f/u3cn5+vrx582a5tbVV/RgeHlZvw+e5dqb6efM5rr377rtPfvPNN+WGhgb5o48+kv/xH/9Rttls8iuvvCLLsvHP77Qr7GRZln/yk5/INTU1ssvlks8555xRY9yknZtuukmurKyUnU6nXFVVJd94443ynj17zL6sjPLGG2/IAE75WLNmjSzLShTEd77zHbmiokJ2u93yxz/+cXnXrl3mXnSam+xnPjw8LK9atUouLS2VnU6nPGfOHHnNmjVyU1OT2Zedtsb7WQOQn3jiCfU2fJ5rZ6qfN5/j2rvjjjvUmqS0tFS+/PLL1aJOlo1/fkuyLMv69AKJiIiIyEhptceOiIiIiCbGwo6IiIgoQ7CwIyIiIsoQLOyIiIiIMgQLOyIiIqIMwcKOiIiIKEOwsCMiIiLKECzsiIiIiDIECzsiIiKiDMHCjoiIiChDsLAjIiIiyhAs7IiIiIgyxP8PWfCmUd7WR60AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfms = [ToFloat(), ToFloat()]\n",
    "batch_tfms = [TSStandardize(by_sample=True)]\n",
    "dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)\n",
    "dls.dataset[0][0].show(), ToTSTensor()(dls.dataset[0][1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize loss function\n",
      "n_epoch: 3\n",
      "cb: LRFinder\n",
      "--> Fit\n",
      "--> Create opt\n",
      "---> opt_func \n",
      "self.model: DCAE_torch(\n",
      "  (downsample): Sequential(\n",
      "    (0): SameConv1d(\n",
      "      (conv1d_same): Conv1d(1, 64, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(32, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (5): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (latent_in): Linear(in_features=32, out_features=60, bias=True)\n",
      "    (latent_out): Linear(in_features=60, out_features=32, bias=True)\n",
      "    (reshape): Reshape(bs, 16, 2)\n",
      "  )\n",
      "  (upsample): Sequential(\n",
      "    (0): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): Upsample(scale_factor=4.0, mode=nearest)\n",
      "    (2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (4): SameConv1d(\n",
      "      (conv1d_same): Conv1d(32, 64, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (6): SameConv1d(\n",
      "      (conv1d_same): Conv1d(64, 1, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "self.splitter(self.model): [Parameter containing:\n",
      "tensor([[[-0.0930, -0.1716,  0.1489,  0.0574,  0.2077, -0.3114,  0.1053,\n",
      "          -0.1996,  0.2002,  0.3150]],\n",
      "\n",
      "        [[ 0.2322, -0.1150,  0.1477, -0.1084, -0.0526,  0.0080, -0.2987,\n",
      "          -0.0510, -0.0853, -0.2442]],\n",
      "\n",
      "        [[-0.0736,  0.1290, -0.0781, -0.2840, -0.1467,  0.2669, -0.0898,\n",
      "           0.0452,  0.1240,  0.2615]],\n",
      "\n",
      "        [[-0.1017, -0.0785,  0.1168,  0.0628,  0.0567, -0.1924,  0.0413,\n",
      "           0.0343, -0.2843,  0.0725]],\n",
      "\n",
      "        [[-0.0012, -0.0636,  0.1301, -0.2079, -0.0908, -0.0504, -0.2468,\n",
      "           0.1042,  0.3114,  0.0398]],\n",
      "\n",
      "        [[ 0.2501,  0.0442, -0.0280,  0.2275, -0.1733, -0.2916,  0.0274,\n",
      "           0.1816, -0.2260,  0.0552]],\n",
      "\n",
      "        [[ 0.1419,  0.0802, -0.0487,  0.0039,  0.1968,  0.3085, -0.2017,\n",
      "          -0.1304,  0.2417,  0.1926]],\n",
      "\n",
      "        [[-0.1772,  0.0862,  0.2347, -0.2710, -0.1441,  0.1429, -0.0482,\n",
      "          -0.3149,  0.1533, -0.1493]],\n",
      "\n",
      "        [[ 0.0811, -0.1643,  0.0496,  0.1719, -0.1281,  0.3078, -0.2871,\n",
      "          -0.0691, -0.1381, -0.2475]],\n",
      "\n",
      "        [[ 0.0073,  0.1232,  0.0175,  0.1896, -0.0163, -0.1384,  0.1260,\n",
      "           0.2085, -0.1919, -0.0916]],\n",
      "\n",
      "        [[ 0.0132,  0.1973,  0.2441, -0.1545,  0.3133, -0.0864, -0.1215,\n",
      "           0.0076,  0.3025,  0.0700]],\n",
      "\n",
      "        [[-0.2989, -0.2862, -0.1084, -0.1349,  0.0192, -0.1936,  0.0201,\n",
      "          -0.1415, -0.1626,  0.0127]],\n",
      "\n",
      "        [[ 0.1312, -0.2161, -0.1568,  0.2679, -0.0412, -0.2621, -0.2114,\n",
      "           0.3005,  0.3078, -0.2071]],\n",
      "\n",
      "        [[-0.2736, -0.0564, -0.1939, -0.0925, -0.0878,  0.2785,  0.1922,\n",
      "           0.1390,  0.0095, -0.0482]],\n",
      "\n",
      "        [[ 0.0235,  0.2649, -0.0728,  0.0633,  0.1701,  0.2597,  0.0384,\n",
      "           0.1500, -0.0322,  0.1009]],\n",
      "\n",
      "        [[-0.2302, -0.2686, -0.1393, -0.1132, -0.1200, -0.1594, -0.0507,\n",
      "          -0.0988,  0.3003, -0.1116]],\n",
      "\n",
      "        [[ 0.2244,  0.1239, -0.2763,  0.2274, -0.0490,  0.1533,  0.1253,\n",
      "          -0.1829,  0.2352,  0.2513]],\n",
      "\n",
      "        [[ 0.0425,  0.1210,  0.2655,  0.2336, -0.0036, -0.1895,  0.1176,\n",
      "          -0.1536,  0.2828,  0.0080]],\n",
      "\n",
      "        [[-0.2519, -0.2509, -0.0748,  0.1711, -0.0886,  0.1676,  0.2437,\n",
      "          -0.2912, -0.1026, -0.2689]],\n",
      "\n",
      "        [[ 0.0188,  0.1859,  0.2050, -0.0693, -0.2496,  0.1163,  0.1836,\n",
      "          -0.2550,  0.1377,  0.1088]],\n",
      "\n",
      "        [[ 0.1686,  0.0967,  0.1739,  0.2840,  0.0109, -0.1985,  0.2785,\n",
      "           0.0117, -0.1750,  0.1841]],\n",
      "\n",
      "        [[ 0.2597, -0.0904, -0.1121,  0.0612,  0.1777, -0.2522,  0.2884,\n",
      "          -0.1747,  0.2661, -0.2457]],\n",
      "\n",
      "        [[ 0.0452,  0.2892,  0.2336,  0.1930,  0.1028, -0.0910,  0.1080,\n",
      "          -0.1242,  0.2773,  0.2221]],\n",
      "\n",
      "        [[-0.2184, -0.2346,  0.2206, -0.1256,  0.0326, -0.3032,  0.2731,\n",
      "          -0.0277,  0.2360,  0.1068]],\n",
      "\n",
      "        [[ 0.0799,  0.0537,  0.0172, -0.0967,  0.1740,  0.1638, -0.1986,\n",
      "           0.1697,  0.2307, -0.3071]],\n",
      "\n",
      "        [[-0.2085, -0.3123,  0.0539, -0.0864,  0.1823,  0.2926, -0.2033,\n",
      "           0.1354, -0.1054,  0.2071]],\n",
      "\n",
      "        [[ 0.0573, -0.2217, -0.0240, -0.2019, -0.0983, -0.3055,  0.0758,\n",
      "          -0.2093,  0.1857,  0.0401]],\n",
      "\n",
      "        [[-0.1764,  0.0019, -0.0644, -0.0054,  0.3005,  0.1854, -0.1493,\n",
      "           0.0272,  0.1359, -0.2682]],\n",
      "\n",
      "        [[-0.1026,  0.0361, -0.2319, -0.1768, -0.2693,  0.0391, -0.0513,\n",
      "           0.2367, -0.2374,  0.0645]],\n",
      "\n",
      "        [[ 0.2171,  0.2697,  0.2347, -0.1632, -0.2059, -0.0454, -0.0014,\n",
      "           0.2269,  0.1073, -0.3088]],\n",
      "\n",
      "        [[-0.2088, -0.0969,  0.1486,  0.2762,  0.0121,  0.1647, -0.0898,\n",
      "          -0.0251,  0.0118,  0.2988]],\n",
      "\n",
      "        [[ 0.1599,  0.2969,  0.0295,  0.1362, -0.0503,  0.1484, -0.1463,\n",
      "          -0.0435,  0.0575, -0.1712]],\n",
      "\n",
      "        [[-0.2057,  0.1844,  0.0471,  0.2964, -0.1073, -0.0634, -0.0353,\n",
      "           0.2179,  0.2406,  0.0419]],\n",
      "\n",
      "        [[ 0.0283, -0.2343,  0.1352, -0.2082, -0.1548, -0.2580, -0.1782,\n",
      "          -0.1449, -0.2621, -0.1117]],\n",
      "\n",
      "        [[ 0.2839,  0.2412, -0.2857,  0.0989, -0.1748,  0.0151, -0.2058,\n",
      "           0.1396,  0.0059, -0.0210]],\n",
      "\n",
      "        [[ 0.3042,  0.2898,  0.0426, -0.1054,  0.3076, -0.0673,  0.3072,\n",
      "          -0.0823, -0.1700,  0.2335]],\n",
      "\n",
      "        [[-0.2344, -0.2144,  0.1335,  0.1921, -0.1859, -0.2708, -0.3028,\n",
      "           0.2163, -0.2276, -0.2478]],\n",
      "\n",
      "        [[ 0.1457,  0.1984,  0.1782, -0.0858,  0.1806, -0.0907, -0.3056,\n",
      "           0.2672,  0.0693, -0.1639]],\n",
      "\n",
      "        [[-0.2105, -0.2151,  0.0787, -0.2574,  0.2316, -0.2689,  0.1737,\n",
      "          -0.0224,  0.2540, -0.1030]],\n",
      "\n",
      "        [[ 0.0137, -0.2541, -0.2526, -0.1093,  0.0890,  0.2439,  0.2025,\n",
      "          -0.0671, -0.0152,  0.2827]],\n",
      "\n",
      "        [[ 0.1107, -0.1071,  0.1567,  0.2371, -0.0753, -0.0294, -0.0449,\n",
      "           0.2502,  0.1764, -0.1549]],\n",
      "\n",
      "        [[ 0.2288, -0.2260, -0.0801, -0.0923,  0.1345, -0.2570, -0.1242,\n",
      "           0.0104, -0.2863,  0.1106]],\n",
      "\n",
      "        [[ 0.1928, -0.0093, -0.2123,  0.1335, -0.2083, -0.2388,  0.2990,\n",
      "          -0.0316, -0.2092,  0.2349]],\n",
      "\n",
      "        [[ 0.0787,  0.1291, -0.1416,  0.1635, -0.3001, -0.0425, -0.0502,\n",
      "          -0.2650, -0.3055,  0.0810]],\n",
      "\n",
      "        [[-0.2691,  0.1287,  0.2158, -0.3037,  0.3119, -0.0860,  0.0928,\n",
      "           0.0518,  0.2693,  0.1012]],\n",
      "\n",
      "        [[ 0.0845,  0.1677, -0.0704,  0.0066, -0.2298, -0.0034,  0.1620,\n",
      "          -0.2342, -0.0024,  0.1253]],\n",
      "\n",
      "        [[-0.1434,  0.2066, -0.0549,  0.2122, -0.0570, -0.1333, -0.1317,\n",
      "           0.3093, -0.2149, -0.2914]],\n",
      "\n",
      "        [[-0.0701, -0.1341, -0.0494,  0.0189,  0.1167, -0.0205, -0.2731,\n",
      "          -0.2543,  0.1942,  0.2546]],\n",
      "\n",
      "        [[-0.1179,  0.0195, -0.0819, -0.2311,  0.0260,  0.0984,  0.2416,\n",
      "           0.0429, -0.1261, -0.1753]],\n",
      "\n",
      "        [[-0.2667, -0.1839, -0.1930, -0.0069, -0.1668,  0.2266,  0.0163,\n",
      "           0.0559,  0.0913, -0.2742]],\n",
      "\n",
      "        [[-0.3106, -0.1922, -0.0146,  0.1985,  0.2925, -0.3019, -0.1716,\n",
      "           0.0144, -0.2235,  0.0478]],\n",
      "\n",
      "        [[-0.0642, -0.2242, -0.2426, -0.0161,  0.0145, -0.1875,  0.1834,\n",
      "          -0.2036, -0.1629, -0.2575]],\n",
      "\n",
      "        [[ 0.1647, -0.0601,  0.2476,  0.2217, -0.0878, -0.2292,  0.2348,\n",
      "          -0.2301, -0.1110,  0.2596]],\n",
      "\n",
      "        [[ 0.1059, -0.0278,  0.0855,  0.1284,  0.0919,  0.2285,  0.2571,\n",
      "           0.0109, -0.2434,  0.0890]],\n",
      "\n",
      "        [[-0.2929,  0.0410,  0.1441,  0.2980,  0.2768,  0.2534,  0.0019,\n",
      "           0.1121,  0.0462, -0.2042]],\n",
      "\n",
      "        [[ 0.0072,  0.1666,  0.2834,  0.0664,  0.1649, -0.3112,  0.2248,\n",
      "          -0.2430, -0.1739, -0.1169]],\n",
      "\n",
      "        [[ 0.0992,  0.0818, -0.2998, -0.0083,  0.0266,  0.2211, -0.1899,\n",
      "           0.0143, -0.1783,  0.0640]],\n",
      "\n",
      "        [[ 0.1290,  0.2614, -0.2051,  0.0309,  0.1584,  0.2988, -0.0126,\n",
      "           0.0868,  0.2969,  0.3095]],\n",
      "\n",
      "        [[ 0.0730, -0.1910, -0.2535, -0.1700, -0.2999,  0.2247,  0.1273,\n",
      "          -0.0564,  0.3147,  0.2205]],\n",
      "\n",
      "        [[ 0.1178, -0.1579,  0.2261, -0.2302, -0.2108,  0.1509,  0.0580,\n",
      "          -0.1827, -0.1594,  0.0870]],\n",
      "\n",
      "        [[ 0.0080,  0.1938,  0.0281,  0.0641, -0.3039,  0.0863, -0.0799,\n",
      "          -0.3146, -0.0046,  0.2440]],\n",
      "\n",
      "        [[-0.2825,  0.1723,  0.0064, -0.1135,  0.0969, -0.2644, -0.0423,\n",
      "           0.2071,  0.1805,  0.0026]],\n",
      "\n",
      "        [[-0.0633, -0.0832,  0.0481, -0.0241,  0.0361,  0.2840,  0.0123,\n",
      "           0.2298,  0.1886, -0.0028]],\n",
      "\n",
      "        [[-0.2994,  0.2798, -0.2474, -0.3108,  0.2385,  0.2152,  0.2579,\n",
      "           0.1536,  0.1807, -0.2212]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 6.4778e-03, -2.0256e-02,  1.4676e-03, -1.5999e-03,  1.5367e-02,\n",
      "        -4.8345e-03,  3.3734e-04, -4.8271e-03,  4.7595e-04,  9.2185e-03,\n",
      "        -9.0061e-03,  4.0992e-03, -7.8069e-03, -4.0483e-03, -3.7509e-03,\n",
      "         2.7540e-03,  5.3588e-03,  4.3044e-03,  1.1115e-02,  3.4970e-04,\n",
      "        -2.3525e-02,  5.9020e-03, -6.3689e-04,  1.7809e-02,  1.5812e-02,\n",
      "        -5.2244e-03,  1.0921e-03,  9.8902e-03,  6.2064e-03, -9.0070e-03,\n",
      "         2.0802e-02, -1.0903e-02,  5.5950e-04, -7.2457e-03, -1.5263e-02,\n",
      "         9.4480e-04, -1.8154e-02, -1.2184e-03, -7.3712e-03,  1.4718e-02,\n",
      "         9.8367e-03, -5.5118e-04, -7.5655e-03, -6.6245e-03, -3.2709e-03,\n",
      "         1.4377e-03,  1.3866e-02, -1.8074e-03,  2.4245e-03, -1.8572e-03,\n",
      "         2.0887e-03, -2.7324e-02,  1.7119e-02, -2.9227e-03,  2.6570e-05,\n",
      "        -2.0623e-04,  1.4801e-02, -3.4891e-03,  9.9486e-03,  1.3322e-02,\n",
      "         2.4582e-02, -6.2911e-03,  1.0835e-02, -2.4117e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-5.0232e-02,  1.2646e-02, -4.8151e-02,  2.3546e-02, -3.6512e-02],\n",
      "         [-3.2064e-02,  3.1551e-02, -3.0031e-02,  2.4537e-02, -6.1196e-03],\n",
      "         [-5.5080e-02,  5.0841e-02,  1.0238e-02,  3.9576e-02,  2.3361e-02],\n",
      "         ...,\n",
      "         [-2.1877e-02, -4.2188e-02, -1.0357e-02,  2.2303e-02, -7.7867e-03],\n",
      "         [-4.5401e-02,  4.6589e-02, -9.8572e-03,  1.4722e-02, -5.3971e-02],\n",
      "         [ 5.0908e-02,  1.8723e-02, -1.1045e-02, -3.6627e-02, -3.0749e-03]],\n",
      "\n",
      "        [[ 5.2553e-02,  2.3173e-02,  2.1272e-02, -3.0393e-02,  2.7197e-02],\n",
      "         [-5.3937e-02,  2.9782e-02, -1.3070e-02,  1.5885e-02,  2.5224e-02],\n",
      "         [-3.1820e-02, -4.8941e-02, -7.5188e-03,  2.3096e-02, -1.8155e-04],\n",
      "         ...,\n",
      "         [ 1.8733e-02, -5.5445e-02,  4.8967e-02, -2.3524e-06,  1.5843e-02],\n",
      "         [ 8.4442e-03,  2.4046e-02, -2.8717e-02,  5.3695e-02, -7.4054e-03],\n",
      "         [-2.6767e-02, -4.4127e-02, -3.5357e-02, -3.5400e-02, -4.3833e-02]],\n",
      "\n",
      "        [[ 3.8178e-02,  4.6894e-02, -6.8627e-03,  3.5513e-02, -1.0814e-02],\n",
      "         [-2.1846e-02,  1.9751e-02,  4.0708e-03,  5.2411e-02, -3.4571e-02],\n",
      "         [-9.9717e-03, -1.2527e-02, -5.4862e-02, -3.6150e-02,  3.6884e-02],\n",
      "         ...,\n",
      "         [ 3.9119e-02,  2.4411e-02, -2.1658e-02, -1.8365e-02, -1.1501e-03],\n",
      "         [ 2.5827e-03, -5.1522e-02,  2.0366e-02,  9.8432e-03, -4.2195e-02],\n",
      "         [ 5.4704e-02,  3.6366e-02,  2.1237e-02,  9.8391e-03,  1.9568e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.4412e-03, -3.7465e-02, -2.0373e-02,  4.4546e-02, -5.4206e-02],\n",
      "         [-2.5331e-02, -1.8772e-02,  2.4309e-04, -3.1250e-02, -1.6986e-02],\n",
      "         [ 3.2985e-02,  7.3540e-03, -2.9531e-03, -2.9331e-02,  5.1339e-02],\n",
      "         ...,\n",
      "         [-1.2101e-02,  1.0421e-02,  5.0514e-02,  5.3516e-02,  1.0211e-02],\n",
      "         [ 1.9228e-02,  6.9470e-03, -2.5894e-02, -4.7285e-02, -5.2905e-02],\n",
      "         [-5.9828e-03,  4.2404e-02, -3.1764e-02, -4.7555e-02, -3.3362e-02]],\n",
      "\n",
      "        [[-2.9484e-02,  5.1761e-02,  4.6365e-02, -2.1687e-02,  3.0393e-02],\n",
      "         [-3.4066e-02,  5.0927e-03,  1.3165e-02, -4.8971e-02, -7.1763e-03],\n",
      "         [-4.2634e-02,  2.7263e-02, -2.9425e-02, -5.4449e-02, -3.0856e-02],\n",
      "         ...,\n",
      "         [-2.9719e-02, -5.1660e-02, -3.2381e-02,  2.9492e-02, -3.6336e-02],\n",
      "         [-5.1239e-02,  2.1552e-02,  3.0369e-02, -1.8063e-02,  1.3637e-02],\n",
      "         [ 5.4407e-02, -3.5069e-02, -3.2336e-03,  3.6654e-02,  3.9680e-02]],\n",
      "\n",
      "        [[ 6.1013e-04,  2.3141e-02,  4.8611e-02, -4.1561e-02, -3.3628e-02],\n",
      "         [ 3.6663e-03, -2.4109e-03, -5.8727e-03, -4.3847e-02, -4.3952e-02],\n",
      "         [ 2.8521e-02,  3.6516e-02, -1.4114e-03,  4.5765e-03, -5.4988e-02],\n",
      "         ...,\n",
      "         [ 8.8152e-03, -3.7679e-02,  9.4452e-03,  1.2736e-02, -3.5117e-02],\n",
      "         [ 3.3911e-02,  2.0034e-02,  7.6863e-03, -2.7035e-02,  4.5314e-02],\n",
      "         [-3.8897e-03,  1.8979e-02,  2.2638e-02,  2.0141e-02,  3.3650e-02]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0019, -0.0097, -0.0064,  0.0008, -0.0099,  0.0261,  0.0041,  0.0138,\n",
      "         0.0074, -0.0025, -0.0008, -0.0048, -0.0045,  0.0124, -0.0013, -0.0091,\n",
      "         0.0091,  0.0062, -0.0034,  0.0089, -0.0158, -0.0054,  0.0032,  0.0114,\n",
      "         0.0107,  0.0232, -0.0085, -0.0018, -0.0096,  0.0031,  0.0120, -0.0075],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0044,  0.0405, -0.0074, -0.0098,  0.0726],\n",
      "         [ 0.0331,  0.0770,  0.0472,  0.0097, -0.0639],\n",
      "         [ 0.0102, -0.0439, -0.0160,  0.0763,  0.0429],\n",
      "         ...,\n",
      "         [ 0.0582, -0.0408, -0.0764, -0.0308, -0.0552],\n",
      "         [ 0.0159, -0.0068,  0.0285, -0.0620,  0.0098],\n",
      "         [ 0.0256, -0.0360, -0.0692, -0.0648,  0.0538]],\n",
      "\n",
      "        [[ 0.0415,  0.0524, -0.0619, -0.0045, -0.0248],\n",
      "         [-0.0256,  0.0540, -0.0482, -0.0171, -0.0757],\n",
      "         [-0.0068,  0.0172,  0.0044, -0.0549, -0.0328],\n",
      "         ...,\n",
      "         [ 0.0246,  0.0268, -0.0257,  0.0040,  0.0428],\n",
      "         [ 0.0677, -0.0107,  0.0282,  0.0344,  0.0009],\n",
      "         [-0.0548, -0.0308,  0.0564,  0.0066, -0.0779]],\n",
      "\n",
      "        [[-0.0241, -0.0132,  0.0776,  0.0456, -0.0022],\n",
      "         [-0.0122,  0.0159,  0.0251,  0.0372,  0.0312],\n",
      "         [-0.0453, -0.0418, -0.0570,  0.0673,  0.0216],\n",
      "         ...,\n",
      "         [ 0.0546, -0.0173, -0.0151,  0.0615, -0.0157],\n",
      "         [-0.0513,  0.0137,  0.0101,  0.0533,  0.0131],\n",
      "         [ 0.0706, -0.0229,  0.0637, -0.0269,  0.0746]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0257, -0.0460,  0.0663,  0.0139, -0.0236],\n",
      "         [ 0.0690,  0.0281,  0.0571,  0.0067, -0.0011],\n",
      "         [-0.0761, -0.0348, -0.0746, -0.0620, -0.0009],\n",
      "         ...,\n",
      "         [-0.0495,  0.0357,  0.0460, -0.0004,  0.0058],\n",
      "         [ 0.0346, -0.0558,  0.0282, -0.0348, -0.0194],\n",
      "         [ 0.0378, -0.0657, -0.0709, -0.0477, -0.0640]],\n",
      "\n",
      "        [[-0.0036, -0.0325,  0.0403, -0.0014, -0.0066],\n",
      "         [-0.0622, -0.0790,  0.0136, -0.0637, -0.0354],\n",
      "         [-0.0454,  0.0321, -0.0230, -0.0629, -0.0457],\n",
      "         ...,\n",
      "         [ 0.0498,  0.0486, -0.0453, -0.0002, -0.0110],\n",
      "         [ 0.0035, -0.0638, -0.0259,  0.0730, -0.0627],\n",
      "         [ 0.0315, -0.0586, -0.0003, -0.0671, -0.0261]],\n",
      "\n",
      "        [[-0.0384,  0.0535, -0.0164,  0.0252, -0.0139],\n",
      "         [-0.0673,  0.0016,  0.0368,  0.0471, -0.0032],\n",
      "         [ 0.0373,  0.0732,  0.0181,  0.0395, -0.0769],\n",
      "         ...,\n",
      "         [-0.0359, -0.0219,  0.0057, -0.0073,  0.0134],\n",
      "         [ 0.0465, -0.0148, -0.0080,  0.0059, -0.0104],\n",
      "         [-0.0024,  0.0494, -0.0372,  0.0772,  0.0428]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0095,  0.0044, -0.0032,  0.0164,  0.0063, -0.0075,  0.0033,  0.0073,\n",
      "        -0.0088, -0.0045,  0.0132,  0.0089, -0.0120, -0.0162, -0.0146, -0.0068],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0136,  0.0731, -0.0387,  ..., -0.1578,  0.0406, -0.0532],\n",
      "        [-0.0268,  0.1126,  0.0278,  ...,  0.1299,  0.0468, -0.0800],\n",
      "        [ 0.0034, -0.0882, -0.0912,  ..., -0.0532,  0.1072, -0.1190],\n",
      "        ...,\n",
      "        [-0.0181, -0.1186,  0.1672,  ..., -0.0456,  0.1146, -0.0807],\n",
      "        [-0.0529, -0.0318, -0.1196,  ..., -0.0447, -0.1364,  0.1700],\n",
      "        [ 0.0533, -0.0133, -0.0365,  ...,  0.1308,  0.0885, -0.0518]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0737,  0.1248,  0.1098,  0.0670,  0.0179,  0.0067,  0.1221,  0.1358,\n",
      "        -0.0982,  0.1511,  0.0111, -0.1544, -0.0135, -0.1284,  0.0666, -0.0584,\n",
      "        -0.1737, -0.0663,  0.0682,  0.0299, -0.1202,  0.0612,  0.0207,  0.1083,\n",
      "         0.1598,  0.1587,  0.1577,  0.1524, -0.0828, -0.1278, -0.1041,  0.0032,\n",
      "         0.0665, -0.0665, -0.0370,  0.1061,  0.0896, -0.0091,  0.1012,  0.1141,\n",
      "         0.1573, -0.0388, -0.0875,  0.0817, -0.0760, -0.0707, -0.0971, -0.0356,\n",
      "        -0.1724,  0.0205, -0.1099,  0.0902, -0.0249, -0.0695, -0.1320, -0.1551,\n",
      "         0.0305,  0.0865, -0.1291,  0.0040], requires_grad=True), Parameter containing:\n",
      "tensor([[ 4.9307e-02,  1.0913e-01,  7.7332e-02,  ..., -5.3763e-02,\n",
      "         -2.3392e-02, -7.5340e-02],\n",
      "        [ 6.9719e-02,  8.8350e-02,  1.1500e-01,  ..., -7.6423e-02,\n",
      "          6.7819e-02, -5.7113e-02],\n",
      "        [-3.6272e-02,  1.1581e-01,  3.0163e-02,  ...,  8.6044e-02,\n",
      "          1.2588e-01,  6.7044e-03],\n",
      "        ...,\n",
      "        [-7.2323e-02, -3.5345e-02,  1.1645e-01,  ...,  6.6330e-06,\n",
      "          5.9968e-02, -6.2851e-02],\n",
      "        [ 1.2166e-01, -1.0173e-01, -9.6049e-02,  ..., -6.5660e-02,\n",
      "          1.1767e-01, -7.8363e-02],\n",
      "        [ 6.0702e-02, -5.5319e-02,  4.8264e-02,  ..., -1.6593e-02,\n",
      "         -5.7970e-02, -8.6406e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0332, -0.0673,  0.0476, -0.0446,  0.0581,  0.0983,  0.0186, -0.0714,\n",
      "        -0.0573, -0.0572,  0.0133, -0.1052,  0.0796,  0.0071, -0.0746,  0.0613,\n",
      "         0.0918, -0.0440,  0.1197,  0.0221, -0.1269, -0.0698,  0.0036, -0.0783,\n",
      "        -0.0762,  0.0124,  0.1032, -0.0705, -0.0916,  0.0153, -0.0369,  0.0516],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0554,  0.0680,  0.0816, -0.0171,  0.0135],\n",
      "         [ 0.0939, -0.0529, -0.0277,  0.0833, -0.0145],\n",
      "         [ 0.0267, -0.0311, -0.0092,  0.0556,  0.0499],\n",
      "         ...,\n",
      "         [ 0.0027, -0.0735, -0.0774,  0.0828,  0.0321],\n",
      "         [ 0.0922,  0.0248,  0.0739, -0.0185, -0.0996],\n",
      "         [ 0.0769,  0.0151, -0.0270,  0.1065,  0.0596]],\n",
      "\n",
      "        [[ 0.0313,  0.0495, -0.0643,  0.0907,  0.0509],\n",
      "         [-0.0113,  0.0365,  0.0681,  0.0651,  0.0605],\n",
      "         [-0.0634, -0.0320, -0.0554,  0.0125,  0.0310],\n",
      "         ...,\n",
      "         [-0.0784,  0.0043,  0.1103, -0.0957,  0.0874],\n",
      "         [-0.0551, -0.0181, -0.0402, -0.0128,  0.0455],\n",
      "         [ 0.0046, -0.0183,  0.0901,  0.0812,  0.0318]],\n",
      "\n",
      "        [[-0.0944,  0.0659,  0.0273,  0.0886, -0.0208],\n",
      "         [ 0.1106, -0.0194, -0.1114, -0.0147,  0.0510],\n",
      "         [ 0.1045, -0.0079, -0.0923,  0.0781,  0.0862],\n",
      "         ...,\n",
      "         [ 0.0173, -0.0317, -0.0932, -0.0122, -0.0456],\n",
      "         [ 0.0911,  0.1021, -0.0762, -0.0015, -0.0578],\n",
      "         [ 0.0362,  0.0124,  0.0735, -0.0107,  0.0653]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0704, -0.1115, -0.0503,  0.0829, -0.0279],\n",
      "         [-0.0528,  0.0175,  0.0041, -0.0434, -0.1113],\n",
      "         [-0.0962, -0.0437,  0.0986,  0.0689, -0.0838],\n",
      "         ...,\n",
      "         [ 0.0481, -0.0563, -0.0365, -0.0548, -0.0657],\n",
      "         [-0.0051, -0.0030, -0.1080, -0.0311, -0.0287],\n",
      "         [ 0.0016, -0.0385, -0.0315,  0.1083,  0.0869]],\n",
      "\n",
      "        [[-0.0539,  0.0831, -0.0316, -0.0655,  0.0387],\n",
      "         [-0.0574, -0.0210, -0.0204, -0.0196, -0.1085],\n",
      "         [-0.0345,  0.0452, -0.1008, -0.0678,  0.0729],\n",
      "         ...,\n",
      "         [-0.0043, -0.0987,  0.1051, -0.1081, -0.0689],\n",
      "         [-0.0130,  0.0583,  0.0584, -0.0720, -0.0696],\n",
      "         [-0.0838, -0.0217, -0.0206,  0.0306,  0.0341]],\n",
      "\n",
      "        [[ 0.0405,  0.0435,  0.0858,  0.0057,  0.0664],\n",
      "         [ 0.0335,  0.0241, -0.0152,  0.0423,  0.0646],\n",
      "         [ 0.0306, -0.1098, -0.0947,  0.0638, -0.0179],\n",
      "         ...,\n",
      "         [-0.0285, -0.0193,  0.0439, -0.0808, -0.0585],\n",
      "         [-0.0261, -0.0666,  0.0604, -0.0649,  0.0315],\n",
      "         [ 0.1026,  0.1031,  0.0114, -0.0707,  0.0425]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0125,  0.0071,  0.0044,  0.0302, -0.0053,  0.0043,  0.0029,  0.0046,\n",
      "        -0.0044,  0.0149,  0.0009,  0.0084, -0.0030, -0.0050, -0.0073, -0.0200],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0716, -0.0337, -0.0111,  0.0349,  0.0315],\n",
      "         [-0.0149,  0.0538, -0.0991, -0.0572, -0.0496],\n",
      "         [ 0.0279,  0.0519, -0.0273,  0.0368, -0.0100],\n",
      "         ...,\n",
      "         [ 0.0110, -0.0592, -0.0466, -0.0352, -0.0166],\n",
      "         [ 0.0813, -0.0149,  0.0801,  0.0578, -0.0054],\n",
      "         [ 0.0985,  0.0148,  0.0499,  0.0244,  0.0166]],\n",
      "\n",
      "        [[-0.0422,  0.0776, -0.0748,  0.0130, -0.0229],\n",
      "         [ 0.0478,  0.0208, -0.0197, -0.1101,  0.0621],\n",
      "         [-0.0820, -0.0231, -0.0468, -0.0944, -0.0744],\n",
      "         ...,\n",
      "         [-0.0858, -0.0533, -0.0038, -0.0566,  0.0046],\n",
      "         [ 0.0577, -0.0196,  0.1091, -0.0155, -0.0641],\n",
      "         [-0.0502, -0.0576, -0.0429,  0.0552, -0.0745]],\n",
      "\n",
      "        [[ 0.0604, -0.1074, -0.0854,  0.0652, -0.0433],\n",
      "         [ 0.0158, -0.0494, -0.0050,  0.0061, -0.0606],\n",
      "         [ 0.0398, -0.0186,  0.0399,  0.0861, -0.0196],\n",
      "         ...,\n",
      "         [ 0.0712, -0.0751, -0.0975, -0.0814,  0.0246],\n",
      "         [-0.0964,  0.0018, -0.0563, -0.0164,  0.0107],\n",
      "         [-0.0845,  0.0266, -0.0864,  0.0440,  0.0617]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0725,  0.1058,  0.0191, -0.0457, -0.0412],\n",
      "         [-0.0783,  0.0886,  0.0694,  0.0513, -0.0616],\n",
      "         [-0.1072, -0.0127,  0.0717, -0.0684, -0.0191],\n",
      "         ...,\n",
      "         [-0.0734,  0.0526,  0.0059,  0.0294, -0.0064],\n",
      "         [ 0.0644, -0.0183,  0.0345,  0.0697,  0.0082],\n",
      "         [ 0.0010,  0.0450,  0.0002,  0.0847,  0.0579]],\n",
      "\n",
      "        [[-0.0091, -0.0993,  0.0347,  0.0609,  0.0311],\n",
      "         [-0.0837, -0.0709, -0.0708, -0.0689, -0.0150],\n",
      "         [-0.0631,  0.0422,  0.0405,  0.0097, -0.0740],\n",
      "         ...,\n",
      "         [-0.0149, -0.0354,  0.0607, -0.0655, -0.0527],\n",
      "         [-0.0264,  0.0755, -0.0485, -0.0689, -0.0059],\n",
      "         [ 0.0663,  0.1030,  0.0154,  0.1030,  0.0578]],\n",
      "\n",
      "        [[-0.0055, -0.0349,  0.0457, -0.1055, -0.0057],\n",
      "         [-0.0869, -0.0462, -0.0183, -0.0830, -0.1098],\n",
      "         [ 0.0015,  0.0164, -0.0779,  0.0145,  0.0908],\n",
      "         ...,\n",
      "         [-0.0618, -0.0782, -0.0914,  0.0668, -0.0952],\n",
      "         [ 0.0645, -0.0666,  0.0414, -0.0646, -0.0386],\n",
      "         [ 0.0590, -0.0452,  0.0734,  0.1027, -0.0462]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0045, -0.0010,  0.0077,  0.0123,  0.0274,  0.0006, -0.0091,  0.0047,\n",
      "         0.0170, -0.0016, -0.0045,  0.0079,  0.0001,  0.0201, -0.0004, -0.0135,\n",
      "        -0.0015,  0.0045,  0.0103, -0.0020,  0.0155, -0.0007,  0.0100,  0.0015,\n",
      "         0.0070, -0.0064,  0.0055,  0.0008, -0.0052, -0.0040, -0.0109, -0.0002],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0280, -0.0269,  0.0162,  ...,  0.0102, -0.0470, -0.0227],\n",
      "         [ 0.0496, -0.0312, -0.0210,  ..., -0.0395,  0.0187, -0.0407],\n",
      "         [ 0.0251,  0.0502, -0.0511,  ...,  0.0287, -0.0068,  0.0013],\n",
      "         ...,\n",
      "         [ 0.0531, -0.0344, -0.0337,  ..., -0.0130,  0.0524, -0.0544],\n",
      "         [-0.0332,  0.0531,  0.0355,  ...,  0.0239, -0.0480, -0.0545],\n",
      "         [-0.0021,  0.0287, -0.0342,  ...,  0.0015,  0.0156, -0.0150]],\n",
      "\n",
      "        [[-0.0123,  0.0171,  0.0003,  ...,  0.0435,  0.0443, -0.0076],\n",
      "         [-0.0002, -0.0139, -0.0138,  ..., -0.0223, -0.0321,  0.0106],\n",
      "         [-0.0535,  0.0292,  0.0424,  ..., -0.0405,  0.0232, -0.0409],\n",
      "         ...,\n",
      "         [ 0.0225, -0.0489, -0.0500,  ..., -0.0535,  0.0508, -0.0046],\n",
      "         [ 0.0194, -0.0160,  0.0116,  ...,  0.0266,  0.0426,  0.0171],\n",
      "         [ 0.0094, -0.0369, -0.0030,  ..., -0.0071, -0.0292, -0.0059]],\n",
      "\n",
      "        [[-0.0043, -0.0213,  0.0184,  ..., -0.0313,  0.0542,  0.0060],\n",
      "         [-0.0256, -0.0325, -0.0479,  ..., -0.0264,  0.0038,  0.0357],\n",
      "         [ 0.0279,  0.0061,  0.0534,  ...,  0.0352, -0.0360, -0.0377],\n",
      "         ...,\n",
      "         [-0.0327, -0.0042,  0.0018,  ...,  0.0442,  0.0086, -0.0253],\n",
      "         [-0.0394,  0.0340, -0.0261,  ..., -0.0199, -0.0177,  0.0209],\n",
      "         [ 0.0103, -0.0117,  0.0238,  ...,  0.0194, -0.0532,  0.0052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0293, -0.0338, -0.0085,  ..., -0.0168, -0.0346, -0.0379],\n",
      "         [ 0.0490, -0.0539, -0.0352,  ...,  0.0085, -0.0124, -0.0030],\n",
      "         [-0.0315,  0.0330, -0.0134,  ...,  0.0284,  0.0135,  0.0096],\n",
      "         ...,\n",
      "         [ 0.0317, -0.0476, -0.0488,  ...,  0.0557, -0.0064, -0.0434],\n",
      "         [ 0.0379,  0.0285, -0.0062,  ...,  0.0120, -0.0272,  0.0336],\n",
      "         [ 0.0167, -0.0298,  0.0291,  ...,  0.0435,  0.0436, -0.0187]],\n",
      "\n",
      "        [[-0.0535, -0.0551,  0.0387,  ..., -0.0238, -0.0090,  0.0456],\n",
      "         [ 0.0047,  0.0120,  0.0534,  ..., -0.0213, -0.0082,  0.0460],\n",
      "         [-0.0094, -0.0245, -0.0403,  ..., -0.0216, -0.0039,  0.0177],\n",
      "         ...,\n",
      "         [ 0.0423,  0.0043,  0.0296,  ...,  0.0265, -0.0250,  0.0069],\n",
      "         [ 0.0079,  0.0252, -0.0140,  ...,  0.0307,  0.0540,  0.0381],\n",
      "         [ 0.0288,  0.0143, -0.0183,  ...,  0.0346, -0.0294,  0.0154]],\n",
      "\n",
      "        [[ 0.0274,  0.0044,  0.0390,  ...,  0.0429, -0.0383, -0.0524],\n",
      "         [-0.0362, -0.0335, -0.0030,  ...,  0.0494,  0.0218,  0.0500],\n",
      "         [ 0.0313,  0.0011,  0.0273,  ..., -0.0235,  0.0097, -0.0410],\n",
      "         ...,\n",
      "         [-0.0458,  0.0356, -0.0531,  ...,  0.0307, -0.0010, -0.0215],\n",
      "         [ 0.0496,  0.0058,  0.0294,  ...,  0.0476, -0.0480,  0.0501],\n",
      "         [-0.0361, -0.0010,  0.0147,  ..., -0.0369,  0.0056, -0.0249]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0037,  0.0179,  0.0038, -0.0083,  0.0116, -0.0162, -0.0136,  0.0157,\n",
      "        -0.0026, -0.0028, -0.0097, -0.0085, -0.0002, -0.0048, -0.0037,  0.0050,\n",
      "        -0.0146,  0.0043,  0.0047,  0.0080,  0.0152,  0.0091,  0.0060,  0.0065,\n",
      "         0.0229,  0.0078, -0.0072, -0.0025, -0.0074,  0.0112, -0.0109, -0.0051,\n",
      "        -0.0050, -0.0014,  0.0094,  0.0105,  0.0007,  0.0007, -0.0126,  0.0010,\n",
      "        -0.0036, -0.0157, -0.0076, -0.0047, -0.0078,  0.0045, -0.0106,  0.0142,\n",
      "        -0.0072, -0.0097, -0.0073, -0.0059,  0.0081, -0.0056, -0.0025, -0.0003,\n",
      "         0.0033,  0.0007, -0.0033,  0.0156,  0.0029,  0.0099, -0.0012,  0.0115],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-2.9305e-02, -1.9832e-02, -3.3455e-02, -9.3809e-03,  3.1520e-02,\n",
      "          -8.1339e-04, -3.0244e-02, -3.7869e-02,  1.5483e-02,  3.1080e-02],\n",
      "         [ 2.5120e-02, -3.4742e-02, -1.4839e-02,  3.0606e-02,  1.1401e-02,\n",
      "          -1.6440e-02, -3.1294e-02,  7.7163e-03, -4.7015e-03,  2.1203e-02],\n",
      "         [-2.3744e-02, -3.3954e-02, -3.3837e-02,  1.9171e-02,  3.9278e-02,\n",
      "          -3.5149e-02,  2.6183e-02, -8.5177e-03, -3.4507e-03,  3.3883e-02],\n",
      "         [-1.4172e-02, -2.7876e-02, -2.2714e-02,  1.2568e-03, -1.2603e-02,\n",
      "          -7.9428e-03, -2.8447e-02, -3.3775e-02,  3.6986e-02,  2.6537e-02],\n",
      "         [-1.5633e-02, -2.4041e-02, -8.7031e-03,  6.1535e-03, -1.1311e-02,\n",
      "           1.8798e-02, -2.5753e-02,  1.9109e-02, -2.4680e-02,  2.5277e-03],\n",
      "         [-2.1397e-03,  1.2513e-02,  2.0221e-02, -3.4914e-03, -2.0633e-02,\n",
      "           2.9610e-02,  9.4397e-03,  2.4349e-02,  1.7429e-02,  3.0528e-03],\n",
      "         [-1.4451e-02, -1.7990e-02, -8.2430e-03, -2.1959e-02, -1.0701e-02,\n",
      "           2.4062e-02,  2.8019e-02, -7.3300e-03,  7.5863e-04, -3.2010e-02],\n",
      "         [-1.8105e-02,  1.2539e-02,  2.0834e-02, -3.0159e-02, -1.1979e-02,\n",
      "          -1.0400e-02, -2.3472e-02,  2.5423e-02, -3.3470e-03,  2.1279e-02],\n",
      "         [ 2.8597e-02,  1.3103e-02,  1.9281e-02, -8.3266e-03, -6.4838e-03,\n",
      "          -4.8643e-03,  1.0848e-02, -2.5657e-02,  2.2100e-02, -1.3932e-02],\n",
      "         [ 3.7453e-03, -1.0566e-02, -3.2401e-02, -3.7363e-02, -3.7070e-02,\n",
      "           2.2489e-02,  7.1620e-03, -8.5898e-03,  1.0936e-02, -7.8975e-03],\n",
      "         [-5.8546e-03,  3.8664e-03, -4.3789e-03,  3.5351e-03,  6.9983e-03,\n",
      "          -2.2275e-02, -1.8386e-02, -4.7650e-03, -7.5210e-03,  1.2015e-02],\n",
      "         [-3.5356e-02,  8.4052e-03,  2.4675e-02,  8.2284e-03, -1.1728e-03,\n",
      "           3.8390e-02, -5.4799e-03,  2.0665e-02,  3.1782e-02, -1.1870e-02],\n",
      "         [ 1.9719e-02, -2.0064e-03, -3.9217e-02,  1.8202e-02, -3.2330e-03,\n",
      "          -3.5360e-02,  6.9881e-03,  9.5929e-04, -2.1472e-02, -9.6712e-03],\n",
      "         [-2.9865e-02, -3.4259e-02,  3.8648e-02,  2.5578e-02,  2.9913e-02,\n",
      "          -2.7155e-02,  1.0154e-02,  4.9068e-03, -1.3151e-02,  1.8966e-02],\n",
      "         [ 3.2472e-02,  5.2298e-03, -1.5081e-02,  1.9913e-02, -2.8942e-02,\n",
      "           1.9667e-02,  1.2939e-02,  2.6391e-02,  2.9688e-02, -1.5459e-02],\n",
      "         [-3.2852e-02,  2.5285e-02, -1.2561e-02, -3.6066e-02,  2.3501e-03,\n",
      "           4.4069e-03, -1.3606e-02, -7.3000e-03,  2.7328e-02,  2.5108e-03],\n",
      "         [-6.4067e-03, -1.6110e-02,  2.9695e-03, -8.4639e-03, -2.8641e-05,\n",
      "           1.4439e-02, -6.9867e-03,  3.7906e-02,  2.7913e-02, -3.7831e-02],\n",
      "         [ 8.7345e-03, -2.3877e-02, -3.2832e-03, -3.2505e-02,  3.6721e-02,\n",
      "           2.5893e-02,  1.4995e-02,  2.1180e-02,  3.8067e-03, -1.0310e-02],\n",
      "         [-2.2859e-02,  3.8382e-02,  5.5687e-03,  2.4390e-02,  5.6833e-03,\n",
      "           3.5492e-02,  3.3101e-02, -2.4903e-02, -6.2620e-03,  2.7968e-03],\n",
      "         [-1.3784e-02, -1.2071e-02,  2.5950e-02, -3.6032e-02, -2.0601e-02,\n",
      "           3.2328e-02,  2.1360e-03,  1.3257e-03,  3.1443e-02,  7.1949e-03],\n",
      "         [-3.3742e-02,  1.0422e-02, -1.1011e-02, -4.6534e-03, -1.9929e-02,\n",
      "           3.8744e-02,  2.3494e-03,  3.8843e-02, -2.3166e-02, -2.4926e-02],\n",
      "         [ 3.4133e-02,  2.3582e-02,  5.4148e-03, -2.9277e-02, -1.9648e-02,\n",
      "           9.9806e-03,  1.1310e-02,  1.7079e-02, -2.5038e-02, -3.0311e-02],\n",
      "         [ 1.8901e-02,  1.6003e-02, -3.6022e-02,  2.8366e-02, -3.3047e-02,\n",
      "           1.4508e-02,  1.0608e-02, -3.6136e-03,  3.1179e-02,  3.4007e-02],\n",
      "         [-3.1859e-02,  4.3945e-03,  1.6774e-02, -3.8563e-02,  2.8047e-02,\n",
      "          -1.5831e-02, -3.3877e-02,  3.4343e-02, -3.6678e-02,  3.8275e-02],\n",
      "         [-2.4614e-02,  1.0653e-02,  2.8079e-02, -2.0763e-03, -1.3077e-02,\n",
      "           1.9715e-02, -2.9877e-02,  3.7336e-02,  1.7330e-02, -3.8052e-02],\n",
      "         [-3.5058e-02,  2.2816e-02, -3.1340e-02, -1.9596e-02,  2.2619e-02,\n",
      "           2.8894e-02,  1.2422e-02,  3.0652e-02,  3.3204e-02,  2.4375e-03],\n",
      "         [ 6.0397e-04, -2.7262e-02,  2.9281e-02, -8.8850e-03, -1.5843e-02,\n",
      "          -3.4520e-02, -9.7039e-03,  1.8831e-02,  1.1772e-02,  2.4363e-02],\n",
      "         [-2.5382e-02,  8.5916e-04,  3.4340e-02,  9.5004e-03, -2.1698e-02,\n",
      "           1.2982e-02,  1.7078e-02, -1.5202e-02,  3.0379e-02, -3.2484e-04],\n",
      "         [-3.2011e-02, -3.0708e-02,  2.2993e-02, -1.3862e-02,  3.9399e-02,\n",
      "          -2.1923e-02, -1.4989e-02, -1.8422e-02,  3.0113e-02,  1.6804e-02],\n",
      "         [ 2.8131e-02, -1.8784e-02, -4.3486e-03, -3.6357e-02,  1.4842e-03,\n",
      "          -1.4245e-02,  3.3421e-03,  1.8293e-02,  3.0638e-02,  5.5965e-03],\n",
      "         [-3.8962e-03,  3.2746e-02, -1.9855e-02, -2.8151e-02, -1.0046e-02,\n",
      "          -3.3753e-02, -2.8476e-02, -2.8379e-02,  1.6757e-02, -2.9676e-02],\n",
      "         [ 3.1182e-02,  3.0570e-02, -2.8586e-02, -3.1953e-03, -1.9697e-02,\n",
      "          -3.4199e-03,  3.4478e-02, -1.0953e-02, -1.2689e-03,  2.4434e-02],\n",
      "         [ 3.2321e-02,  3.6619e-02, -6.8801e-03, -3.3866e-03,  2.6665e-02,\n",
      "          -1.9595e-02, -1.1087e-02, -3.5211e-02,  3.6676e-02, -8.5510e-03],\n",
      "         [ 1.9786e-02, -3.6586e-02, -1.9765e-02,  8.9423e-05,  9.4009e-03,\n",
      "           2.5123e-03, -9.8067e-03, -2.7740e-02, -2.9935e-02,  5.3094e-04],\n",
      "         [-2.9767e-02,  1.1013e-02, -2.0725e-02,  1.8244e-02, -2.4209e-02,\n",
      "           8.7141e-03,  2.2630e-02, -5.4998e-03, -2.5321e-02,  7.0326e-03],\n",
      "         [-1.5027e-02, -2.7587e-03,  3.3537e-02, -7.5119e-03,  1.1132e-02,\n",
      "          -3.2182e-03, -3.8603e-02,  1.8538e-02,  3.9427e-02, -3.6688e-02],\n",
      "         [ 2.4674e-03,  1.5798e-02, -1.3845e-02,  1.9439e-02, -3.0135e-02,\n",
      "          -9.4853e-03, -1.3323e-02, -1.0570e-02, -1.1899e-02, -2.9958e-02],\n",
      "         [ 5.1072e-03, -1.8675e-02, -2.7145e-02, -7.8657e-03, -1.9174e-02,\n",
      "           2.7257e-02,  6.0265e-04, -4.7289e-04, -3.3748e-02,  1.3281e-02],\n",
      "         [ 3.5940e-02, -3.1215e-02, -2.7865e-02, -1.5711e-02, -2.2201e-02,\n",
      "          -5.6856e-03, -3.2434e-02,  1.8161e-02, -3.2445e-02, -1.6135e-03],\n",
      "         [-1.2531e-02,  2.4252e-02,  2.8961e-02, -2.1081e-02,  3.9514e-03,\n",
      "          -3.8444e-02,  2.5184e-02, -1.9919e-02, -2.7001e-02,  1.2347e-02],\n",
      "         [ 2.1288e-02, -3.0898e-03, -2.3790e-02,  2.5396e-02, -2.0947e-02,\n",
      "          -3.8004e-02,  9.5421e-03, -1.9913e-02,  3.6216e-02, -2.3697e-02],\n",
      "         [ 1.5744e-02, -2.6563e-02,  3.0288e-02,  3.9280e-02, -2.8072e-02,\n",
      "          -6.4204e-03, -1.3770e-02, -2.2454e-02,  1.0619e-02, -9.4254e-03],\n",
      "         [ 3.6940e-02, -3.3809e-02, -2.8756e-02, -3.3866e-02, -1.5644e-02,\n",
      "          -2.0567e-03,  8.9919e-03,  2.9884e-02,  3.6743e-02, -1.3212e-02],\n",
      "         [-2.6417e-02, -3.0422e-03,  2.2973e-02,  9.8425e-03,  3.1667e-03,\n",
      "           1.8067e-02, -2.7355e-02, -2.5414e-02, -3.9249e-02,  2.4533e-02],\n",
      "         [-1.4791e-02,  2.4384e-02, -2.8761e-02, -3.7470e-02, -1.2627e-02,\n",
      "          -2.3087e-02,  2.3258e-02, -1.3609e-02, -2.1477e-02, -2.7730e-02],\n",
      "         [ 3.0535e-02, -1.9353e-02, -1.8912e-02, -4.3501e-03, -2.0807e-02,\n",
      "           3.4719e-02, -6.5424e-03,  5.3467e-03, -3.1878e-02, -2.0205e-02],\n",
      "         [ 2.4191e-02,  1.6975e-02, -3.3483e-02,  2.9078e-02,  3.7054e-02,\n",
      "           1.5333e-02,  3.0682e-02, -3.0968e-02, -2.6142e-02,  3.0438e-02],\n",
      "         [ 1.5302e-02, -1.3778e-02,  4.5685e-03,  1.2838e-02,  2.7262e-02,\n",
      "           2.2352e-02, -2.7629e-02, -3.8209e-02, -1.2941e-02, -3.8498e-02],\n",
      "         [-1.9014e-02,  3.0644e-02, -6.5607e-04, -2.2444e-02, -2.8237e-02,\n",
      "          -2.9570e-02, -4.3340e-03, -3.3453e-02,  5.7704e-03,  3.9918e-03],\n",
      "         [ 2.0898e-02, -3.7843e-02, -2.5440e-02, -9.7074e-03, -1.2708e-02,\n",
      "           2.7923e-03,  1.6243e-02,  2.5902e-02, -3.9492e-03, -3.3033e-02],\n",
      "         [ 3.1062e-02,  1.3258e-04,  1.7022e-03, -2.3531e-02, -2.7329e-02,\n",
      "          -4.2622e-03, -1.6007e-02, -1.7824e-02, -4.1313e-03, -3.1664e-02],\n",
      "         [ 2.2663e-02, -7.7870e-04, -2.9517e-02,  1.3222e-02,  3.1567e-02,\n",
      "           9.5966e-03,  3.8147e-03, -3.9410e-02, -5.3303e-03, -3.0356e-02],\n",
      "         [-7.9817e-03,  3.6705e-02, -5.9551e-03, -2.4374e-02, -3.4287e-02,\n",
      "           3.1211e-02,  2.9434e-02,  1.8539e-02,  2.3306e-02,  1.1993e-02],\n",
      "         [-2.0179e-02, -4.6453e-03, -2.3105e-02,  2.8660e-02, -2.8078e-02,\n",
      "           1.1799e-02, -1.0885e-02,  2.9603e-02,  2.2479e-02, -6.4300e-03],\n",
      "         [-5.0445e-03,  2.1244e-02,  1.2440e-02,  6.1109e-03,  3.3024e-02,\n",
      "           1.6058e-02,  3.0608e-02, -5.1423e-03,  2.9954e-03, -2.5751e-02],\n",
      "         [-1.9167e-02,  1.2714e-02,  3.2642e-02, -2.8111e-02,  3.9512e-02,\n",
      "           1.0894e-02,  3.0422e-02,  2.6620e-02, -2.3479e-02,  3.9277e-02],\n",
      "         [-6.7127e-04,  2.4354e-02,  1.3671e-02,  2.4647e-02,  9.7347e-03,\n",
      "          -1.9588e-02,  7.8402e-03, -2.9664e-02, -1.6564e-02,  3.3906e-02],\n",
      "         [ 3.1427e-02,  1.5694e-02,  2.0228e-02, -3.7215e-02,  1.5437e-02,\n",
      "           3.8005e-02,  3.1837e-02, -1.2370e-02, -1.9965e-02,  4.9945e-03],\n",
      "         [-2.3802e-03, -1.4262e-02,  9.0298e-03,  2.1193e-02, -2.7078e-02,\n",
      "           2.5859e-02, -7.6503e-03,  2.3431e-02,  2.6136e-02,  1.1072e-02],\n",
      "         [ 3.2380e-03, -7.9644e-03, -1.5239e-02, -3.0884e-02,  2.8545e-02,\n",
      "          -1.7490e-02,  3.3261e-02,  2.1659e-02,  3.0044e-02,  1.9006e-02],\n",
      "         [ 2.7025e-02,  3.7208e-02, -1.7923e-02, -1.3673e-03, -3.0562e-02,\n",
      "          -3.7698e-02,  2.7745e-02, -6.2217e-03, -1.7371e-02,  2.9896e-02],\n",
      "         [ 1.6844e-02, -1.2805e-02,  1.2815e-02,  1.0675e-03, -2.0830e-03,\n",
      "           7.9926e-03, -7.9110e-03,  1.6571e-02, -1.6036e-02, -6.9482e-03],\n",
      "         [-3.8345e-02, -7.3853e-03, -1.3327e-02,  2.4952e-02,  6.0023e-03,\n",
      "          -1.4240e-02, -2.7696e-02,  2.6686e-02, -3.6352e-02,  2.0153e-02],\n",
      "         [-2.6128e-02,  2.6953e-02,  2.4991e-02,  3.8792e-02, -3.7646e-02,\n",
      "           3.4965e-02,  4.3615e-03, -3.7130e-02, -3.9046e-02, -1.4510e-02]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0019], requires_grad=True)]\n",
      "Learning rate: 0.001\n",
      "OPT func: <function Adam at 0x7f4ea5ac9870>\n",
      "Adam optimizer\n",
      "Get cbs\n",
      "decouple_wd: True\n",
      "weight_decay <function weight_decay at 0x7f4ea5ac9240>\n",
      "l2_reg <function l2_reg at 0x7f4ea5ac92d0>\n",
      "Cbs: [<function weight_decay at 0x7f4ea5ac9240>]\n",
      "Add to cbs\n",
      "average_sqr_grad<function average_sqr_grad at 0x7f4ea5ac93f0>\n",
      "step_stat<function step_stat at 0x7f4ea5ac96c0>\n",
      "adam_step<function adam_step at 0x7f4ea5ac97e0>\n",
      "partial(average_grad, dampening=True): functools.partial(<function average_grad at 0x7f4ea5ac9360>, dampening=True)\n",
      "About to get optimizer\n",
      "Get params\n",
      "Get cbs\n",
      "Get defaults\n",
      "Get param list from params: [Parameter containing:\n",
      "tensor([[[-0.0930, -0.1716,  0.1489,  0.0574,  0.2077, -0.3114,  0.1053,\n",
      "          -0.1996,  0.2002,  0.3150]],\n",
      "\n",
      "        [[ 0.2322, -0.1150,  0.1477, -0.1084, -0.0526,  0.0080, -0.2987,\n",
      "          -0.0510, -0.0853, -0.2442]],\n",
      "\n",
      "        [[-0.0736,  0.1290, -0.0781, -0.2840, -0.1467,  0.2669, -0.0898,\n",
      "           0.0452,  0.1240,  0.2615]],\n",
      "\n",
      "        [[-0.1017, -0.0785,  0.1168,  0.0628,  0.0567, -0.1924,  0.0413,\n",
      "           0.0343, -0.2843,  0.0725]],\n",
      "\n",
      "        [[-0.0012, -0.0636,  0.1301, -0.2079, -0.0908, -0.0504, -0.2468,\n",
      "           0.1042,  0.3114,  0.0398]],\n",
      "\n",
      "        [[ 0.2501,  0.0442, -0.0280,  0.2275, -0.1733, -0.2916,  0.0274,\n",
      "           0.1816, -0.2260,  0.0552]],\n",
      "\n",
      "        [[ 0.1419,  0.0802, -0.0487,  0.0039,  0.1968,  0.3085, -0.2017,\n",
      "          -0.1304,  0.2417,  0.1926]],\n",
      "\n",
      "        [[-0.1772,  0.0862,  0.2347, -0.2710, -0.1441,  0.1429, -0.0482,\n",
      "          -0.3149,  0.1533, -0.1493]],\n",
      "\n",
      "        [[ 0.0811, -0.1643,  0.0496,  0.1719, -0.1281,  0.3078, -0.2871,\n",
      "          -0.0691, -0.1381, -0.2475]],\n",
      "\n",
      "        [[ 0.0073,  0.1232,  0.0175,  0.1896, -0.0163, -0.1384,  0.1260,\n",
      "           0.2085, -0.1919, -0.0916]],\n",
      "\n",
      "        [[ 0.0132,  0.1973,  0.2441, -0.1545,  0.3133, -0.0864, -0.1215,\n",
      "           0.0076,  0.3025,  0.0700]],\n",
      "\n",
      "        [[-0.2989, -0.2862, -0.1084, -0.1349,  0.0192, -0.1936,  0.0201,\n",
      "          -0.1415, -0.1626,  0.0127]],\n",
      "\n",
      "        [[ 0.1312, -0.2161, -0.1568,  0.2679, -0.0412, -0.2621, -0.2114,\n",
      "           0.3005,  0.3078, -0.2071]],\n",
      "\n",
      "        [[-0.2736, -0.0564, -0.1939, -0.0925, -0.0878,  0.2785,  0.1922,\n",
      "           0.1390,  0.0095, -0.0482]],\n",
      "\n",
      "        [[ 0.0235,  0.2649, -0.0728,  0.0633,  0.1701,  0.2597,  0.0384,\n",
      "           0.1500, -0.0322,  0.1009]],\n",
      "\n",
      "        [[-0.2302, -0.2686, -0.1393, -0.1132, -0.1200, -0.1594, -0.0507,\n",
      "          -0.0988,  0.3003, -0.1116]],\n",
      "\n",
      "        [[ 0.2244,  0.1239, -0.2763,  0.2274, -0.0490,  0.1533,  0.1253,\n",
      "          -0.1829,  0.2352,  0.2513]],\n",
      "\n",
      "        [[ 0.0425,  0.1210,  0.2655,  0.2336, -0.0036, -0.1895,  0.1176,\n",
      "          -0.1536,  0.2828,  0.0080]],\n",
      "\n",
      "        [[-0.2519, -0.2509, -0.0748,  0.1711, -0.0886,  0.1676,  0.2437,\n",
      "          -0.2912, -0.1026, -0.2689]],\n",
      "\n",
      "        [[ 0.0188,  0.1859,  0.2050, -0.0693, -0.2496,  0.1163,  0.1836,\n",
      "          -0.2550,  0.1377,  0.1088]],\n",
      "\n",
      "        [[ 0.1686,  0.0967,  0.1739,  0.2840,  0.0109, -0.1985,  0.2785,\n",
      "           0.0117, -0.1750,  0.1841]],\n",
      "\n",
      "        [[ 0.2597, -0.0904, -0.1121,  0.0612,  0.1777, -0.2522,  0.2884,\n",
      "          -0.1747,  0.2661, -0.2457]],\n",
      "\n",
      "        [[ 0.0452,  0.2892,  0.2336,  0.1930,  0.1028, -0.0910,  0.1080,\n",
      "          -0.1242,  0.2773,  0.2221]],\n",
      "\n",
      "        [[-0.2184, -0.2346,  0.2206, -0.1256,  0.0326, -0.3032,  0.2731,\n",
      "          -0.0277,  0.2360,  0.1068]],\n",
      "\n",
      "        [[ 0.0799,  0.0537,  0.0172, -0.0967,  0.1740,  0.1638, -0.1986,\n",
      "           0.1697,  0.2307, -0.3071]],\n",
      "\n",
      "        [[-0.2085, -0.3123,  0.0539, -0.0864,  0.1823,  0.2926, -0.2033,\n",
      "           0.1354, -0.1054,  0.2071]],\n",
      "\n",
      "        [[ 0.0573, -0.2217, -0.0240, -0.2019, -0.0983, -0.3055,  0.0758,\n",
      "          -0.2093,  0.1857,  0.0401]],\n",
      "\n",
      "        [[-0.1764,  0.0019, -0.0644, -0.0054,  0.3005,  0.1854, -0.1493,\n",
      "           0.0272,  0.1359, -0.2682]],\n",
      "\n",
      "        [[-0.1026,  0.0361, -0.2319, -0.1768, -0.2693,  0.0391, -0.0513,\n",
      "           0.2367, -0.2374,  0.0645]],\n",
      "\n",
      "        [[ 0.2171,  0.2697,  0.2347, -0.1632, -0.2059, -0.0454, -0.0014,\n",
      "           0.2269,  0.1073, -0.3088]],\n",
      "\n",
      "        [[-0.2088, -0.0969,  0.1486,  0.2762,  0.0121,  0.1647, -0.0898,\n",
      "          -0.0251,  0.0118,  0.2988]],\n",
      "\n",
      "        [[ 0.1599,  0.2969,  0.0295,  0.1362, -0.0503,  0.1484, -0.1463,\n",
      "          -0.0435,  0.0575, -0.1712]],\n",
      "\n",
      "        [[-0.2057,  0.1844,  0.0471,  0.2964, -0.1073, -0.0634, -0.0353,\n",
      "           0.2179,  0.2406,  0.0419]],\n",
      "\n",
      "        [[ 0.0283, -0.2343,  0.1352, -0.2082, -0.1548, -0.2580, -0.1782,\n",
      "          -0.1449, -0.2621, -0.1117]],\n",
      "\n",
      "        [[ 0.2839,  0.2412, -0.2857,  0.0989, -0.1748,  0.0151, -0.2058,\n",
      "           0.1396,  0.0059, -0.0210]],\n",
      "\n",
      "        [[ 0.3042,  0.2898,  0.0426, -0.1054,  0.3076, -0.0673,  0.3072,\n",
      "          -0.0823, -0.1700,  0.2335]],\n",
      "\n",
      "        [[-0.2344, -0.2144,  0.1335,  0.1921, -0.1859, -0.2708, -0.3028,\n",
      "           0.2163, -0.2276, -0.2478]],\n",
      "\n",
      "        [[ 0.1457,  0.1984,  0.1782, -0.0858,  0.1806, -0.0907, -0.3056,\n",
      "           0.2672,  0.0693, -0.1639]],\n",
      "\n",
      "        [[-0.2105, -0.2151,  0.0787, -0.2574,  0.2316, -0.2689,  0.1737,\n",
      "          -0.0224,  0.2540, -0.1030]],\n",
      "\n",
      "        [[ 0.0137, -0.2541, -0.2526, -0.1093,  0.0890,  0.2439,  0.2025,\n",
      "          -0.0671, -0.0152,  0.2827]],\n",
      "\n",
      "        [[ 0.1107, -0.1071,  0.1567,  0.2371, -0.0753, -0.0294, -0.0449,\n",
      "           0.2502,  0.1764, -0.1549]],\n",
      "\n",
      "        [[ 0.2288, -0.2260, -0.0801, -0.0923,  0.1345, -0.2570, -0.1242,\n",
      "           0.0104, -0.2863,  0.1106]],\n",
      "\n",
      "        [[ 0.1928, -0.0093, -0.2123,  0.1335, -0.2083, -0.2388,  0.2990,\n",
      "          -0.0316, -0.2092,  0.2349]],\n",
      "\n",
      "        [[ 0.0787,  0.1291, -0.1416,  0.1635, -0.3001, -0.0425, -0.0502,\n",
      "          -0.2650, -0.3055,  0.0810]],\n",
      "\n",
      "        [[-0.2691,  0.1287,  0.2158, -0.3037,  0.3119, -0.0860,  0.0928,\n",
      "           0.0518,  0.2693,  0.1012]],\n",
      "\n",
      "        [[ 0.0845,  0.1677, -0.0704,  0.0066, -0.2298, -0.0034,  0.1620,\n",
      "          -0.2342, -0.0024,  0.1253]],\n",
      "\n",
      "        [[-0.1434,  0.2066, -0.0549,  0.2122, -0.0570, -0.1333, -0.1317,\n",
      "           0.3093, -0.2149, -0.2914]],\n",
      "\n",
      "        [[-0.0701, -0.1341, -0.0494,  0.0189,  0.1167, -0.0205, -0.2731,\n",
      "          -0.2543,  0.1942,  0.2546]],\n",
      "\n",
      "        [[-0.1179,  0.0195, -0.0819, -0.2311,  0.0260,  0.0984,  0.2416,\n",
      "           0.0429, -0.1261, -0.1753]],\n",
      "\n",
      "        [[-0.2667, -0.1839, -0.1930, -0.0069, -0.1668,  0.2266,  0.0163,\n",
      "           0.0559,  0.0913, -0.2742]],\n",
      "\n",
      "        [[-0.3106, -0.1922, -0.0146,  0.1985,  0.2925, -0.3019, -0.1716,\n",
      "           0.0144, -0.2235,  0.0478]],\n",
      "\n",
      "        [[-0.0642, -0.2242, -0.2426, -0.0161,  0.0145, -0.1875,  0.1834,\n",
      "          -0.2036, -0.1629, -0.2575]],\n",
      "\n",
      "        [[ 0.1647, -0.0601,  0.2476,  0.2217, -0.0878, -0.2292,  0.2348,\n",
      "          -0.2301, -0.1110,  0.2596]],\n",
      "\n",
      "        [[ 0.1059, -0.0278,  0.0855,  0.1284,  0.0919,  0.2285,  0.2571,\n",
      "           0.0109, -0.2434,  0.0890]],\n",
      "\n",
      "        [[-0.2929,  0.0410,  0.1441,  0.2980,  0.2768,  0.2534,  0.0019,\n",
      "           0.1121,  0.0462, -0.2042]],\n",
      "\n",
      "        [[ 0.0072,  0.1666,  0.2834,  0.0664,  0.1649, -0.3112,  0.2248,\n",
      "          -0.2430, -0.1739, -0.1169]],\n",
      "\n",
      "        [[ 0.0992,  0.0818, -0.2998, -0.0083,  0.0266,  0.2211, -0.1899,\n",
      "           0.0143, -0.1783,  0.0640]],\n",
      "\n",
      "        [[ 0.1290,  0.2614, -0.2051,  0.0309,  0.1584,  0.2988, -0.0126,\n",
      "           0.0868,  0.2969,  0.3095]],\n",
      "\n",
      "        [[ 0.0730, -0.1910, -0.2535, -0.1700, -0.2999,  0.2247,  0.1273,\n",
      "          -0.0564,  0.3147,  0.2205]],\n",
      "\n",
      "        [[ 0.1178, -0.1579,  0.2261, -0.2302, -0.2108,  0.1509,  0.0580,\n",
      "          -0.1827, -0.1594,  0.0870]],\n",
      "\n",
      "        [[ 0.0080,  0.1938,  0.0281,  0.0641, -0.3039,  0.0863, -0.0799,\n",
      "          -0.3146, -0.0046,  0.2440]],\n",
      "\n",
      "        [[-0.2825,  0.1723,  0.0064, -0.1135,  0.0969, -0.2644, -0.0423,\n",
      "           0.2071,  0.1805,  0.0026]],\n",
      "\n",
      "        [[-0.0633, -0.0832,  0.0481, -0.0241,  0.0361,  0.2840,  0.0123,\n",
      "           0.2298,  0.1886, -0.0028]],\n",
      "\n",
      "        [[-0.2994,  0.2798, -0.2474, -0.3108,  0.2385,  0.2152,  0.2579,\n",
      "           0.1536,  0.1807, -0.2212]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 6.4778e-03, -2.0256e-02,  1.4676e-03, -1.5999e-03,  1.5367e-02,\n",
      "        -4.8345e-03,  3.3734e-04, -4.8271e-03,  4.7595e-04,  9.2185e-03,\n",
      "        -9.0061e-03,  4.0992e-03, -7.8069e-03, -4.0483e-03, -3.7509e-03,\n",
      "         2.7540e-03,  5.3588e-03,  4.3044e-03,  1.1115e-02,  3.4970e-04,\n",
      "        -2.3525e-02,  5.9020e-03, -6.3689e-04,  1.7809e-02,  1.5812e-02,\n",
      "        -5.2244e-03,  1.0921e-03,  9.8902e-03,  6.2064e-03, -9.0070e-03,\n",
      "         2.0802e-02, -1.0903e-02,  5.5950e-04, -7.2457e-03, -1.5263e-02,\n",
      "         9.4480e-04, -1.8154e-02, -1.2184e-03, -7.3712e-03,  1.4718e-02,\n",
      "         9.8367e-03, -5.5118e-04, -7.5655e-03, -6.6245e-03, -3.2709e-03,\n",
      "         1.4377e-03,  1.3866e-02, -1.8074e-03,  2.4245e-03, -1.8572e-03,\n",
      "         2.0887e-03, -2.7324e-02,  1.7119e-02, -2.9227e-03,  2.6570e-05,\n",
      "        -2.0623e-04,  1.4801e-02, -3.4891e-03,  9.9486e-03,  1.3322e-02,\n",
      "         2.4582e-02, -6.2911e-03,  1.0835e-02, -2.4117e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-5.0232e-02,  1.2646e-02, -4.8151e-02,  2.3546e-02, -3.6512e-02],\n",
      "         [-3.2064e-02,  3.1551e-02, -3.0031e-02,  2.4537e-02, -6.1196e-03],\n",
      "         [-5.5080e-02,  5.0841e-02,  1.0238e-02,  3.9576e-02,  2.3361e-02],\n",
      "         ...,\n",
      "         [-2.1877e-02, -4.2188e-02, -1.0357e-02,  2.2303e-02, -7.7867e-03],\n",
      "         [-4.5401e-02,  4.6589e-02, -9.8572e-03,  1.4722e-02, -5.3971e-02],\n",
      "         [ 5.0908e-02,  1.8723e-02, -1.1045e-02, -3.6627e-02, -3.0749e-03]],\n",
      "\n",
      "        [[ 5.2553e-02,  2.3173e-02,  2.1272e-02, -3.0393e-02,  2.7197e-02],\n",
      "         [-5.3937e-02,  2.9782e-02, -1.3070e-02,  1.5885e-02,  2.5224e-02],\n",
      "         [-3.1820e-02, -4.8941e-02, -7.5188e-03,  2.3096e-02, -1.8155e-04],\n",
      "         ...,\n",
      "         [ 1.8733e-02, -5.5445e-02,  4.8967e-02, -2.3524e-06,  1.5843e-02],\n",
      "         [ 8.4442e-03,  2.4046e-02, -2.8717e-02,  5.3695e-02, -7.4054e-03],\n",
      "         [-2.6767e-02, -4.4127e-02, -3.5357e-02, -3.5400e-02, -4.3833e-02]],\n",
      "\n",
      "        [[ 3.8178e-02,  4.6894e-02, -6.8627e-03,  3.5513e-02, -1.0814e-02],\n",
      "         [-2.1846e-02,  1.9751e-02,  4.0708e-03,  5.2411e-02, -3.4571e-02],\n",
      "         [-9.9717e-03, -1.2527e-02, -5.4862e-02, -3.6150e-02,  3.6884e-02],\n",
      "         ...,\n",
      "         [ 3.9119e-02,  2.4411e-02, -2.1658e-02, -1.8365e-02, -1.1501e-03],\n",
      "         [ 2.5827e-03, -5.1522e-02,  2.0366e-02,  9.8432e-03, -4.2195e-02],\n",
      "         [ 5.4704e-02,  3.6366e-02,  2.1237e-02,  9.8391e-03,  1.9568e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.4412e-03, -3.7465e-02, -2.0373e-02,  4.4546e-02, -5.4206e-02],\n",
      "         [-2.5331e-02, -1.8772e-02,  2.4309e-04, -3.1250e-02, -1.6986e-02],\n",
      "         [ 3.2985e-02,  7.3540e-03, -2.9531e-03, -2.9331e-02,  5.1339e-02],\n",
      "         ...,\n",
      "         [-1.2101e-02,  1.0421e-02,  5.0514e-02,  5.3516e-02,  1.0211e-02],\n",
      "         [ 1.9228e-02,  6.9470e-03, -2.5894e-02, -4.7285e-02, -5.2905e-02],\n",
      "         [-5.9828e-03,  4.2404e-02, -3.1764e-02, -4.7555e-02, -3.3362e-02]],\n",
      "\n",
      "        [[-2.9484e-02,  5.1761e-02,  4.6365e-02, -2.1687e-02,  3.0393e-02],\n",
      "         [-3.4066e-02,  5.0927e-03,  1.3165e-02, -4.8971e-02, -7.1763e-03],\n",
      "         [-4.2634e-02,  2.7263e-02, -2.9425e-02, -5.4449e-02, -3.0856e-02],\n",
      "         ...,\n",
      "         [-2.9719e-02, -5.1660e-02, -3.2381e-02,  2.9492e-02, -3.6336e-02],\n",
      "         [-5.1239e-02,  2.1552e-02,  3.0369e-02, -1.8063e-02,  1.3637e-02],\n",
      "         [ 5.4407e-02, -3.5069e-02, -3.2336e-03,  3.6654e-02,  3.9680e-02]],\n",
      "\n",
      "        [[ 6.1013e-04,  2.3141e-02,  4.8611e-02, -4.1561e-02, -3.3628e-02],\n",
      "         [ 3.6663e-03, -2.4109e-03, -5.8727e-03, -4.3847e-02, -4.3952e-02],\n",
      "         [ 2.8521e-02,  3.6516e-02, -1.4114e-03,  4.5765e-03, -5.4988e-02],\n",
      "         ...,\n",
      "         [ 8.8152e-03, -3.7679e-02,  9.4452e-03,  1.2736e-02, -3.5117e-02],\n",
      "         [ 3.3911e-02,  2.0034e-02,  7.6863e-03, -2.7035e-02,  4.5314e-02],\n",
      "         [-3.8897e-03,  1.8979e-02,  2.2638e-02,  2.0141e-02,  3.3650e-02]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0019, -0.0097, -0.0064,  0.0008, -0.0099,  0.0261,  0.0041,  0.0138,\n",
      "         0.0074, -0.0025, -0.0008, -0.0048, -0.0045,  0.0124, -0.0013, -0.0091,\n",
      "         0.0091,  0.0062, -0.0034,  0.0089, -0.0158, -0.0054,  0.0032,  0.0114,\n",
      "         0.0107,  0.0232, -0.0085, -0.0018, -0.0096,  0.0031,  0.0120, -0.0075],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0044,  0.0405, -0.0074, -0.0098,  0.0726],\n",
      "         [ 0.0331,  0.0770,  0.0472,  0.0097, -0.0639],\n",
      "         [ 0.0102, -0.0439, -0.0160,  0.0763,  0.0429],\n",
      "         ...,\n",
      "         [ 0.0582, -0.0408, -0.0764, -0.0308, -0.0552],\n",
      "         [ 0.0159, -0.0068,  0.0285, -0.0620,  0.0098],\n",
      "         [ 0.0256, -0.0360, -0.0692, -0.0648,  0.0538]],\n",
      "\n",
      "        [[ 0.0415,  0.0524, -0.0619, -0.0045, -0.0248],\n",
      "         [-0.0256,  0.0540, -0.0482, -0.0171, -0.0757],\n",
      "         [-0.0068,  0.0172,  0.0044, -0.0549, -0.0328],\n",
      "         ...,\n",
      "         [ 0.0246,  0.0268, -0.0257,  0.0040,  0.0428],\n",
      "         [ 0.0677, -0.0107,  0.0282,  0.0344,  0.0009],\n",
      "         [-0.0548, -0.0308,  0.0564,  0.0066, -0.0779]],\n",
      "\n",
      "        [[-0.0241, -0.0132,  0.0776,  0.0456, -0.0022],\n",
      "         [-0.0122,  0.0159,  0.0251,  0.0372,  0.0312],\n",
      "         [-0.0453, -0.0418, -0.0570,  0.0673,  0.0216],\n",
      "         ...,\n",
      "         [ 0.0546, -0.0173, -0.0151,  0.0615, -0.0157],\n",
      "         [-0.0513,  0.0137,  0.0101,  0.0533,  0.0131],\n",
      "         [ 0.0706, -0.0229,  0.0637, -0.0269,  0.0746]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0257, -0.0460,  0.0663,  0.0139, -0.0236],\n",
      "         [ 0.0690,  0.0281,  0.0571,  0.0067, -0.0011],\n",
      "         [-0.0761, -0.0348, -0.0746, -0.0620, -0.0009],\n",
      "         ...,\n",
      "         [-0.0495,  0.0357,  0.0460, -0.0004,  0.0058],\n",
      "         [ 0.0346, -0.0558,  0.0282, -0.0348, -0.0194],\n",
      "         [ 0.0378, -0.0657, -0.0709, -0.0477, -0.0640]],\n",
      "\n",
      "        [[-0.0036, -0.0325,  0.0403, -0.0014, -0.0066],\n",
      "         [-0.0622, -0.0790,  0.0136, -0.0637, -0.0354],\n",
      "         [-0.0454,  0.0321, -0.0230, -0.0629, -0.0457],\n",
      "         ...,\n",
      "         [ 0.0498,  0.0486, -0.0453, -0.0002, -0.0110],\n",
      "         [ 0.0035, -0.0638, -0.0259,  0.0730, -0.0627],\n",
      "         [ 0.0315, -0.0586, -0.0003, -0.0671, -0.0261]],\n",
      "\n",
      "        [[-0.0384,  0.0535, -0.0164,  0.0252, -0.0139],\n",
      "         [-0.0673,  0.0016,  0.0368,  0.0471, -0.0032],\n",
      "         [ 0.0373,  0.0732,  0.0181,  0.0395, -0.0769],\n",
      "         ...,\n",
      "         [-0.0359, -0.0219,  0.0057, -0.0073,  0.0134],\n",
      "         [ 0.0465, -0.0148, -0.0080,  0.0059, -0.0104],\n",
      "         [-0.0024,  0.0494, -0.0372,  0.0772,  0.0428]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0095,  0.0044, -0.0032,  0.0164,  0.0063, -0.0075,  0.0033,  0.0073,\n",
      "        -0.0088, -0.0045,  0.0132,  0.0089, -0.0120, -0.0162, -0.0146, -0.0068],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0136,  0.0731, -0.0387,  ..., -0.1578,  0.0406, -0.0532],\n",
      "        [-0.0268,  0.1126,  0.0278,  ...,  0.1299,  0.0468, -0.0800],\n",
      "        [ 0.0034, -0.0882, -0.0912,  ..., -0.0532,  0.1072, -0.1190],\n",
      "        ...,\n",
      "        [-0.0181, -0.1186,  0.1672,  ..., -0.0456,  0.1146, -0.0807],\n",
      "        [-0.0529, -0.0318, -0.1196,  ..., -0.0447, -0.1364,  0.1700],\n",
      "        [ 0.0533, -0.0133, -0.0365,  ...,  0.1308,  0.0885, -0.0518]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0737,  0.1248,  0.1098,  0.0670,  0.0179,  0.0067,  0.1221,  0.1358,\n",
      "        -0.0982,  0.1511,  0.0111, -0.1544, -0.0135, -0.1284,  0.0666, -0.0584,\n",
      "        -0.1737, -0.0663,  0.0682,  0.0299, -0.1202,  0.0612,  0.0207,  0.1083,\n",
      "         0.1598,  0.1587,  0.1577,  0.1524, -0.0828, -0.1278, -0.1041,  0.0032,\n",
      "         0.0665, -0.0665, -0.0370,  0.1061,  0.0896, -0.0091,  0.1012,  0.1141,\n",
      "         0.1573, -0.0388, -0.0875,  0.0817, -0.0760, -0.0707, -0.0971, -0.0356,\n",
      "        -0.1724,  0.0205, -0.1099,  0.0902, -0.0249, -0.0695, -0.1320, -0.1551,\n",
      "         0.0305,  0.0865, -0.1291,  0.0040], requires_grad=True), Parameter containing:\n",
      "tensor([[ 4.9307e-02,  1.0913e-01,  7.7332e-02,  ..., -5.3763e-02,\n",
      "         -2.3392e-02, -7.5340e-02],\n",
      "        [ 6.9719e-02,  8.8350e-02,  1.1500e-01,  ..., -7.6423e-02,\n",
      "          6.7819e-02, -5.7113e-02],\n",
      "        [-3.6272e-02,  1.1581e-01,  3.0163e-02,  ...,  8.6044e-02,\n",
      "          1.2588e-01,  6.7044e-03],\n",
      "        ...,\n",
      "        [-7.2323e-02, -3.5345e-02,  1.1645e-01,  ...,  6.6330e-06,\n",
      "          5.9968e-02, -6.2851e-02],\n",
      "        [ 1.2166e-01, -1.0173e-01, -9.6049e-02,  ..., -6.5660e-02,\n",
      "          1.1767e-01, -7.8363e-02],\n",
      "        [ 6.0702e-02, -5.5319e-02,  4.8264e-02,  ..., -1.6593e-02,\n",
      "         -5.7970e-02, -8.6406e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0332, -0.0673,  0.0476, -0.0446,  0.0581,  0.0983,  0.0186, -0.0714,\n",
      "        -0.0573, -0.0572,  0.0133, -0.1052,  0.0796,  0.0071, -0.0746,  0.0613,\n",
      "         0.0918, -0.0440,  0.1197,  0.0221, -0.1269, -0.0698,  0.0036, -0.0783,\n",
      "        -0.0762,  0.0124,  0.1032, -0.0705, -0.0916,  0.0153, -0.0369,  0.0516],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0554,  0.0680,  0.0816, -0.0171,  0.0135],\n",
      "         [ 0.0939, -0.0529, -0.0277,  0.0833, -0.0145],\n",
      "         [ 0.0267, -0.0311, -0.0092,  0.0556,  0.0499],\n",
      "         ...,\n",
      "         [ 0.0027, -0.0735, -0.0774,  0.0828,  0.0321],\n",
      "         [ 0.0922,  0.0248,  0.0739, -0.0185, -0.0996],\n",
      "         [ 0.0769,  0.0151, -0.0270,  0.1065,  0.0596]],\n",
      "\n",
      "        [[ 0.0313,  0.0495, -0.0643,  0.0907,  0.0509],\n",
      "         [-0.0113,  0.0365,  0.0681,  0.0651,  0.0605],\n",
      "         [-0.0634, -0.0320, -0.0554,  0.0125,  0.0310],\n",
      "         ...,\n",
      "         [-0.0784,  0.0043,  0.1103, -0.0957,  0.0874],\n",
      "         [-0.0551, -0.0181, -0.0402, -0.0128,  0.0455],\n",
      "         [ 0.0046, -0.0183,  0.0901,  0.0812,  0.0318]],\n",
      "\n",
      "        [[-0.0944,  0.0659,  0.0273,  0.0886, -0.0208],\n",
      "         [ 0.1106, -0.0194, -0.1114, -0.0147,  0.0510],\n",
      "         [ 0.1045, -0.0079, -0.0923,  0.0781,  0.0862],\n",
      "         ...,\n",
      "         [ 0.0173, -0.0317, -0.0932, -0.0122, -0.0456],\n",
      "         [ 0.0911,  0.1021, -0.0762, -0.0015, -0.0578],\n",
      "         [ 0.0362,  0.0124,  0.0735, -0.0107,  0.0653]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0704, -0.1115, -0.0503,  0.0829, -0.0279],\n",
      "         [-0.0528,  0.0175,  0.0041, -0.0434, -0.1113],\n",
      "         [-0.0962, -0.0437,  0.0986,  0.0689, -0.0838],\n",
      "         ...,\n",
      "         [ 0.0481, -0.0563, -0.0365, -0.0548, -0.0657],\n",
      "         [-0.0051, -0.0030, -0.1080, -0.0311, -0.0287],\n",
      "         [ 0.0016, -0.0385, -0.0315,  0.1083,  0.0869]],\n",
      "\n",
      "        [[-0.0539,  0.0831, -0.0316, -0.0655,  0.0387],\n",
      "         [-0.0574, -0.0210, -0.0204, -0.0196, -0.1085],\n",
      "         [-0.0345,  0.0452, -0.1008, -0.0678,  0.0729],\n",
      "         ...,\n",
      "         [-0.0043, -0.0987,  0.1051, -0.1081, -0.0689],\n",
      "         [-0.0130,  0.0583,  0.0584, -0.0720, -0.0696],\n",
      "         [-0.0838, -0.0217, -0.0206,  0.0306,  0.0341]],\n",
      "\n",
      "        [[ 0.0405,  0.0435,  0.0858,  0.0057,  0.0664],\n",
      "         [ 0.0335,  0.0241, -0.0152,  0.0423,  0.0646],\n",
      "         [ 0.0306, -0.1098, -0.0947,  0.0638, -0.0179],\n",
      "         ...,\n",
      "         [-0.0285, -0.0193,  0.0439, -0.0808, -0.0585],\n",
      "         [-0.0261, -0.0666,  0.0604, -0.0649,  0.0315],\n",
      "         [ 0.1026,  0.1031,  0.0114, -0.0707,  0.0425]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0125,  0.0071,  0.0044,  0.0302, -0.0053,  0.0043,  0.0029,  0.0046,\n",
      "        -0.0044,  0.0149,  0.0009,  0.0084, -0.0030, -0.0050, -0.0073, -0.0200],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0716, -0.0337, -0.0111,  0.0349,  0.0315],\n",
      "         [-0.0149,  0.0538, -0.0991, -0.0572, -0.0496],\n",
      "         [ 0.0279,  0.0519, -0.0273,  0.0368, -0.0100],\n",
      "         ...,\n",
      "         [ 0.0110, -0.0592, -0.0466, -0.0352, -0.0166],\n",
      "         [ 0.0813, -0.0149,  0.0801,  0.0578, -0.0054],\n",
      "         [ 0.0985,  0.0148,  0.0499,  0.0244,  0.0166]],\n",
      "\n",
      "        [[-0.0422,  0.0776, -0.0748,  0.0130, -0.0229],\n",
      "         [ 0.0478,  0.0208, -0.0197, -0.1101,  0.0621],\n",
      "         [-0.0820, -0.0231, -0.0468, -0.0944, -0.0744],\n",
      "         ...,\n",
      "         [-0.0858, -0.0533, -0.0038, -0.0566,  0.0046],\n",
      "         [ 0.0577, -0.0196,  0.1091, -0.0155, -0.0641],\n",
      "         [-0.0502, -0.0576, -0.0429,  0.0552, -0.0745]],\n",
      "\n",
      "        [[ 0.0604, -0.1074, -0.0854,  0.0652, -0.0433],\n",
      "         [ 0.0158, -0.0494, -0.0050,  0.0061, -0.0606],\n",
      "         [ 0.0398, -0.0186,  0.0399,  0.0861, -0.0196],\n",
      "         ...,\n",
      "         [ 0.0712, -0.0751, -0.0975, -0.0814,  0.0246],\n",
      "         [-0.0964,  0.0018, -0.0563, -0.0164,  0.0107],\n",
      "         [-0.0845,  0.0266, -0.0864,  0.0440,  0.0617]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0725,  0.1058,  0.0191, -0.0457, -0.0412],\n",
      "         [-0.0783,  0.0886,  0.0694,  0.0513, -0.0616],\n",
      "         [-0.1072, -0.0127,  0.0717, -0.0684, -0.0191],\n",
      "         ...,\n",
      "         [-0.0734,  0.0526,  0.0059,  0.0294, -0.0064],\n",
      "         [ 0.0644, -0.0183,  0.0345,  0.0697,  0.0082],\n",
      "         [ 0.0010,  0.0450,  0.0002,  0.0847,  0.0579]],\n",
      "\n",
      "        [[-0.0091, -0.0993,  0.0347,  0.0609,  0.0311],\n",
      "         [-0.0837, -0.0709, -0.0708, -0.0689, -0.0150],\n",
      "         [-0.0631,  0.0422,  0.0405,  0.0097, -0.0740],\n",
      "         ...,\n",
      "         [-0.0149, -0.0354,  0.0607, -0.0655, -0.0527],\n",
      "         [-0.0264,  0.0755, -0.0485, -0.0689, -0.0059],\n",
      "         [ 0.0663,  0.1030,  0.0154,  0.1030,  0.0578]],\n",
      "\n",
      "        [[-0.0055, -0.0349,  0.0457, -0.1055, -0.0057],\n",
      "         [-0.0869, -0.0462, -0.0183, -0.0830, -0.1098],\n",
      "         [ 0.0015,  0.0164, -0.0779,  0.0145,  0.0908],\n",
      "         ...,\n",
      "         [-0.0618, -0.0782, -0.0914,  0.0668, -0.0952],\n",
      "         [ 0.0645, -0.0666,  0.0414, -0.0646, -0.0386],\n",
      "         [ 0.0590, -0.0452,  0.0734,  0.1027, -0.0462]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0045, -0.0010,  0.0077,  0.0123,  0.0274,  0.0006, -0.0091,  0.0047,\n",
      "         0.0170, -0.0016, -0.0045,  0.0079,  0.0001,  0.0201, -0.0004, -0.0135,\n",
      "        -0.0015,  0.0045,  0.0103, -0.0020,  0.0155, -0.0007,  0.0100,  0.0015,\n",
      "         0.0070, -0.0064,  0.0055,  0.0008, -0.0052, -0.0040, -0.0109, -0.0002],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0280, -0.0269,  0.0162,  ...,  0.0102, -0.0470, -0.0227],\n",
      "         [ 0.0496, -0.0312, -0.0210,  ..., -0.0395,  0.0187, -0.0407],\n",
      "         [ 0.0251,  0.0502, -0.0511,  ...,  0.0287, -0.0068,  0.0013],\n",
      "         ...,\n",
      "         [ 0.0531, -0.0344, -0.0337,  ..., -0.0130,  0.0524, -0.0544],\n",
      "         [-0.0332,  0.0531,  0.0355,  ...,  0.0239, -0.0480, -0.0545],\n",
      "         [-0.0021,  0.0287, -0.0342,  ...,  0.0015,  0.0156, -0.0150]],\n",
      "\n",
      "        [[-0.0123,  0.0171,  0.0003,  ...,  0.0435,  0.0443, -0.0076],\n",
      "         [-0.0002, -0.0139, -0.0138,  ..., -0.0223, -0.0321,  0.0106],\n",
      "         [-0.0535,  0.0292,  0.0424,  ..., -0.0405,  0.0232, -0.0409],\n",
      "         ...,\n",
      "         [ 0.0225, -0.0489, -0.0500,  ..., -0.0535,  0.0508, -0.0046],\n",
      "         [ 0.0194, -0.0160,  0.0116,  ...,  0.0266,  0.0426,  0.0171],\n",
      "         [ 0.0094, -0.0369, -0.0030,  ..., -0.0071, -0.0292, -0.0059]],\n",
      "\n",
      "        [[-0.0043, -0.0213,  0.0184,  ..., -0.0313,  0.0542,  0.0060],\n",
      "         [-0.0256, -0.0325, -0.0479,  ..., -0.0264,  0.0038,  0.0357],\n",
      "         [ 0.0279,  0.0061,  0.0534,  ...,  0.0352, -0.0360, -0.0377],\n",
      "         ...,\n",
      "         [-0.0327, -0.0042,  0.0018,  ...,  0.0442,  0.0086, -0.0253],\n",
      "         [-0.0394,  0.0340, -0.0261,  ..., -0.0199, -0.0177,  0.0209],\n",
      "         [ 0.0103, -0.0117,  0.0238,  ...,  0.0194, -0.0532,  0.0052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0293, -0.0338, -0.0085,  ..., -0.0168, -0.0346, -0.0379],\n",
      "         [ 0.0490, -0.0539, -0.0352,  ...,  0.0085, -0.0124, -0.0030],\n",
      "         [-0.0315,  0.0330, -0.0134,  ...,  0.0284,  0.0135,  0.0096],\n",
      "         ...,\n",
      "         [ 0.0317, -0.0476, -0.0488,  ...,  0.0557, -0.0064, -0.0434],\n",
      "         [ 0.0379,  0.0285, -0.0062,  ...,  0.0120, -0.0272,  0.0336],\n",
      "         [ 0.0167, -0.0298,  0.0291,  ...,  0.0435,  0.0436, -0.0187]],\n",
      "\n",
      "        [[-0.0535, -0.0551,  0.0387,  ..., -0.0238, -0.0090,  0.0456],\n",
      "         [ 0.0047,  0.0120,  0.0534,  ..., -0.0213, -0.0082,  0.0460],\n",
      "         [-0.0094, -0.0245, -0.0403,  ..., -0.0216, -0.0039,  0.0177],\n",
      "         ...,\n",
      "         [ 0.0423,  0.0043,  0.0296,  ...,  0.0265, -0.0250,  0.0069],\n",
      "         [ 0.0079,  0.0252, -0.0140,  ...,  0.0307,  0.0540,  0.0381],\n",
      "         [ 0.0288,  0.0143, -0.0183,  ...,  0.0346, -0.0294,  0.0154]],\n",
      "\n",
      "        [[ 0.0274,  0.0044,  0.0390,  ...,  0.0429, -0.0383, -0.0524],\n",
      "         [-0.0362, -0.0335, -0.0030,  ...,  0.0494,  0.0218,  0.0500],\n",
      "         [ 0.0313,  0.0011,  0.0273,  ..., -0.0235,  0.0097, -0.0410],\n",
      "         ...,\n",
      "         [-0.0458,  0.0356, -0.0531,  ...,  0.0307, -0.0010, -0.0215],\n",
      "         [ 0.0496,  0.0058,  0.0294,  ...,  0.0476, -0.0480,  0.0501],\n",
      "         [-0.0361, -0.0010,  0.0147,  ..., -0.0369,  0.0056, -0.0249]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0037,  0.0179,  0.0038, -0.0083,  0.0116, -0.0162, -0.0136,  0.0157,\n",
      "        -0.0026, -0.0028, -0.0097, -0.0085, -0.0002, -0.0048, -0.0037,  0.0050,\n",
      "        -0.0146,  0.0043,  0.0047,  0.0080,  0.0152,  0.0091,  0.0060,  0.0065,\n",
      "         0.0229,  0.0078, -0.0072, -0.0025, -0.0074,  0.0112, -0.0109, -0.0051,\n",
      "        -0.0050, -0.0014,  0.0094,  0.0105,  0.0007,  0.0007, -0.0126,  0.0010,\n",
      "        -0.0036, -0.0157, -0.0076, -0.0047, -0.0078,  0.0045, -0.0106,  0.0142,\n",
      "        -0.0072, -0.0097, -0.0073, -0.0059,  0.0081, -0.0056, -0.0025, -0.0003,\n",
      "         0.0033,  0.0007, -0.0033,  0.0156,  0.0029,  0.0099, -0.0012,  0.0115],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-2.9305e-02, -1.9832e-02, -3.3455e-02, -9.3809e-03,  3.1520e-02,\n",
      "          -8.1339e-04, -3.0244e-02, -3.7869e-02,  1.5483e-02,  3.1080e-02],\n",
      "         [ 2.5120e-02, -3.4742e-02, -1.4839e-02,  3.0606e-02,  1.1401e-02,\n",
      "          -1.6440e-02, -3.1294e-02,  7.7163e-03, -4.7015e-03,  2.1203e-02],\n",
      "         [-2.3744e-02, -3.3954e-02, -3.3837e-02,  1.9171e-02,  3.9278e-02,\n",
      "          -3.5149e-02,  2.6183e-02, -8.5177e-03, -3.4507e-03,  3.3883e-02],\n",
      "         [-1.4172e-02, -2.7876e-02, -2.2714e-02,  1.2568e-03, -1.2603e-02,\n",
      "          -7.9428e-03, -2.8447e-02, -3.3775e-02,  3.6986e-02,  2.6537e-02],\n",
      "         [-1.5633e-02, -2.4041e-02, -8.7031e-03,  6.1535e-03, -1.1311e-02,\n",
      "           1.8798e-02, -2.5753e-02,  1.9109e-02, -2.4680e-02,  2.5277e-03],\n",
      "         [-2.1397e-03,  1.2513e-02,  2.0221e-02, -3.4914e-03, -2.0633e-02,\n",
      "           2.9610e-02,  9.4397e-03,  2.4349e-02,  1.7429e-02,  3.0528e-03],\n",
      "         [-1.4451e-02, -1.7990e-02, -8.2430e-03, -2.1959e-02, -1.0701e-02,\n",
      "           2.4062e-02,  2.8019e-02, -7.3300e-03,  7.5863e-04, -3.2010e-02],\n",
      "         [-1.8105e-02,  1.2539e-02,  2.0834e-02, -3.0159e-02, -1.1979e-02,\n",
      "          -1.0400e-02, -2.3472e-02,  2.5423e-02, -3.3470e-03,  2.1279e-02],\n",
      "         [ 2.8597e-02,  1.3103e-02,  1.9281e-02, -8.3266e-03, -6.4838e-03,\n",
      "          -4.8643e-03,  1.0848e-02, -2.5657e-02,  2.2100e-02, -1.3932e-02],\n",
      "         [ 3.7453e-03, -1.0566e-02, -3.2401e-02, -3.7363e-02, -3.7070e-02,\n",
      "           2.2489e-02,  7.1620e-03, -8.5898e-03,  1.0936e-02, -7.8975e-03],\n",
      "         [-5.8546e-03,  3.8664e-03, -4.3789e-03,  3.5351e-03,  6.9983e-03,\n",
      "          -2.2275e-02, -1.8386e-02, -4.7650e-03, -7.5210e-03,  1.2015e-02],\n",
      "         [-3.5356e-02,  8.4052e-03,  2.4675e-02,  8.2284e-03, -1.1728e-03,\n",
      "           3.8390e-02, -5.4799e-03,  2.0665e-02,  3.1782e-02, -1.1870e-02],\n",
      "         [ 1.9719e-02, -2.0064e-03, -3.9217e-02,  1.8202e-02, -3.2330e-03,\n",
      "          -3.5360e-02,  6.9881e-03,  9.5929e-04, -2.1472e-02, -9.6712e-03],\n",
      "         [-2.9865e-02, -3.4259e-02,  3.8648e-02,  2.5578e-02,  2.9913e-02,\n",
      "          -2.7155e-02,  1.0154e-02,  4.9068e-03, -1.3151e-02,  1.8966e-02],\n",
      "         [ 3.2472e-02,  5.2298e-03, -1.5081e-02,  1.9913e-02, -2.8942e-02,\n",
      "           1.9667e-02,  1.2939e-02,  2.6391e-02,  2.9688e-02, -1.5459e-02],\n",
      "         [-3.2852e-02,  2.5285e-02, -1.2561e-02, -3.6066e-02,  2.3501e-03,\n",
      "           4.4069e-03, -1.3606e-02, -7.3000e-03,  2.7328e-02,  2.5108e-03],\n",
      "         [-6.4067e-03, -1.6110e-02,  2.9695e-03, -8.4639e-03, -2.8641e-05,\n",
      "           1.4439e-02, -6.9867e-03,  3.7906e-02,  2.7913e-02, -3.7831e-02],\n",
      "         [ 8.7345e-03, -2.3877e-02, -3.2832e-03, -3.2505e-02,  3.6721e-02,\n",
      "           2.5893e-02,  1.4995e-02,  2.1180e-02,  3.8067e-03, -1.0310e-02],\n",
      "         [-2.2859e-02,  3.8382e-02,  5.5687e-03,  2.4390e-02,  5.6833e-03,\n",
      "           3.5492e-02,  3.3101e-02, -2.4903e-02, -6.2620e-03,  2.7968e-03],\n",
      "         [-1.3784e-02, -1.2071e-02,  2.5950e-02, -3.6032e-02, -2.0601e-02,\n",
      "           3.2328e-02,  2.1360e-03,  1.3257e-03,  3.1443e-02,  7.1949e-03],\n",
      "         [-3.3742e-02,  1.0422e-02, -1.1011e-02, -4.6534e-03, -1.9929e-02,\n",
      "           3.8744e-02,  2.3494e-03,  3.8843e-02, -2.3166e-02, -2.4926e-02],\n",
      "         [ 3.4133e-02,  2.3582e-02,  5.4148e-03, -2.9277e-02, -1.9648e-02,\n",
      "           9.9806e-03,  1.1310e-02,  1.7079e-02, -2.5038e-02, -3.0311e-02],\n",
      "         [ 1.8901e-02,  1.6003e-02, -3.6022e-02,  2.8366e-02, -3.3047e-02,\n",
      "           1.4508e-02,  1.0608e-02, -3.6136e-03,  3.1179e-02,  3.4007e-02],\n",
      "         [-3.1859e-02,  4.3945e-03,  1.6774e-02, -3.8563e-02,  2.8047e-02,\n",
      "          -1.5831e-02, -3.3877e-02,  3.4343e-02, -3.6678e-02,  3.8275e-02],\n",
      "         [-2.4614e-02,  1.0653e-02,  2.8079e-02, -2.0763e-03, -1.3077e-02,\n",
      "           1.9715e-02, -2.9877e-02,  3.7336e-02,  1.7330e-02, -3.8052e-02],\n",
      "         [-3.5058e-02,  2.2816e-02, -3.1340e-02, -1.9596e-02,  2.2619e-02,\n",
      "           2.8894e-02,  1.2422e-02,  3.0652e-02,  3.3204e-02,  2.4375e-03],\n",
      "         [ 6.0397e-04, -2.7262e-02,  2.9281e-02, -8.8850e-03, -1.5843e-02,\n",
      "          -3.4520e-02, -9.7039e-03,  1.8831e-02,  1.1772e-02,  2.4363e-02],\n",
      "         [-2.5382e-02,  8.5916e-04,  3.4340e-02,  9.5004e-03, -2.1698e-02,\n",
      "           1.2982e-02,  1.7078e-02, -1.5202e-02,  3.0379e-02, -3.2484e-04],\n",
      "         [-3.2011e-02, -3.0708e-02,  2.2993e-02, -1.3862e-02,  3.9399e-02,\n",
      "          -2.1923e-02, -1.4989e-02, -1.8422e-02,  3.0113e-02,  1.6804e-02],\n",
      "         [ 2.8131e-02, -1.8784e-02, -4.3486e-03, -3.6357e-02,  1.4842e-03,\n",
      "          -1.4245e-02,  3.3421e-03,  1.8293e-02,  3.0638e-02,  5.5965e-03],\n",
      "         [-3.8962e-03,  3.2746e-02, -1.9855e-02, -2.8151e-02, -1.0046e-02,\n",
      "          -3.3753e-02, -2.8476e-02, -2.8379e-02,  1.6757e-02, -2.9676e-02],\n",
      "         [ 3.1182e-02,  3.0570e-02, -2.8586e-02, -3.1953e-03, -1.9697e-02,\n",
      "          -3.4199e-03,  3.4478e-02, -1.0953e-02, -1.2689e-03,  2.4434e-02],\n",
      "         [ 3.2321e-02,  3.6619e-02, -6.8801e-03, -3.3866e-03,  2.6665e-02,\n",
      "          -1.9595e-02, -1.1087e-02, -3.5211e-02,  3.6676e-02, -8.5510e-03],\n",
      "         [ 1.9786e-02, -3.6586e-02, -1.9765e-02,  8.9423e-05,  9.4009e-03,\n",
      "           2.5123e-03, -9.8067e-03, -2.7740e-02, -2.9935e-02,  5.3094e-04],\n",
      "         [-2.9767e-02,  1.1013e-02, -2.0725e-02,  1.8244e-02, -2.4209e-02,\n",
      "           8.7141e-03,  2.2630e-02, -5.4998e-03, -2.5321e-02,  7.0326e-03],\n",
      "         [-1.5027e-02, -2.7587e-03,  3.3537e-02, -7.5119e-03,  1.1132e-02,\n",
      "          -3.2182e-03, -3.8603e-02,  1.8538e-02,  3.9427e-02, -3.6688e-02],\n",
      "         [ 2.4674e-03,  1.5798e-02, -1.3845e-02,  1.9439e-02, -3.0135e-02,\n",
      "          -9.4853e-03, -1.3323e-02, -1.0570e-02, -1.1899e-02, -2.9958e-02],\n",
      "         [ 5.1072e-03, -1.8675e-02, -2.7145e-02, -7.8657e-03, -1.9174e-02,\n",
      "           2.7257e-02,  6.0265e-04, -4.7289e-04, -3.3748e-02,  1.3281e-02],\n",
      "         [ 3.5940e-02, -3.1215e-02, -2.7865e-02, -1.5711e-02, -2.2201e-02,\n",
      "          -5.6856e-03, -3.2434e-02,  1.8161e-02, -3.2445e-02, -1.6135e-03],\n",
      "         [-1.2531e-02,  2.4252e-02,  2.8961e-02, -2.1081e-02,  3.9514e-03,\n",
      "          -3.8444e-02,  2.5184e-02, -1.9919e-02, -2.7001e-02,  1.2347e-02],\n",
      "         [ 2.1288e-02, -3.0898e-03, -2.3790e-02,  2.5396e-02, -2.0947e-02,\n",
      "          -3.8004e-02,  9.5421e-03, -1.9913e-02,  3.6216e-02, -2.3697e-02],\n",
      "         [ 1.5744e-02, -2.6563e-02,  3.0288e-02,  3.9280e-02, -2.8072e-02,\n",
      "          -6.4204e-03, -1.3770e-02, -2.2454e-02,  1.0619e-02, -9.4254e-03],\n",
      "         [ 3.6940e-02, -3.3809e-02, -2.8756e-02, -3.3866e-02, -1.5644e-02,\n",
      "          -2.0567e-03,  8.9919e-03,  2.9884e-02,  3.6743e-02, -1.3212e-02],\n",
      "         [-2.6417e-02, -3.0422e-03,  2.2973e-02,  9.8425e-03,  3.1667e-03,\n",
      "           1.8067e-02, -2.7355e-02, -2.5414e-02, -3.9249e-02,  2.4533e-02],\n",
      "         [-1.4791e-02,  2.4384e-02, -2.8761e-02, -3.7470e-02, -1.2627e-02,\n",
      "          -2.3087e-02,  2.3258e-02, -1.3609e-02, -2.1477e-02, -2.7730e-02],\n",
      "         [ 3.0535e-02, -1.9353e-02, -1.8912e-02, -4.3501e-03, -2.0807e-02,\n",
      "           3.4719e-02, -6.5424e-03,  5.3467e-03, -3.1878e-02, -2.0205e-02],\n",
      "         [ 2.4191e-02,  1.6975e-02, -3.3483e-02,  2.9078e-02,  3.7054e-02,\n",
      "           1.5333e-02,  3.0682e-02, -3.0968e-02, -2.6142e-02,  3.0438e-02],\n",
      "         [ 1.5302e-02, -1.3778e-02,  4.5685e-03,  1.2838e-02,  2.7262e-02,\n",
      "           2.2352e-02, -2.7629e-02, -3.8209e-02, -1.2941e-02, -3.8498e-02],\n",
      "         [-1.9014e-02,  3.0644e-02, -6.5607e-04, -2.2444e-02, -2.8237e-02,\n",
      "          -2.9570e-02, -4.3340e-03, -3.3453e-02,  5.7704e-03,  3.9918e-03],\n",
      "         [ 2.0898e-02, -3.7843e-02, -2.5440e-02, -9.7074e-03, -1.2708e-02,\n",
      "           2.7923e-03,  1.6243e-02,  2.5902e-02, -3.9492e-03, -3.3033e-02],\n",
      "         [ 3.1062e-02,  1.3258e-04,  1.7022e-03, -2.3531e-02, -2.7329e-02,\n",
      "          -4.2622e-03, -1.6007e-02, -1.7824e-02, -4.1313e-03, -3.1664e-02],\n",
      "         [ 2.2663e-02, -7.7870e-04, -2.9517e-02,  1.3222e-02,  3.1567e-02,\n",
      "           9.5966e-03,  3.8147e-03, -3.9410e-02, -5.3303e-03, -3.0356e-02],\n",
      "         [-7.9817e-03,  3.6705e-02, -5.9551e-03, -2.4374e-02, -3.4287e-02,\n",
      "           3.1211e-02,  2.9434e-02,  1.8539e-02,  2.3306e-02,  1.1993e-02],\n",
      "         [-2.0179e-02, -4.6453e-03, -2.3105e-02,  2.8660e-02, -2.8078e-02,\n",
      "           1.1799e-02, -1.0885e-02,  2.9603e-02,  2.2479e-02, -6.4300e-03],\n",
      "         [-5.0445e-03,  2.1244e-02,  1.2440e-02,  6.1109e-03,  3.3024e-02,\n",
      "           1.6058e-02,  3.0608e-02, -5.1423e-03,  2.9954e-03, -2.5751e-02],\n",
      "         [-1.9167e-02,  1.2714e-02,  3.2642e-02, -2.8111e-02,  3.9512e-02,\n",
      "           1.0894e-02,  3.0422e-02,  2.6620e-02, -2.3479e-02,  3.9277e-02],\n",
      "         [-6.7127e-04,  2.4354e-02,  1.3671e-02,  2.4647e-02,  9.7347e-03,\n",
      "          -1.9588e-02,  7.8402e-03, -2.9664e-02, -1.6564e-02,  3.3906e-02],\n",
      "         [ 3.1427e-02,  1.5694e-02,  2.0228e-02, -3.7215e-02,  1.5437e-02,\n",
      "           3.8005e-02,  3.1837e-02, -1.2370e-02, -1.9965e-02,  4.9945e-03],\n",
      "         [-2.3802e-03, -1.4262e-02,  9.0298e-03,  2.1193e-02, -2.7078e-02,\n",
      "           2.5859e-02, -7.6503e-03,  2.3431e-02,  2.6136e-02,  1.1072e-02],\n",
      "         [ 3.2380e-03, -7.9644e-03, -1.5239e-02, -3.0884e-02,  2.8545e-02,\n",
      "          -1.7490e-02,  3.3261e-02,  2.1659e-02,  3.0044e-02,  1.9006e-02],\n",
      "         [ 2.7025e-02,  3.7208e-02, -1.7923e-02, -1.3673e-03, -3.0562e-02,\n",
      "          -3.7698e-02,  2.7745e-02, -6.2217e-03, -1.7371e-02,  2.9896e-02],\n",
      "         [ 1.6844e-02, -1.2805e-02,  1.2815e-02,  1.0675e-03, -2.0830e-03,\n",
      "           7.9926e-03, -7.9110e-03,  1.6571e-02, -1.6036e-02, -6.9482e-03],\n",
      "         [-3.8345e-02, -7.3853e-03, -1.3327e-02,  2.4952e-02,  6.0023e-03,\n",
      "          -1.4240e-02, -2.7696e-02,  2.6686e-02, -3.6352e-02,  2.0153e-02],\n",
      "         [-2.6128e-02,  2.6953e-02,  2.4991e-02,  3.8792e-02, -3.7646e-02,\n",
      "           3.4965e-02,  4.3615e-03, -3.7130e-02, -3.9046e-02, -1.4510e-02]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0019], requires_grad=True)]\n",
      "At least 1 param\n",
      "Get hyperes\n",
      "Set hypers\n",
      "Set frozen idx\n",
      "Return optimizer\n",
      "-- opt_func -> \n",
      "Estoy aqui\n",
      "--> bn_bias_state\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "mapping var [Parameter containing:\n",
      "tensor([ 6.4778e-03, -2.0256e-02,  1.4676e-03, -1.5999e-03,  1.5367e-02,\n",
      "        -4.8345e-03,  3.3734e-04, -4.8271e-03,  4.7595e-04,  9.2185e-03,\n",
      "        -9.0061e-03,  4.0992e-03, -7.8069e-03, -4.0483e-03, -3.7509e-03,\n",
      "         2.7540e-03,  5.3588e-03,  4.3044e-03,  1.1115e-02,  3.4970e-04,\n",
      "        -2.3525e-02,  5.9020e-03, -6.3689e-04,  1.7809e-02,  1.5812e-02,\n",
      "        -5.2244e-03,  1.0921e-03,  9.8902e-03,  6.2064e-03, -9.0070e-03,\n",
      "         2.0802e-02, -1.0903e-02,  5.5950e-04, -7.2457e-03, -1.5263e-02,\n",
      "         9.4480e-04, -1.8154e-02, -1.2184e-03, -7.3712e-03,  1.4718e-02,\n",
      "         9.8367e-03, -5.5118e-04, -7.5655e-03, -6.6245e-03, -3.2709e-03,\n",
      "         1.4377e-03,  1.3866e-02, -1.8074e-03,  2.4245e-03, -1.8572e-03,\n",
      "         2.0887e-03, -2.7324e-02,  1.7119e-02, -2.9227e-03,  2.6570e-05,\n",
      "        -2.0623e-04,  1.4801e-02, -3.4891e-03,  9.9486e-03,  1.3322e-02,\n",
      "         2.4582e-02, -6.2911e-03,  1.0835e-02, -2.4117e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 6.4778e-03, -2.0256e-02,  1.4676e-03, -1.5999e-03,  1.5367e-02,\n",
      "        -4.8345e-03,  3.3734e-04, -4.8271e-03,  4.7595e-04,  9.2185e-03,\n",
      "        -9.0061e-03,  4.0992e-03, -7.8069e-03, -4.0483e-03, -3.7509e-03,\n",
      "         2.7540e-03,  5.3588e-03,  4.3044e-03,  1.1115e-02,  3.4970e-04,\n",
      "        -2.3525e-02,  5.9020e-03, -6.3689e-04,  1.7809e-02,  1.5812e-02,\n",
      "        -5.2244e-03,  1.0921e-03,  9.8902e-03,  6.2064e-03, -9.0070e-03,\n",
      "         2.0802e-02, -1.0903e-02,  5.5950e-04, -7.2457e-03, -1.5263e-02,\n",
      "         9.4480e-04, -1.8154e-02, -1.2184e-03, -7.3712e-03,  1.4718e-02,\n",
      "         9.8367e-03, -5.5118e-04, -7.5655e-03, -6.6245e-03, -3.2709e-03,\n",
      "         1.4377e-03,  1.3866e-02, -1.8074e-03,  2.4245e-03, -1.8572e-03,\n",
      "         2.0887e-03, -2.7324e-02,  1.7119e-02, -2.9227e-03,  2.6570e-05,\n",
      "        -2.0623e-04,  1.4801e-02, -3.4891e-03,  9.9486e-03,  1.3322e-02,\n",
      "         2.4582e-02, -6.2911e-03,  1.0835e-02, -2.4117e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0019, -0.0097, -0.0064,  0.0008, -0.0099,  0.0261,  0.0041,  0.0138,\n",
      "         0.0074, -0.0025, -0.0008, -0.0048, -0.0045,  0.0124, -0.0013, -0.0091,\n",
      "         0.0091,  0.0062, -0.0034,  0.0089, -0.0158, -0.0054,  0.0032,  0.0114,\n",
      "         0.0107,  0.0232, -0.0085, -0.0018, -0.0096,  0.0031,  0.0120, -0.0075],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0095,  0.0044, -0.0032,  0.0164,  0.0063, -0.0075,  0.0033,  0.0073,\n",
      "        -0.0088, -0.0045,  0.0132,  0.0089, -0.0120, -0.0162, -0.0146, -0.0068],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0737,  0.1248,  0.1098,  0.0670,  0.0179,  0.0067,  0.1221,  0.1358,\n",
      "        -0.0982,  0.1511,  0.0111, -0.1544, -0.0135, -0.1284,  0.0666, -0.0584,\n",
      "        -0.1737, -0.0663,  0.0682,  0.0299, -0.1202,  0.0612,  0.0207,  0.1083,\n",
      "         0.1598,  0.1587,  0.1577,  0.1524, -0.0828, -0.1278, -0.1041,  0.0032,\n",
      "         0.0665, -0.0665, -0.0370,  0.1061,  0.0896, -0.0091,  0.1012,  0.1141,\n",
      "         0.1573, -0.0388, -0.0875,  0.0817, -0.0760, -0.0707, -0.0971, -0.0356,\n",
      "        -0.1724,  0.0205, -0.1099,  0.0902, -0.0249, -0.0695, -0.1320, -0.1551,\n",
      "         0.0305,  0.0865, -0.1291,  0.0040], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0332, -0.0673,  0.0476, -0.0446,  0.0581,  0.0983,  0.0186, -0.0714,\n",
      "        -0.0573, -0.0572,  0.0133, -0.1052,  0.0796,  0.0071, -0.0746,  0.0613,\n",
      "         0.0918, -0.0440,  0.1197,  0.0221, -0.1269, -0.0698,  0.0036, -0.0783,\n",
      "        -0.0762,  0.0124,  0.1032, -0.0705, -0.0916,  0.0153, -0.0369,  0.0516],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0125,  0.0071,  0.0044,  0.0302, -0.0053,  0.0043,  0.0029,  0.0046,\n",
      "        -0.0044,  0.0149,  0.0009,  0.0084, -0.0030, -0.0050, -0.0073, -0.0200],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0045, -0.0010,  0.0077,  0.0123,  0.0274,  0.0006, -0.0091,  0.0047,\n",
      "         0.0170, -0.0016, -0.0045,  0.0079,  0.0001,  0.0201, -0.0004, -0.0135,\n",
      "        -0.0015,  0.0045,  0.0103, -0.0020,  0.0155, -0.0007,  0.0100,  0.0015,\n",
      "         0.0070, -0.0064,  0.0055,  0.0008, -0.0052, -0.0040, -0.0109, -0.0002],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0037,  0.0179,  0.0038, -0.0083,  0.0116, -0.0162, -0.0136,  0.0157,\n",
      "        -0.0026, -0.0028, -0.0097, -0.0085, -0.0002, -0.0048, -0.0037,  0.0050,\n",
      "        -0.0146,  0.0043,  0.0047,  0.0080,  0.0152,  0.0091,  0.0060,  0.0065,\n",
      "         0.0229,  0.0078, -0.0072, -0.0025, -0.0074,  0.0112, -0.0109, -0.0051,\n",
      "        -0.0050, -0.0014,  0.0094,  0.0105,  0.0007,  0.0007, -0.0126,  0.0010,\n",
      "        -0.0036, -0.0157, -0.0076, -0.0047, -0.0078,  0.0045, -0.0106,  0.0142,\n",
      "        -0.0072, -0.0097, -0.0073, -0.0059,  0.0081, -0.0056, -0.0025, -0.0003,\n",
      "         0.0033,  0.0007, -0.0033,  0.0156,  0.0029,  0.0099, -0.0012,  0.0115],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0037,  0.0179,  0.0038, -0.0083,  0.0116, -0.0162, -0.0136,  0.0157,\n",
      "        -0.0026, -0.0028, -0.0097, -0.0085, -0.0002, -0.0048, -0.0037,  0.0050,\n",
      "        -0.0146,  0.0043,  0.0047,  0.0080,  0.0152,  0.0091,  0.0060,  0.0065,\n",
      "         0.0229,  0.0078, -0.0072, -0.0025, -0.0074,  0.0112, -0.0109, -0.0051,\n",
      "        -0.0050, -0.0014,  0.0094,  0.0105,  0.0007,  0.0007, -0.0126,  0.0010,\n",
      "        -0.0036, -0.0157, -0.0076, -0.0047, -0.0078,  0.0045, -0.0106,  0.0142,\n",
      "        -0.0072, -0.0097, -0.0073, -0.0059,  0.0081, -0.0056, -0.0025, -0.0003,\n",
      "         0.0033,  0.0007, -0.0033,  0.0156,  0.0029,  0.0099, -0.0012,  0.0115],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0019], requires_grad=True), Parameter containing:\n",
      "tensor([0.0019], requires_grad=True)]\n",
      "Returning\n",
      "Got norm bias state\n",
      "--> bn_bias_state\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "mapping var []\n",
      "Returning\n",
      "Create opt -->\n",
      "About to fit\n",
      "Event: fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_397439/237031045.py\", line 7, in <module>\n",
      "    lr_valley, lr_steep = learn.lr_find(suggest_funcs=[valley, steep])\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/callback/schedule.py\", line 308, in lr_find\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/learner.py\", line 295, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/learner.py\", line 213, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/learner.py\", line 172, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastcore/foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastcore/basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastcore/basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/learner.py\", line 176, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/callback/core.py\", line 62, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/callback/core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/fastai/callback/wandb.py\", line 54, in before_fit\n",
      "    raise ValueError('You must call wandb.init() before WandbCallback()')\n",
      "ValueError: Exception occured in `WandbCallback` when calling event `before_fit`:\n",
      "\tYou must call wandb.init() before WandbCallback()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/macu/env/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "m = DCAE_torch(c_in=X_train.shape[1], seq_len=config.w, delta=config.delta, \n",
    "               pool_szs=config.pool_szs, nfs=config.nfs)\n",
    "learn = Learner(dls=dls, model=m, loss_func=nn.MSELoss(), opt_func=Adam, \n",
    "                cbs=[WandbCallback(log_preds=False)])\n",
    "#print(type(dls))\n",
    "#print(type(m))\n",
    "lr_valley, lr_steep = learn.lr_find(suggest_funcs=[valley, steep])\n",
    "learn.fit_one_cycle(config.epochs, lr_max=lr_valley)\n",
    "#learn.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To track the performance of this model fit, go to the project dashboard in Weights & Biases. The link is provided at the beginning of this notebook, after the execution of the function `wandb.init()'' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, log the learner to be used by the next notebook in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanning up\n",
      "--> Create opt\n",
      "---> opt_func \n",
      "self.model: DCAE_torch(\n",
      "  (downsample): Sequential(\n",
      "    (0): SameConv1d(\n",
      "      (conv1d_same): Conv1d(1, 64, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(32, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (5): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (latent_in): Linear(in_features=32, out_features=60, bias=True)\n",
      "    (latent_out): Linear(in_features=60, out_features=32, bias=True)\n",
      "    (reshape): Reshape(bs, 16, 2)\n",
      "  )\n",
      "  (upsample): Sequential(\n",
      "    (0): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): Upsample(scale_factor=4.0, mode=nearest)\n",
      "    (2): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (3): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (4): SameConv1d(\n",
      "      (conv1d_same): Conv1d(32, 64, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (6): SameConv1d(\n",
      "      (conv1d_same): Conv1d(64, 1, kernel_size=(10,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "self.splitter(self.model): [Parameter containing:\n",
      "tensor([[[ 6.6656e-02, -1.0343e-01,  2.9486e-01,  2.3959e-01, -1.0280e-01,\n",
      "           2.3948e-03, -3.6234e-01, -2.2473e-01,  2.8100e-01, -2.4462e-03]],\n",
      "\n",
      "        [[ 2.0949e-01, -1.7610e-01,  7.3429e-03,  1.8096e-01, -1.2255e-01,\n",
      "          -2.2338e-01, -2.0943e-01, -1.4229e-01, -1.7746e-01, -1.7607e-01]],\n",
      "\n",
      "        [[-2.4283e-01, -3.6749e-01,  1.1730e-01, -1.8839e-01, -1.4939e-01,\n",
      "           3.1865e-01, -2.1466e-01,  1.4396e-01, -1.2838e-01, -1.4000e-01]],\n",
      "\n",
      "        [[-2.0260e-01,  5.1226e-02,  2.7496e-01, -9.3813e-02, -1.4655e-01,\n",
      "           1.4028e-01, -2.9907e-01,  5.1253e-02,  1.4474e-01, -1.8388e-01]],\n",
      "\n",
      "        [[ 2.8959e-01,  1.5597e-01, -9.7332e-02,  2.6465e-01, -8.2650e-04,\n",
      "           1.9592e-01,  2.6554e-01,  2.8538e-01,  5.6051e-02,  2.2103e-01]],\n",
      "\n",
      "        [[-2.4029e-01, -2.7539e-01, -2.4475e-01, -1.8089e-01,  1.2424e-01,\n",
      "          -1.8236e-01, -7.5213e-02, -2.7004e-01,  1.3153e-01,  2.6815e-01]],\n",
      "\n",
      "        [[-1.8005e-01, -2.8449e-01, -1.6436e-01,  8.8025e-02,  1.3400e-01,\n",
      "          -1.4913e-01, -1.0056e-01, -1.3442e-01, -1.5264e-01,  2.3074e-01]],\n",
      "\n",
      "        [[ 3.1686e-01,  1.3116e-01, -1.0269e-01,  1.6542e-01,  1.8082e-01,\n",
      "          -3.7922e-02,  3.6041e-01, -1.1928e-01, -2.4680e-01,  9.2628e-02]],\n",
      "\n",
      "        [[ 1.3117e-01, -1.7472e-01, -2.6133e-01,  6.8715e-02,  2.1469e-01,\n",
      "          -5.5675e-02, -4.0328e-02,  3.2165e-01,  7.6610e-02,  1.9607e-01]],\n",
      "\n",
      "        [[ 1.0620e-01, -5.7139e-02,  2.8150e-01,  9.8311e-02, -3.3140e-01,\n",
      "          -1.6367e-02,  1.8785e-01,  2.5481e-01, -3.0744e-01,  1.1252e-01]],\n",
      "\n",
      "        [[-2.5087e-01,  3.9788e-01, -3.4059e-01,  1.5980e-01, -2.1049e-01,\n",
      "          -2.9250e-01,  1.6385e-01,  2.5662e-01,  5.1672e-02,  1.4448e-01]],\n",
      "\n",
      "        [[-2.1634e-01, -1.7257e-01, -2.8525e-01,  1.2971e-01, -5.4174e-02,\n",
      "          -3.2259e-01,  7.7967e-02, -2.7234e-01, -1.6598e-01, -1.4599e-01]],\n",
      "\n",
      "        [[ 2.7875e-02, -2.9748e-01,  1.1125e-01, -1.6513e-01,  1.1998e-01,\n",
      "           1.4765e-01,  3.5338e-01,  1.6585e-01,  8.2610e-02,  2.7279e-01]],\n",
      "\n",
      "        [[-2.7423e-01, -1.2517e-01, -2.9408e-01, -3.0030e-01, -2.3169e-01,\n",
      "           1.2731e-01, -1.0292e-01,  2.6602e-01, -3.8962e-02,  1.8910e-01]],\n",
      "\n",
      "        [[-1.1620e-01,  2.3440e-01, -2.8811e-01,  1.5776e-01,  1.5837e-01,\n",
      "          -3.5509e-01, -3.4725e-02, -1.5108e-01,  2.6221e-01, -1.1472e-01]],\n",
      "\n",
      "        [[-7.8740e-02,  1.9094e-01,  1.5469e-01,  2.3117e-01,  3.0530e-01,\n",
      "           2.4988e-01,  2.0855e-01, -2.4430e-01,  2.6418e-01,  2.2222e-01]],\n",
      "\n",
      "        [[-1.4129e-01, -2.2346e-01, -2.3489e-01,  1.2964e-01, -2.4199e-02,\n",
      "           1.6239e-01,  1.5920e-01, -3.2794e-01, -2.9545e-01, -2.1250e-01]],\n",
      "\n",
      "        [[ 1.4407e-01, -1.7405e-01,  1.2427e-01, -1.9555e-01,  8.0386e-02,\n",
      "          -2.7857e-01,  8.1325e-02, -4.4792e-02, -1.5962e-01,  2.1995e-01]],\n",
      "\n",
      "        [[-2.4004e-01,  2.4138e-01, -1.5218e-01, -2.8143e-01, -6.3960e-02,\n",
      "           2.8859e-02,  2.8023e-01,  5.5258e-02, -3.5425e-01,  6.3700e-02]],\n",
      "\n",
      "        [[ 1.3746e-01, -3.7824e-02, -3.0994e-01, -1.4022e-02, -1.3090e-01,\n",
      "          -2.4446e-01, -2.9273e-01, -1.1144e-01, -1.2670e-01,  2.2885e-01]],\n",
      "\n",
      "        [[-2.6829e-01,  2.7518e-01, -2.1397e-01,  9.0503e-02,  1.9216e-01,\n",
      "           2.6310e-01, -2.0469e-01,  2.6085e-01,  9.2754e-02, -1.5294e-01]],\n",
      "\n",
      "        [[-4.5486e-02, -3.0150e-01,  2.0611e-01, -2.7376e-01, -3.6750e-01,\n",
      "          -2.2131e-03,  3.1784e-02, -2.6233e-01,  1.1960e-01, -1.8234e-01]],\n",
      "\n",
      "        [[-2.4232e-01,  2.6557e-01,  2.3292e-01, -6.3665e-02,  2.8280e-01,\n",
      "          -6.5625e-02,  2.3059e-02,  4.1130e-02, -1.5527e-01,  9.1640e-02]],\n",
      "\n",
      "        [[-1.8664e-01,  2.4024e-01,  2.4677e-02,  2.1367e-01, -1.2598e-01,\n",
      "           9.2238e-02,  2.7632e-01, -2.8466e-01,  3.6976e-01,  2.3590e-01]],\n",
      "\n",
      "        [[-2.8724e-01,  2.3868e-01, -6.9769e-02,  1.6966e-01,  2.5105e-01,\n",
      "           3.2974e-01,  9.6770e-02,  3.0986e-01,  2.8184e-01, -2.9152e-01]],\n",
      "\n",
      "        [[ 1.4585e-01,  2.9122e-01, -3.2881e-02, -1.1370e-01,  1.9713e-01,\n",
      "          -9.5015e-03,  9.4027e-02, -1.5531e-01, -2.9534e-01, -2.5718e-01]],\n",
      "\n",
      "        [[-1.7058e-01,  2.1384e-01,  1.7284e-01, -1.8227e-01, -2.4190e-01,\n",
      "           9.6733e-03,  6.5776e-02, -1.3657e-01,  2.1798e-01, -1.1895e-01]],\n",
      "\n",
      "        [[ 2.7976e-01, -7.1592e-02,  3.2516e-01,  1.4961e-01, -2.1165e-01,\n",
      "          -2.6754e-01, -2.3421e-02, -4.4854e-04, -1.6299e-01,  1.9191e-01]],\n",
      "\n",
      "        [[ 3.3289e-01,  2.9753e-01,  2.6159e-02,  3.1960e-01, -7.7488e-02,\n",
      "           1.9422e-01,  1.0168e-01, -1.5827e-01,  2.2144e-01,  1.8133e-01]],\n",
      "\n",
      "        [[ 1.8108e-01,  1.6514e-01, -2.9799e-01, -1.0200e-01, -1.2324e-01,\n",
      "          -8.6307e-02, -3.7539e-02, -2.3643e-01, -2.3700e-01,  3.1725e-01]],\n",
      "\n",
      "        [[ 1.5928e-01, -6.2867e-02, -1.5724e-01, -3.0187e-01,  3.0146e-02,\n",
      "          -5.5764e-02, -2.8343e-01, -2.4077e-02,  2.3344e-01,  2.4706e-01]],\n",
      "\n",
      "        [[ 1.1766e-01,  3.3486e-01, -2.5757e-02, -2.0037e-01,  2.6410e-01,\n",
      "           4.0849e-02, -5.4501e-02, -3.3342e-01,  2.0376e-01,  2.9959e-01]],\n",
      "\n",
      "        [[-2.8153e-01,  1.7450e-01,  2.7401e-01, -2.3053e-01,  2.7426e-01,\n",
      "          -1.7920e-01,  1.5064e-01, -2.8303e-01,  1.7792e-01, -1.0724e-01]],\n",
      "\n",
      "        [[-1.2587e-01, -2.1320e-01,  1.2881e-01, -2.3220e-01,  2.5689e-01,\n",
      "           4.4550e-02, -1.4857e-01,  2.1527e-01, -3.0917e-01, -6.4659e-02]],\n",
      "\n",
      "        [[ 3.1274e-01, -2.4348e-01,  1.5583e-01,  2.9752e-01, -7.3029e-02,\n",
      "           2.6517e-02, -1.6978e-01, -7.0935e-02,  2.0703e-01, -2.2267e-01]],\n",
      "\n",
      "        [[-2.6178e-02, -2.3617e-01,  1.9081e-01,  2.8452e-01, -6.5271e-02,\n",
      "           2.4141e-01,  1.4013e-01, -1.1737e-01, -9.2917e-02,  2.1293e-01]],\n",
      "\n",
      "        [[ 1.3898e-01,  8.9123e-02,  2.1193e-02, -1.8041e-01,  2.9427e-01,\n",
      "          -2.5458e-01,  3.0880e-01,  3.1444e-01,  1.3063e-01,  2.9523e-01]],\n",
      "\n",
      "        [[-1.4708e-01, -1.0137e-01, -2.4519e-01, -2.7644e-01, -2.2722e-01,\n",
      "           1.1321e-01,  2.5001e-02, -2.1953e-02, -4.5436e-02, -1.6569e-02]],\n",
      "\n",
      "        [[ 9.1905e-02,  3.0027e-01,  2.2692e-01, -1.2644e-01,  1.6332e-01,\n",
      "          -1.9772e-01,  2.8590e-01,  3.8821e-01,  3.7614e-01,  2.6615e-01]],\n",
      "\n",
      "        [[ 2.1371e-01, -3.1069e-01,  9.5718e-02, -2.4904e-01,  2.9122e-01,\n",
      "          -2.8408e-02, -1.5073e-01, -3.5457e-02,  5.4652e-02, -2.1497e-01]],\n",
      "\n",
      "        [[ 1.3084e-01,  3.2485e-01,  1.4110e-01, -2.0939e-01, -2.8940e-01,\n",
      "          -3.9549e-02,  1.5295e-01,  2.4285e-01,  2.5333e-01,  1.5389e-01]],\n",
      "\n",
      "        [[ 1.6237e-01,  3.1711e-01,  1.6325e-01, -1.3694e-01,  1.0519e-01,\n",
      "           5.0427e-02,  1.1138e-01, -1.7191e-01, -2.4633e-01,  2.7433e-01]],\n",
      "\n",
      "        [[-2.0224e-01,  1.8828e-02,  2.5481e-01,  2.4168e-01,  1.2699e-01,\n",
      "          -2.2744e-02,  6.7943e-02, -3.6285e-02,  2.9645e-01, -1.3055e-01]],\n",
      "\n",
      "        [[ 4.8528e-02,  1.7642e-01,  1.5040e-01, -3.1432e-01, -1.5217e-01,\n",
      "           6.9092e-02, -2.1481e-01, -1.8491e-01, -1.0780e-01, -1.2030e-01]],\n",
      "\n",
      "        [[ 4.7627e-02,  1.7409e-01, -1.7937e-01, -2.7678e-01,  1.0461e-01,\n",
      "          -3.4943e-03, -2.1559e-01,  6.3376e-02, -3.3541e-01, -1.3137e-01]],\n",
      "\n",
      "        [[-1.1641e-01,  2.1429e-01,  8.0327e-02,  3.2984e-01, -4.6791e-02,\n",
      "           2.9175e-01,  3.7378e-02, -7.7606e-02, -1.7335e-01, -3.2654e-03]],\n",
      "\n",
      "        [[-3.0455e-01, -1.8504e-01, -1.1467e-01,  2.7348e-01,  1.5969e-01,\n",
      "          -3.4470e-01, -7.1385e-03,  2.7145e-01, -2.0998e-01,  2.8961e-01]],\n",
      "\n",
      "        [[ 2.0403e-01, -2.5086e-01, -2.6645e-01, -2.3873e-01,  1.4637e-01,\n",
      "           2.2996e-01,  2.9070e-01,  6.9968e-02, -9.4872e-02, -2.6143e-01]],\n",
      "\n",
      "        [[ 3.6986e-02,  1.8019e-01, -2.3644e-01,  2.8271e-01, -1.1935e-02,\n",
      "           4.2441e-02, -2.7907e-01, -2.5504e-01,  2.5484e-01, -1.1748e-01]],\n",
      "\n",
      "        [[-2.9581e-01, -5.6931e-02, -9.2201e-02, -6.4614e-02,  9.5389e-02,\n",
      "          -1.2749e-01, -2.1826e-01,  2.1475e-01, -1.7813e-01, -2.6479e-03]],\n",
      "\n",
      "        [[-7.3536e-02,  1.5493e-01,  1.5279e-01,  1.7139e-01,  2.4409e-01,\n",
      "          -8.1937e-02, -3.2480e-01, -2.8684e-01,  1.2889e-02,  2.7667e-01]],\n",
      "\n",
      "        [[ 2.5660e-01, -1.7647e-01,  2.6874e-02, -1.2138e-04,  1.7515e-01,\n",
      "          -1.6514e-01,  2.1760e-01,  2.8970e-01,  1.5037e-01, -3.1414e-01]],\n",
      "\n",
      "        [[ 1.5649e-02, -2.0205e-01, -1.1675e-01, -1.8187e-01,  4.9633e-02,\n",
      "          -2.6969e-01, -1.7023e-01, -1.2713e-01,  9.8376e-03, -2.6305e-01]],\n",
      "\n",
      "        [[ 2.4839e-01, -1.3489e-01, -2.7426e-01,  7.1374e-02,  1.6851e-01,\n",
      "           1.7485e-01,  2.5272e-01, -1.8265e-02,  2.9686e-01,  2.7072e-01]],\n",
      "\n",
      "        [[-3.8998e-02,  1.8746e-01,  2.2760e-01,  1.4024e-01, -2.5161e-01,\n",
      "           2.2570e-01,  3.2425e-01,  8.2590e-02, -9.6669e-02,  2.4518e-01]],\n",
      "\n",
      "        [[-3.2024e-01, -3.0010e-01, -3.0315e-01, -1.6701e-01,  2.0354e-01,\n",
      "          -1.5823e-02, -5.0088e-02, -1.3700e-01, -1.0017e-01,  2.2535e-01]],\n",
      "\n",
      "        [[-1.6221e-01,  5.6019e-02,  2.8678e-01, -7.1274e-03,  2.9227e-01,\n",
      "          -2.1311e-01,  2.5926e-01, -8.8501e-02,  3.1667e-01, -2.7501e-01]],\n",
      "\n",
      "        [[-1.6185e-01,  2.7024e-01,  2.2871e-01,  2.8501e-02, -3.3587e-01,\n",
      "           1.9632e-01,  1.6968e-01,  1.7389e-01,  3.0758e-02, -1.9350e-01]],\n",
      "\n",
      "        [[ 2.7160e-01, -4.4743e-02, -3.1823e-01,  1.3845e-01,  2.9876e-01,\n",
      "          -2.9162e-01,  2.0944e-01,  5.9971e-02, -1.5534e-01,  2.2584e-01]],\n",
      "\n",
      "        [[-2.8641e-01, -2.4495e-01,  9.8587e-03,  2.9056e-01, -3.1011e-01,\n",
      "           9.3061e-02, -1.2695e-01,  8.6509e-02,  1.5929e-01, -1.3779e-01]],\n",
      "\n",
      "        [[-1.4478e-02, -4.8786e-02, -3.3464e-01, -3.5557e-02, -3.6480e-01,\n",
      "           1.1398e-01,  1.4394e-01,  2.7449e-02, -2.0039e-02,  2.9723e-01]],\n",
      "\n",
      "        [[ 1.7716e-01,  2.0963e-01,  5.8884e-02, -3.0956e-01, -7.6851e-02,\n",
      "           1.2101e-01,  1.9908e-01, -8.4050e-02,  1.9690e-01,  1.3150e-01]],\n",
      "\n",
      "        [[-1.2121e-01,  4.0397e-02, -2.3317e-01, -1.9635e-01,  2.3934e-01,\n",
      "          -4.6979e-02,  2.9313e-01,  3.5061e-01,  1.5242e-01,  1.7969e-01]],\n",
      "\n",
      "        [[ 1.6171e-01,  2.7940e-01,  1.1337e-01,  3.0123e-01, -2.0505e-01,\n",
      "          -8.0438e-02, -2.4959e-01, -6.1686e-03,  1.0103e-01, -7.5770e-02]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0091,  0.0297, -0.0227,  0.0327,  0.0376,  0.0567,  0.0283,  0.0609,\n",
      "         0.0454, -0.0118, -0.0023,  0.0193,  0.0257,  0.0471,  0.0140,  0.0252,\n",
      "         0.0438,  0.0302,  0.0264,  0.0547,  0.0193,  0.0217, -0.0169,  0.0359,\n",
      "         0.0363,  0.0382,  0.0419,  0.0463,  0.0287,  0.0347,  0.0454, -0.0220,\n",
      "        -0.0569,  0.0253,  0.0395,  0.0425,  0.0212,  0.0451,  0.0412,  0.0063,\n",
      "         0.0508,  0.0346,  0.0458,  0.0160,  0.0459,  0.0215,  0.0225,  0.0502,\n",
      "         0.0429,  0.0181,  0.0631,  0.0195,  0.0068,  0.0244,  0.0183,  0.0395,\n",
      "         0.0226,  0.0371,  0.0307, -0.0088, -0.0200,  0.0458,  0.0354,  0.0470],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0125, -0.0947,  0.0229, -0.0044, -0.0375],\n",
      "         [-0.1051,  0.0233,  0.0248, -0.0455, -0.0278],\n",
      "         [ 0.0467, -0.0646, -0.0001, -0.0312,  0.0095],\n",
      "         ...,\n",
      "         [-0.0328, -0.0534, -0.0022, -0.0945, -0.0523],\n",
      "         [ 0.0003, -0.0427,  0.0081, -0.0439,  0.0036],\n",
      "         [ 0.0552, -0.0366,  0.0109, -0.0178,  0.0100]],\n",
      "\n",
      "        [[-0.0464,  0.0408, -0.0861, -0.0105,  0.0319],\n",
      "         [ 0.0227,  0.0260, -0.0056, -0.0066, -0.0310],\n",
      "         [ 0.1178, -0.0163, -0.0157, -0.0506, -0.0118],\n",
      "         ...,\n",
      "         [-0.0516, -0.0239,  0.0081, -0.0624,  0.0610],\n",
      "         [ 0.0403, -0.0019, -0.1049, -0.0006, -0.0355],\n",
      "         [-0.0892,  0.0298,  0.0086,  0.0266, -0.0023]],\n",
      "\n",
      "        [[-0.0347,  0.0308, -0.0320,  0.0359, -0.0405],\n",
      "         [ 0.0520,  0.0552,  0.0588,  0.0268,  0.0101],\n",
      "         [-0.0736,  0.0579,  0.0096,  0.0022, -0.0300],\n",
      "         ...,\n",
      "         [-0.0556, -0.0087, -0.0429, -0.0426,  0.0651],\n",
      "         [ 0.0687, -0.0345,  0.0452, -0.0088, -0.0796],\n",
      "         [ 0.0142,  0.0205, -0.0136, -0.0253,  0.0430]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0423, -0.0215,  0.0220, -0.0254,  0.0148],\n",
      "         [ 0.0452,  0.0698, -0.0193, -0.0003,  0.0318],\n",
      "         [-0.0049, -0.0090,  0.0273, -0.0166,  0.0224],\n",
      "         ...,\n",
      "         [-0.0709, -0.0004, -0.0168,  0.0081,  0.0512],\n",
      "         [-0.0042,  0.0039,  0.0012,  0.0291,  0.0033],\n",
      "         [-0.0709,  0.0036, -0.0536,  0.0101,  0.0019]],\n",
      "\n",
      "        [[ 0.0152, -0.0369, -0.0027,  0.0330, -0.0268],\n",
      "         [ 0.1000, -0.0267,  0.0351,  0.0179, -0.0294],\n",
      "         [-0.0708, -0.0616, -0.0212, -0.0027, -0.0224],\n",
      "         ...,\n",
      "         [-0.0027, -0.0268, -0.0430,  0.0452, -0.0243],\n",
      "         [-0.0553,  0.0787, -0.0297,  0.0447,  0.0394],\n",
      "         [ 0.0423, -0.0283,  0.0358,  0.0552,  0.0222]],\n",
      "\n",
      "        [[-0.0276, -0.0082,  0.0354, -0.0642,  0.0538],\n",
      "         [ 0.0287,  0.0047, -0.0700,  0.0272,  0.0160],\n",
      "         [-0.0549,  0.0172, -0.0282,  0.0270, -0.0544],\n",
      "         ...,\n",
      "         [ 0.0522, -0.0084,  0.0704,  0.0363,  0.0271],\n",
      "         [-0.0153, -0.0206, -0.0420,  0.0330,  0.0394],\n",
      "         [ 0.0548,  0.0540,  0.0396,  0.0049, -0.0234]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0412, -0.0279,  0.0303,  0.0324,  0.0575, -0.0356,  0.0431,  0.0412,\n",
      "         0.0595,  0.0482,  0.0555,  0.0284, -0.0397, -0.0525, -0.0475,  0.0260,\n",
      "         0.0580,  0.0486,  0.0526, -0.0103,  0.0430,  0.0391,  0.0005,  0.0563,\n",
      "        -0.0423, -0.0536,  0.0304,  0.0194,  0.0459,  0.0607,  0.0582,  0.0374],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0390,  0.0527,  0.0747, -0.0752, -0.0211],\n",
      "         [-0.0684,  0.0157,  0.0692,  0.0200, -0.0649],\n",
      "         [ 0.0014,  0.0354,  0.0958,  0.0496,  0.0416],\n",
      "         ...,\n",
      "         [ 0.0421,  0.0837, -0.0432, -0.0011,  0.0033],\n",
      "         [ 0.0209, -0.0500,  0.0999, -0.0042,  0.0259],\n",
      "         [-0.0353, -0.0387,  0.0704,  0.0018,  0.0423]],\n",
      "\n",
      "        [[ 0.0415,  0.0074,  0.0697,  0.0330,  0.0787],\n",
      "         [-0.0453,  0.0529,  0.0824,  0.0073,  0.0072],\n",
      "         [-0.0572,  0.0118,  0.0570,  0.0444,  0.0127],\n",
      "         ...,\n",
      "         [ 0.0499,  0.0235, -0.0841, -0.1066, -0.0696],\n",
      "         [ 0.0441,  0.0390,  0.0454, -0.0915, -0.0901],\n",
      "         [-0.0344,  0.0455, -0.1093,  0.0181, -0.0449]],\n",
      "\n",
      "        [[ 0.0702, -0.0057, -0.0728,  0.0101,  0.0290],\n",
      "         [-0.0618, -0.0597,  0.0147,  0.0199, -0.1050],\n",
      "         [-0.0625,  0.0540,  0.0557,  0.0131, -0.0460],\n",
      "         ...,\n",
      "         [-0.0500, -0.0376, -0.0611,  0.0748, -0.0063],\n",
      "         [ 0.0205,  0.0073,  0.0306, -0.0109,  0.0380],\n",
      "         [-0.0282,  0.0242, -0.1018, -0.0137, -0.0071]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0784, -0.0924, -0.0481, -0.0243, -0.0544],\n",
      "         [-0.0382,  0.0601, -0.0909, -0.0443, -0.0374],\n",
      "         [-0.0661, -0.0401,  0.0837,  0.0649,  0.0053],\n",
      "         ...,\n",
      "         [ 0.0084, -0.0478,  0.0562, -0.0163, -0.0075],\n",
      "         [ 0.0897,  0.0030,  0.0366, -0.0339,  0.0767],\n",
      "         [ 0.0123,  0.0668, -0.0447, -0.0154, -0.0354]],\n",
      "\n",
      "        [[ 0.0557,  0.0535,  0.0565,  0.0171,  0.0687],\n",
      "         [ 0.0032,  0.1968,  0.1080,  0.0648, -0.0553],\n",
      "         [ 0.0604,  0.0414,  0.0246, -0.0811, -0.0076],\n",
      "         ...,\n",
      "         [ 0.0139, -0.1100, -0.0159, -0.0966, -0.0137],\n",
      "         [ 0.0669, -0.1071, -0.0571,  0.0463, -0.0587],\n",
      "         [ 0.0090, -0.1643, -0.0498,  0.0009, -0.0015]],\n",
      "\n",
      "        [[-0.0588,  0.0388, -0.0513, -0.0599, -0.0157],\n",
      "         [-0.0497,  0.0769, -0.0004,  0.0989,  0.0466],\n",
      "         [ 0.0761, -0.0445,  0.0189,  0.0709, -0.0081],\n",
      "         ...,\n",
      "         [ 0.0178,  0.0863,  0.0699,  0.0800, -0.0640],\n",
      "         [-0.0544,  0.0033,  0.0019,  0.0750,  0.0443],\n",
      "         [ 0.0463,  0.0111,  0.0790, -0.0471,  0.0282]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0289, -0.0481,  0.0525, -0.0452, -0.0448,  0.0462,  0.0324,  0.0272,\n",
      "         0.0078,  0.0319,  0.0398, -0.0462,  0.0444,  0.0215, -0.0345,  0.0223],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1430, -0.0997,  0.1614,  ..., -0.1272,  0.1134,  0.1352],\n",
      "        [-0.0935,  0.0602,  0.1322,  ...,  0.0922,  0.1284, -0.0422],\n",
      "        [-0.1761,  0.0283, -0.1374,  ...,  0.1375, -0.0518,  0.1658],\n",
      "        ...,\n",
      "        [ 0.0670, -0.0996, -0.0439,  ..., -0.1531, -0.0848,  0.0185],\n",
      "        [-0.1734, -0.0031, -0.0752,  ..., -0.0083, -0.0777, -0.1311],\n",
      "        [ 0.1876, -0.0291,  0.0063,  ...,  0.0391,  0.1661,  0.1631]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1787,  0.1439,  0.0739, -0.1441,  0.0360,  0.0101,  0.0026,  0.1760,\n",
      "        -0.1391,  0.1755,  0.0132,  0.0010,  0.0734, -0.1378, -0.0405,  0.1421,\n",
      "        -0.0315,  0.0301,  0.0157, -0.1622,  0.0857,  0.0588, -0.0461, -0.0010,\n",
      "         0.0316, -0.1123, -0.1128, -0.0773, -0.2031,  0.1606, -0.0740, -0.0771,\n",
      "        -0.1989, -0.2108,  0.1825, -0.1265, -0.1686,  0.1041, -0.1684,  0.1140,\n",
      "        -0.1802, -0.0728,  0.0923, -0.1977, -0.0582, -0.0639,  0.0261, -0.2006,\n",
      "         0.0458,  0.0759, -0.0481, -0.0514, -0.1824,  0.1723,  0.0628,  0.0583,\n",
      "         0.0472, -0.0402, -0.1434,  0.0098], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0910, -0.0455,  0.0408,  ..., -0.0386, -0.0373, -0.0187],\n",
      "        [ 0.0718, -0.0040,  0.0065,  ..., -0.0928, -0.0836,  0.0920],\n",
      "        [-0.0813, -0.0585,  0.0903,  ...,  0.0832,  0.0587, -0.0003],\n",
      "        ...,\n",
      "        [-0.0154,  0.1119, -0.0955,  ...,  0.0056, -0.1137,  0.0899],\n",
      "        [-0.0618, -0.0637,  0.0959,  ..., -0.0326,  0.0277, -0.0049],\n",
      "        [-0.0385,  0.0730, -0.0745,  ...,  0.0267,  0.0925, -0.0171]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0595,  0.0972, -0.0555,  0.1262, -0.0151, -0.1565,  0.0752,  0.0175,\n",
      "        -0.1076, -0.0527, -0.0226, -0.1673, -0.0874, -0.0855, -0.0538,  0.1195,\n",
      "        -0.1108, -0.1334,  0.0405, -0.0413,  0.0278, -0.0362, -0.0028,  0.0226,\n",
      "        -0.1421,  0.1332, -0.0870, -0.0757,  0.1527,  0.1228,  0.0805,  0.1380],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0563,  0.1176, -0.0380,  0.0759, -0.1083],\n",
      "         [ 0.0207,  0.0748, -0.1059,  0.1219,  0.0531],\n",
      "         [-0.1077, -0.0591,  0.0451,  0.0982,  0.0050],\n",
      "         ...,\n",
      "         [-0.0548, -0.0057, -0.0427, -0.0130, -0.0035],\n",
      "         [-0.0230, -0.0252, -0.0792,  0.0951,  0.0957],\n",
      "         [ 0.0501, -0.0592,  0.0369,  0.1371,  0.0199]],\n",
      "\n",
      "        [[ 0.0930,  0.0307,  0.0218, -0.0626, -0.0430],\n",
      "         [ 0.0416,  0.1129,  0.1014,  0.0300,  0.0423],\n",
      "         [ 0.0652, -0.0807,  0.0527, -0.1015,  0.0692],\n",
      "         ...,\n",
      "         [ 0.0479,  0.0036, -0.0638, -0.0378, -0.0048],\n",
      "         [ 0.0659, -0.0033, -0.0260, -0.1137, -0.0670],\n",
      "         [ 0.0538, -0.0057, -0.0336, -0.0744,  0.0202]],\n",
      "\n",
      "        [[ 0.0976, -0.0007,  0.0210,  0.0415, -0.0921],\n",
      "         [-0.0515,  0.0687, -0.0221, -0.0139,  0.0176],\n",
      "         [-0.0934,  0.0194,  0.0589, -0.0532, -0.0504],\n",
      "         ...,\n",
      "         [ 0.0428, -0.0391, -0.1804, -0.0290, -0.0328],\n",
      "         [ 0.0158,  0.0654,  0.0551, -0.0388, -0.0274],\n",
      "         [ 0.0748,  0.0358,  0.0853,  0.0807, -0.0289]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0747, -0.0145, -0.0356,  0.1098, -0.0218],\n",
      "         [ 0.1040, -0.0317,  0.0483,  0.1057, -0.0065],\n",
      "         [ 0.0400, -0.0677, -0.1154, -0.0084,  0.0953],\n",
      "         ...,\n",
      "         [-0.0290, -0.0238, -0.1227,  0.0823, -0.0378],\n",
      "         [-0.0479,  0.0262, -0.0613, -0.0140,  0.0491],\n",
      "         [-0.0696, -0.0404,  0.0527, -0.0803, -0.1072]],\n",
      "\n",
      "        [[ 0.0015,  0.0696, -0.0263, -0.0465,  0.0760],\n",
      "         [-0.0750,  0.0361, -0.1004,  0.1112,  0.0517],\n",
      "         [ 0.0480, -0.1104, -0.0755,  0.0474,  0.0363],\n",
      "         ...,\n",
      "         [ 0.0151,  0.0565,  0.0899, -0.0169,  0.1037],\n",
      "         [-0.0139,  0.0576,  0.0847,  0.0610,  0.0704],\n",
      "         [-0.0543,  0.0339,  0.0076,  0.0610, -0.0868]],\n",
      "\n",
      "        [[ 0.0632,  0.1119, -0.0830,  0.0604,  0.0787],\n",
      "         [-0.0710,  0.0105, -0.1049,  0.0928,  0.0315],\n",
      "         [-0.0973,  0.1188,  0.0360,  0.0167, -0.0439],\n",
      "         ...,\n",
      "         [ 0.0095, -0.1239,  0.0552, -0.0135,  0.0654],\n",
      "         [-0.0433, -0.0406,  0.1013, -0.0012, -0.0230],\n",
      "         [ 0.0289, -0.0571,  0.1191,  0.0336, -0.0882]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0503, -0.0326,  0.0345, -0.0522,  0.0521, -0.0256, -0.0329, -0.0163,\n",
      "        -0.0119,  0.0499,  0.0595, -0.0350,  0.0390,  0.0414,  0.0473,  0.0340],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0239,  0.0716,  0.0498,  0.0711, -0.0009],\n",
      "         [ 0.1270,  0.0320,  0.0519,  0.0735,  0.0132],\n",
      "         [-0.0349,  0.0605, -0.1235,  0.0364,  0.0408],\n",
      "         ...,\n",
      "         [ 0.0922, -0.0330,  0.0384, -0.1048,  0.0313],\n",
      "         [-0.0325, -0.0212,  0.0422,  0.0425, -0.0991],\n",
      "         [-0.0149,  0.0653,  0.0291,  0.0045,  0.1260]],\n",
      "\n",
      "        [[-0.0128,  0.0751, -0.0110, -0.1572, -0.1151],\n",
      "         [-0.0266, -0.0547, -0.0578,  0.1341, -0.0086],\n",
      "         [-0.1204, -0.0486, -0.1015,  0.0720, -0.1262],\n",
      "         ...,\n",
      "         [ 0.0747,  0.0426, -0.0858, -0.0603, -0.0815],\n",
      "         [-0.1054,  0.0733, -0.1048, -0.0953, -0.0514],\n",
      "         [-0.0254, -0.0154, -0.1170, -0.0590,  0.0077]],\n",
      "\n",
      "        [[-0.0185,  0.0898, -0.0246, -0.0758, -0.0213],\n",
      "         [-0.1067, -0.0223,  0.0205, -0.0082, -0.0309],\n",
      "         [-0.0044,  0.0553,  0.0876,  0.0582,  0.0438],\n",
      "         ...,\n",
      "         [-0.0404,  0.0108, -0.0869, -0.0087,  0.1035],\n",
      "         [ 0.0837,  0.0525,  0.0679,  0.0862, -0.0389],\n",
      "         [-0.0376,  0.0365, -0.0011,  0.0444,  0.0118]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0093, -0.1063, -0.0137, -0.1488,  0.0719],\n",
      "         [-0.0049, -0.0111,  0.1260,  0.1169,  0.0595],\n",
      "         [ 0.0514, -0.0520, -0.0752, -0.0591, -0.1188],\n",
      "         ...,\n",
      "         [ 0.0918, -0.0238, -0.0532, -0.1331, -0.0500],\n",
      "         [ 0.0455, -0.0447, -0.1154,  0.0816,  0.0531],\n",
      "         [-0.0482, -0.1146, -0.0084, -0.0389, -0.0477]],\n",
      "\n",
      "        [[ 0.0927,  0.0174,  0.0771,  0.0780, -0.1225],\n",
      "         [ 0.0296, -0.0874, -0.0692, -0.0379,  0.0427],\n",
      "         [ 0.0299, -0.0936, -0.0179,  0.0319, -0.1097],\n",
      "         ...,\n",
      "         [ 0.0957, -0.0049,  0.0319,  0.0167, -0.0157],\n",
      "         [ 0.0542, -0.1109, -0.0366, -0.1043,  0.0476],\n",
      "         [ 0.0984,  0.0898,  0.0167, -0.0895, -0.0733]],\n",
      "\n",
      "        [[ 0.0152, -0.0425, -0.0387, -0.0566, -0.1299],\n",
      "         [-0.1086,  0.0018, -0.0532,  0.0413,  0.1567],\n",
      "         [ 0.0702, -0.1122, -0.0600, -0.0176,  0.0211],\n",
      "         ...,\n",
      "         [ 0.0708, -0.1874, -0.0364,  0.0623,  0.0681],\n",
      "         [ 0.0802,  0.0622,  0.0032,  0.0431, -0.0256],\n",
      "         [ 0.1538,  0.1317,  0.0030, -0.1452, -0.1495]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0277, -0.0302,  0.0082,  0.0395,  0.0280,  0.0546,  0.0338, -0.0301,\n",
      "        -0.0508,  0.0447, -0.0490, -0.0538, -0.0448,  0.0302, -0.0474,  0.0574,\n",
      "         0.0406,  0.0438, -0.0263,  0.0445,  0.0440,  0.0268,  0.0415,  0.0281,\n",
      "        -0.0372, -0.0335,  0.0349, -0.0550,  0.0088, -0.0423, -0.0652, -0.0455],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 2.4207e-02, -6.4110e-04,  4.4881e-02,  ..., -1.5832e-02,\n",
      "           2.2332e-02, -9.0957e-02],\n",
      "         [-1.5445e-02,  4.7072e-02,  2.9918e-02,  ..., -9.5487e-02,\n",
      "          -6.2533e-02, -2.7958e-02],\n",
      "         [-2.8905e-02, -2.3074e-05, -7.1340e-02,  ...,  1.4528e-02,\n",
      "           2.0521e-02,  4.3581e-02],\n",
      "         ...,\n",
      "         [ 5.6893e-02, -1.7663e-02,  5.5215e-02,  ..., -4.5053e-02,\n",
      "          -9.2355e-02, -1.0400e-01],\n",
      "         [-4.2184e-02, -6.1206e-02,  3.8717e-04,  ...,  5.4505e-02,\n",
      "           2.5008e-02, -8.8328e-03],\n",
      "         [ 3.8703e-02,  1.3617e-02,  6.4066e-03,  ...,  8.0378e-02,\n",
      "           6.8240e-02,  6.4568e-02]],\n",
      "\n",
      "        [[ 1.2992e-02,  6.9215e-02,  5.2160e-02,  ...,  1.9402e-02,\n",
      "          -3.6276e-02, -1.0036e-02],\n",
      "         [-3.3286e-02,  3.7124e-02, -2.9515e-02,  ...,  2.4649e-02,\n",
      "          -1.9410e-02, -4.4134e-03],\n",
      "         [ 2.6259e-02, -3.2437e-02, -1.5622e-02,  ..., -5.7512e-02,\n",
      "          -5.3951e-02, -2.7487e-02],\n",
      "         ...,\n",
      "         [-2.1769e-02,  5.0531e-02,  4.1576e-02,  ..., -1.4431e-02,\n",
      "           6.5468e-02,  1.1221e-02],\n",
      "         [-6.2787e-02, -6.4703e-03,  1.4149e-02,  ..., -1.0084e-02,\n",
      "           1.5817e-02, -4.6559e-02],\n",
      "         [-4.0501e-02,  9.0681e-03,  4.9041e-02,  ...,  4.3477e-02,\n",
      "          -8.3645e-02, -8.5559e-02]],\n",
      "\n",
      "        [[ 3.8535e-02,  4.4203e-02,  4.7387e-02,  ...,  4.0449e-02,\n",
      "           5.6932e-02,  2.6860e-02],\n",
      "         [-2.9093e-02,  4.6393e-02, -5.3336e-02,  ...,  3.3833e-02,\n",
      "           9.0230e-02,  5.7319e-02],\n",
      "         [-1.0292e-02,  3.7012e-02, -3.7178e-02,  ..., -3.8121e-02,\n",
      "          -1.1038e-02,  1.0447e-02],\n",
      "         ...,\n",
      "         [ 3.6701e-02, -1.3346e-02, -2.6178e-02,  ...,  7.5552e-02,\n",
      "           2.4911e-02,  3.5587e-02],\n",
      "         [-8.9758e-02, -2.9876e-02,  2.8221e-03,  ...,  1.5070e-02,\n",
      "          -4.9186e-02, -8.1930e-02],\n",
      "         [ 6.0111e-03,  2.4377e-02,  1.3707e-02,  ...,  8.8795e-03,\n",
      "          -6.6068e-02, -6.9919e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.0980e-02,  5.5803e-02,  6.6154e-02,  ...,  5.3758e-03,\n",
      "          -3.4130e-02, -4.2978e-02],\n",
      "         [ 2.8698e-02,  4.0791e-02, -3.8854e-02,  ..., -1.1229e-01,\n",
      "          -1.0484e-01, -2.3173e-02],\n",
      "         [-5.6717e-02,  5.7759e-03,  3.5257e-02,  ..., -2.1862e-04,\n",
      "           1.2286e-02,  5.7672e-02],\n",
      "         ...,\n",
      "         [ 4.6090e-03,  1.5654e-03, -1.7719e-02,  ..., -7.7570e-02,\n",
      "          -7.1091e-02, -5.4889e-02],\n",
      "         [ 2.6225e-02, -6.6453e-03,  7.5727e-03,  ..., -5.3233e-03,\n",
      "           6.8336e-02,  2.4470e-02],\n",
      "         [ 5.9466e-02,  5.4694e-02, -5.3400e-02,  ...,  5.0612e-02,\n",
      "           4.7158e-02,  1.7209e-02]],\n",
      "\n",
      "        [[-1.1989e-01, -4.0844e-02, -3.3371e-02,  ..., -2.5501e-02,\n",
      "           4.2416e-02, -1.3471e-02],\n",
      "         [ 1.5848e-02,  4.1972e-02, -1.3142e-02,  ...,  2.6090e-02,\n",
      "          -6.5219e-02,  9.0269e-03],\n",
      "         [ 8.2798e-02,  6.2718e-02,  3.1929e-02,  ...,  2.8762e-02,\n",
      "          -2.1738e-02, -2.6153e-04],\n",
      "         ...,\n",
      "         [ 2.3644e-02,  3.9992e-03, -2.0240e-02,  ..., -2.7350e-02,\n",
      "          -1.0224e-02, -7.3125e-02],\n",
      "         [ 1.2908e-01, -3.8637e-02, -2.6733e-02,  ...,  9.9391e-03,\n",
      "           5.7350e-02,  9.2575e-02],\n",
      "         [ 5.4355e-02,  3.2041e-03,  4.6986e-02,  ..., -1.1150e-01,\n",
      "           4.1002e-02,  8.6697e-02]],\n",
      "\n",
      "        [[-1.4395e-02, -8.7728e-02, -1.1378e-02,  ..., -3.0958e-02,\n",
      "          -3.8998e-02, -5.2535e-02],\n",
      "         [ 3.6560e-02, -3.0765e-02,  1.5072e-02,  ..., -4.2724e-02,\n",
      "          -7.1632e-02,  1.9756e-02],\n",
      "         [ 6.7754e-02,  5.5813e-02,  1.5949e-02,  ...,  1.7453e-02,\n",
      "           7.8818e-03,  5.9309e-02],\n",
      "         ...,\n",
      "         [ 4.8031e-03, -3.2518e-02,  1.4227e-02,  ..., -1.8981e-03,\n",
      "          -6.2652e-03, -7.8385e-02],\n",
      "         [ 6.9160e-02, -1.1221e-02, -4.5644e-02,  ...,  3.4740e-02,\n",
      "           4.3347e-02,  9.4767e-02],\n",
      "         [-7.1884e-03, -3.5555e-02, -4.4124e-02,  ...,  2.7012e-02,\n",
      "           8.1645e-02,  7.4865e-02]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0292, -0.0244, -0.0248, -0.0384, -0.0294, -0.0291,  0.0139, -0.0316,\n",
      "         0.0376,  0.0359, -0.0355, -0.0324, -0.0339,  0.0283, -0.0391,  0.0259,\n",
      "         0.0240,  0.0163, -0.0367,  0.0383, -0.0255, -0.0362, -0.0343,  0.0369,\n",
      "         0.0047, -0.0363, -0.0330, -0.0430, -0.0333,  0.0341,  0.0425, -0.0424,\n",
      "        -0.0206,  0.0300, -0.0223,  0.0268, -0.0213, -0.0391,  0.0351,  0.0457,\n",
      "         0.0143,  0.0385,  0.0407,  0.0338, -0.0206, -0.0295,  0.0216, -0.0314,\n",
      "        -0.0278,  0.0293, -0.0371, -0.0330, -0.0248, -0.0174,  0.0386,  0.0410,\n",
      "        -0.0388, -0.0365, -0.0179,  0.0229, -0.0389,  0.0159,  0.0249,  0.0303],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0402, -0.0224, -0.0116, -0.0292,  0.0582,  0.0145,  0.0691,\n",
      "           0.0613,  0.0569,  0.0296],\n",
      "         [-0.0465, -0.0195,  0.0087, -0.0448, -0.0192, -0.0256,  0.0003,\n",
      "           0.0167, -0.0452, -0.0422],\n",
      "         [-0.0035, -0.0403, -0.0192, -0.0323, -0.0579, -0.0459, -0.0351,\n",
      "          -0.0398, -0.0124, -0.0396],\n",
      "         [-0.0348, -0.0406, -0.0255, -0.0240, -0.0533, -0.0095, -0.0457,\n",
      "          -0.0374, -0.0500, -0.0384],\n",
      "         [-0.0463, -0.0558, -0.0603, -0.0075, -0.0619,  0.0350, -0.0403,\n",
      "           0.0204, -0.0153,  0.0036],\n",
      "         [ 0.0384, -0.0104, -0.0350, -0.0155, -0.0096, -0.0244, -0.0267,\n",
      "          -0.0329, -0.0524,  0.0090],\n",
      "         [ 0.0333, -0.0248,  0.0024, -0.0509,  0.0097,  0.0500,  0.0273,\n",
      "           0.0549,  0.0386,  0.0492],\n",
      "         [-0.0659, -0.0843, -0.0327, -0.0640, -0.0402,  0.0308,  0.0049,\n",
      "          -0.0212,  0.0378,  0.0441],\n",
      "         [ 0.0681,  0.0578,  0.0562,  0.0531,  0.0283,  0.0261, -0.0071,\n",
      "           0.0343, -0.0182, -0.0007],\n",
      "         [-0.0002,  0.0393, -0.0012,  0.0084,  0.0032, -0.0180,  0.0275,\n",
      "           0.0490,  0.0130,  0.0497],\n",
      "         [-0.0485,  0.0040,  0.0099, -0.0437, -0.0660, -0.0259, -0.0271,\n",
      "           0.0186, -0.0176, -0.0077],\n",
      "         [ 0.0229,  0.0097, -0.0229,  0.0219, -0.0535, -0.0086, -0.0325,\n",
      "          -0.0635, -0.0525, -0.0446],\n",
      "         [-0.0054,  0.0264, -0.0110, -0.0319, -0.0513, -0.0014, -0.0252,\n",
      "          -0.0282, -0.0179, -0.0314],\n",
      "         [ 0.0028,  0.0209, -0.0026,  0.0596,  0.0569,  0.0457, -0.0303,\n",
      "           0.0427, -0.0376, -0.0151],\n",
      "         [-0.0123, -0.0444, -0.0162, -0.0163, -0.0026,  0.0075,  0.0143,\n",
      "          -0.0191, -0.0402, -0.0176],\n",
      "         [ 0.0296, -0.0217,  0.0218, -0.0039, -0.0084,  0.0449, -0.0209,\n",
      "           0.0262,  0.0337,  0.0312],\n",
      "         [ 0.0526,  0.0442,  0.0615,  0.0453,  0.0263, -0.0089, -0.0086,\n",
      "           0.0112,  0.0126,  0.0073],\n",
      "         [-0.0178,  0.0310,  0.0391,  0.0211,  0.0501, -0.0189,  0.0343,\n",
      "          -0.0033,  0.0439,  0.0530],\n",
      "         [ 0.0140, -0.0416, -0.0381,  0.0193, -0.0680, -0.0398, -0.0541,\n",
      "          -0.0077, -0.0535, -0.0329],\n",
      "         [ 0.0504,  0.0094, -0.0201,  0.0419,  0.0517,  0.0186, -0.0020,\n",
      "           0.0441,  0.0060,  0.0430],\n",
      "         [-0.0118, -0.0360,  0.0099,  0.0204, -0.0642,  0.0273, -0.0399,\n",
      "          -0.0071, -0.0353,  0.0291],\n",
      "         [ 0.0355,  0.0109, -0.0162, -0.0273, -0.0495, -0.0399, -0.0648,\n",
      "          -0.0482, -0.0018, -0.0180],\n",
      "         [-0.0465, -0.0733, -0.0008, -0.0639, -0.0349,  0.0211,  0.0122,\n",
      "          -0.0314,  0.0252, -0.0180],\n",
      "         [ 0.0208,  0.0394,  0.0553, -0.0116,  0.0255,  0.0197,  0.0397,\n",
      "           0.0207, -0.0294, -0.0306],\n",
      "         [ 0.0474,  0.0043,  0.0421,  0.0436,  0.0636,  0.0293, -0.0093,\n",
      "           0.0359, -0.0028, -0.0190],\n",
      "         [-0.0406, -0.0179,  0.0276, -0.0083, -0.0618, -0.0367, -0.0357,\n",
      "          -0.0475, -0.0343, -0.0017],\n",
      "         [-0.0401, -0.0407, -0.0275,  0.0163, -0.0173, -0.0043, -0.0027,\n",
      "          -0.0369, -0.0178, -0.0553],\n",
      "         [-0.0642, -0.0827, -0.0859, -0.0180, -0.0423,  0.0579,  0.0295,\n",
      "          -0.0168,  0.0459,  0.0058],\n",
      "         [-0.0048, -0.0622, -0.0511, -0.0401, -0.0554, -0.0137,  0.0449,\n",
      "          -0.0094,  0.0073, -0.0200],\n",
      "         [-0.0127, -0.0284,  0.0267, -0.0002,  0.0466,  0.0364,  0.0333,\n",
      "           0.0039,  0.0420,  0.0344],\n",
      "         [ 0.0056, -0.0002, -0.0418, -0.0212,  0.0001,  0.0494,  0.0360,\n",
      "           0.0579,  0.0340,  0.0704],\n",
      "         [-0.0045,  0.0160,  0.0231,  0.0591, -0.0108,  0.0047, -0.0501,\n",
      "          -0.0460, -0.0563, -0.0431],\n",
      "         [-0.0064, -0.0575, -0.0186, -0.0681, -0.0329,  0.0539, -0.0030,\n",
      "          -0.0185,  0.0006,  0.0218],\n",
      "         [ 0.0054, -0.0208,  0.0178,  0.0397,  0.0065,  0.0467,  0.0291,\n",
      "           0.0474,  0.0577, -0.0104],\n",
      "         [-0.0556, -0.0398, -0.0561, -0.0630, -0.0474, -0.0286,  0.0307,\n",
      "           0.0256,  0.0116, -0.0271],\n",
      "         [ 0.0641,  0.0412,  0.0257,  0.0357,  0.0556,  0.0231, -0.0341,\n",
      "           0.0120, -0.0109,  0.0277],\n",
      "         [-0.0565, -0.0594, -0.0118, -0.0302, -0.0390, -0.0172,  0.0429,\n",
      "           0.0020, -0.0342, -0.0144],\n",
      "         [-0.0405, -0.0502, -0.0017, -0.0473, -0.0563,  0.0187,  0.0067,\n",
      "          -0.0150, -0.0500, -0.0565],\n",
      "         [ 0.0056, -0.0144,  0.0349,  0.0203,  0.0170,  0.0357,  0.0360,\n",
      "           0.0454,  0.0359,  0.0428],\n",
      "         [ 0.0209,  0.0667,  0.0624,  0.0532,  0.0563, -0.0012, -0.0001,\n",
      "          -0.0323,  0.0021, -0.0255],\n",
      "         [-0.0158,  0.0397, -0.0079, -0.0276,  0.0641,  0.0284,  0.0188,\n",
      "           0.0548,  0.0403,  0.0104],\n",
      "         [ 0.0183,  0.0575,  0.0651,  0.0630, -0.0007,  0.0206,  0.0278,\n",
      "          -0.0244,  0.0132, -0.0142],\n",
      "         [ 0.0194,  0.0366, -0.0254,  0.0110,  0.0066,  0.0050, -0.0051,\n",
      "           0.0497,  0.0642,  0.0601],\n",
      "         [-0.0075, -0.0162,  0.0216, -0.0161,  0.0535, -0.0106,  0.0548,\n",
      "           0.0553,  0.0641,  0.0227],\n",
      "         [-0.0159, -0.0037,  0.0074, -0.0111, -0.0516, -0.0378, -0.0492,\n",
      "          -0.0402, -0.0339, -0.0321],\n",
      "         [-0.0486, -0.0095, -0.0262,  0.0107, -0.0027,  0.0312, -0.0386,\n",
      "           0.0135, -0.0598, -0.0473],\n",
      "         [ 0.0580,  0.0558,  0.0447,  0.0585, -0.0106, -0.0388,  0.0287,\n",
      "          -0.0094,  0.0050,  0.0310],\n",
      "         [-0.0330, -0.0495, -0.0378, -0.0197, -0.0491,  0.0114, -0.0192,\n",
      "          -0.0432, -0.0225, -0.0147],\n",
      "         [ 0.0159, -0.0230,  0.0063,  0.0016, -0.0461, -0.0479, -0.0256,\n",
      "          -0.0144, -0.0210, -0.0227],\n",
      "         [ 0.0020,  0.0434, -0.0152,  0.0423,  0.0226,  0.0444,  0.0248,\n",
      "          -0.0059, -0.0168,  0.0327],\n",
      "         [-0.0084, -0.0366, -0.0391, -0.0571, -0.0654, -0.0464, -0.0123,\n",
      "           0.0119, -0.0164, -0.0179],\n",
      "         [ 0.0240,  0.0042,  0.0134, -0.0326, -0.0551, -0.0632, -0.0629,\n",
      "          -0.0149, -0.0301,  0.0035],\n",
      "         [-0.0223, -0.0942, -0.0851, -0.0776, -0.0229,  0.0227,  0.0597,\n",
      "           0.0310, -0.0109,  0.0396],\n",
      "         [ 0.0093, -0.0106, -0.0404, -0.0485, -0.0658, -0.0365, -0.0008,\n",
      "           0.0009, -0.0037,  0.0268],\n",
      "         [-0.0075,  0.0039,  0.0280,  0.0342,  0.0032,  0.0221,  0.0433,\n",
      "           0.0106,  0.0302,  0.0082],\n",
      "         [-0.0196, -0.0370, -0.0434,  0.0021,  0.0251,  0.0448,  0.0575,\n",
      "           0.0406,  0.0671,  0.0572],\n",
      "         [-0.0231,  0.0339,  0.0147,  0.0140,  0.0025, -0.0328, -0.0070,\n",
      "          -0.0332, -0.0528, -0.0711],\n",
      "         [-0.0635, -0.0232, -0.0424,  0.0095, -0.0284, -0.0345, -0.0511,\n",
      "           0.0080, -0.0236, -0.0094],\n",
      "         [-0.0365, -0.0065, -0.0005, -0.0234, -0.0317, -0.0390, -0.0540,\n",
      "          -0.0275, -0.0045, -0.0069],\n",
      "         [ 0.0314,  0.0121, -0.0158,  0.0404,  0.0357,  0.0169,  0.0530,\n",
      "           0.0417,  0.0311,  0.0203],\n",
      "         [-0.0561, -0.0535, -0.0381, -0.0588,  0.0146,  0.0473,  0.0329,\n",
      "           0.0083, -0.0394, -0.0102],\n",
      "         [-0.0436,  0.0131, -0.0144, -0.0171,  0.0485,  0.0043,  0.0459,\n",
      "           0.0261,  0.0448,  0.0689],\n",
      "         [ 0.0014,  0.0672,  0.0366,  0.0199,  0.0400,  0.0262,  0.0123,\n",
      "          -0.0341, -0.0138, -0.0082],\n",
      "         [ 0.0408,  0.0114,  0.0312,  0.0306,  0.0536,  0.0300,  0.0232,\n",
      "          -0.0034, -0.0263,  0.0422]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0508], requires_grad=True)]\n",
      "Learning rate: 0.001\n",
      "OPT func: <function Adam at 0x7f4ea5ac9870>\n",
      "Adam optimizer\n",
      "Get cbs\n",
      "decouple_wd: True\n",
      "weight_decay <function weight_decay at 0x7f4ea5ac9240>\n",
      "l2_reg <function l2_reg at 0x7f4ea5ac92d0>\n",
      "Cbs: [<function weight_decay at 0x7f4ea5ac9240>]\n",
      "Add to cbs\n",
      "average_sqr_grad<function average_sqr_grad at 0x7f4ea5ac93f0>\n",
      "step_stat<function step_stat at 0x7f4ea5ac96c0>\n",
      "adam_step<function adam_step at 0x7f4ea5ac97e0>\n",
      "partial(average_grad, dampening=True): functools.partial(<function average_grad at 0x7f4ea5ac9360>, dampening=True)\n",
      "About to get optimizer\n",
      "Get params\n",
      "Get cbs\n",
      "Get defaults\n",
      "Get param list from params: [Parameter containing:\n",
      "tensor([[[ 6.6656e-02, -1.0343e-01,  2.9486e-01,  2.3959e-01, -1.0280e-01,\n",
      "           2.3948e-03, -3.6234e-01, -2.2473e-01,  2.8100e-01, -2.4462e-03]],\n",
      "\n",
      "        [[ 2.0949e-01, -1.7610e-01,  7.3429e-03,  1.8096e-01, -1.2255e-01,\n",
      "          -2.2338e-01, -2.0943e-01, -1.4229e-01, -1.7746e-01, -1.7607e-01]],\n",
      "\n",
      "        [[-2.4283e-01, -3.6749e-01,  1.1730e-01, -1.8839e-01, -1.4939e-01,\n",
      "           3.1865e-01, -2.1466e-01,  1.4396e-01, -1.2838e-01, -1.4000e-01]],\n",
      "\n",
      "        [[-2.0260e-01,  5.1226e-02,  2.7496e-01, -9.3813e-02, -1.4655e-01,\n",
      "           1.4028e-01, -2.9907e-01,  5.1253e-02,  1.4474e-01, -1.8388e-01]],\n",
      "\n",
      "        [[ 2.8959e-01,  1.5597e-01, -9.7332e-02,  2.6465e-01, -8.2650e-04,\n",
      "           1.9592e-01,  2.6554e-01,  2.8538e-01,  5.6051e-02,  2.2103e-01]],\n",
      "\n",
      "        [[-2.4029e-01, -2.7539e-01, -2.4475e-01, -1.8089e-01,  1.2424e-01,\n",
      "          -1.8236e-01, -7.5213e-02, -2.7004e-01,  1.3153e-01,  2.6815e-01]],\n",
      "\n",
      "        [[-1.8005e-01, -2.8449e-01, -1.6436e-01,  8.8025e-02,  1.3400e-01,\n",
      "          -1.4913e-01, -1.0056e-01, -1.3442e-01, -1.5264e-01,  2.3074e-01]],\n",
      "\n",
      "        [[ 3.1686e-01,  1.3116e-01, -1.0269e-01,  1.6542e-01,  1.8082e-01,\n",
      "          -3.7922e-02,  3.6041e-01, -1.1928e-01, -2.4680e-01,  9.2628e-02]],\n",
      "\n",
      "        [[ 1.3117e-01, -1.7472e-01, -2.6133e-01,  6.8715e-02,  2.1469e-01,\n",
      "          -5.5675e-02, -4.0328e-02,  3.2165e-01,  7.6610e-02,  1.9607e-01]],\n",
      "\n",
      "        [[ 1.0620e-01, -5.7139e-02,  2.8150e-01,  9.8311e-02, -3.3140e-01,\n",
      "          -1.6367e-02,  1.8785e-01,  2.5481e-01, -3.0744e-01,  1.1252e-01]],\n",
      "\n",
      "        [[-2.5087e-01,  3.9788e-01, -3.4059e-01,  1.5980e-01, -2.1049e-01,\n",
      "          -2.9250e-01,  1.6385e-01,  2.5662e-01,  5.1672e-02,  1.4448e-01]],\n",
      "\n",
      "        [[-2.1634e-01, -1.7257e-01, -2.8525e-01,  1.2971e-01, -5.4174e-02,\n",
      "          -3.2259e-01,  7.7967e-02, -2.7234e-01, -1.6598e-01, -1.4599e-01]],\n",
      "\n",
      "        [[ 2.7875e-02, -2.9748e-01,  1.1125e-01, -1.6513e-01,  1.1998e-01,\n",
      "           1.4765e-01,  3.5338e-01,  1.6585e-01,  8.2610e-02,  2.7279e-01]],\n",
      "\n",
      "        [[-2.7423e-01, -1.2517e-01, -2.9408e-01, -3.0030e-01, -2.3169e-01,\n",
      "           1.2731e-01, -1.0292e-01,  2.6602e-01, -3.8962e-02,  1.8910e-01]],\n",
      "\n",
      "        [[-1.1620e-01,  2.3440e-01, -2.8811e-01,  1.5776e-01,  1.5837e-01,\n",
      "          -3.5509e-01, -3.4725e-02, -1.5108e-01,  2.6221e-01, -1.1472e-01]],\n",
      "\n",
      "        [[-7.8740e-02,  1.9094e-01,  1.5469e-01,  2.3117e-01,  3.0530e-01,\n",
      "           2.4988e-01,  2.0855e-01, -2.4430e-01,  2.6418e-01,  2.2222e-01]],\n",
      "\n",
      "        [[-1.4129e-01, -2.2346e-01, -2.3489e-01,  1.2964e-01, -2.4199e-02,\n",
      "           1.6239e-01,  1.5920e-01, -3.2794e-01, -2.9545e-01, -2.1250e-01]],\n",
      "\n",
      "        [[ 1.4407e-01, -1.7405e-01,  1.2427e-01, -1.9555e-01,  8.0386e-02,\n",
      "          -2.7857e-01,  8.1325e-02, -4.4792e-02, -1.5962e-01,  2.1995e-01]],\n",
      "\n",
      "        [[-2.4004e-01,  2.4138e-01, -1.5218e-01, -2.8143e-01, -6.3960e-02,\n",
      "           2.8859e-02,  2.8023e-01,  5.5258e-02, -3.5425e-01,  6.3700e-02]],\n",
      "\n",
      "        [[ 1.3746e-01, -3.7824e-02, -3.0994e-01, -1.4022e-02, -1.3090e-01,\n",
      "          -2.4446e-01, -2.9273e-01, -1.1144e-01, -1.2670e-01,  2.2885e-01]],\n",
      "\n",
      "        [[-2.6829e-01,  2.7518e-01, -2.1397e-01,  9.0503e-02,  1.9216e-01,\n",
      "           2.6310e-01, -2.0469e-01,  2.6085e-01,  9.2754e-02, -1.5294e-01]],\n",
      "\n",
      "        [[-4.5486e-02, -3.0150e-01,  2.0611e-01, -2.7376e-01, -3.6750e-01,\n",
      "          -2.2131e-03,  3.1784e-02, -2.6233e-01,  1.1960e-01, -1.8234e-01]],\n",
      "\n",
      "        [[-2.4232e-01,  2.6557e-01,  2.3292e-01, -6.3665e-02,  2.8280e-01,\n",
      "          -6.5625e-02,  2.3059e-02,  4.1130e-02, -1.5527e-01,  9.1640e-02]],\n",
      "\n",
      "        [[-1.8664e-01,  2.4024e-01,  2.4677e-02,  2.1367e-01, -1.2598e-01,\n",
      "           9.2238e-02,  2.7632e-01, -2.8466e-01,  3.6976e-01,  2.3590e-01]],\n",
      "\n",
      "        [[-2.8724e-01,  2.3868e-01, -6.9769e-02,  1.6966e-01,  2.5105e-01,\n",
      "           3.2974e-01,  9.6770e-02,  3.0986e-01,  2.8184e-01, -2.9152e-01]],\n",
      "\n",
      "        [[ 1.4585e-01,  2.9122e-01, -3.2881e-02, -1.1370e-01,  1.9713e-01,\n",
      "          -9.5015e-03,  9.4027e-02, -1.5531e-01, -2.9534e-01, -2.5718e-01]],\n",
      "\n",
      "        [[-1.7058e-01,  2.1384e-01,  1.7284e-01, -1.8227e-01, -2.4190e-01,\n",
      "           9.6733e-03,  6.5776e-02, -1.3657e-01,  2.1798e-01, -1.1895e-01]],\n",
      "\n",
      "        [[ 2.7976e-01, -7.1592e-02,  3.2516e-01,  1.4961e-01, -2.1165e-01,\n",
      "          -2.6754e-01, -2.3421e-02, -4.4854e-04, -1.6299e-01,  1.9191e-01]],\n",
      "\n",
      "        [[ 3.3289e-01,  2.9753e-01,  2.6159e-02,  3.1960e-01, -7.7488e-02,\n",
      "           1.9422e-01,  1.0168e-01, -1.5827e-01,  2.2144e-01,  1.8133e-01]],\n",
      "\n",
      "        [[ 1.8108e-01,  1.6514e-01, -2.9799e-01, -1.0200e-01, -1.2324e-01,\n",
      "          -8.6307e-02, -3.7539e-02, -2.3643e-01, -2.3700e-01,  3.1725e-01]],\n",
      "\n",
      "        [[ 1.5928e-01, -6.2867e-02, -1.5724e-01, -3.0187e-01,  3.0146e-02,\n",
      "          -5.5764e-02, -2.8343e-01, -2.4077e-02,  2.3344e-01,  2.4706e-01]],\n",
      "\n",
      "        [[ 1.1766e-01,  3.3486e-01, -2.5757e-02, -2.0037e-01,  2.6410e-01,\n",
      "           4.0849e-02, -5.4501e-02, -3.3342e-01,  2.0376e-01,  2.9959e-01]],\n",
      "\n",
      "        [[-2.8153e-01,  1.7450e-01,  2.7401e-01, -2.3053e-01,  2.7426e-01,\n",
      "          -1.7920e-01,  1.5064e-01, -2.8303e-01,  1.7792e-01, -1.0724e-01]],\n",
      "\n",
      "        [[-1.2587e-01, -2.1320e-01,  1.2881e-01, -2.3220e-01,  2.5689e-01,\n",
      "           4.4550e-02, -1.4857e-01,  2.1527e-01, -3.0917e-01, -6.4659e-02]],\n",
      "\n",
      "        [[ 3.1274e-01, -2.4348e-01,  1.5583e-01,  2.9752e-01, -7.3029e-02,\n",
      "           2.6517e-02, -1.6978e-01, -7.0935e-02,  2.0703e-01, -2.2267e-01]],\n",
      "\n",
      "        [[-2.6178e-02, -2.3617e-01,  1.9081e-01,  2.8452e-01, -6.5271e-02,\n",
      "           2.4141e-01,  1.4013e-01, -1.1737e-01, -9.2917e-02,  2.1293e-01]],\n",
      "\n",
      "        [[ 1.3898e-01,  8.9123e-02,  2.1193e-02, -1.8041e-01,  2.9427e-01,\n",
      "          -2.5458e-01,  3.0880e-01,  3.1444e-01,  1.3063e-01,  2.9523e-01]],\n",
      "\n",
      "        [[-1.4708e-01, -1.0137e-01, -2.4519e-01, -2.7644e-01, -2.2722e-01,\n",
      "           1.1321e-01,  2.5001e-02, -2.1953e-02, -4.5436e-02, -1.6569e-02]],\n",
      "\n",
      "        [[ 9.1905e-02,  3.0027e-01,  2.2692e-01, -1.2644e-01,  1.6332e-01,\n",
      "          -1.9772e-01,  2.8590e-01,  3.8821e-01,  3.7614e-01,  2.6615e-01]],\n",
      "\n",
      "        [[ 2.1371e-01, -3.1069e-01,  9.5718e-02, -2.4904e-01,  2.9122e-01,\n",
      "          -2.8408e-02, -1.5073e-01, -3.5457e-02,  5.4652e-02, -2.1497e-01]],\n",
      "\n",
      "        [[ 1.3084e-01,  3.2485e-01,  1.4110e-01, -2.0939e-01, -2.8940e-01,\n",
      "          -3.9549e-02,  1.5295e-01,  2.4285e-01,  2.5333e-01,  1.5389e-01]],\n",
      "\n",
      "        [[ 1.6237e-01,  3.1711e-01,  1.6325e-01, -1.3694e-01,  1.0519e-01,\n",
      "           5.0427e-02,  1.1138e-01, -1.7191e-01, -2.4633e-01,  2.7433e-01]],\n",
      "\n",
      "        [[-2.0224e-01,  1.8828e-02,  2.5481e-01,  2.4168e-01,  1.2699e-01,\n",
      "          -2.2744e-02,  6.7943e-02, -3.6285e-02,  2.9645e-01, -1.3055e-01]],\n",
      "\n",
      "        [[ 4.8528e-02,  1.7642e-01,  1.5040e-01, -3.1432e-01, -1.5217e-01,\n",
      "           6.9092e-02, -2.1481e-01, -1.8491e-01, -1.0780e-01, -1.2030e-01]],\n",
      "\n",
      "        [[ 4.7627e-02,  1.7409e-01, -1.7937e-01, -2.7678e-01,  1.0461e-01,\n",
      "          -3.4943e-03, -2.1559e-01,  6.3376e-02, -3.3541e-01, -1.3137e-01]],\n",
      "\n",
      "        [[-1.1641e-01,  2.1429e-01,  8.0327e-02,  3.2984e-01, -4.6791e-02,\n",
      "           2.9175e-01,  3.7378e-02, -7.7606e-02, -1.7335e-01, -3.2654e-03]],\n",
      "\n",
      "        [[-3.0455e-01, -1.8504e-01, -1.1467e-01,  2.7348e-01,  1.5969e-01,\n",
      "          -3.4470e-01, -7.1385e-03,  2.7145e-01, -2.0998e-01,  2.8961e-01]],\n",
      "\n",
      "        [[ 2.0403e-01, -2.5086e-01, -2.6645e-01, -2.3873e-01,  1.4637e-01,\n",
      "           2.2996e-01,  2.9070e-01,  6.9968e-02, -9.4872e-02, -2.6143e-01]],\n",
      "\n",
      "        [[ 3.6986e-02,  1.8019e-01, -2.3644e-01,  2.8271e-01, -1.1935e-02,\n",
      "           4.2441e-02, -2.7907e-01, -2.5504e-01,  2.5484e-01, -1.1748e-01]],\n",
      "\n",
      "        [[-2.9581e-01, -5.6931e-02, -9.2201e-02, -6.4614e-02,  9.5389e-02,\n",
      "          -1.2749e-01, -2.1826e-01,  2.1475e-01, -1.7813e-01, -2.6479e-03]],\n",
      "\n",
      "        [[-7.3536e-02,  1.5493e-01,  1.5279e-01,  1.7139e-01,  2.4409e-01,\n",
      "          -8.1937e-02, -3.2480e-01, -2.8684e-01,  1.2889e-02,  2.7667e-01]],\n",
      "\n",
      "        [[ 2.5660e-01, -1.7647e-01,  2.6874e-02, -1.2138e-04,  1.7515e-01,\n",
      "          -1.6514e-01,  2.1760e-01,  2.8970e-01,  1.5037e-01, -3.1414e-01]],\n",
      "\n",
      "        [[ 1.5649e-02, -2.0205e-01, -1.1675e-01, -1.8187e-01,  4.9633e-02,\n",
      "          -2.6969e-01, -1.7023e-01, -1.2713e-01,  9.8376e-03, -2.6305e-01]],\n",
      "\n",
      "        [[ 2.4839e-01, -1.3489e-01, -2.7426e-01,  7.1374e-02,  1.6851e-01,\n",
      "           1.7485e-01,  2.5272e-01, -1.8265e-02,  2.9686e-01,  2.7072e-01]],\n",
      "\n",
      "        [[-3.8998e-02,  1.8746e-01,  2.2760e-01,  1.4024e-01, -2.5161e-01,\n",
      "           2.2570e-01,  3.2425e-01,  8.2590e-02, -9.6669e-02,  2.4518e-01]],\n",
      "\n",
      "        [[-3.2024e-01, -3.0010e-01, -3.0315e-01, -1.6701e-01,  2.0354e-01,\n",
      "          -1.5823e-02, -5.0088e-02, -1.3700e-01, -1.0017e-01,  2.2535e-01]],\n",
      "\n",
      "        [[-1.6221e-01,  5.6019e-02,  2.8678e-01, -7.1274e-03,  2.9227e-01,\n",
      "          -2.1311e-01,  2.5926e-01, -8.8501e-02,  3.1667e-01, -2.7501e-01]],\n",
      "\n",
      "        [[-1.6185e-01,  2.7024e-01,  2.2871e-01,  2.8501e-02, -3.3587e-01,\n",
      "           1.9632e-01,  1.6968e-01,  1.7389e-01,  3.0758e-02, -1.9350e-01]],\n",
      "\n",
      "        [[ 2.7160e-01, -4.4743e-02, -3.1823e-01,  1.3845e-01,  2.9876e-01,\n",
      "          -2.9162e-01,  2.0944e-01,  5.9971e-02, -1.5534e-01,  2.2584e-01]],\n",
      "\n",
      "        [[-2.8641e-01, -2.4495e-01,  9.8587e-03,  2.9056e-01, -3.1011e-01,\n",
      "           9.3061e-02, -1.2695e-01,  8.6509e-02,  1.5929e-01, -1.3779e-01]],\n",
      "\n",
      "        [[-1.4478e-02, -4.8786e-02, -3.3464e-01, -3.5557e-02, -3.6480e-01,\n",
      "           1.1398e-01,  1.4394e-01,  2.7449e-02, -2.0039e-02,  2.9723e-01]],\n",
      "\n",
      "        [[ 1.7716e-01,  2.0963e-01,  5.8884e-02, -3.0956e-01, -7.6851e-02,\n",
      "           1.2101e-01,  1.9908e-01, -8.4050e-02,  1.9690e-01,  1.3150e-01]],\n",
      "\n",
      "        [[-1.2121e-01,  4.0397e-02, -2.3317e-01, -1.9635e-01,  2.3934e-01,\n",
      "          -4.6979e-02,  2.9313e-01,  3.5061e-01,  1.5242e-01,  1.7969e-01]],\n",
      "\n",
      "        [[ 1.6171e-01,  2.7940e-01,  1.1337e-01,  3.0123e-01, -2.0505e-01,\n",
      "          -8.0438e-02, -2.4959e-01, -6.1686e-03,  1.0103e-01, -7.5770e-02]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0091,  0.0297, -0.0227,  0.0327,  0.0376,  0.0567,  0.0283,  0.0609,\n",
      "         0.0454, -0.0118, -0.0023,  0.0193,  0.0257,  0.0471,  0.0140,  0.0252,\n",
      "         0.0438,  0.0302,  0.0264,  0.0547,  0.0193,  0.0217, -0.0169,  0.0359,\n",
      "         0.0363,  0.0382,  0.0419,  0.0463,  0.0287,  0.0347,  0.0454, -0.0220,\n",
      "        -0.0569,  0.0253,  0.0395,  0.0425,  0.0212,  0.0451,  0.0412,  0.0063,\n",
      "         0.0508,  0.0346,  0.0458,  0.0160,  0.0459,  0.0215,  0.0225,  0.0502,\n",
      "         0.0429,  0.0181,  0.0631,  0.0195,  0.0068,  0.0244,  0.0183,  0.0395,\n",
      "         0.0226,  0.0371,  0.0307, -0.0088, -0.0200,  0.0458,  0.0354,  0.0470],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0125, -0.0947,  0.0229, -0.0044, -0.0375],\n",
      "         [-0.1051,  0.0233,  0.0248, -0.0455, -0.0278],\n",
      "         [ 0.0467, -0.0646, -0.0001, -0.0312,  0.0095],\n",
      "         ...,\n",
      "         [-0.0328, -0.0534, -0.0022, -0.0945, -0.0523],\n",
      "         [ 0.0003, -0.0427,  0.0081, -0.0439,  0.0036],\n",
      "         [ 0.0552, -0.0366,  0.0109, -0.0178,  0.0100]],\n",
      "\n",
      "        [[-0.0464,  0.0408, -0.0861, -0.0105,  0.0319],\n",
      "         [ 0.0227,  0.0260, -0.0056, -0.0066, -0.0310],\n",
      "         [ 0.1178, -0.0163, -0.0157, -0.0506, -0.0118],\n",
      "         ...,\n",
      "         [-0.0516, -0.0239,  0.0081, -0.0624,  0.0610],\n",
      "         [ 0.0403, -0.0019, -0.1049, -0.0006, -0.0355],\n",
      "         [-0.0892,  0.0298,  0.0086,  0.0266, -0.0023]],\n",
      "\n",
      "        [[-0.0347,  0.0308, -0.0320,  0.0359, -0.0405],\n",
      "         [ 0.0520,  0.0552,  0.0588,  0.0268,  0.0101],\n",
      "         [-0.0736,  0.0579,  0.0096,  0.0022, -0.0300],\n",
      "         ...,\n",
      "         [-0.0556, -0.0087, -0.0429, -0.0426,  0.0651],\n",
      "         [ 0.0687, -0.0345,  0.0452, -0.0088, -0.0796],\n",
      "         [ 0.0142,  0.0205, -0.0136, -0.0253,  0.0430]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0423, -0.0215,  0.0220, -0.0254,  0.0148],\n",
      "         [ 0.0452,  0.0698, -0.0193, -0.0003,  0.0318],\n",
      "         [-0.0049, -0.0090,  0.0273, -0.0166,  0.0224],\n",
      "         ...,\n",
      "         [-0.0709, -0.0004, -0.0168,  0.0081,  0.0512],\n",
      "         [-0.0042,  0.0039,  0.0012,  0.0291,  0.0033],\n",
      "         [-0.0709,  0.0036, -0.0536,  0.0101,  0.0019]],\n",
      "\n",
      "        [[ 0.0152, -0.0369, -0.0027,  0.0330, -0.0268],\n",
      "         [ 0.1000, -0.0267,  0.0351,  0.0179, -0.0294],\n",
      "         [-0.0708, -0.0616, -0.0212, -0.0027, -0.0224],\n",
      "         ...,\n",
      "         [-0.0027, -0.0268, -0.0430,  0.0452, -0.0243],\n",
      "         [-0.0553,  0.0787, -0.0297,  0.0447,  0.0394],\n",
      "         [ 0.0423, -0.0283,  0.0358,  0.0552,  0.0222]],\n",
      "\n",
      "        [[-0.0276, -0.0082,  0.0354, -0.0642,  0.0538],\n",
      "         [ 0.0287,  0.0047, -0.0700,  0.0272,  0.0160],\n",
      "         [-0.0549,  0.0172, -0.0282,  0.0270, -0.0544],\n",
      "         ...,\n",
      "         [ 0.0522, -0.0084,  0.0704,  0.0363,  0.0271],\n",
      "         [-0.0153, -0.0206, -0.0420,  0.0330,  0.0394],\n",
      "         [ 0.0548,  0.0540,  0.0396,  0.0049, -0.0234]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0412, -0.0279,  0.0303,  0.0324,  0.0575, -0.0356,  0.0431,  0.0412,\n",
      "         0.0595,  0.0482,  0.0555,  0.0284, -0.0397, -0.0525, -0.0475,  0.0260,\n",
      "         0.0580,  0.0486,  0.0526, -0.0103,  0.0430,  0.0391,  0.0005,  0.0563,\n",
      "        -0.0423, -0.0536,  0.0304,  0.0194,  0.0459,  0.0607,  0.0582,  0.0374],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0390,  0.0527,  0.0747, -0.0752, -0.0211],\n",
      "         [-0.0684,  0.0157,  0.0692,  0.0200, -0.0649],\n",
      "         [ 0.0014,  0.0354,  0.0958,  0.0496,  0.0416],\n",
      "         ...,\n",
      "         [ 0.0421,  0.0837, -0.0432, -0.0011,  0.0033],\n",
      "         [ 0.0209, -0.0500,  0.0999, -0.0042,  0.0259],\n",
      "         [-0.0353, -0.0387,  0.0704,  0.0018,  0.0423]],\n",
      "\n",
      "        [[ 0.0415,  0.0074,  0.0697,  0.0330,  0.0787],\n",
      "         [-0.0453,  0.0529,  0.0824,  0.0073,  0.0072],\n",
      "         [-0.0572,  0.0118,  0.0570,  0.0444,  0.0127],\n",
      "         ...,\n",
      "         [ 0.0499,  0.0235, -0.0841, -0.1066, -0.0696],\n",
      "         [ 0.0441,  0.0390,  0.0454, -0.0915, -0.0901],\n",
      "         [-0.0344,  0.0455, -0.1093,  0.0181, -0.0449]],\n",
      "\n",
      "        [[ 0.0702, -0.0057, -0.0728,  0.0101,  0.0290],\n",
      "         [-0.0618, -0.0597,  0.0147,  0.0199, -0.1050],\n",
      "         [-0.0625,  0.0540,  0.0557,  0.0131, -0.0460],\n",
      "         ...,\n",
      "         [-0.0500, -0.0376, -0.0611,  0.0748, -0.0063],\n",
      "         [ 0.0205,  0.0073,  0.0306, -0.0109,  0.0380],\n",
      "         [-0.0282,  0.0242, -0.1018, -0.0137, -0.0071]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0784, -0.0924, -0.0481, -0.0243, -0.0544],\n",
      "         [-0.0382,  0.0601, -0.0909, -0.0443, -0.0374],\n",
      "         [-0.0661, -0.0401,  0.0837,  0.0649,  0.0053],\n",
      "         ...,\n",
      "         [ 0.0084, -0.0478,  0.0562, -0.0163, -0.0075],\n",
      "         [ 0.0897,  0.0030,  0.0366, -0.0339,  0.0767],\n",
      "         [ 0.0123,  0.0668, -0.0447, -0.0154, -0.0354]],\n",
      "\n",
      "        [[ 0.0557,  0.0535,  0.0565,  0.0171,  0.0687],\n",
      "         [ 0.0032,  0.1968,  0.1080,  0.0648, -0.0553],\n",
      "         [ 0.0604,  0.0414,  0.0246, -0.0811, -0.0076],\n",
      "         ...,\n",
      "         [ 0.0139, -0.1100, -0.0159, -0.0966, -0.0137],\n",
      "         [ 0.0669, -0.1071, -0.0571,  0.0463, -0.0587],\n",
      "         [ 0.0090, -0.1643, -0.0498,  0.0009, -0.0015]],\n",
      "\n",
      "        [[-0.0588,  0.0388, -0.0513, -0.0599, -0.0157],\n",
      "         [-0.0497,  0.0769, -0.0004,  0.0989,  0.0466],\n",
      "         [ 0.0761, -0.0445,  0.0189,  0.0709, -0.0081],\n",
      "         ...,\n",
      "         [ 0.0178,  0.0863,  0.0699,  0.0800, -0.0640],\n",
      "         [-0.0544,  0.0033,  0.0019,  0.0750,  0.0443],\n",
      "         [ 0.0463,  0.0111,  0.0790, -0.0471,  0.0282]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0289, -0.0481,  0.0525, -0.0452, -0.0448,  0.0462,  0.0324,  0.0272,\n",
      "         0.0078,  0.0319,  0.0398, -0.0462,  0.0444,  0.0215, -0.0345,  0.0223],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1430, -0.0997,  0.1614,  ..., -0.1272,  0.1134,  0.1352],\n",
      "        [-0.0935,  0.0602,  0.1322,  ...,  0.0922,  0.1284, -0.0422],\n",
      "        [-0.1761,  0.0283, -0.1374,  ...,  0.1375, -0.0518,  0.1658],\n",
      "        ...,\n",
      "        [ 0.0670, -0.0996, -0.0439,  ..., -0.1531, -0.0848,  0.0185],\n",
      "        [-0.1734, -0.0031, -0.0752,  ..., -0.0083, -0.0777, -0.1311],\n",
      "        [ 0.1876, -0.0291,  0.0063,  ...,  0.0391,  0.1661,  0.1631]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1787,  0.1439,  0.0739, -0.1441,  0.0360,  0.0101,  0.0026,  0.1760,\n",
      "        -0.1391,  0.1755,  0.0132,  0.0010,  0.0734, -0.1378, -0.0405,  0.1421,\n",
      "        -0.0315,  0.0301,  0.0157, -0.1622,  0.0857,  0.0588, -0.0461, -0.0010,\n",
      "         0.0316, -0.1123, -0.1128, -0.0773, -0.2031,  0.1606, -0.0740, -0.0771,\n",
      "        -0.1989, -0.2108,  0.1825, -0.1265, -0.1686,  0.1041, -0.1684,  0.1140,\n",
      "        -0.1802, -0.0728,  0.0923, -0.1977, -0.0582, -0.0639,  0.0261, -0.2006,\n",
      "         0.0458,  0.0759, -0.0481, -0.0514, -0.1824,  0.1723,  0.0628,  0.0583,\n",
      "         0.0472, -0.0402, -0.1434,  0.0098], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0910, -0.0455,  0.0408,  ..., -0.0386, -0.0373, -0.0187],\n",
      "        [ 0.0718, -0.0040,  0.0065,  ..., -0.0928, -0.0836,  0.0920],\n",
      "        [-0.0813, -0.0585,  0.0903,  ...,  0.0832,  0.0587, -0.0003],\n",
      "        ...,\n",
      "        [-0.0154,  0.1119, -0.0955,  ...,  0.0056, -0.1137,  0.0899],\n",
      "        [-0.0618, -0.0637,  0.0959,  ..., -0.0326,  0.0277, -0.0049],\n",
      "        [-0.0385,  0.0730, -0.0745,  ...,  0.0267,  0.0925, -0.0171]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0595,  0.0972, -0.0555,  0.1262, -0.0151, -0.1565,  0.0752,  0.0175,\n",
      "        -0.1076, -0.0527, -0.0226, -0.1673, -0.0874, -0.0855, -0.0538,  0.1195,\n",
      "        -0.1108, -0.1334,  0.0405, -0.0413,  0.0278, -0.0362, -0.0028,  0.0226,\n",
      "        -0.1421,  0.1332, -0.0870, -0.0757,  0.1527,  0.1228,  0.0805,  0.1380],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0563,  0.1176, -0.0380,  0.0759, -0.1083],\n",
      "         [ 0.0207,  0.0748, -0.1059,  0.1219,  0.0531],\n",
      "         [-0.1077, -0.0591,  0.0451,  0.0982,  0.0050],\n",
      "         ...,\n",
      "         [-0.0548, -0.0057, -0.0427, -0.0130, -0.0035],\n",
      "         [-0.0230, -0.0252, -0.0792,  0.0951,  0.0957],\n",
      "         [ 0.0501, -0.0592,  0.0369,  0.1371,  0.0199]],\n",
      "\n",
      "        [[ 0.0930,  0.0307,  0.0218, -0.0626, -0.0430],\n",
      "         [ 0.0416,  0.1129,  0.1014,  0.0300,  0.0423],\n",
      "         [ 0.0652, -0.0807,  0.0527, -0.1015,  0.0692],\n",
      "         ...,\n",
      "         [ 0.0479,  0.0036, -0.0638, -0.0378, -0.0048],\n",
      "         [ 0.0659, -0.0033, -0.0260, -0.1137, -0.0670],\n",
      "         [ 0.0538, -0.0057, -0.0336, -0.0744,  0.0202]],\n",
      "\n",
      "        [[ 0.0976, -0.0007,  0.0210,  0.0415, -0.0921],\n",
      "         [-0.0515,  0.0687, -0.0221, -0.0139,  0.0176],\n",
      "         [-0.0934,  0.0194,  0.0589, -0.0532, -0.0504],\n",
      "         ...,\n",
      "         [ 0.0428, -0.0391, -0.1804, -0.0290, -0.0328],\n",
      "         [ 0.0158,  0.0654,  0.0551, -0.0388, -0.0274],\n",
      "         [ 0.0748,  0.0358,  0.0853,  0.0807, -0.0289]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0747, -0.0145, -0.0356,  0.1098, -0.0218],\n",
      "         [ 0.1040, -0.0317,  0.0483,  0.1057, -0.0065],\n",
      "         [ 0.0400, -0.0677, -0.1154, -0.0084,  0.0953],\n",
      "         ...,\n",
      "         [-0.0290, -0.0238, -0.1227,  0.0823, -0.0378],\n",
      "         [-0.0479,  0.0262, -0.0613, -0.0140,  0.0491],\n",
      "         [-0.0696, -0.0404,  0.0527, -0.0803, -0.1072]],\n",
      "\n",
      "        [[ 0.0015,  0.0696, -0.0263, -0.0465,  0.0760],\n",
      "         [-0.0750,  0.0361, -0.1004,  0.1112,  0.0517],\n",
      "         [ 0.0480, -0.1104, -0.0755,  0.0474,  0.0363],\n",
      "         ...,\n",
      "         [ 0.0151,  0.0565,  0.0899, -0.0169,  0.1037],\n",
      "         [-0.0139,  0.0576,  0.0847,  0.0610,  0.0704],\n",
      "         [-0.0543,  0.0339,  0.0076,  0.0610, -0.0868]],\n",
      "\n",
      "        [[ 0.0632,  0.1119, -0.0830,  0.0604,  0.0787],\n",
      "         [-0.0710,  0.0105, -0.1049,  0.0928,  0.0315],\n",
      "         [-0.0973,  0.1188,  0.0360,  0.0167, -0.0439],\n",
      "         ...,\n",
      "         [ 0.0095, -0.1239,  0.0552, -0.0135,  0.0654],\n",
      "         [-0.0433, -0.0406,  0.1013, -0.0012, -0.0230],\n",
      "         [ 0.0289, -0.0571,  0.1191,  0.0336, -0.0882]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0503, -0.0326,  0.0345, -0.0522,  0.0521, -0.0256, -0.0329, -0.0163,\n",
      "        -0.0119,  0.0499,  0.0595, -0.0350,  0.0390,  0.0414,  0.0473,  0.0340],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 0.0239,  0.0716,  0.0498,  0.0711, -0.0009],\n",
      "         [ 0.1270,  0.0320,  0.0519,  0.0735,  0.0132],\n",
      "         [-0.0349,  0.0605, -0.1235,  0.0364,  0.0408],\n",
      "         ...,\n",
      "         [ 0.0922, -0.0330,  0.0384, -0.1048,  0.0313],\n",
      "         [-0.0325, -0.0212,  0.0422,  0.0425, -0.0991],\n",
      "         [-0.0149,  0.0653,  0.0291,  0.0045,  0.1260]],\n",
      "\n",
      "        [[-0.0128,  0.0751, -0.0110, -0.1572, -0.1151],\n",
      "         [-0.0266, -0.0547, -0.0578,  0.1341, -0.0086],\n",
      "         [-0.1204, -0.0486, -0.1015,  0.0720, -0.1262],\n",
      "         ...,\n",
      "         [ 0.0747,  0.0426, -0.0858, -0.0603, -0.0815],\n",
      "         [-0.1054,  0.0733, -0.1048, -0.0953, -0.0514],\n",
      "         [-0.0254, -0.0154, -0.1170, -0.0590,  0.0077]],\n",
      "\n",
      "        [[-0.0185,  0.0898, -0.0246, -0.0758, -0.0213],\n",
      "         [-0.1067, -0.0223,  0.0205, -0.0082, -0.0309],\n",
      "         [-0.0044,  0.0553,  0.0876,  0.0582,  0.0438],\n",
      "         ...,\n",
      "         [-0.0404,  0.0108, -0.0869, -0.0087,  0.1035],\n",
      "         [ 0.0837,  0.0525,  0.0679,  0.0862, -0.0389],\n",
      "         [-0.0376,  0.0365, -0.0011,  0.0444,  0.0118]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0093, -0.1063, -0.0137, -0.1488,  0.0719],\n",
      "         [-0.0049, -0.0111,  0.1260,  0.1169,  0.0595],\n",
      "         [ 0.0514, -0.0520, -0.0752, -0.0591, -0.1188],\n",
      "         ...,\n",
      "         [ 0.0918, -0.0238, -0.0532, -0.1331, -0.0500],\n",
      "         [ 0.0455, -0.0447, -0.1154,  0.0816,  0.0531],\n",
      "         [-0.0482, -0.1146, -0.0084, -0.0389, -0.0477]],\n",
      "\n",
      "        [[ 0.0927,  0.0174,  0.0771,  0.0780, -0.1225],\n",
      "         [ 0.0296, -0.0874, -0.0692, -0.0379,  0.0427],\n",
      "         [ 0.0299, -0.0936, -0.0179,  0.0319, -0.1097],\n",
      "         ...,\n",
      "         [ 0.0957, -0.0049,  0.0319,  0.0167, -0.0157],\n",
      "         [ 0.0542, -0.1109, -0.0366, -0.1043,  0.0476],\n",
      "         [ 0.0984,  0.0898,  0.0167, -0.0895, -0.0733]],\n",
      "\n",
      "        [[ 0.0152, -0.0425, -0.0387, -0.0566, -0.1299],\n",
      "         [-0.1086,  0.0018, -0.0532,  0.0413,  0.1567],\n",
      "         [ 0.0702, -0.1122, -0.0600, -0.0176,  0.0211],\n",
      "         ...,\n",
      "         [ 0.0708, -0.1874, -0.0364,  0.0623,  0.0681],\n",
      "         [ 0.0802,  0.0622,  0.0032,  0.0431, -0.0256],\n",
      "         [ 0.1538,  0.1317,  0.0030, -0.1452, -0.1495]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0277, -0.0302,  0.0082,  0.0395,  0.0280,  0.0546,  0.0338, -0.0301,\n",
      "        -0.0508,  0.0447, -0.0490, -0.0538, -0.0448,  0.0302, -0.0474,  0.0574,\n",
      "         0.0406,  0.0438, -0.0263,  0.0445,  0.0440,  0.0268,  0.0415,  0.0281,\n",
      "        -0.0372, -0.0335,  0.0349, -0.0550,  0.0088, -0.0423, -0.0652, -0.0455],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[ 2.4207e-02, -6.4110e-04,  4.4881e-02,  ..., -1.5832e-02,\n",
      "           2.2332e-02, -9.0957e-02],\n",
      "         [-1.5445e-02,  4.7072e-02,  2.9918e-02,  ..., -9.5487e-02,\n",
      "          -6.2533e-02, -2.7958e-02],\n",
      "         [-2.8905e-02, -2.3074e-05, -7.1340e-02,  ...,  1.4528e-02,\n",
      "           2.0521e-02,  4.3581e-02],\n",
      "         ...,\n",
      "         [ 5.6893e-02, -1.7663e-02,  5.5215e-02,  ..., -4.5053e-02,\n",
      "          -9.2355e-02, -1.0400e-01],\n",
      "         [-4.2184e-02, -6.1206e-02,  3.8717e-04,  ...,  5.4505e-02,\n",
      "           2.5008e-02, -8.8328e-03],\n",
      "         [ 3.8703e-02,  1.3617e-02,  6.4066e-03,  ...,  8.0378e-02,\n",
      "           6.8240e-02,  6.4568e-02]],\n",
      "\n",
      "        [[ 1.2992e-02,  6.9215e-02,  5.2160e-02,  ...,  1.9402e-02,\n",
      "          -3.6276e-02, -1.0036e-02],\n",
      "         [-3.3286e-02,  3.7124e-02, -2.9515e-02,  ...,  2.4649e-02,\n",
      "          -1.9410e-02, -4.4134e-03],\n",
      "         [ 2.6259e-02, -3.2437e-02, -1.5622e-02,  ..., -5.7512e-02,\n",
      "          -5.3951e-02, -2.7487e-02],\n",
      "         ...,\n",
      "         [-2.1769e-02,  5.0531e-02,  4.1576e-02,  ..., -1.4431e-02,\n",
      "           6.5468e-02,  1.1221e-02],\n",
      "         [-6.2787e-02, -6.4703e-03,  1.4149e-02,  ..., -1.0084e-02,\n",
      "           1.5817e-02, -4.6559e-02],\n",
      "         [-4.0501e-02,  9.0681e-03,  4.9041e-02,  ...,  4.3477e-02,\n",
      "          -8.3645e-02, -8.5559e-02]],\n",
      "\n",
      "        [[ 3.8535e-02,  4.4203e-02,  4.7387e-02,  ...,  4.0449e-02,\n",
      "           5.6932e-02,  2.6860e-02],\n",
      "         [-2.9093e-02,  4.6393e-02, -5.3336e-02,  ...,  3.3833e-02,\n",
      "           9.0230e-02,  5.7319e-02],\n",
      "         [-1.0292e-02,  3.7012e-02, -3.7178e-02,  ..., -3.8121e-02,\n",
      "          -1.1038e-02,  1.0447e-02],\n",
      "         ...,\n",
      "         [ 3.6701e-02, -1.3346e-02, -2.6178e-02,  ...,  7.5552e-02,\n",
      "           2.4911e-02,  3.5587e-02],\n",
      "         [-8.9758e-02, -2.9876e-02,  2.8221e-03,  ...,  1.5070e-02,\n",
      "          -4.9186e-02, -8.1930e-02],\n",
      "         [ 6.0111e-03,  2.4377e-02,  1.3707e-02,  ...,  8.8795e-03,\n",
      "          -6.6068e-02, -6.9919e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.0980e-02,  5.5803e-02,  6.6154e-02,  ...,  5.3758e-03,\n",
      "          -3.4130e-02, -4.2978e-02],\n",
      "         [ 2.8698e-02,  4.0791e-02, -3.8854e-02,  ..., -1.1229e-01,\n",
      "          -1.0484e-01, -2.3173e-02],\n",
      "         [-5.6717e-02,  5.7759e-03,  3.5257e-02,  ..., -2.1862e-04,\n",
      "           1.2286e-02,  5.7672e-02],\n",
      "         ...,\n",
      "         [ 4.6090e-03,  1.5654e-03, -1.7719e-02,  ..., -7.7570e-02,\n",
      "          -7.1091e-02, -5.4889e-02],\n",
      "         [ 2.6225e-02, -6.6453e-03,  7.5727e-03,  ..., -5.3233e-03,\n",
      "           6.8336e-02,  2.4470e-02],\n",
      "         [ 5.9466e-02,  5.4694e-02, -5.3400e-02,  ...,  5.0612e-02,\n",
      "           4.7158e-02,  1.7209e-02]],\n",
      "\n",
      "        [[-1.1989e-01, -4.0844e-02, -3.3371e-02,  ..., -2.5501e-02,\n",
      "           4.2416e-02, -1.3471e-02],\n",
      "         [ 1.5848e-02,  4.1972e-02, -1.3142e-02,  ...,  2.6090e-02,\n",
      "          -6.5219e-02,  9.0269e-03],\n",
      "         [ 8.2798e-02,  6.2718e-02,  3.1929e-02,  ...,  2.8762e-02,\n",
      "          -2.1738e-02, -2.6153e-04],\n",
      "         ...,\n",
      "         [ 2.3644e-02,  3.9992e-03, -2.0240e-02,  ..., -2.7350e-02,\n",
      "          -1.0224e-02, -7.3125e-02],\n",
      "         [ 1.2908e-01, -3.8637e-02, -2.6733e-02,  ...,  9.9391e-03,\n",
      "           5.7350e-02,  9.2575e-02],\n",
      "         [ 5.4355e-02,  3.2041e-03,  4.6986e-02,  ..., -1.1150e-01,\n",
      "           4.1002e-02,  8.6697e-02]],\n",
      "\n",
      "        [[-1.4395e-02, -8.7728e-02, -1.1378e-02,  ..., -3.0958e-02,\n",
      "          -3.8998e-02, -5.2535e-02],\n",
      "         [ 3.6560e-02, -3.0765e-02,  1.5072e-02,  ..., -4.2724e-02,\n",
      "          -7.1632e-02,  1.9756e-02],\n",
      "         [ 6.7754e-02,  5.5813e-02,  1.5949e-02,  ...,  1.7453e-02,\n",
      "           7.8818e-03,  5.9309e-02],\n",
      "         ...,\n",
      "         [ 4.8031e-03, -3.2518e-02,  1.4227e-02,  ..., -1.8981e-03,\n",
      "          -6.2652e-03, -7.8385e-02],\n",
      "         [ 6.9160e-02, -1.1221e-02, -4.5644e-02,  ...,  3.4740e-02,\n",
      "           4.3347e-02,  9.4767e-02],\n",
      "         [-7.1884e-03, -3.5555e-02, -4.4124e-02,  ...,  2.7012e-02,\n",
      "           8.1645e-02,  7.4865e-02]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0292, -0.0244, -0.0248, -0.0384, -0.0294, -0.0291,  0.0139, -0.0316,\n",
      "         0.0376,  0.0359, -0.0355, -0.0324, -0.0339,  0.0283, -0.0391,  0.0259,\n",
      "         0.0240,  0.0163, -0.0367,  0.0383, -0.0255, -0.0362, -0.0343,  0.0369,\n",
      "         0.0047, -0.0363, -0.0330, -0.0430, -0.0333,  0.0341,  0.0425, -0.0424,\n",
      "        -0.0206,  0.0300, -0.0223,  0.0268, -0.0213, -0.0391,  0.0351,  0.0457,\n",
      "         0.0143,  0.0385,  0.0407,  0.0338, -0.0206, -0.0295,  0.0216, -0.0314,\n",
      "        -0.0278,  0.0293, -0.0371, -0.0330, -0.0248, -0.0174,  0.0386,  0.0410,\n",
      "        -0.0388, -0.0365, -0.0179,  0.0229, -0.0389,  0.0159,  0.0249,  0.0303],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[-0.0402, -0.0224, -0.0116, -0.0292,  0.0582,  0.0145,  0.0691,\n",
      "           0.0613,  0.0569,  0.0296],\n",
      "         [-0.0465, -0.0195,  0.0087, -0.0448, -0.0192, -0.0256,  0.0003,\n",
      "           0.0167, -0.0452, -0.0422],\n",
      "         [-0.0035, -0.0403, -0.0192, -0.0323, -0.0579, -0.0459, -0.0351,\n",
      "          -0.0398, -0.0124, -0.0396],\n",
      "         [-0.0348, -0.0406, -0.0255, -0.0240, -0.0533, -0.0095, -0.0457,\n",
      "          -0.0374, -0.0500, -0.0384],\n",
      "         [-0.0463, -0.0558, -0.0603, -0.0075, -0.0619,  0.0350, -0.0403,\n",
      "           0.0204, -0.0153,  0.0036],\n",
      "         [ 0.0384, -0.0104, -0.0350, -0.0155, -0.0096, -0.0244, -0.0267,\n",
      "          -0.0329, -0.0524,  0.0090],\n",
      "         [ 0.0333, -0.0248,  0.0024, -0.0509,  0.0097,  0.0500,  0.0273,\n",
      "           0.0549,  0.0386,  0.0492],\n",
      "         [-0.0659, -0.0843, -0.0327, -0.0640, -0.0402,  0.0308,  0.0049,\n",
      "          -0.0212,  0.0378,  0.0441],\n",
      "         [ 0.0681,  0.0578,  0.0562,  0.0531,  0.0283,  0.0261, -0.0071,\n",
      "           0.0343, -0.0182, -0.0007],\n",
      "         [-0.0002,  0.0393, -0.0012,  0.0084,  0.0032, -0.0180,  0.0275,\n",
      "           0.0490,  0.0130,  0.0497],\n",
      "         [-0.0485,  0.0040,  0.0099, -0.0437, -0.0660, -0.0259, -0.0271,\n",
      "           0.0186, -0.0176, -0.0077],\n",
      "         [ 0.0229,  0.0097, -0.0229,  0.0219, -0.0535, -0.0086, -0.0325,\n",
      "          -0.0635, -0.0525, -0.0446],\n",
      "         [-0.0054,  0.0264, -0.0110, -0.0319, -0.0513, -0.0014, -0.0252,\n",
      "          -0.0282, -0.0179, -0.0314],\n",
      "         [ 0.0028,  0.0209, -0.0026,  0.0596,  0.0569,  0.0457, -0.0303,\n",
      "           0.0427, -0.0376, -0.0151],\n",
      "         [-0.0123, -0.0444, -0.0162, -0.0163, -0.0026,  0.0075,  0.0143,\n",
      "          -0.0191, -0.0402, -0.0176],\n",
      "         [ 0.0296, -0.0217,  0.0218, -0.0039, -0.0084,  0.0449, -0.0209,\n",
      "           0.0262,  0.0337,  0.0312],\n",
      "         [ 0.0526,  0.0442,  0.0615,  0.0453,  0.0263, -0.0089, -0.0086,\n",
      "           0.0112,  0.0126,  0.0073],\n",
      "         [-0.0178,  0.0310,  0.0391,  0.0211,  0.0501, -0.0189,  0.0343,\n",
      "          -0.0033,  0.0439,  0.0530],\n",
      "         [ 0.0140, -0.0416, -0.0381,  0.0193, -0.0680, -0.0398, -0.0541,\n",
      "          -0.0077, -0.0535, -0.0329],\n",
      "         [ 0.0504,  0.0094, -0.0201,  0.0419,  0.0517,  0.0186, -0.0020,\n",
      "           0.0441,  0.0060,  0.0430],\n",
      "         [-0.0118, -0.0360,  0.0099,  0.0204, -0.0642,  0.0273, -0.0399,\n",
      "          -0.0071, -0.0353,  0.0291],\n",
      "         [ 0.0355,  0.0109, -0.0162, -0.0273, -0.0495, -0.0399, -0.0648,\n",
      "          -0.0482, -0.0018, -0.0180],\n",
      "         [-0.0465, -0.0733, -0.0008, -0.0639, -0.0349,  0.0211,  0.0122,\n",
      "          -0.0314,  0.0252, -0.0180],\n",
      "         [ 0.0208,  0.0394,  0.0553, -0.0116,  0.0255,  0.0197,  0.0397,\n",
      "           0.0207, -0.0294, -0.0306],\n",
      "         [ 0.0474,  0.0043,  0.0421,  0.0436,  0.0636,  0.0293, -0.0093,\n",
      "           0.0359, -0.0028, -0.0190],\n",
      "         [-0.0406, -0.0179,  0.0276, -0.0083, -0.0618, -0.0367, -0.0357,\n",
      "          -0.0475, -0.0343, -0.0017],\n",
      "         [-0.0401, -0.0407, -0.0275,  0.0163, -0.0173, -0.0043, -0.0027,\n",
      "          -0.0369, -0.0178, -0.0553],\n",
      "         [-0.0642, -0.0827, -0.0859, -0.0180, -0.0423,  0.0579,  0.0295,\n",
      "          -0.0168,  0.0459,  0.0058],\n",
      "         [-0.0048, -0.0622, -0.0511, -0.0401, -0.0554, -0.0137,  0.0449,\n",
      "          -0.0094,  0.0073, -0.0200],\n",
      "         [-0.0127, -0.0284,  0.0267, -0.0002,  0.0466,  0.0364,  0.0333,\n",
      "           0.0039,  0.0420,  0.0344],\n",
      "         [ 0.0056, -0.0002, -0.0418, -0.0212,  0.0001,  0.0494,  0.0360,\n",
      "           0.0579,  0.0340,  0.0704],\n",
      "         [-0.0045,  0.0160,  0.0231,  0.0591, -0.0108,  0.0047, -0.0501,\n",
      "          -0.0460, -0.0563, -0.0431],\n",
      "         [-0.0064, -0.0575, -0.0186, -0.0681, -0.0329,  0.0539, -0.0030,\n",
      "          -0.0185,  0.0006,  0.0218],\n",
      "         [ 0.0054, -0.0208,  0.0178,  0.0397,  0.0065,  0.0467,  0.0291,\n",
      "           0.0474,  0.0577, -0.0104],\n",
      "         [-0.0556, -0.0398, -0.0561, -0.0630, -0.0474, -0.0286,  0.0307,\n",
      "           0.0256,  0.0116, -0.0271],\n",
      "         [ 0.0641,  0.0412,  0.0257,  0.0357,  0.0556,  0.0231, -0.0341,\n",
      "           0.0120, -0.0109,  0.0277],\n",
      "         [-0.0565, -0.0594, -0.0118, -0.0302, -0.0390, -0.0172,  0.0429,\n",
      "           0.0020, -0.0342, -0.0144],\n",
      "         [-0.0405, -0.0502, -0.0017, -0.0473, -0.0563,  0.0187,  0.0067,\n",
      "          -0.0150, -0.0500, -0.0565],\n",
      "         [ 0.0056, -0.0144,  0.0349,  0.0203,  0.0170,  0.0357,  0.0360,\n",
      "           0.0454,  0.0359,  0.0428],\n",
      "         [ 0.0209,  0.0667,  0.0624,  0.0532,  0.0563, -0.0012, -0.0001,\n",
      "          -0.0323,  0.0021, -0.0255],\n",
      "         [-0.0158,  0.0397, -0.0079, -0.0276,  0.0641,  0.0284,  0.0188,\n",
      "           0.0548,  0.0403,  0.0104],\n",
      "         [ 0.0183,  0.0575,  0.0651,  0.0630, -0.0007,  0.0206,  0.0278,\n",
      "          -0.0244,  0.0132, -0.0142],\n",
      "         [ 0.0194,  0.0366, -0.0254,  0.0110,  0.0066,  0.0050, -0.0051,\n",
      "           0.0497,  0.0642,  0.0601],\n",
      "         [-0.0075, -0.0162,  0.0216, -0.0161,  0.0535, -0.0106,  0.0548,\n",
      "           0.0553,  0.0641,  0.0227],\n",
      "         [-0.0159, -0.0037,  0.0074, -0.0111, -0.0516, -0.0378, -0.0492,\n",
      "          -0.0402, -0.0339, -0.0321],\n",
      "         [-0.0486, -0.0095, -0.0262,  0.0107, -0.0027,  0.0312, -0.0386,\n",
      "           0.0135, -0.0598, -0.0473],\n",
      "         [ 0.0580,  0.0558,  0.0447,  0.0585, -0.0106, -0.0388,  0.0287,\n",
      "          -0.0094,  0.0050,  0.0310],\n",
      "         [-0.0330, -0.0495, -0.0378, -0.0197, -0.0491,  0.0114, -0.0192,\n",
      "          -0.0432, -0.0225, -0.0147],\n",
      "         [ 0.0159, -0.0230,  0.0063,  0.0016, -0.0461, -0.0479, -0.0256,\n",
      "          -0.0144, -0.0210, -0.0227],\n",
      "         [ 0.0020,  0.0434, -0.0152,  0.0423,  0.0226,  0.0444,  0.0248,\n",
      "          -0.0059, -0.0168,  0.0327],\n",
      "         [-0.0084, -0.0366, -0.0391, -0.0571, -0.0654, -0.0464, -0.0123,\n",
      "           0.0119, -0.0164, -0.0179],\n",
      "         [ 0.0240,  0.0042,  0.0134, -0.0326, -0.0551, -0.0632, -0.0629,\n",
      "          -0.0149, -0.0301,  0.0035],\n",
      "         [-0.0223, -0.0942, -0.0851, -0.0776, -0.0229,  0.0227,  0.0597,\n",
      "           0.0310, -0.0109,  0.0396],\n",
      "         [ 0.0093, -0.0106, -0.0404, -0.0485, -0.0658, -0.0365, -0.0008,\n",
      "           0.0009, -0.0037,  0.0268],\n",
      "         [-0.0075,  0.0039,  0.0280,  0.0342,  0.0032,  0.0221,  0.0433,\n",
      "           0.0106,  0.0302,  0.0082],\n",
      "         [-0.0196, -0.0370, -0.0434,  0.0021,  0.0251,  0.0448,  0.0575,\n",
      "           0.0406,  0.0671,  0.0572],\n",
      "         [-0.0231,  0.0339,  0.0147,  0.0140,  0.0025, -0.0328, -0.0070,\n",
      "          -0.0332, -0.0528, -0.0711],\n",
      "         [-0.0635, -0.0232, -0.0424,  0.0095, -0.0284, -0.0345, -0.0511,\n",
      "           0.0080, -0.0236, -0.0094],\n",
      "         [-0.0365, -0.0065, -0.0005, -0.0234, -0.0317, -0.0390, -0.0540,\n",
      "          -0.0275, -0.0045, -0.0069],\n",
      "         [ 0.0314,  0.0121, -0.0158,  0.0404,  0.0357,  0.0169,  0.0530,\n",
      "           0.0417,  0.0311,  0.0203],\n",
      "         [-0.0561, -0.0535, -0.0381, -0.0588,  0.0146,  0.0473,  0.0329,\n",
      "           0.0083, -0.0394, -0.0102],\n",
      "         [-0.0436,  0.0131, -0.0144, -0.0171,  0.0485,  0.0043,  0.0459,\n",
      "           0.0261,  0.0448,  0.0689],\n",
      "         [ 0.0014,  0.0672,  0.0366,  0.0199,  0.0400,  0.0262,  0.0123,\n",
      "          -0.0341, -0.0138, -0.0082],\n",
      "         [ 0.0408,  0.0114,  0.0312,  0.0306,  0.0536,  0.0300,  0.0232,\n",
      "          -0.0034, -0.0263,  0.0422]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0508], requires_grad=True)]\n",
      "At least 1 param\n",
      "Get hyperes\n",
      "Set hypers\n",
      "Set frozen idx\n",
      "Return optimizer\n",
      "-- opt_func -> \n",
      "Estoy aqui\n",
      "--> bn_bias_state\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "mapping var [Parameter containing:\n",
      "tensor([ 0.0091,  0.0297, -0.0227,  0.0327,  0.0376,  0.0567,  0.0283,  0.0609,\n",
      "         0.0454, -0.0118, -0.0023,  0.0193,  0.0257,  0.0471,  0.0140,  0.0252,\n",
      "         0.0438,  0.0302,  0.0264,  0.0547,  0.0193,  0.0217, -0.0169,  0.0359,\n",
      "         0.0363,  0.0382,  0.0419,  0.0463,  0.0287,  0.0347,  0.0454, -0.0220,\n",
      "        -0.0569,  0.0253,  0.0395,  0.0425,  0.0212,  0.0451,  0.0412,  0.0063,\n",
      "         0.0508,  0.0346,  0.0458,  0.0160,  0.0459,  0.0215,  0.0225,  0.0502,\n",
      "         0.0429,  0.0181,  0.0631,  0.0195,  0.0068,  0.0244,  0.0183,  0.0395,\n",
      "         0.0226,  0.0371,  0.0307, -0.0088, -0.0200,  0.0458,  0.0354,  0.0470],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0091,  0.0297, -0.0227,  0.0327,  0.0376,  0.0567,  0.0283,  0.0609,\n",
      "         0.0454, -0.0118, -0.0023,  0.0193,  0.0257,  0.0471,  0.0140,  0.0252,\n",
      "         0.0438,  0.0302,  0.0264,  0.0547,  0.0193,  0.0217, -0.0169,  0.0359,\n",
      "         0.0363,  0.0382,  0.0419,  0.0463,  0.0287,  0.0347,  0.0454, -0.0220,\n",
      "        -0.0569,  0.0253,  0.0395,  0.0425,  0.0212,  0.0451,  0.0412,  0.0063,\n",
      "         0.0508,  0.0346,  0.0458,  0.0160,  0.0459,  0.0215,  0.0225,  0.0502,\n",
      "         0.0429,  0.0181,  0.0631,  0.0195,  0.0068,  0.0244,  0.0183,  0.0395,\n",
      "         0.0226,  0.0371,  0.0307, -0.0088, -0.0200,  0.0458,  0.0354,  0.0470],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0412, -0.0279,  0.0303,  0.0324,  0.0575, -0.0356,  0.0431,  0.0412,\n",
      "         0.0595,  0.0482,  0.0555,  0.0284, -0.0397, -0.0525, -0.0475,  0.0260,\n",
      "         0.0580,  0.0486,  0.0526, -0.0103,  0.0430,  0.0391,  0.0005,  0.0563,\n",
      "        -0.0423, -0.0536,  0.0304,  0.0194,  0.0459,  0.0607,  0.0582,  0.0374],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0289, -0.0481,  0.0525, -0.0452, -0.0448,  0.0462,  0.0324,  0.0272,\n",
      "         0.0078,  0.0319,  0.0398, -0.0462,  0.0444,  0.0215, -0.0345,  0.0223],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1787,  0.1439,  0.0739, -0.1441,  0.0360,  0.0101,  0.0026,  0.1760,\n",
      "        -0.1391,  0.1755,  0.0132,  0.0010,  0.0734, -0.1378, -0.0405,  0.1421,\n",
      "        -0.0315,  0.0301,  0.0157, -0.1622,  0.0857,  0.0588, -0.0461, -0.0010,\n",
      "         0.0316, -0.1123, -0.1128, -0.0773, -0.2031,  0.1606, -0.0740, -0.0771,\n",
      "        -0.1989, -0.2108,  0.1825, -0.1265, -0.1686,  0.1041, -0.1684,  0.1140,\n",
      "        -0.1802, -0.0728,  0.0923, -0.1977, -0.0582, -0.0639,  0.0261, -0.2006,\n",
      "         0.0458,  0.0759, -0.0481, -0.0514, -0.1824,  0.1723,  0.0628,  0.0583,\n",
      "         0.0472, -0.0402, -0.1434,  0.0098], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0595,  0.0972, -0.0555,  0.1262, -0.0151, -0.1565,  0.0752,  0.0175,\n",
      "        -0.1076, -0.0527, -0.0226, -0.1673, -0.0874, -0.0855, -0.0538,  0.1195,\n",
      "        -0.1108, -0.1334,  0.0405, -0.0413,  0.0278, -0.0362, -0.0028,  0.0226,\n",
      "        -0.1421,  0.1332, -0.0870, -0.0757,  0.1527,  0.1228,  0.0805,  0.1380],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0503, -0.0326,  0.0345, -0.0522,  0.0521, -0.0256, -0.0329, -0.0163,\n",
      "        -0.0119,  0.0499,  0.0595, -0.0350,  0.0390,  0.0414,  0.0473,  0.0340],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0277, -0.0302,  0.0082,  0.0395,  0.0280,  0.0546,  0.0338, -0.0301,\n",
      "        -0.0508,  0.0447, -0.0490, -0.0538, -0.0448,  0.0302, -0.0474,  0.0574,\n",
      "         0.0406,  0.0438, -0.0263,  0.0445,  0.0440,  0.0268,  0.0415,  0.0281,\n",
      "        -0.0372, -0.0335,  0.0349, -0.0550,  0.0088, -0.0423, -0.0652, -0.0455],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0292, -0.0244, -0.0248, -0.0384, -0.0294, -0.0291,  0.0139, -0.0316,\n",
      "         0.0376,  0.0359, -0.0355, -0.0324, -0.0339,  0.0283, -0.0391,  0.0259,\n",
      "         0.0240,  0.0163, -0.0367,  0.0383, -0.0255, -0.0362, -0.0343,  0.0369,\n",
      "         0.0047, -0.0363, -0.0330, -0.0430, -0.0333,  0.0341,  0.0425, -0.0424,\n",
      "        -0.0206,  0.0300, -0.0223,  0.0268, -0.0213, -0.0391,  0.0351,  0.0457,\n",
      "         0.0143,  0.0385,  0.0407,  0.0338, -0.0206, -0.0295,  0.0216, -0.0314,\n",
      "        -0.0278,  0.0293, -0.0371, -0.0330, -0.0248, -0.0174,  0.0386,  0.0410,\n",
      "        -0.0388, -0.0365, -0.0179,  0.0229, -0.0389,  0.0159,  0.0249,  0.0303],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0292, -0.0244, -0.0248, -0.0384, -0.0294, -0.0291,  0.0139, -0.0316,\n",
      "         0.0376,  0.0359, -0.0355, -0.0324, -0.0339,  0.0283, -0.0391,  0.0259,\n",
      "         0.0240,  0.0163, -0.0367,  0.0383, -0.0255, -0.0362, -0.0343,  0.0369,\n",
      "         0.0047, -0.0363, -0.0330, -0.0430, -0.0333,  0.0341,  0.0425, -0.0424,\n",
      "        -0.0206,  0.0300, -0.0223,  0.0268, -0.0213, -0.0391,  0.0351,  0.0457,\n",
      "         0.0143,  0.0385,  0.0407,  0.0338, -0.0206, -0.0295,  0.0216, -0.0314,\n",
      "        -0.0278,  0.0293, -0.0371, -0.0330, -0.0248, -0.0174,  0.0386,  0.0410,\n",
      "        -0.0388, -0.0365, -0.0179,  0.0229, -0.0389,  0.0159,  0.0249,  0.0303],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.0508], requires_grad=True), Parameter containing:\n",
      "tensor([0.0508], requires_grad=True)]\n",
      "Returning\n",
      "Got norm bias state\n",
      "--> bn_bias_state\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "--> norm bias params\n",
      "Getting res\n",
      "--> norm bias params\n",
      "Getting res\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "Okay got res\n",
      "About to return\n",
      "mapping var []\n",
      "Returning\n",
      "Create opt -->\n"
     ]
    }
   ],
   "source": [
    "aux_learn = learn.export_and_get()\n",
    "if config.use_wandb: \n",
    "    ar = ReferenceArtifact(aux_learn, f'dcae', type='learner', metadata=dict(run.config))\n",
    "    run.log_artifact(ar, aliases=f'run-{run.project}-{run.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline models (To rewrite)\n",
    "\n",
    "Calculate baseline models taking into account that the best prediction is the average and median value of each of the windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the autoencoder\n",
    "\n",
    "Let's validate the autoencoder quality visually:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the best and the worst k predictions using the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Enabling Vs Code execution ...\n"
     ]
    }
   ],
   "source": [
    "interp = Interpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([217.3161, 183.4062, 173.9230]), tensor([198,  32,  97]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_losses = interp.top_losses(3)\n",
    "top_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in top_losses.indices: dls.dataset[i][0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
