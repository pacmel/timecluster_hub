{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder) and uses them as input for a \n",
    "dimensionality reduction algorithm, to generate projectsion of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight & Biases\n",
    "import wandb\n",
    "\n",
    "#Yaml\n",
    "from yaml import load, FullLoader\n",
    "\n",
    "#Embeddings\n",
    "from dvats.all import *\n",
    "from tsai.data.preparation import prepare_forecasting_data\n",
    "from tsai.data.validation import get_forecasting_splits\n",
    "from fastcore.all import *\n",
    "\n",
    "#Dimensionality reduction\n",
    "from tsai.imports import *\n",
    "\n",
    "#Clustering\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_memory_usage = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 4089\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m17%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if check_memory_usage:\n",
    "    import nbs_pipeline.utils.memory as mem\n",
    "    import torch \n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get W&B API\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put here everything that could be needed if this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Change to config.py & tml version when fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Buscando una combinación buena\n",
    "cpu_flag = False\n",
    "\n",
    "if cpu_flag:\n",
    "    n_neighbors = 15\n",
    "    min_dist = 0.1\n",
    "else: \n",
    "    n_neighbors = 15 #200\n",
    "    min_dist = 0.1 #0.0001\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    use_wandb = False, # Whether to use or not wandb for experiment tracking\n",
    "    wandb_group = None, # Whether to group this run in a wandb group\n",
    "    wandb_entity = os.environ['WANDB_ENTITY'], # The entity to use for wandb,\n",
    "    wandb_project = os.environ['WANDB_PROJECT'], # The project to use for wandb,\n",
    "    dr_artifact_name = None, # * Set to None for using the default one (encoder validation set)\n",
    "    enc_artifact = 'mi-santamaria/deepvats/mvp-SWV:latest', # Name:version of the encoder artifact\n",
    "    n_neighbors = n_neighbors, #15, #UMAP\n",
    "    min_dist = min_dist, #0.1, #UMAP,\n",
    "    random_state = int(1234), # UMAP\n",
    "    metric = 'euclidean',\n",
    "    cpu = cpu_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model needs to restore the encoder model fitted in the notebook `02x`, as well as the data and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"04_dimensionality_reduction\"\n",
    "runname = name\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/work/nbs_pipeline/04_dimensionality_reduction.ipynb.\n"
     ]
    }
   ],
   "source": [
    "run_dr = wandb.init(\n",
    "    entity=config.wandb_entity,\n",
    "    project=config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group=config.wandb_group,\n",
    "    allow_val_change=True, \n",
    "    job_type='dimensionality_reduction', \n",
    "    mode='online' if config.use_wandb else 'disabled',\n",
    "    anonymous = 'never' if config.use_wandb else 'must',\n",
    "    config=config,\n",
    "    resume = 'allow',\n",
    "    name = runname\n",
    "    #resume=False\n",
    ")\n",
    "config_dr = wandb.config # Object for storing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config_dr.use_wandb else api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.71,\n",
       " 'w': 30,\n",
       " 'MVP': {'r': 0.71,\n",
       "  'lm': 3.0,\n",
       "  'crit': None,\n",
       "  'sync': False,\n",
       "  'fname': 'encoder_MVP',\n",
       "  'dropout': 0.1,\n",
       "  'verbose': False,\n",
       "  'stateful': True,\n",
       "  'save_best': True,\n",
       "  'nan_to_num': 0,\n",
       "  'custom_mask': None,\n",
       "  'future_mask': False,\n",
       "  'weights_path': None,\n",
       "  'variable_mask': False,\n",
       "  'subsequence_mask': True},\n",
       " 'ref': {'hash': '7568234551722072987',\n",
       "  'type': \"<class 'fastai.learner.Learner'>\"},\n",
       " 'freq': '1s',\n",
       " 'alias': 'penguins',\n",
       " 'n_inp': 1,\n",
       " 'device': 'cuda',\n",
       " 'epochs': 100,\n",
       " 'frozen': False,\n",
       " 'mvp_ws': [10, 30],\n",
       " 'stride': 5,\n",
       " 'Learner': {'lr': 0.001,\n",
       "  'wd': None,\n",
       "  'arch': 'tsai.models.InceptionTimePlus.InceptionTimePlus',\n",
       "  'moms': [0.95, 0.85, 0.95],\n",
       "  'path': '.',\n",
       "  '_name': '<fastai.learner.Learner object at 0x7f3f20120fa0>',\n",
       "  'metrics': None,\n",
       "  'opt_func': 'fastai.optimizer.Adam',\n",
       "  'splitter': 'tsai.models.utils.ts_splitter',\n",
       "  'train_bn': True,\n",
       "  'loss_func': {'axis': -1,\n",
       "   '_name': {'axis': -1,\n",
       "    '_name': 'FlattenedLoss of MSELoss()',\n",
       "    'is_2d': False,\n",
       "    'flatten': True,\n",
       "    'floatify': True},\n",
       "   'is_2d': False,\n",
       "   'flatten': True,\n",
       "   'floatify': True},\n",
       "  'model_dir': 'models',\n",
       "  'wd_bn_bias': False,\n",
       "  'default_cbs': True},\n",
       " 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True},\n",
       " 'time_col': None,\n",
       " 'ShowGraph': {'perc': 0.5, 'final_losses': True, 'plot_metrics': True},\n",
       " 'data_cols': [],\n",
       " 'mask_sync': False,\n",
       " 'use_wandb': True,\n",
       " 'batch size': 512,\n",
       " 'batch_size': 512,\n",
       " 'csv_config': {},\n",
       " 'data_fpath': '~/data/MP_first_test_penguin_sample.csv',\n",
       " 'frozen idx': 0,\n",
       " 'valid_size': 0.2,\n",
       " 'mask_future': False,\n",
       " 'wandb_group': None,\n",
       " 'CastToTensor': True,\n",
       " 'dataset.tfms': '[ToFloat:\\nencodes: (Tensor,object) -> encodes\\n(object,object) -> encodes\\ndecodes: (object,object) -> decodes\\n, None]',\n",
       " 'WandbCallback': {'log': None,\n",
       "  'seed': 12345,\n",
       "  'n_preds': 36,\n",
       "  'reorder': True,\n",
       "  'valid_dl': None,\n",
       "  'log_model': False,\n",
       "  'log_preds': False,\n",
       "  'model_name': None,\n",
       "  'log_dataset': False,\n",
       "  'dataset_name': None,\n",
       "  'log_preds_every_epoch': False},\n",
       " 'analysis_mode': 'online',\n",
       " 'artifact_name': 'penguins',\n",
       " 'input 1 dim 1': 512,\n",
       " 'input 1 dim 2': 3,\n",
       " 'input 1 dim 3': 30,\n",
       " 'mask_stateful': True,\n",
       " 'ParamScheduler': True,\n",
       " 'dls.after_item': 'Pipeline: ',\n",
       " 'norm_by_sample': False,\n",
       " 'train_artifact': 'mi-santamaria/deepvats/penguins:latest',\n",
       " 'valid_artifact': None,\n",
       " 'batch per epoch': 34,\n",
       " 'dls.after_batch': 'Pipeline: TSStandardize',\n",
       " 'ProgressCallback': True,\n",
       " 'dls.before_batch': 'Pipeline: ',\n",
       " 'model parameters': 455619,\n",
       " 'TrainEvalCallback': True,\n",
       " 'EarlyStoppingCallback': True,\n",
       " 'norm_use_single_batch': False,\n",
       " 'norm_use_by_single_batch': [False]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')\n",
    "enc_artifact.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mvp-SWV:v73'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_artifact.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the dataset artifact used for training the encoder. Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that \n",
    "it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_artifact_train:  penguins:v3\n"
     ]
    }
   ],
   "source": [
    "enc_logger = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(enc_logger.config['train_artifact'], type='dataset')\n",
    "if enc_logger.config['valid_artifact'] is not None:\n",
    "    enc_artifact_valid = artifacts_gettr(enc_logger.config['valid_artifact'], type='dataset')\n",
    "    print(\"enc_artifact_valid:\", enc_artifact_valid.name)\n",
    "print(\"enc_artifact_train: \", enc_artifact_train.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the dataset artifact that we want to use for the reduction. If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'penguins:v3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config_dr.dr_artifact_name is not None:\n",
    "    dr_artifact = artifacts_gettr(config_dr.dr_artifact_name)\n",
    "else:\n",
    "    dr_artifact = enc_artifact_train\n",
    "dr_artifact.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check whether the artifact that is going to be used fort the dimensionality reduction matches the artifact used to train the encoder. Matching means having the same number of variables, the same window size and stride, and the same frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>RollingMean - var 0 - window - 2</th>\n",
       "      <th>RollingMean - var 0 - window - 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.253906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>0.259033</td>\n",
       "      <td>0.256469</td>\n",
       "      <td>0.256469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.269287</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>0.260742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.270263</td>\n",
       "      <td>0.266520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.265137</td>\n",
       "      <td>0.268189</td>\n",
       "      <td>0.268555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  RollingMean - var 0 - window - 2  \\\n",
       "1970-01-01 00:00:00  0.253906                          0.253906   \n",
       "1970-01-01 00:00:01  0.259033                          0.256469   \n",
       "1970-01-01 00:00:02  0.269287                          0.264160   \n",
       "1970-01-01 00:00:03  0.271240                          0.270263   \n",
       "1970-01-01 00:00:04  0.265137                          0.268189   \n",
       "\n",
       "                     RollingMean - var 0 - window - 3  \n",
       "1970-01-01 00:00:00                          0.253906  \n",
       "1970-01-01 00:00:01                          0.256469  \n",
       "1970-01-01 00:00:02                          0.260742  \n",
       "1970-01-01 00:00:03                          0.266520  \n",
       "1970-01-01 00:00:04                          0.268555  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dr_artifact.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109842, 3)\n",
      "0.1\n",
      "109.8\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(np.round(df.shape[0]/ 1e6, 1))\n",
    "print(np.round(df.shape[0]/ 1e3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_time_series_flag = False\n",
    "if show_time_series_flag:\n",
    "    # Show time series plot\n",
    "    fig, ax = plt.subplots(1, figsize=(15,5), )\n",
    "    cmap = matplotlib.colormaps.get_cmap('viridis')\n",
    "    df.plot(color=cmap(0.05), ax=ax) # or use colormap=cmap\n",
    "    # rect = Rectangle((5000, -4.2), 3000, 8.4, facecolor='lightgrey', alpha=0.5)\n",
    "    # ax.add_patch(rect)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "w = enc_logger.config['w']\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 4089\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m17%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW start |  1708362662.5325708  | end  1708362662.5370085 total (secs):  0.004437685012817383\n",
      "(109812, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "enc_input, _ = prepare_forecasting_data(df, fcst_history = w)\n",
    "t_end = time.time()\n",
    "t = t_end - t_start\n",
    "print(\"SW start | \" , t_start, \" | end \", t_end, \"total (secs): \", t)\n",
    "print(enc_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 4089\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m17%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = enc_logger.config['stride']\n",
    "batch_size = enc_logger.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "print(stride)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109812, 3, 30)\n",
      "mvp-SWV:v73\n"
     ]
    }
   ],
   "source": [
    "print(enc_input.shape)\n",
    "print(enc_artifact.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 4089\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m17%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0.253906\n",
      "0 0 1 0.259033\n",
      "0 0 2 0.269287\n",
      "0 0 3 0.27124\n",
      "0 0 4 0.265137\n",
      "0 0 5 0.26001\n",
      "0 0 6 0.246826\n",
      "0 0 7 0.239746\n",
      "0 0 8 0.231445\n",
      "0 0 9 0.230469\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for a in range (enc_input.shape[0]):\n",
    "    for b in range (enc_input.shape[1]):\n",
    "        for c in range (enc_input.shape[2]):\n",
    "            if enc_input[a,b,c] != 0: \n",
    "                print(a,b,c, enc_input[a,b,c])\n",
    "                i+=1\n",
    "                if i == 10: break\n",
    "        if i == 10: break\n",
    "    if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102400"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_max = 10000000\n",
    "shape = enc_input.shape\n",
    "chunk_size_ = min(shape[1]*shape[2],chunk_max/(shape[1]*shape[2]))\n",
    "N = max(3200,np.floor(chunk_size_/32))\n",
    "chunk_size = N*32\n",
    "chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_enc_embs_set_stride_set_batch_size 7.420173168182373 seconds\n",
      "GE start |  1708362662.8821747  | end  1708362670.3040679 total (secs):  7.421893119812012\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "embs = get_enc_embs_set_stride_set_batch_size(\n",
    "    enc_input, \n",
    "    enc_learner, \n",
    "    stride = stride,\n",
    "    batch_size = batch_size,\n",
    "    cpu=config.cpu,\n",
    "    to_numpy = True, \n",
    "    print_flag = False,\n",
    "    time_flag = True,\n",
    "    chunk_size = chunk_size\n",
    ")\n",
    "t_end = time.time()\n",
    "t = t_end-t_start\n",
    "print(\"GE start | \" , t_start, \" | end \", t_end, \"total (secs): \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,UklGRvQHAABXQVZFZm10IBAAAAABAAEAECcAACBOAAACABAAZGF0YdAHAAAAADoKZBRsHkMo2DEbO/1DcExmVNFbpmLaaGJuNXNMd596KX3nftR/8X87f7Z9YntFeGJ0wW9pamNkuV10VqNOUEaLPWA04CoaIR0X+wzDAoj4WO5F5F/at9Bcx1++zLWzrSGmIp/CmAuTBo68iTOGcoN9gVeAAoB/gM2B6YPQhn6K7I4UlOyZa6CHpzSvZbcNwB3JiNI93CzmRvB6+rYE6g4HGfoitSwmNj4/70cqUOJXCV+WZXtrsXAvdex443sQfm5/+3+3f6J+vXwMepN2WHJibblnZmFzWuxS3UpUQl45CzBoJoccdxJJCA7+1fOw6bDf5dVfzC3DX7oCsiaq1qIfnAuWpZD1iwOI1oRygtyAFoAigP+ArIImhWmIcYw1ka+W1Zyeo/6q6bJTuy3EaM331sngzur29DD/agmWE6EdfScXMWE6TEPIS8hTP1shYmJo+G3acv92Ynr9fMt+yX/2f1F/3H2Ze4x4uXQncN1q5GRGXg5XR0/+RkE+HjWlK+Mh6hfKDZQDWPkn7xHlJ9t50RjIEr93tlSutqarnz6ZeZNmjgyKdIajg56BZ4ABgG6AqoG2g46GLIqLjqSTb5nhn/Gmkq65tli/YcjF0XXbYOV376n55QMbDjoYMiLxK2g1iD5CR4dPSVd9XhZlCmtOcNp0p3iue+t9Wn/4f8R/wH7rfEp64Xa2cs5tM2jtYQZbi1OGSwZDGTrMMC8nUh1FExkJ3v6l9H7qeuCq1h7N5cMOu6iywapmo6KcgZYMkU6MTIgPhZuC9YAegBmA5oCCguyEIIgXjM2QOZZSnA6jYqpDsqO6dMOpzDLW/98A6ib0X/6aCMcS1hy2JlYwpzmaQh9LKlOsWpph6GeMbX1ysnYles98rn68f/p/Zn8Cfs970XgOdYtwT2tkZdNeplfqT6xH9z7cNWksrCK3GJoOZAQp+vbv3eXv2zzS1MjGvyK39a5MpzWgu5nok8aOXoq2htWDv4F4gAKAXYCKgYWDTIbbiSuONpPymFifW6byrQ62pL6lxwPRrdqU5Kju2fgUA0wNbRdoIS0rqjTSPZRG406wVvBdlmSXaulvhHRheHh7xX1Ef/N/0H/cfhh9h3oudxJzOW6raHJimFsoVC9MuEPSOo0x9icdHhQU6Qmv/3X1TOtF4XDX3s2dxL67T7Ndq/ajJp33lnWRqIyXiEqFxoIPgSiAEoDOgFqCs4TXh7+LZpDElc+bf6LIqZ2x9Lm9wurLbdU13zPpVvOO/ckH+RELHO8llC/sOOdBdkqLUhlaE2FuZyBtH3JjduZ5oHyPfq5//X96fyZ+A3wWeWJ17nDAa+NlX18+WI1QWEitP5k2LC11I4QZaQ81Bfn6xfCp5rfc/9KRyXvAzreXr+OnwKA5mliUKI+xivmGCITigYuABIBOgGqBVYMMhouJzI3IkneYz57HpVKtZLXxverGQdDl2cjj2u0J+EQCfAygFp8gaCrsMxs95kU+ThZWYl0UZCJqg28tdBl4QHuefS1/7X/af/d+RH3Denp3bHOibiNp92IqXMVU1kxpRIw7TTK8KOge4hS5Cn8ARfYa7BDiNtiezlfFb7z3s/qriKSrnW+X35EDjeOIhoXygiqBMoAMgLeAMoJ8hJCHaYsBkFCVTpvxoS6p+bBFuQbCLMuo1GveZuiH8r78+QYqET8bJyXSLjE4NEHMSetRhFmKYPJmsmzAcRN2pXlwfG9+n3/+f4x/SH42fFl5tHVPcTFsYWbpX9VYL1EESWJAVjfvLT0kUBo4EAUGyvuU8XbngN3D007KMcF7uDqwe6hMobiaypSLjwWLPoc9hAaCnoAHgEGATIEng86FPYlvjVyS/ZdInjOls6y7tD+9MMZ/zx7Z/eIL7Tj3cwGsC9IV1B+jKS0zYzw2RZhNe1XSXJFjrWkcb9Vz0HcHe3V9FX/lf+R/EX9uff56xHfGcwtvmWl7Y7pcYVV8TRlFRDwNM4Epsh+wFYkLUAEV9+js2+L92F/PEMYhvZ+0mKwapTGe6JdKkl+NMInDhR+DR4E/gAeAooANgkaESocTi5yP3ZTOmmShlahVsJi4T8FuyuTTot2Z57fx7fspBlsQcxpfJBAudTeAQCFJSlHuWAFgdmZDbF9xwnVkeT98Tn6Pf/5/nX9qfmh8mnkGdrBxoGzeZnNga1nQUa9JFkESOLIuBSUcGwcR1gaa/GTyQ+hJ3ofUDMvnwSi53bAUqdmhOJs9lfCPWouEh3OELIKzgAuANIAvgfmCkIXwiBKN8ZGEl8KdoKQVrBO0jbx2xb7OWNgy4j3saPaiANwKBBUKH90obTKrO4ZE8kzgVEJcDmM3abRufHOGd816S337ftx/638pf5d9N3sNeB50cm8Pav5jSl38VSJOyEX8PMwzRyp9IH0WWQwgAuX3t+2m48TZINDLxtO9SLU3ra6luJ5imLaSvI1+iQKGTYNlgUyABICOgOiBEYQFh7+KOY9rlE6a2KD9p7Kv67eawLDJINPZ3Mzm6PAc+1gFjA+mGZcjTS25Nss/dUioUFhYdl/4ZdNr/nBwdSF5DHwsfn1//X+sf4p+mHzbeVZ2D3INbVln/GAAWnBSWUrJQc04dC/NJegb1hGmB2v9M/MQ6RPfS9XKy57C1rmCsa6pZ6K5m7CVVZCxi8uHqoRTgg==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21963, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6201948 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.7060158 , 0.14267355, 0.        , 0.        ,\n",
       "       0.55161285, 0.        , 0.33597487, 0.01723432, 0.        ,\n",
       "       0.06388788, 0.171901  , 0.        , 0.04656938, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0,0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE start |  1708362662.8821747  | end (next cell)  1708362671.3676534 total (secs):  8.485478639602661\n"
     ]
    }
   ],
   "source": [
    "t_end = time.time()\n",
    "t = t_end-t_start\n",
    "print(\"GE start | \" , t_start, \" | end (next cell) \", t_end, \"total (secs): \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 4455\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m18%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if check_memory_usage: mem.gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart kernel (Debugging code 4 analysing where can app be failing. Expecting to be related to GPU mem ussage)\n",
    "#os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21963, 128)\n",
      "(109812, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "print(embs.shape)\n",
    "print(enc_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.20194793e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.06015825e-01, 1.42673552e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.51612854e-01, 0.00000000e+00,\n",
       "       3.35974872e-01, 1.72343217e-02, 0.00000000e+00, 6.38878793e-02,\n",
       "       1.71901003e-01, 0.00000000e+00, 4.65693809e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.35081065e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.21765792e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.79942979e-03, 3.03823173e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.63132775e-01, 0.00000000e+00, 4.66098636e-02,\n",
       "       0.00000000e+00, 8.45909834e-01, 1.44654596e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.07623649e+00, 0.00000000e+00, 1.04239760e-02, 0.00000000e+00,\n",
       "       7.34651461e-02, 1.05758643e+00, 8.84268619e-03, 1.66542158e-02,\n",
       "       0.00000000e+00, 2.93595437e-02, 0.00000000e+00, 1.67081988e+00,\n",
       "       0.00000000e+00, 4.89275679e-02, 1.24246798e-01, 1.40440300e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.30841827e+00,\n",
       "       2.11763814e-01, 2.07556438e+00, 1.19299769e+00, 0.00000000e+00,\n",
       "       5.65485716e-01, 0.00000000e+00, 4.79097106e-02, 1.48736763e+00,\n",
       "       7.08659768e-01, 0.00000000e+00, 0.00000000e+00, 2.08140507e-01,\n",
       "       1.21117607e-01, 0.00000000e+00, 0.00000000e+00, 1.91602206e+00,\n",
       "       1.96233046e+00, 1.58654666e+00, 1.81495342e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.75753683e-01, 1.15928853e+00, 0.00000000e+00,\n",
       "       9.14114773e-01, 0.00000000e+00, 3.15328641e-03, 0.00000000e+00,\n",
       "       1.32223126e-02, 0.00000000e+00, 0.00000000e+00, 1.37910795e+00,\n",
       "       0.00000000e+00, 7.36962780e-02, 2.30438471e+00, 9.82675195e-01,\n",
       "       0.00000000e+00, 8.49327922e-01, 9.11887050e-01, 6.25913322e-01,\n",
       "       4.66448488e-03, 2.75622457e-01, 0.00000000e+00, 9.93815064e-03,\n",
       "       2.21198106e+00, 3.75299938e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.59793615e-04, 0.00000000e+00, 1.05583549e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.07380140e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.12253106e+00, 1.04384564e-01, 0.00000000e+00,\n",
       "       1.68028269e-02, 6.62882775e-02, 3.00823245e-03, 0.00000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21963.0 21963\n"
     ]
    }
   ],
   "source": [
    "#Dimensions check\n",
    "num_inputs = np.ceil(enc_input.shape[0]/stride)\n",
    "num_embs = embs.shape[0]\n",
    "test_eq(num_inputs, num_embs )\n",
    "print(num_inputs, num_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average embeddings in the time dimension, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DR techniques to provide an alternative view for users to visually analyze and explore the time-series data. The algorithm UMAP shows its high competitiveness compared to t-SNE. t-SNE suffers from some limitations such as loss of large-scale information (the inter-cluster relationships). UMAP has a faster runtime and provides better scaling which helps to gain a meaningful organization of clusters, outliers and the preservation of continuums compared to t-SNE\n",
    "\n",
    "For this part of the implementation, the package [umap-learn](https://github.com/lmcinnes/umap) is used. The input of the algoritm is the $n \\times \\delta$ that contains, for each slice of the time series, the corresponding $\\delta$ latent embeddings given by the encoder.\n",
    "\n",
    "The hyperparameters of UMAP are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- umap.UMAP -- False\n",
      "-- cuml.UMAP -- False\n",
      "------- reducer1 --------\n",
      "UMAP(a=1.5769434601962196, b=0.8950608779914887, force_approximation_algorithm=True, n_epochs=200, random_state=1234, target_metric='euclidean', target_n_neighbors=15, verbose=6)\n",
      "------- reducer2 --------\n",
      "UMAP()\n",
      "------- reducer2 --------\n",
      "target_metric: euclidean\u001b[0m\n",
      "a: 1.5769434601962196\u001b[0m\n",
      "b: 0.8950608779914887\u001b[0m\n",
      "\u001b[91m\u001b[1moutput_type is missing in modified dict | 0 \u001b[0m\n",
      "learning_rate: 1.0\u001b[0m\n",
      "set_op_mix_ratio: 1.0\u001b[0m\n",
      "\u001b[93m\u001b[1mtransform_mode is missing in original dict | embedding \u001b[0m\n",
      "\u001b[93m\u001b[1moutput_dens is missing in original dict | False \u001b[0m\n",
      "n_components: 2\u001b[0m\n",
      "min_dist: 0.1\u001b[0m\n",
      "\u001b[93m\u001b[1munique is missing in original dict | False \u001b[0m\n",
      "target_n_neighbors: 15\u001b[0m\n",
      "spread: 1.0\u001b[0m\n",
      "metric: euclidean\u001b[0m\n",
      "\u001b[93m\u001b[1mtransform_seed is missing in original dict | 42 \u001b[0m\n",
      "verbose: 6\u001b[0m\n",
      "init: spectral\u001b[0m\n",
      "\u001b[93m\u001b[1mforce_approximation_algorithm is missing in original dict | True \u001b[0m\n",
      "\u001b[93m\u001b[1moutput_metric is missing in original dict | euclidean \u001b[0m\n",
      "metric_kwds: None\u001b[0m\n",
      "\u001b[93m\u001b[1mdens_frac is missing in original dict | 0.3 \u001b[0m\n",
      "transform_queue_size: 4.0\u001b[0m\n",
      "\u001b[91m\u001b[1mcallback is missing in modified dict | 0 \u001b[0m\n",
      "\u001b[93m\u001b[1mdens_var_shift is missing in original dict | 0.1 \u001b[0m\n",
      "\u001b[94mprecomputed_knn: None\u001b[0m -> (None, None, None)\u001b[0m\n",
      "random_state: 1234\u001b[0m\n",
      "target_weight: 0.5\u001b[0m\n",
      "\u001b[91m\u001b[1mhandle is missing in modified dict | 0 \u001b[0m\n",
      "\u001b[93m\u001b[1mtqdm_kwds is missing in original dict | None \u001b[0m\n",
      "n_neighbors: 15\u001b[0m\n",
      "n_epochs: 200\u001b[0m\n",
      "\u001b[93m\u001b[1mdisconnection_distance is missing in original dict | None \u001b[0m\n",
      "\u001b[93m\u001b[1mtarget_metric_kwds is missing in original dict | None \u001b[0m\n",
      "repulsion_strength: 1.0\u001b[0m\n",
      "\u001b[93m\u001b[1moutput_metric_kwds is missing in original dict | None \u001b[0m\n",
      "\u001b[93m\u001b[1mangular_rp_forest is missing in original dict | False \u001b[0m\n",
      "\u001b[93m\u001b[1mn_jobs is missing in original dict | -1 \u001b[0m\n",
      "local_connectivity: 1.0\u001b[0m\n",
      "\u001b[91m\u001b[1mhash_input is missing in modified dict | 0 \u001b[0m\n",
      "negative_sample_rate: 5\u001b[0m\n",
      "\u001b[93m\u001b[1mlow_memory is missing in original dict | True \u001b[0m\n",
      "\u001b[93m\u001b[1mdensmap is missing in original dict | False \u001b[0m\n",
      "\u001b[93m\u001b[1mdens_lambda is missing in original dict | 2.0 \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cpu_flag:\n",
    "    umap_params = {\n",
    "        'n_neighbors' : config_dr.n_neighbors,\n",
    "        'min_dist' : config_dr.min_dist,\n",
    "        'random_state': np.uint64(1234), \n",
    "        'metric': config_dr.metric,\n",
    "        'a': 1.5769434601962196,\n",
    "        'b': 0.8950608779914887,\n",
    "        #'metric_kwds': {'p': 2}, #No debería ser necesario, just in case\n",
    "        'output_metric': 'euclidean',\n",
    "        'verbose': 4,\n",
    "        'n_epochs': 200\n",
    "    }\n",
    "else:\n",
    "    umap_params = {\n",
    "        'n_neighbors' : config_dr.n_neighbors,\n",
    "        'min_dist' : config_dr.min_dist,\n",
    "        'random_state': np.uint64(1234), \n",
    "        'metric': config_dr.metric,\n",
    "        'a': 1.5769434601962196,\n",
    "        'b': 0.8950608779914887,\n",
    "        'target_metric': 'euclidean',\n",
    "        'target_n_neighbors': config_dr.n_neighbors,\n",
    "        'verbose': 6,\n",
    "        'n_epochs': 200\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "check_reducer = True\n",
    "import utils.config as cfg_\n",
    "if check_reducer:\n",
    "    import umap\n",
    "    import cuml\n",
    "    print(\"-- umap.UMAP --\", cpu_flag)\n",
    "    reducer1 = umap.UMAP(force_approximation_algorithm = True, **umap_params)\n",
    "    print(\"-- cuml.UMAP --\", cpu_flag)\n",
    "    reducer2 = cuml.UMAP(**umap_params)\n",
    "    print(\"------- reducer1 --------\")\n",
    "    print(reducer1)\n",
    "    params1=AttrDict(reducer1.get_params())\n",
    "    print(\"------- reducer2 --------\")\n",
    "    print(reducer2)\n",
    "    params2=AttrDict(reducer2.get_params())\n",
    "    print(\"------- reducer2 --------\")\n",
    "    cfg_.diff_attrdict(dict_original=params2, dict_modified=params1, both=True)\n",
    "    beep(0.10)\n",
    "\n",
    "#if not cpu_flag:\n",
    "    #umap_params['force_approximation_algorithm'] = True # Este no parece ser el influencer\n",
    "    #umap_params['angular_rp_forest'] = True #No es el influencer\n",
    "\n",
    "#if params2['random_state'] != 1234:\n",
    " #   raise Exception(\"Wrong random_state params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21963, 128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure no nan ((Intento de Macu. La celda de comentada abajo es la original. Pero falla por Nan con sunspot))\n",
    "embs_no_nan = embs[~np.isnan(embs).any(axis=1)]\n",
    "embs_no_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 15,\n",
       " 'min_dist': 0.1,\n",
       " 'random_state': 1234,\n",
       " 'metric': 'euclidean',\n",
       " 'a': 1.5769434601962196,\n",
       " 'b': 0.8950608779914887,\n",
       " 'target_metric': 'euclidean',\n",
       " 'target_n_neighbors': 15,\n",
       " 'verbose': 4,\n",
       " 'n_epochs': 1200,\n",
       " 'init': 'random',\n",
       " 'hash_input': True}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_params_cpu = {\n",
    "        'n_neighbors' : config_dr.n_neighbors,\n",
    "        'min_dist' : config_dr.min_dist,\n",
    "        'random_state': np.uint64(1234), \n",
    "        'metric': config_dr.metric,\n",
    "        #'a': 1.5769434601962196,\n",
    "        #'b': 0.8950608779914887,\n",
    "        #'metric_kwds': {'p': 2}, #No debería ser necesario, just in case\n",
    "        #'output_metric': 'euclidean',\n",
    "        'verbose': 4,\n",
    "        #'n_epochs': 200\n",
    "    }\n",
    "umap_params_gpu = {\n",
    "        'n_neighbors' : config_dr.n_neighbors,\n",
    "        'min_dist' : config_dr.min_dist,\n",
    "        'random_state': np.uint64(1234), \n",
    "        'metric': config_dr.metric,\n",
    "        'a': 1.5769434601962196,\n",
    "        'b': 0.8950608779914887,\n",
    "        'target_metric': 'euclidean',\n",
    "        'target_n_neighbors': config_dr.n_neighbors,\n",
    "        'verbose': 4, #6, #CUML_LEVEL_TRACE\n",
    "        'n_epochs': 200*3*2,\n",
    "        'init': 'random',\n",
    "        'hash_input': True\n",
    "    }\n",
    "\n",
    "\n",
    "if cpu_flag:\n",
    "    umap_params = umap_params_cpu\n",
    "else:\n",
    "    umap_params = umap_params_gpu\n",
    "\n",
    "umap_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border:2px solid red; padding:10px;\">\n",
    "    <strong>⚠️ Low quality embeddings graphics when using GPU </strong> \n",
    "    \n",
    "    If getting  low quality embedding graphics, use 'True' for using CPU instead of CPU. There is a known issue in CUML library related to laplacian eigenmaps that affects to the embeddings calculus.\n",
    "> | Check [GPU VS CPU error in cuml](https://github.com/rapidsai/cuml/issues/5474)\n",
    "</div>\n",
    " **Low quality embeddings graphics***\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> get_UMAP_prjs\n",
      "kwargs:  {'n_neighbors': 15, 'min_dist': 0.1, 'random_state': 1234, 'metric': 'euclidean', 'a': 1.5769434601962196, 'b': 0.8950608779914887, 'target_metric': 'euclidean', 'target_n_neighbors': 15, 'verbose': 4, 'n_epochs': 1200, 'init': 'random', 'hash_input': True}\n",
      "594a1baac95dae621d87ca0fe68fccd1\n",
      "GPU | Used mem: 4455\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m18%\u001b[0m\n",
      "-- cuml.UMAP -- False\n",
      "------- reducer --------\n",
      "UMAP()\n",
      "{'handle': <pylibraft.common.handle.Handle object at 0x7f1387385950>, 'verbose': 4, 'output_type': 'input', 'n_neighbors': 15, 'n_components': 2, 'n_epochs': 1200, 'learning_rate': 1.0, 'min_dist': 0.1, 'spread': 1.0, 'set_op_mix_ratio': 1.0, 'local_connectivity': 1.0, 'repulsion_strength': 1.0, 'negative_sample_rate': 5, 'transform_queue_size': 4.0, 'init': 'random', 'a': 1.5769434601962196, 'b': 0.8950608779914887, 'target_n_neighbors': 15, 'target_weight': 0.5, 'target_metric': 'euclidean', 'hash_input': True, 'random_state': 1234, 'callback': None, 'metric': 'euclidean', 'metric_kwds': None, 'precomputed_knn': None}\n",
      "------- reducer --------\n",
      "GPU | Used mem: 4473\n",
      "GPU | Used mem: 24576\n",
      "GPU | Memory Usage: [\u001b[90m███-----------------\u001b[0m] \u001b[90m18%\u001b[0m\n",
      "prjs checksum  6932ee579679295d411e49780f01b6bb\n",
      "get_UMAP_prjs -->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21963, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prjs_umap = get_UMAP_prjs(\n",
    "    input_data = embs_no_nan, \n",
    "    cpu = cpu_flag, #config_dr.cpu, \n",
    "    print_flag = True, \n",
    "    #target_weight=1,\n",
    "    **umap_params\n",
    ")\n",
    "prjs_umap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,UklGRvQHAABXQVZFZm10IBAAAAABAAEAECcAACBOAAACABAAZGF0YdAHAAAAAGweGztmVNpoTHfnfjt/RXhpanRWiz0aIcMCReRcx7Otwpi8iX2Bf4DQhhSUh6cNwD3cevoHGSY2KlCWZS91EH63fwx6Ym1zWlRCaCZJCLDpX8wCsh+c9YtygiKAJoU1kZ6jU7v31vb0lhMXMchLIWLacv189n+ZeydwRl7+RqUryg0n73nRd7arn2aOo4MBgLaDi47hn7m2xdF37xsO8StCR31eTnCue/h/63y2cu1hhkvMMEUTpfSq1g67ZqMMkQ+FHoCCgheMUpxDsqnMAOqaCLYmmkKsWoxtJXq8fwJ+DnVkZepP3DW3GCn679vGv0yn6JO2hniAioHbifKY8q2lx5TkFANoIdI9sFaXamF4RH/cfi53q2goVNI6HR6v/0XhncRdq/eWl4gPgc6A14fElcipvcI13479CxzsOItSbmdjdo9+en8WecBrPlitP3UjNQWp5pHJl685mrGK4oFOgAyGyJLHpfG95dkJ+KAW7DM+ThRkLXSefdp/w3qibipcaUS8KLkKGuyezvezq50DjfKCDIB8hAGQ8aFFuajUh/IqEdIuzEmKYMBxcHz+fzZ8T3HpXwRJ7y04EJTxw9N7uEyhi489hAeAJ4NvjUieu7R/zwvtrAujKTZF0lwcbwd75X9ufcZze2N8TQ0zsBUV9/3YIb0apUqSw4U/gA2CE4vOmlWwbsqZ5ykGXySAQO5YQ2xkeY9/an4Gdt5m0FESOBwbmvxJ3ufBFKk9lYSHs4AvgfCIhJcVrHbFMuKiAAofqzvgVDdphnf7fil/DXgPavxV/Dx9ICACpuPLxjetYph+iWWBjoAFh2uU/aeawNncHPumGbk2qFD4ZXB1LH6sf9t5DW0AWslBzSWmBxDpysuCsbmbsYtTgimAVIWHkQ+k3LuR15j1NhStMUtMiWIhcyB98n9ve9hv2F13RgwrKQ2G7uLQ8rVBnxuOfYMCgN6D145NoD+3XdIY8L0OiSzJR+tem3DYe/t/x3xtcoRhA0s1MKUSA/QQ1oW69qK8kOKEGICigl2MuJzEsj7Noeo8CVEnJEMfW+BtVXrGf+V9zHQBZWtPSDUYGIb5U9s6v9emkZODhmuAo4EailOZb644yDPltwMFImA+KFfwapd4VX/GfvJ2TWiuU0I6fx0N/6fgDcTkqpuWXYj6gOCAD4gflkCqTMPS3zH+qRx+OQdTzWehdqd+a3/geGhryFcgP9kikgQK5v7IGa/XmXCKx4FagD6GHZM6pn2+gdqr+EAXgDS+TnlkcXS8fdJ/lXpQbrlb30MiKBcKeesIznSzQ528jM+CEICnhFCQX6LNuUHVKPPLEWovUEr1YApylnz9fw98A3F9X35IVy2XD/PwKtP0t9+gPo8UhASAS4O3jbGeP7UW0KztTgw8Kr9FQl1sbzR7639NfYBzFWP7THcyDxVz9mLYlryopPaRk4U1gCqCVosxm9WwAss46MsG+yQMQWNZmmyXeZx/UH7GdXxmU1F/N34a+Put3VnBnajjlE2Ho4BFgSyJ4peQrAfG0OJFAagfOjxZVZNpwHcPfxZ/1HezaYRVbTzfH34BCOM6xrusA5hBiU2BnYA6h8SUc6gnwXbdv/tGGkw3JlFaZrB1R36gf6l5uGyMWT1BMiUEB3DoNssCsVWbbYs1gjKAg4XZkYCkZrws2Dr21xRDMs1M8GJoc0F97X9De4lvaV3vRXIqhwzl7UvQbbXWntGNWIMEgAaEI4+5oMW39dK68F4PIi1PSFdf6HAAfP1/o3wkchphf0qfLwQSYfN31f25hqJskLaEEoDEgqOMH51Gs9PNQeveCesnr0ORWzNuhHrPf8d9iXScZOtOtDR4F+T4t9quvmOmO5NQhl6AvYFairSZ7K7KyNLlWQSiIu4+nldJa854ZX+vfrZ272cyU7E54Rxq/grgfsNrqj+WI4jngPOASYh6lrmq28Nw4NP+SB0POoJTLGjddr5+W3+reBBrUVeSPjwi8ANr5WvIm651mTCKrIFmgHGGc5Oupgm/HNtN+d8XFDU+T91ktHTafcp/Znr9bUdbVUOHJ3UJ2epzzfKy3Jx1jK6CFoDThJ+Qz6JVutrVyvNsEgAw1UpeYVNyu3z7f+Z7t3ARX/hHvyz1DlHwktJut3Og8Y7sgwOAcIMBjhufw7Wt0E3u8AzWKkdGsV28b1978H8sfTpzrWJ5TOIxbxTR9cjXDLw3pKSRZIUsgEiCmYuWm1WxlsvY6G0HliWYQddZ72zJeah/NX6GdRtm1VDtNt4ZVvsQ3cvAJqiLlBiHk4BdgWiJQZgLrZjGbuPnAUUgyjzSVe9p+XcjfwN/m3dXaQpV3TtCH9sAaeKpxUCspZcFiTeBrYBxhx2V6qi1wRLeYfzlGt43pFG7Zu91YX6Tf3Z5YmwXWbFAliRiBtHnosqCsPGaK4sXgjuAsoUskvKk8LzG2Nz2dxXYMk9NV2Ouc2J9538Xezhv+lxmRdkp5QtE7bTP6rRtnoiNM4MGgC6EcI8moUu4jdNb8f8Pui3VSMNfNXEofP5/fXzacbBg+0kIL2MRv/Le1HW5GKIckIuEDYDmguqMhp3Js2nO4euACoYoOEQCXIVus3rYf6h9RXQ4ZGtOIDTYFkL4HNoivu+l5pIehlKA2IGaihaaaq9dyXHm/AQ+I3s/FViiaw==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beep(0.15)\n",
    "beep(0.15)\n",
    "beep(0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-12.466263  ,  -0.41525936],\n",
       "       [-12.377644  ,  -0.37939835],\n",
       "       [-12.382557  ,  -0.4246359 ],\n",
       "       [-12.526073  ,  -1.3260908 ],\n",
       "       [-12.51997   ,  -1.317771  ],\n",
       "       [-12.336531  ,  -0.27458382],\n",
       "       [-12.37616   ,  -0.1576004 ],\n",
       "       [-12.513777  ,  -1.5542946 ],\n",
       "       [-12.7708435 ,  -2.5611105 ],\n",
       "       [-12.907396  ,  -2.8380222 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prjs_umap[0:10] # En R head(res[1,],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prjs = get_UMAP_prjs(embs, cpu=False, **umap_params)\n",
    "#prjs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the projections as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_wandb: \n",
    "    run.log_artifact(ReferenceArtifact(prjs, 'projections', type='projections', \n",
    "metadata=dict(run_dr.config)), aliases=f'run-{run.project}-{run.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Precomputed Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate precomputed clusters into the embedding space, it's necessary to log artifacts that include the labels of the newly created clusters. \n",
    "\n",
    "The cluster creation process is presented below. This creation procedure can be modified according to specific needs. However, the structure of the new artifact must be preserved (it must be a numpy.ndarray and the number of elements must be equal to the number of points in the embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN supported metrics: ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity', 'seuclidean', 'mahalanobis', 'wminkowski', 'hamming', 'canberra', 'braycurtis', 'matching', 'jaccard', 'dice', 'kulsinski', 'rogerstanimoto', 'russellrao', 'sokalmichener', 'sokalsneath', 'haversine', 'cosine', 'arccos', 'pyfunc']\n"
     ]
    }
   ],
   "source": [
    "print(f'HDBSCAN supported metrics: {list(hdbscan.dist_metrics.METRIC_MAPPING.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HDBSCAN parameters\n",
    "hdbscan_kwargs = {\n",
    "    'min_cluster_size' : 100, #100,\n",
    "    'min_samples' : 100,\n",
    "    'cluster_selection_epsilon' : 0.0001,\n",
    "}\n",
    "metric_kwargs = {\n",
    "    'metric' : 'euclidean' #'jaccard'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 13912),\n",
       " (6, 158),\n",
       " (-1, 286),\n",
       " (1, 532),\n",
       " (3, 102),\n",
       " (0, 5233),\n",
       " (4, 114),\n",
       " (2, 499),\n",
       " (5, 1127)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create clusters using HDBSCAN\n",
    "clusters = hdbscan.HDBSCAN(**hdbscan_kwargs, **metric_kwargs).fit(prjs_umap)\n",
    "clusters_labels = clusters.labels_\n",
    "list(Counter(clusters_labels).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure good quality embeddings\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette_score: 0.114582345\n"
     ]
    }
   ],
   "source": [
    "score = cluster_score(prjs_umap, clusters_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette_score: 0.114582345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.114582345"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if score <= 0:\n",
    "    print(\"Clusters are not good enough. Repeat embeddings with CPU\")\n",
    "    prjs_umap = get_UMAP_prjs(input_data = embs_no_nan, cpu = True, print_flag = False, **umap_params_cpu)\n",
    "    prjs_umap.shape    \n",
    "    # Create clusters using HDBSCAN\n",
    "    clusters = hdbscan.HDBSCAN(**hdbscan_kwargs, **metric_kwargs).fit(prjs_umap)\n",
    "    clusters_labels = clusters.labels_\n",
    "    list(Counter(clusters_labels).items())\n",
    "\n",
    "cluster_score(prjs_umap, clusters_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing artifact structure \n",
    "test_eq_type(type(clusters_labels), np.ndarray)\n",
    "test_eq(clusters_labels.size, prjs_umap.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'FileNotFoundError'>",
     "evalue": "[Errno 2] No such file or directory: '/home/data/wandb_artifacts/3159745204730249258'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create and log 'clusters_labels' artifact\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m clusters_ar \u001b[38;5;241m=\u001b[39m ReferenceArtifact(obj\u001b[38;5;241m=\u001b[39mclusters_labels, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters_labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m clusters_ar\u001b[38;5;241m.\u001b[39mmetadata, clusters_ar\u001b[38;5;241m.\u001b[39mmanifest\u001b[38;5;241m.\u001b[39mentries\u001b[38;5;241m.\u001b[39mvalues()\n",
      "File \u001b[0;32m~/work/dvats/utils.py:53\u001b[0m, in \u001b[0;36mReferenceArtifact.__init__\u001b[0;34m(self, obj, name, type, folder, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m hash_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mhash\u001b[39m(pickle\u001b[38;5;241m.\u001b[39mdumps(obj)))\n\u001b[1;32m     52\u001b[0m folder \u001b[38;5;241m=\u001b[39m Path(ifnone(folder, Path\u001b[38;5;241m.\u001b[39mhome()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_storage_path))\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhash_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     54\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(obj, f)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_reference(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/data/wandb_artifacts/3159745204730249258'"
     ]
    }
   ],
   "source": [
    "# Create and log 'clusters_labels' artifact\n",
    "clusters_ar = ReferenceArtifact(obj=clusters_labels, name='clusters_labels')\n",
    "clusters_ar.metadata, clusters_ar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.log_artifact(clusters_ar, aliases=['hdbscan_jaccard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the connected scatter plot is a simple visualization technique, it has very specific functions in our approach. Every sliding window is represented as a dot in the plot after the projection process (Fig. 4C, D of the paper). Before labeling, all points have the same color and transparency, and when they are concentrated in one area, the densities are accumulated. Lines are used to connect consecutive points preserving the temporal ordering of the data and allowing the user to see temporal connections (Fig. 4B of the paper). Thus, the point is linked to the previous point (inner) and to the posterior point (outer) as an indication of the flow of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_projections(prjs, umap_params, fig_size = (25,25)):\n",
    "    \"Plot 2D projections thorugh a connected scatter plot\"\n",
    "    df_prjs = pd.DataFrame(prjs, columns = ['x1', 'x2'])\n",
    "    fig = plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(df_prjs['x1'], df_prjs['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    ax.plot(df_prjs['x1'], df_prjs['x2'], alpha=0.5, picker=1)\n",
    "    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f}'.format(\n",
    "        umap_params['n_neighbors'],umap_params['min_dist']))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_projections_clusters(prjs, clusters_labels, umap_params, fig_size = (25,25)):\n",
    "    \"Plot 2D projections thorugh a connected scatter plot\"\n",
    "    df_prjs = pd.DataFrame(prjs, columns = ['x1', 'x2'])\n",
    "    df_prjs['cluster'] = clusters_labels\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Create a scatter plot for each cluster with different colors\n",
    "    unique_labels = df_prjs['cluster'].unique()\n",
    "    print(unique_labels)\n",
    "    for label in unique_labels:\n",
    "        cluster_data = df_prjs[df_prjs['cluster'] == label]\n",
    "        ax.scatter(cluster_data['x1'], cluster_data['x2'], label=f'Cluster {label}')\n",
    "        #ax.scatter(df_prjs['x1'], df_prjs['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    \n",
    "    #ax.plot(df_prjs['x1'], df_prjs['x2'], alpha=0.5, picker=1)\n",
    "    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f}'.format(\n",
    "        umap_params['n_neighbors'],umap_params['min_dist']))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs_plt = plot_projections_clusters(prjs_umap, clusters_labels, umap_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep(0.25)\n",
    "beep(0.25)\n",
    "beep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs_plt = plot_projections(prjs_umap, umap_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log this plot as part of the current wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Get the figure of the embedding plot, and save it on thea wandb run.\n",
    "run_dr.log({\"img\": [wandb.Image(prjs_plt.get_figure(), caption=\"dr_projections_plot\")]})\n",
    "\n",
    "#run_dr.log({'embeddings_plot': embeddings_plot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "run_dr.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability with SHAP (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "# ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "# ax.set_title('Select the point you want to visualize as a time window in the original space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot interactive to allow selection of subsets of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_indices = None\n",
    "# selected_points = None\n",
    "\n",
    "# def onpick(event):\n",
    "#     global selected_points\n",
    "#     thisline = event.artist\n",
    "#     xdata = thisline.get_xdata()\n",
    "#     ydata = thisline.get_ydata()\n",
    "#     global selected_indices\n",
    "#     selected_indices = event.ind\n",
    "#     selected_points = tuple(zip(xdata[selected_indices], ydata[selected_indices]))\n",
    "#     print('onpick points (first):', selected_points[0])\n",
    "\n",
    "# fig.canvas.mpl_connect('pick_event', onpick)\n",
    "\n",
    "# plt.show()\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(f'../img/w={w}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for the dimensionality reduction\n",
    "\n",
    "There are a number of parameters that can be set for the UMAP algorithm. The major \n",
    "ones are `n_neighbors` and `min_dist`. Thus, we will carry out a hyperparameter \n",
    "sweep in Weights and Biases for these two parameters. Note that there is no objective\n",
    "way of deciding that some embeddings are better than others. Thus, we must rely on our\n",
    "intuition by visualizing the 2D plots of each of the runs in the sweep.\n",
    "\n",
    "The first thing we need is gather all the pipeline of the previous section into a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linking back points of the 2D projection to the original time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `selected_points` and `ind` contain an array of the points and indices selected in the previous 2D projection. We will take the first of them (there can be many selected points with just one click), and use its index to get the corresponding time window of the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_window = input_data[df_embeddings.sample(n=1).index][0] if selected_indices is None else input_data[selected_indices[0]]\n",
    "# selected_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing all the variables in the time window (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# g = sns.FacetGrid(df_output_tidy, col=\"variable\", col_wrap=3, aspect=2)\n",
    "# g = g.map(plt.plot, \"timestamp\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution: Visualize only the most relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In high dimensional time series, not only is interesting to see the window associated to a point in the 2D space, but also it is extremely important to spot which variables are mainly causing that the window is positioned in that point of the 2D space.\n",
    "\n",
    "Since UMAP does not provide capabilities to understand feature importance, there are [different ways](https://stats.stackexchange.com/questions/438025/understand-important-features-in-umap) to tackle this problem:\n",
    "\n",
    "1. Use another dimensionality reduction technique that provides importance, such as [sparse PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html)\n",
    "\n",
    "2. Create a surrogate model on top of the inputs/output of UMAP and explain it using XAI techniques. We will try here this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a surrogate model that takes the multivariate time series as input and produces the associated points in the 2D space as ouput. Since we already have a Deep Convolutional Autoencoder (DCAE) that takes a multivariate time series as input, and it contains the latent features that represent that input, we can use it for the surrogate. We will use the intermediate model that goes from the input to the layer containing the latent space, and then add a `Dense` layer with 2 units and linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):\n",
    "#     \"Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \\\n",
    "#     `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`\"\n",
    "#     x = dcae.get_layer(lat_ln).output\n",
    "#     x = Dense(units=embeddings.shape[1], activation='linear')(x)\n",
    "#     surrogate_model = Model(dcae.input, x)\n",
    "#     l_nms = [layer.name for layer in surrogate_model.layers]\n",
    "#     layer_idx = l_nms.index(lat_ln)\n",
    "#     # The layers that are already trained from the autoencoder must be `frozen`\n",
    "#     for layer in surrogate_model.layers[:layer_idx]:\n",
    "#         layer.trainable = False\n",
    "#     return surrogate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = train_surrogate_model(m, embeddings, lat_ln='latent_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.equals(sm.input.shape, m.input.shape)\n",
    "# test.equals(sm.output.shape[1], embeddings.shape[1])\n",
    "# l_nms = [layer.name for layer in sm.layers]\n",
    "# layer_idx = l_nms.index('latent_features')\n",
    "# test.all_equal([layer.trainable for layer in sm.layers], \\\n",
    "#                np.repeat([False, True], [layer_idx + 1, len(sm.layers) -1 -layer_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "# opt = 'adam'\n",
    "# bs = 100\n",
    "# epochs = 10\n",
    "# val = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.fit(x=input_data, y=embeddings, batch_size=bs, validation_split=val, epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"gradient\", intermediate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd= innvestigate.create_analyzer(\"gradient\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data[np.random.choice(input_data.shape[0], 100, replace=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background = input_data[np.random.choice(input_data.shape[0], 100, replace=False)]\n",
    "# e = shap.DeepExplainer(intermediate_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = e.shap_values(input_data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution ended\")\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart kernel (Debugging code 4 analysing where can app be failing. Expecting to be related to GPU mem ussage)\n",
    "#os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
