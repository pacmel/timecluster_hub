{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import umap\n",
    "import cudf\n",
    "import cuml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from dvats.imports import *\n",
    "from dvats.load import TSArtifact\n",
    "from dvats.memory import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_compatibility(dr_ar:TSArtifact, enc_ar:TSArtifact):\n",
    "    \"Function to check that the artifact used by the encoder model and the artifact that is \\\n",
    "    going to be passed through the DR are compatible\"\n",
    "    try:\n",
    "        # Check that both artifacts have the same variables\n",
    "        chk_vars = dr_ar.metadata['TS']['vars'] == enc_ar.metadata['TS']['vars']\n",
    "        # Check that both artifacts have the same freq\n",
    "        chk_freq = dr_ar.metadata['TS']['freq'] == enc_ar.metadata['TS']['freq']\n",
    "        # Check that the dr artifact is not normalized (not normalized data has not the key normalization)\n",
    "        chk_norm = dr_ar.metadata['TS'].get('normalization') is None\n",
    "        # Check that the dr artifact has not missing values\n",
    "        chk_miss = dr_ar.metadata['TS']['has_missing_values'] == \"False\"\n",
    "        # Check all logical vars.\n",
    "        if chk_vars and chk_freq and chk_norm and chk_miss:\n",
    "            print(\"Artifacts are compatible.\")\n",
    "        else:\n",
    "            raise Exception\n",
    "    except Exception as e:\n",
    "        print(\"Artifacts are not compatible.\")\n",
    "        raise e\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get projections (UMAP, T-SNET, PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Comment this part after 4_seconds debugged\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import warnings\n",
    "import sys\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "@delegates(cuml.UMAP)\n",
    "def get_UMAP_prjs(\n",
    "    input_data, \n",
    "    cpu=True, \n",
    "    print_flag = False, \n",
    "    check_memory_usage = True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"Compute the projections of `input_data` using UMAP, with a configuration contained in `**kwargs`.\"\n",
    "    if print_flag: \n",
    "        print(\"--> get_UMAP_prjs\")\n",
    "        print(\"kwargs: \", kwargs)\n",
    "        sys.stdout.flush()\n",
    "        ####\n",
    "        checksum = hashlib.md5(input_data.tobytes()).hexdigest()\n",
    "        print(checksum)\n",
    "        ####\n",
    "        \n",
    "    if check_memory_usage: gpu_memory_status()\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=NumbaPerformanceWarning) # silence NumbaPerformanceWarning\n",
    "    \n",
    "    #reducer = umap.UMAP(**kwargs) if cpu else cuml.UMAP(**kwargs)\n",
    "    if cpu:\n",
    "        print(\"-- umap.UMAP --\", cpu)\n",
    "        sys.stdout.flush()\n",
    "        reducer = umap.UMAP(**kwargs)\n",
    "    else:\n",
    "        print(\"-- cuml.UMAP --\", cpu)\n",
    "        sys.stdout.flush()\n",
    "        if 'random_state' in kwargs:\n",
    "            kwargs['random_state'] = np.uint64(kwargs['random_state'])\n",
    "        reducer = cuml.UMAP(**kwargs)\n",
    "    \n",
    "    if print_flag: \n",
    "        print(\"------- reducer --------\")\n",
    "        print(reducer)\n",
    "        print(reducer.get_params())\n",
    "        print(\"------- reducer --------\")\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    projections = reducer.fit_transform(input_data)\n",
    "    \n",
    "    if check_memory_usage: gpu_memory_status()\n",
    "    if print_flag: \n",
    "        checksum = hashlib.md5(projections.tobytes()).hexdigest()\n",
    "        print(\"prjs checksum \", checksum)\n",
    "        print(\"get_UMAP_prjs -->\")\n",
    "        sys.stdout.flush()\n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| slow\n",
    "foo = np.random.rand(5, 10)\n",
    "bar = get_UMAP_prjs(\n",
    "    foo, \n",
    "    cpu=False, \n",
    "    print_flag = True,\n",
    "    check_memory_usage = True,\n",
    "    random_state = 1234, #822569775\n",
    "    n_neighbors=3, \n",
    "    min_dist=0.1\n",
    ")\n",
    "test_eq(bar.shape, (foo.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| slow\n",
    "foo = np.random.rand(5, 10)\n",
    "bar = get_UMAP_prjs(\n",
    "    foo, \n",
    "    cpu=True, \n",
    "    print_flag = True,\n",
    "    check_memory_usage = True\n",
    "    n_neighbors=3, \n",
    "    min_dist=0.1\n",
    ")\n",
    "test_eq(bar.shape, (foo.shape[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have consistent results across executions, use `random_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "bar = get_UMAP_prjs(foo, cpu=True, n_neighbors=3, random_state=1234)\n",
    "baz = get_UMAP_prjs(foo, cpu=True, n_neighbors=3, random_state=1234)\n",
    "test_eq(bar, baz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(cuml.PCA)\n",
    "def get_PCA_prjs(X, cpu=False, **kwargs):\n",
    "    r\"\"\"\n",
    "    Computes PCA projections of X\n",
    "    \"\"\"\n",
    "    if cpu:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        reducer = cuml.PCA(**kwargs)\n",
    "    projections = reducer.fit_transform(X)\n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Test the function get_PCA_prjs\n",
    "foo = np.random.rand(5, 10)\n",
    "bar = get_PCA_prjs(foo, cpu=False, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(cuml.TSNE)\n",
    "def get_TSNE_prjs(X, cpu=False, **kwargs):\n",
    "    r\"\"\"\n",
    "    Computes TSNE projections of X\n",
    "    \"\"\"\n",
    "    if cpu:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        reducer = cuml.TSNE(**kwargs)\n",
    "    projections = reducer.fit_transform(X)\n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| Test the function get_TSNE_prjs\n",
    "foo = np.random.rand(90, 10)\n",
    "bar = get_TSNE_prjs(foo, cpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "def cluster_score(prjs, clusters_labels, print_flag):\n",
    "    score = silhouette_score(prjs, clusters_labels)\n",
    "    if print_flag: print(\"Silhouette_score:\", score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#from nbdev.export import notebook2script\n",
    "#notebook2script()\n",
    "beep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
