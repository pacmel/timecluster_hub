{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa093821-a793-49fd-a8c2-32cacdbdc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6adb50-be0c-4f0b-9beb-38d4e78c5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#%load_ext autoreload --> Not working TODO:REVISAR\n",
    "# %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bedfb7-6a74-4f6c-a769-cc79fe37686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#-- Global\n",
    "### --- Errors & warnings\n",
    "import warnings\n",
    "import traceback\n",
    "### --- Data & operations\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "import wandb\n",
    "import time\n",
    "import einops\n",
    "## -- plots\n",
    "import matplotlib.pyplot as plt\n",
    "## -- Classes & types\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Tuple, Callable, Union, Any\n",
    "#-- Fourier\n",
    "from tqdm.auto import tqdm\n",
    "#-- Torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.profiler as profiler\n",
    "#-- Dvats\n",
    "from dvats.memory import *\n",
    "import dvats.utils as ut\n",
    "from dvats.config import show_attrdict\n",
    "from dvats.utils import find_dominant_window_sizes_list\n",
    "#-- Fastai\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.hook import hook_outputs\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.learner import Learner\n",
    "from fastai.losses import BaseLoss\n",
    "from fastai.metrics import mae\n",
    "import fastai.optimizer as fastopt\n",
    "#-- Tsai\n",
    "from tsai.data.core import TSDataLoaders\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from tsai.callback.MVP import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.models.explainability import get_acts_and_grads\n",
    "from tsai.models.layers import *\n",
    "from tsai.data.validation import combine_split_data, TimeSplitter\n",
    "from tsai.basics import *\n",
    "#-- Moirai\n",
    "import uni2ts\n",
    "import uni2ts.optim as moirai_opt\n",
    "import uni2ts.model.moirai.module as moirai\n",
    "import uni2ts.model.moirai.forecast as moirai_forecast\n",
    "#| Moment\n",
    "from momentfm.utils.masking import Masking\n",
    "from momentfm import MOMENTPipeline\n",
    "#-- Transformers\n",
    "from transformers import get_scheduler\n",
    "#-- Evaluate\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c94f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from tsai.all import *\n",
    "from dvats.imports import beep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a4a02-5015-4a3e-9a64-6089de4e9532",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "> Architectures and functions for creating encoders that create the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec211d6-c9be-4e42-8c58-47df6678ef79",
   "metadata": {},
   "source": [
    "## Encoder class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4be0f-e17b-4d7d-b491-1b3b0497fbb5",
   "metadata": {},
   "source": [
    "### Encoder input\n",
    "Saves the information about the encoder input, including its data, the windows and the meta-data on how to mask it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df581235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderInput:\n",
    "    # Data\n",
    "    _data               : Union [ pd.DataFrame, List [ List [ List [ float ]]] ] = None\n",
    "    _size               : int                               = None\n",
    "    _shape              : Optional [ Tuple [ int, ... ] ]   = None\n",
    "    _shapes             : List [ Tuple [ int, ...]]         = None\n",
    "    stride              : int                               = None\n",
    "    batch_size          : int                               = None\n",
    "    _update_size        : bool                              = True\n",
    "    _update_shape       : bool                              = True\n",
    "    # Windows                   \n",
    "    n_windows           : int                               = None\n",
    "    n_windows_percent   : float                             = None\n",
    "    validation_percent  : float                             = None\n",
    "    training_percent    : float                             = None\n",
    "    window_mask_percent : float                             = None\n",
    "    # Time                  \n",
    "    time_flag           : bool                              = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self._update_size       = True\n",
    "        self._update_shape      = True\n",
    "        #Todo: check how to validate the input dataset allowing both windowed or not\n",
    "        # --- Not working\n",
    "        ###self._data              = ut._check_value(self.data, None, \"_data\", pd.DataFrame, allow_none = True )\n",
    "        ###if self._data is None: \n",
    "        ###    self._data = ut._validate_nested_list(self._data, None, \"_data\", [float, int], 3, False, False, False)\n",
    "        self.stride,_               = ut._check_value(self.stride, 1, \"stride\", int, positive = True)\n",
    "        self.batch_size,_           = ut._check_value(self.batch_size, 32, \"batch_size\", int,  )\n",
    "        self.validation_percent,_   = ut._check_value(self.validation_percent, 0.2, \"validation_percent\", percent = True)\n",
    "        self.training_percent,_     = ut._check_value(self.training_percent, 0.2, \"training_percent\", percent = True)\n",
    "        self.window_mask_percent,_  = ut._check_value(self.window_mask_percent, 0.3, \"training_percent\", percent = True)\n",
    "        self.time_flag,_            = ut._check_value(self.time_flag, False, \"time_flag\", bool)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        if self._data is not None and ( self._update_size or self._size is None or self._size == 0):\n",
    "            self._size          = len(self._data)\n",
    "            self._update_size   = False\n",
    "            self._size,_ = ut._check_value(self._size, 0, \"_size\", int)\n",
    "            self._size = max(self._size, 0)\n",
    "        elif self._update_size: \n",
    "            self._size = 0\n",
    "            self._update_size = True\n",
    "        return self._size\n",
    "    \n",
    "    @property\n",
    "    def shape(self) -> Tuple[int, ...]:\n",
    "        if (\n",
    "                self._data is not None and \n",
    "                ( self._update_shape or self._shape is None or self._shape == 0 )\n",
    "        ):\n",
    "            try: \n",
    "                self._shape     = self._data.shape\n",
    "                self._shapes    = [ self._shape ]\n",
    "            except:\n",
    "                self._shape  = self._data[0].shape\n",
    "                self._shapes = [ self._data[i].shape for i in range(len(self._data))]\n",
    "            self._update_shape = False\n",
    "        elif self._update_shape: \n",
    "            self._shape = 0,\n",
    "            self._shapes = []\n",
    "            self._update_shape = True\n",
    "        return self._shape\n",
    "    @property\n",
    "    def shapes(self) -> List [ Tuple [ int, ... ]]:\n",
    "        if (\n",
    "            self._data is not None and \n",
    "            ( self._update_shape or self._shapes is None or self._shapes ==[])\n",
    "        ):\n",
    "            try: \n",
    "                self._shape     = self._data.shape\n",
    "                self._shapes    = [ self._shape ]\n",
    "            except:\n",
    "                self._shape     = self._data[0].shape\n",
    "                self._shapes    = [ self._data[i].shape for i in range(len(self._data))]\n",
    "            self._update_shape  = False\n",
    "        elif self._update_shape: \n",
    "            self._shape         = 0,\n",
    "            self._shapes        = []\n",
    "            self._update_shape  = True\n",
    "        return self._shapes\n",
    "            \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        self._data          = value\n",
    "        self._update_size   = True\n",
    "        self._update_shape  = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503fd7a-fb5f-4089-b719-44982985d43c",
   "metadata": {},
   "source": [
    "### LRScheduler\n",
    "Contains the information needed to use different schedulers types (for MVP, Model and Moirai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1687d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class LRScheduler:\n",
    "    lr              : float = None\n",
    "    flag            : bool  = None\n",
    "    name            : str   = None\n",
    "    num_warmup_steps: int   = None\n",
    "    scheduler               = None\n",
    "    monitor         : str   = \"valid_loss\"\n",
    "    interval        : str   = \"step\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.lr                 = self._check_lr(self.lr, 1e-5)\n",
    "        self.flag               = self._check_flag(self.flag, False)\n",
    "        self.name               = self._check_name(self.name, \"OneCycleR\")\n",
    "        self.num_warmup_steps   = self._check_steps(self.num_warmup_steps, 0)\n",
    "\n",
    "    # Validation methods\n",
    "    def _check_lr(self, value, default):\n",
    "        if not isinstance(value, (float, int)) or not math.isfinite(value) or value <= 0:\n",
    "            warnings.warn(f\"Invalid learning rate 'lr' ({value}). Using default: {default}\")\n",
    "            return default\n",
    "        return float(value)\n",
    "\n",
    "    def _check_flag(self, value, default):\n",
    "        if not isinstance(value, bool):\n",
    "            warnings.warn(f\"Invalid type for 'flag' ({type(value)}). Using default: {default}\")\n",
    "            return default\n",
    "        return value\n",
    "\n",
    "    def _check_name(self, value, default):\n",
    "        if not isinstance(value, str):\n",
    "            warnings.warn(f\"Invalid type for 'name' ({type(value)}). Using default: {default}\")\n",
    "            return default\n",
    "        return value\n",
    "\n",
    "    def _check_steps(self, value, default):\n",
    "        if not isinstance(value, int) or value < 0:\n",
    "            warnings.warn(f\"Invalid type or negative value for 'num_warmup_steps' ({value}). Using default: {default}\")\n",
    "            return default\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea800e7-4100-4905-86d7-5d6fcdf48d38",
   "metadata": {},
   "source": [
    "### EncoderOptimizer\n",
    "Contains the optimizer and the LRScheduler information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886179ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOptimizer():\n",
    "    criterion   : Optional   [ torch.nn.Module ]          = torch.nn.MSELoss\n",
    "    optimizer   : Optional   [ torch.optim.Optimizer ]    = None\n",
    "    lr          : Union      [ float, LRScheduler ]       = 1e-5\n",
    "\n",
    "    def _post__init__(self):\n",
    "        self.lr,_ = ut._check_value( self.lr, 1e-5, \"lr\", [ int, float ], False, True, False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1e53e-78ce-43e8-ba76-1b577ebc114f",
   "metadata": {},
   "source": [
    "#### Encoder \n",
    "Contains the full information about the encoder and its configuration and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d32d39e-3043-4f5a-98c3-8d86c26249b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Encoder():\n",
    "    input               : EncoderInput      = None \n",
    "    model               : Union [\n",
    "                            Learner, \n",
    "                            MOMENTPipeline,\n",
    "                            moirai.MoiraiModule\n",
    "    ]                                       = None\n",
    "    mssg                : ut.Mssg           = ut.Mssg()\n",
    "    cpu                 : bool              = False\n",
    "    to_numpy            : bool              = False\n",
    "    num_epochs          : int               = 1\n",
    "    optim               : EncoderOptimizer  = EncoderOptimizer()\n",
    "    mask_stateful       : bool              = False\n",
    "    mask_future         : bool              = False\n",
    "    mask_sync           : bool              = False\n",
    "    eval_stats_pre      : AttrDict          = None\n",
    "    eval_stats_post     : AttrDict          = None\n",
    "    use_moment_masks    : bool              = False\n",
    "    model_class         : str               = None\n",
    "    time_flag           : bool              = False\n",
    "    use_wandb           : bool              = False\n",
    "    analysis_mode       : str               = 'online'\n",
    "    splits              : Tuple             = None\n",
    "    show_plot           : bool              = False\n",
    "    norm_by_sample      : bool              = True\n",
    "    norm_use_single_batch : bool            = True\n",
    "    #--- Modificar para usar el diccionario\n",
    "    _metrics             : List [ Union [ Callable, evaluate.EvaluationModule ] ] = None\n",
    "    _metrics_names       : List [ str ]      = None\n",
    "    _metrics_args                            = None\n",
    "    #---\n",
    "    metrics_dict        : AttrDict          = None\n",
    "    default_metric                          = MSELossFlat #-- Default for MVP\n",
    "    criterion                               = None\n",
    "    scheduler_specific_kwargs : AttrDict    = None # Only for MOIRAI\n",
    "    #mvp_ws              : Tuple [ int, int ]= 0,0\n",
    "    errors               : pd.DataFrame     = pd.DataFrame(columns=[\"window\", \"error\"])\n",
    "    window_sizes         : List [int]       = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.model          , _ = ut._check_value(self.model, None, \"model\", [ MOMENTPipeline, Learner, moirai.MoiraiModule ], True, False, False, mssg = self.mssg)\n",
    "        self.model              = self.set_model_(self.model)\n",
    "        ## TODO: check how to do this check\n",
    "        #self.input          , _ = ut._check_value(self.input, EncoderInput(), \"input\", EncoderInput, True)\n",
    "        self.mssg           , _ = ut._check_value(self.mssg, ut.Mssg(), \"mssg\", ut.Mssg, mssg = self.mssg)\n",
    "        self.cpu            , _ = ut._check_value(self.cpu, False, \"cpu\", bool, mssg = self.mssg)\n",
    "        self.to_numpy       , _ = ut._check_value(self.to_numpy, False, \"to_numpy\", bool,  mssg = self.mssg)\n",
    "        self.num_epochs     , _ = ut._check_value(self.num_epochs, 1, \"num_epochs\", int, False, True,  mssg = self.mssg)\n",
    "        ## TODO: check how to do this check\n",
    "        #self.optim          , _ = ut._check_value(self.optim, EncoderOptimizer(), \"optim\", EncoderOptimizer)\n",
    "        self.mask_stateful  , _ = ut._check_value(self.mask_stateful, False, \"mask_statefull\", bool,  mssg = self.mssg)\n",
    "        self.mask_future    , _ = ut._check_value(self.mask_future, False, \"mask_future\", bool,  mssg = self.mssg)\n",
    "        self.mask_sync      , _ = ut._check_value(self.mask_sync, False, \"mask_sync\", bool,  mssg = self.mssg)\n",
    "        self.eval_stats_pre , _ = ut._check_value(self.eval_stats_pre, None, \"eval_stats_pre\", AttrDict, True,  mssg = self.mssg)\n",
    "        self.eval_stats_post, _ = ut._check_value(self.eval_stats_post, None, \"eval_stats_post\", AttrDict, True,  mssg = self.mssg)\n",
    "        self.use_moment_masks, _= ut._check_value(self.use_moment_masks, False, \"use_moment_masks\", bool,  mssg = self.mssg)\n",
    "        self.model_class        = None # Must be computed through get_model_class to avoid errors\n",
    "        self.time_flag      , _ = ut._check_value(self.time_flag, False, \"time_flag\", bool,  mssg = self.mssg)\n",
    "        self.show_plot      , _ = ut._check_value(self.show_plot, False, \"show_plot\", bool, mssg = self.mssg)\n",
    "        self.window_sizes       = [] if self.window_sizes is None else self.window_sizes\n",
    "    @property\n",
    "    def metrics_names(self):\n",
    "        self._metrics_names = self.metrics_dict.keys() if self.metrics_dict else None\n",
    "        return self._metrics_names\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        self._metrics = None\n",
    "        if self.metrics_dict:\n",
    "            self._metrics = [\n",
    "                self.metrics_dict[n]['metric']\n",
    "                for n in self.metrics_dict.keys()\n",
    "            ]\n",
    "        return self._metrics\n",
    "    \n",
    "    @property\n",
    "    def metrics_args(self):\n",
    "        self._metric_args = None \n",
    "        if self.metrics_dict:\n",
    "            self._metrics_args = [\n",
    "                self.metrics_dict[n]['args']\n",
    "                for n in self.metrics_dict.keys()\n",
    "            ]\n",
    "        return self._metrics_args\n",
    "    \n",
    "    def print(self, **kwargs):\n",
    "        self.mssg.print(**kwargs)\n",
    "\n",
    "    def get_model_class(self, force : bool = False): \n",
    "        if force or self.model_class is None:\n",
    "            self.model_class = str(self.model.__class__)[8:-2]\n",
    "        return self.model_class\n",
    "    def set_model_(self, model):\n",
    "        if model is not None:\n",
    "            self.model          = model\n",
    "            self.model_class    = self.get_model_class() \n",
    "            try: # Initially it may not be defined and that would result in an execution error\n",
    "                self.fine_tune_     = self.set_fine_tune_()\n",
    "            except:\n",
    "                self.fine_tune_ = None\n",
    "        return self.model\n",
    "    \n",
    "    def get_splits_(self, n_sample: int = None):\n",
    "        self.mssg.initial_(ut.funcname())\n",
    "        #TODO: add checks for datatype to ensure the dataset is not already windowed\n",
    "        assert self.analysis_mode in [ 'ofline', 'online'], 'Invalid analysis mode'\n",
    "        X = self.input.data if n_sample is None else self.input.data[n_sample]\n",
    "        self.mssg.print(f\"len(X)={len(X)}\")\n",
    "        match self.analysis_mode:\n",
    "            case 'online':\n",
    "                self.mssg.print(\"Online analysis\", verbose_level = self.mssg.level+1)\n",
    "                self.splits = TimeSplitter(valid_size = 0.2, show_plot = self.show_plot)(X)\n",
    "            case 'offline':\n",
    "                self.mssg.print(\"Offline analysis\", verbose_level = self.mssg.level+1)\n",
    "                self.splits = get_splits(np.arange(len(X)), valid_size=self.valid_size, show_plot = self.show_plot)\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Encoderl{ut.funcname()} | Case {self.analysis_mode} not implemented. Use one of the following options: <online|offline>.\")\n",
    "        self.mssg.print(f\"X~{X.shape}\")\n",
    "        self.mssg.print(f\"Train: {len(self.splits[0])} | Test { len(self.splits[1])}\")\n",
    "        self.mssg.final()\n",
    "        return X   \n",
    "    def setup_scheduler(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def config_optim(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    #--- Moment\n",
    "    def sure_eval_moment(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_eval_preprocess(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_(self): \n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_train_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_train_loop_step_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_eval_step_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    #--- MVP\n",
    "    def fine_tune_mvp_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_mvp_(self): \n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    #--- Moirai\n",
    "    def configure_optimizer_moirai(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def get_enc_embs_moirai_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def get_dist_moirai_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_eval_step_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_eval_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_(self): \n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_train_loop_step_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_train_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    #--- Global\n",
    "    def fine_tune_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def set_fine_tune_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def show_eval_stats(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moment_eval_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e10213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_fine_tune_single_(\n",
    "    self: Encoder\n",
    ") -> Callable:\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    model_class = self.get_model_class()\n",
    "    self.mssg.print(f\"Model class: {model_class}\")\n",
    "    match model_class:\n",
    "        case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "            self.fine_tune_single_ = self.fine_tune_moment_single_\n",
    "        case \"fastai.learner.Learner\":\n",
    "            self.fine_tune_single_ = self.fine_tune_mvp_single_\n",
    "        case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "            self.fine_tune_single_ = self.fine_tune_moirai_single_\n",
    "        case _:\n",
    "            self.mssg.print(f\"Fine-tune single shot implementation is not yet implemented for {self.model_class}.\", verbose_level = self.mssg.level+1)\n",
    "            raise NotImplementedError(f\"fine_tune_single_ | Not yet implemented for {self.model_class}\")\n",
    "    self.mssg.final(ut.funcname())\n",
    "    return(self.fine_tune_single_)\n",
    "Encoder.set_fine_tune_single_ = set_fine_tune_single_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abcdc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_fine_tune_(\n",
    "    self: Encoder\n",
    ") -> Callable:\n",
    "    self.mssg.initial_(\"set_fine_tune_\")\n",
    "    model_class = self.get_model_class()\n",
    "    self.mssg.print(f\"Model class: {model_class}\")\n",
    "    match model_class:\n",
    "        case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "            self.mssg.print(f\"Moment\")\n",
    "            self.fine_tune_ = self.fine_tune_moment_\n",
    "        case \"fastai.learner.Learner\":\n",
    "            self.mssg.print(f\"MVP\")\n",
    "            self.fine_tune_ = self.fine_tune_mvp_\n",
    "        case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "            raise NotImplementedError(f\"fine_tune | Not yet implemented for {self.model_class}\")\n",
    "            self.mssg.print(f\"Moirai\")\n",
    "            self.fine_tune_ = self.fine_tune_moirai_\n",
    "        case _:\n",
    "            self.mssg.print(f\"Fine-tune implementation is not yet implemented for {self.model_class}.\", verbose_level = self.mssg.level+1)\n",
    "            raise NotImplementedError(f\"fine_tune | Not yet implemented for {self.model_class}\")\n",
    "    self.mssg.final(ut.funcname())\n",
    "    return(self.fine_tune_)\n",
    "Encoder.set_fine_tune_ = set_fine_tune_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9002505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_eval_stats(\n",
    "    self            : Encoder, \n",
    "    print_to_path   : bool      = None, \n",
    "    print_path      : str       = None, \n",
    "    print_mode      : str       = None,\n",
    "    eval_pre        : bool = False,\n",
    "    eval_post       : bool = False,\n",
    "    eval_stats_pre  : AttrDict = None,\n",
    "    eval_stats_post : AttrDict = None,\n",
    "    func_name       : str = \"\"\n",
    "):\n",
    "    self.mssg.print(f\"{func_name} | Evaluation summary\")\n",
    "    self.eval_stats_pre = self.eval_stats_pre if eval_stats_pre is None else eval_stats_pre\n",
    "    self.eval_stats_post = self.eval_stats_post if eval_stats_post is None else eval_stats_post\n",
    "    self.mssg.to_path = self.mssg.to_path if print_to_path is None else print_to_path\n",
    "    self.mssg.path = self.mssg.path if print_path is None else print_path\n",
    "    self.mssg.mode = self.mssg.mode if print_mode is None else print_mode        \n",
    "    if (eval_pre):\n",
    "        self.mssg.print(f\"Eval pre: \")\n",
    "        show_attrdict(\n",
    "            self.eval_stats_pre,\n",
    "            print_to_path   = self.mssg.to_path,\n",
    "            print_path      = self.mssg.path,\n",
    "            print_mode      = self.mssg.mode\n",
    "        )\n",
    "    if eval_post:\n",
    "        self.mssg.print(f\"Eval post: \")\n",
    "        show_attrdict(\n",
    "            self.eval_stats_post,\n",
    "            print_to_path   = self.mssg.to_path,\n",
    "            print_path      = self.mssg.path,\n",
    "            print_mode      = self.mssg.mode \n",
    "        )\n",
    "Encoder.show_eval_stats = show_eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71de2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def plot_eval_stats(\n",
    "    self, \n",
    "    figsize         = (10, 6), \n",
    "    save_fig        = False, \n",
    "    save_path       = \"./\", \n",
    "    fname           = \"evaluation_metrics_plot\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot evaluation metrics from eval_results_pre and eval_results_post across epochs.\n",
    "    \"\"\"\n",
    "    self.mssg.level += 1\n",
    "    fname = self.mssg.function\n",
    "    self.mssg.initial_(\"plot_eval_stats\")\n",
    "    # Validar que las métricas están presentes\n",
    "    if not self.eval_stats_pre or not self.eval_stats_post:\n",
    "        raise ValueError(\"Evaluation results (eval_stats_pre or eval_stats_post) are missing.\")\n",
    "    \n",
    "    # Extraer las métricas pre y post\n",
    "    metrics_pre = self.eval_stats_pre  # Diccionario con las métricas iniciales\n",
    "    metrics_post = self.eval_stats_post  # Lista de diccionarios con métricas post-época\n",
    "\n",
    "    # Crear el rango de épocas (incluyendo la inicial)\n",
    "    epochs = list(range(self.num_epochs-1))\n",
    "    self.mssg.print_error(f\"epochs~{len(epochs)}: {epochs}\")\n",
    "    # Inicializar el gráfico\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Iterar sobre las métricas (las claves del diccionario pre/post)\n",
    "    for metric in metrics_pre.keys():\n",
    "        # Crear lista de valores para esta métrica\n",
    "        values = [metrics_pre[metric]] + metrics_post[metric]\n",
    "        #self.mssg.print_error(f\"{metric}.values~{len(values)}: {values}\")\n",
    "        # Graficar la métrica\n",
    "        plt.plot(epochs, values, label=metric)\n",
    "    \n",
    "    # Configurar etiquetas y leyenda\n",
    "    plt.title(\"Evaluation Metrics Across Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Metric Value\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    if save_fig:\n",
    "        # Asegurarse de que el directorio existe\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Ruta completa del archivo\n",
    "        save_file = os.path.join(save_path, \"{fname}.png\")\n",
    "        \n",
    "        # Guardar el gráfico\n",
    "        plt.savefig(save_file, dpi=300, bbox_inches=\"tight\")\n",
    "        self.mssg.print(f\"Stats plot saved at: {save_file}\")\n",
    "    plt.show()\n",
    "    self.mssg.final()\n",
    "    self.mssg.function = fname\n",
    "Encoder.plot_eval_stats = plot_eval_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04637a46",
   "metadata": {},
   "source": [
    "## Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c036898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "class DCAE_torch(Module):\n",
    "    def __init__(self, c_in, seq_len, delta, nfs=[64, 32, 12], kss=[10, 5, 5],\n",
    "                 pool_szs=[2,2,3], output_fsz=10):\n",
    "        \"\"\"\n",
    "        Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions,\n",
    "        sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be\n",
    "        contained in the Dense layer of the network. The the number of features\n",
    "        maps (filters), the filter size and the pool size can also be adjusted.\"\n",
    "        \"\"\"\n",
    "        assert all_equal([len(x) for x in [nfs, kss, pool_szs]], np.repeat(len(nfs), 3)), \\\n",
    "            'nfs, kss, and pool_szs must have the same length'\n",
    "        assert np.prod(pool_szs) == nfs[-1], \\\n",
    "            'The number of filters in the last conv layer must be equal to the product of pool sizes'\n",
    "        assert seq_len % np.prod(pool_szs) == 0, \\\n",
    "            'The product of pool sizes must be a divisor of the window size'\n",
    "        layers = []\n",
    "        for i in range_of(kss):\n",
    "            layers += [Conv1d(ni=nfs[i-1] if i>0 else c_in, nf=nfs[i], ks=kss[i]),\n",
    "                       nn.MaxPool1d(kernel_size=pool_szs[i])]\n",
    "        self.downsample = nn.Sequential(*layers)\n",
    "        self.bottleneck = nn.Sequential(OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('latent_in', nn.Linear(seq_len, delta)),\n",
    "            ('latent_out', nn.Linear(delta, seq_len)),\n",
    "            ('reshape', Reshape(nfs[-1], seq_len // np.prod(pool_szs)))\n",
    "        ]))\n",
    "        layers = []\n",
    "        for i in reversed(range_of(kss)):\n",
    "            layers += [Conv1d(ni=nfs[i+1] if i != (len(nfs)-1) else nfs[-1],\n",
    "                              nf=nfs[i], ks=kss[i]),\n",
    "                       nn.Upsample(scale_factor=pool_szs[i])]\n",
    "        layers += [Conv1d(ni=nfs[0], nf=c_in, kernel_size=output_fsz)]\n",
    "        self.upsample = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59aa6e7-36df-4697-993e-60f737bb0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = torch.rand(3, 1, 48)\n",
    "m = DCAE_torch(c_in=foo.shape[1], seq_len=foo.shape[2], delta=12)\n",
    "m(foo).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a4a1d-389c-481a-a54d-3f86cd2115f5",
   "metadata": {},
   "source": [
    "### Dictionary to get the default backbone modules to get the embeddings from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3eb9f1b6-ae45-4b6e-b535-c7f121208721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "ENCODER_EMBS_MODULE_NAME = {\n",
    "    InceptionTimePlus: 'backbone', # for mvp based models\n",
    "    DCAE_torch: 'bottleneck.latent_in'#,\n",
    "    #MoiraiForecast: 'mask_encoding' #TODO: check\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd092c6",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b767199f-99b4-4819-8a00-54f15577f7a4",
   "metadata": {},
   "source": [
    "### Weight & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2b185-ade0-49cb-80f3-f40d6c7a03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CustomWandbCallback(WandbCallback):\n",
    "    \"\"\"\n",
    "    Callback that extends WandbCallback to avoid errors when validation \n",
    "    is done before training.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def before_fit(self):\n",
    "        \"\"\"\n",
    "        Overrides before_fit to ensure that'epoch' key exists.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if wandb.run is not None and wandb.run.step:\n",
    "                if 'epoch' not in wandb.run.summary._as_dict():\n",
    "                    wandb.run.summary.update({'epoch': 0})\n",
    "        except Exception as e:\n",
    "            print(f\"Error while checking epoch in wandb: {e}\")\n",
    "            raise \n",
    "        super().before_fit() # Call the original method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db8a5d-177c-48f5-a1b3-1d0adc4ccce6",
   "metadata": {},
   "source": [
    "## Get activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ddd69f0-e3b8-4ebc-8fdf-0808eb9e0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def kwargs_to_gpu_(**kwargs):\n",
    "    for key in kwargs:\n",
    "        try: #if not able to be moved, just not move it\n",
    "            kwargs[key] = kwargs[key].to(\"cuda\")\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "def kwargs_to_cpu_(**kwargs):\n",
    "    for key in kwargs:\n",
    "        try: #if not able to be moved, just not move it\n",
    "            kwargs[key] = kwargs[key].cpu()\n",
    "        except:\n",
    "            continue\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ac0f9ca-a5c1-4292-8e7b-d3f76872c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_acts(\n",
    "    model : torch.nn.Module, \n",
    "    module: torch.nn.Module, \n",
    "    cpu   : bool, \n",
    "    verbose : int = 0,\n",
    "    retry: bool = False,\n",
    "    acts_indices: List [ int ] = None,\n",
    "    #- Printing options for debugging\n",
    "    print_to_path   : bool          = False,\n",
    "    print_path      : str           = \"~/data/logs/logs.txt\",\n",
    "    print_mode      : str           = 'a',\n",
    "    continue_if_fail: bool          = False,\n",
    "    **model_kwargs #Parameters of the model\n",
    "):\n",
    "    if verbose > 0:\n",
    "        ut.print_flush(f\"--> get acts | acts indices: {acts_indices}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    if cpu:\n",
    "        if verbose > 0: ut.print_flush(f\"get acts | Moving to cpu\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "        for key in model_kwargs:\n",
    "            try: #if not able to be moved, just not move it\n",
    "                model_kwargs[key] = model_kwargs[key].cpu()\n",
    "            except:\n",
    "                continue\n",
    "        model.to(\"cpu\")\n",
    "    else:\n",
    "        if verbose > 0: ut.print_flush(f\"get acts | Moving to gpu\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "        for key in model_kwargs:\n",
    "            try: #if not able to be moved, just not move it\n",
    "                model_kwargs[key] = model_kwargs[key].to(\"cuda\")\n",
    "            except:\n",
    "                continue\n",
    "        model.to(\"cuda\")\n",
    "    if verbose > 0: ut.print_flush(f\"get acts | Add hooks\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    h_act = hook_outputs([module], detach = True, cpu = cpu, grad = False)\n",
    "    with torch.no_grad():\n",
    "        if verbose > 0: ut.print_flush(f\"get acts | --> Run forward\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "        if retry:\n",
    "            if verbose > 0: ut.print_flush(f\"get acts | Retry\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "            try: \n",
    "                preds = model.eval()(**model_kwargs)\n",
    "            except Exception as e:\n",
    "                ut.print_flush(f\"get acts | Retry | Error: {e}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                ut.print_flush(f\"get acts | Retry | Kwargs: {model_kwargs}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                if not cpu:\n",
    "                    ut.print_flush(f\"get acts | Retry | Moving to cpu\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                    for key in model_kwargs:\n",
    "                        try: #if not able to be moved, just not move it\n",
    "                            model_kwargs[key] = model_kwargs[key].cpu()\n",
    "                        except:\n",
    "                            continue\n",
    "                    model.to(\"cpu\")\n",
    "                    if verbose > 0: ut.print_flush(f\"get acts | Retry | cpu\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                    ut.print_flush(f\"get acts | Retry | Get acts\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                    preds = model.eval()(**model_kwargs)\n",
    "        else:\n",
    "            if verbose > 2: ut.print_flush(f\"get acts | No Retry | Get acts | model kwargs: {model_kwargs}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "            preds = model.eval()(**model_kwargs)\n",
    "    if acts_indices is None:\n",
    "        res = [o.stored for o in h_act]\n",
    "    else: \n",
    "        stored = [o.stored for o in h_act]\n",
    "        res = [stored[i] for i in acts_indices]\n",
    "        if len(acts_indices) == 1:\n",
    "            res = res[0]\n",
    "        del stored\n",
    "    if verbose > 0: ut.print_flush(f\"get acts | Run forward -->\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    if verbose > 0:ut.print_flush(f\"get acts -->\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6807aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_acts_moment(\n",
    "    enc_learn, \n",
    "    cpu             : bool          = False, \n",
    "    verbose         : int           = 0, \n",
    "    y               : List [ float ]= [], \n",
    "    mask                            = None, \n",
    "    padd_step       : int           = 100, \n",
    "    # Parameters for avoiding errors\n",
    "    retry           : bool          = False, \n",
    "    max_trials      : int           = 5,\n",
    "    # Activation selector (various vectors in the acts)\n",
    "    acts_indices    : List [ int ]  = [0],\n",
    "    #- Printing options for debugging\n",
    "    print_to_path   : bool          = False,\n",
    "    print_path      : str           = \"~/data/logs/logs.txt\",\n",
    "    print_mode      : str           = 'a',\n",
    "    continue_if_fail: bool          = False\n",
    "):\n",
    "    success = False \n",
    "    trial = 0\n",
    "    embs = None\n",
    "    while not success and trial < max_trials:\n",
    "        trial += 1\n",
    "        try:\n",
    "            if verbose > 0: ut.print_flush(f\"get_acts_moment | Trial {trial} | x_enc ~ {y.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "            embs = get_acts(\n",
    "                model = enc_learn,\n",
    "                #module = enc_learn.encoder.dropout,\n",
    "                module = enc_learn.head.dropout,\n",
    "                cpu = cpu,\n",
    "                verbose = 0,\n",
    "                x_enc = y,\n",
    "                retry = retry,\n",
    "                acts_indices = acts_indices,\n",
    "                mask = mask,\n",
    "                print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, print_time = print_to_path\n",
    "            )\n",
    "            success = True\n",
    "            if verbose > 0 and acts_indices == [0] : ut.print_flush(f\"get_acts_moment | Trial {trial} | embs ~ {embs.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "        except Exception as e:\n",
    "            if trial == max_trials - 1 : raise\n",
    "            if verbose > 0:\n",
    "                ut.print_flush(f\"get_acts_moment | Trial {trial} | About to pad X (encoder input) | exception {e} | padd step: {padd_step}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                ut.print_flush(f\"get_acts_moment | Trial {trial} | y ~ {y.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "            if \"tensor a\" in str(e) and \"tensor b\" in str(e):\n",
    "                match = re.search(r'tensor a \\((\\d+)\\) must match the size of tensor b \\((\\d+)\\)', str(e))\n",
    "                tensor_a_size = int(match.group(1))\n",
    "                tensor_b_size = int(match.group(2))\n",
    "                padd = True\n",
    "                if trial > 1: \n",
    "                    if verbose > 0: ut.print_flush(f\"------------------- Trial {trial}  -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                    if tensor_a_size > tensor_a_size_old:\n",
    "                        if verbose > 0:  ut.print_flush(f\"------------------- Trial {trial} | a > a_old -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                        padd = False\n",
    "                        y = y [ ..., : tensor_a_size - tensor_b_size]\n",
    "                        if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} |a > a_old | Reduced |  y ~ {y.shape} -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                if padd:\n",
    "                    if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} | Padd -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                    if tensor_a_size > tensor_b_size: \n",
    "                        if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} | Padd | a > b -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                        padd_step = tensor_a_size - tensor_b_size\n",
    "                    y = torch.nn.functional.pad(y,(0,padd_step))\n",
    "                tensor_a_size_old = tensor_a_size\n",
    "            else:\n",
    "                if verbose > 0: ut.print_flush(\"Not the usual error. No padding, just fail\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "                raise\n",
    "                \n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f86af7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| todo pasar a clase\n",
    "def sure_eval_moment_old(\n",
    "    enc_learn, \n",
    "    cpu, \n",
    "    verbose, \n",
    "    y, \n",
    "    input_mask      = None, \n",
    "    mask            = None, \n",
    "    padd_step       = 100, \n",
    "    retry           = False, \n",
    "    max_trials      = 5, \n",
    "    acts_indices    = [0],\n",
    "    #- Printing options for debugging\n",
    "    print_to_path   : bool          = False,\n",
    "    print_path      : str           = \"~/data/logs/logs.txt\",\n",
    "    print_mode      : str           = 'a',\n",
    "    continue_if_fail: bool          = False\n",
    "):\n",
    "    if verbose > 0: ut.print_flush(f\"---> sure_eval_moment\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    device = \"cpu\" if cpu else torch.cuda.current_device()\n",
    "    y_copy = y.clone()\n",
    "    try: \n",
    "        y_copy.to(\"cpu\")\n",
    "    except:\n",
    "        ut.print_flush(f\"sure_eval_moment | Failed moving y to  {device}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = 5, print_time = print_to_path) \n",
    "    if verbose > 0: ut.print_flush(f\"sure_eval_moment | cpu | {cpu} | device | {device}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path) \n",
    "    success = False \n",
    "    trial = 0\n",
    "    output = None\n",
    "\n",
    "    ut.print_flush(f\"sure_eval_moment | in | {enc_learn.head.linear.in_features} out | {enc_learn.head.linear.out_features} | y ~{y.shape}\")\n",
    "    \n",
    "    while not success and (trial == 0 or (retry & trial < max_trials)):\n",
    "        trial += 1\n",
    "        try:\n",
    "            if verbose > 0: ut.print_flush(f\"sure_eval_moment | Trial {trial} | x_enc ~ {y.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "            if input_mask is not None: input_mask = input_mask.to(device)\n",
    "            if mask is not None: mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "            enc_learn = enc_learn.to(device)\n",
    "            if verbose > 0: \n",
    "                ut.print_flush(f\"sure_eval_moment | Trial {trial} | device {device} | input_mask~{input_mask.shape} device: {input_mask.device if input_mask is not None else 'None'}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                ut.print_flush(f\"sure_eval_moment | Trial {trial} | device {device} | mask device~{mask.shape}: {mask.device if mask is not None else 'None'}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                ut.print_flush(f\"sure_eval_moment | Trial {trial} | device {device} | y~{y.shape} device: {y.device}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "            output = enc_learn(\n",
    "                x_enc = y, \n",
    "                input_mask = input_mask, mask = mask)\n",
    "            success = True\n",
    "            if verbose > 0 and acts_indices == [0] : \n",
    "                ut.print_flush(f\"sure_eval_moment | Trial {trial} | embs ~ {embs.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "        except Exception as e:\n",
    "            if verbose > 0:\n",
    "                ut.print_flush(f\"sure_eval_moment | Trial {trial} | About to pad X (encoder input) | exception {e} | padd step: {padd_step}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                ut.print_flush(f\"sure_eval_moment | Trial {trial} | y ~ {y.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                traceback.print_exc()\n",
    "            if \"tensor a\" in str(e) and \"tensor b\" in str(e) and \"dimension\" in str(e):\n",
    "                match = re.search(r'tensor a \\((\\d+)\\) must match the size of tensor b \\((\\d+)\\) at non-singleton dimension (\\d+)', str(e))\n",
    "                tensor_a_size = int(match.group(1))\n",
    "                tensor_b_size = int(match.group(2))\n",
    "                dimension = int(match.group(3))\n",
    "                match dimension:\n",
    "                    case 2 | 1:\n",
    "                        padd = True\n",
    "                        if trial > 1: \n",
    "                            if verbose > 0: ut.print_flush(f\"------------------- Trial {trial}  -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                            if tensor_a_size > tensor_a_size_old:\n",
    "                                if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} | a > a_old -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                                padd = False\n",
    "                                y = y [ ..., : tensor_a_size - tensor_b_size]\n",
    "                                if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} |a > a_old | Reduced |  y ~ {y.shape} -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                        if padd:\n",
    "                            if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} | Padd -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                            if tensor_a_size > tensor_b_size: \n",
    "                                if verbose > 0: ut.print_flush(f\"------------------- Trial {trial} | Padd | a > b -----------------\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                                padd_step = tensor_a_size - tensor_b_size\n",
    "                            y = torch.nn.functional.pad(y,(0,padd_step))\n",
    "                        tensor_a_size_old = tensor_a_size\n",
    "                    #case 1: \n",
    "                    #    if verbose > 0:\n",
    "                    #        ut.print_flush(f\"sure_eval_moment | Trial {trial} | Error dimension 0 | mask ~ {mask.shape} | mask_input ~ {input_mask.shape} | batch ~ {y.shape}\")\n",
    "                    #        if mask.shape[1] < y.shape[2]: mask = torch.nn.functional.pad(mask,(0,y.shape[2]-mask.shape[1]))\n",
    "                    #        if input_mask.shape[2] < y.shape[2]: mask = torch.nn.functional.pad(input_mask,(0,y.shape[2]-input_mask.shape[2]))\n",
    "\n",
    "                    case 0:\n",
    "                        if verbose > 0: \n",
    "                            ut.print_flush(f\"sure_eval_moment | Trial {trial} | Error dimension 0 | mask ~ {mask.shape} | mask_input ~ {input_mask.shape} | batch ~ {y.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)                    \n",
    "                        if mask.shape[0] > y.shape[0]:\n",
    "                            mask = mask[:y.shape[0]]\n",
    "                        if input_mask.shape[0] > y.shape[0]:\n",
    "                            input_mask = input_mask[:y.shape[0]]\n",
    "                        \n",
    "                        if mask.shape[0] < y.shape[0]:\n",
    "                            extra_rows_shape = (-mask.shape[0]+y.shape[0],mask.shape[1])\n",
    "                            if verbose > 0: ut.print_flush(f\"sure_eval_moment | Trial {trial} | Mask lower than batch | rows to add: {extra_rows_shape }\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                            extra_rows = torch.zeros(extra_rows_shape, dtype = torch.float32)\n",
    "                            mask = torch.cat((mask, extra_rows), dim=0)\n",
    "                        if input_mask.shape[0] < y.shape[0]:\n",
    "                            extra_rows_shape = (-input_mask.shape[0]+y.shape[0],y.shape[1], y.shape[2])\n",
    "                            if verbose > 0: ut.print_flush(f\"sure_eval_moment | Trial {trial} | Mask lower than batch | rows to add: {extra_rows_shape }\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                            extra_rows = torch.zeros(extra_rows_shape, dtype = torch.float32)\n",
    "                            input_mask = torch.cat((input_mask, extra_rows), dim=0)\n",
    "            else:\n",
    "                if verbose > 0: \n",
    "                    ut.print_flush(\"Not the usual error. No padding, just fail\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "                if not continue_if_fail: raise\n",
    "        #if verbose > 0: ut.print_flush(f\"sure_eval_moment | output {output.__class__} | enc_learn {enc_learn.__class__} -->\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "        if verbose > 0: ut.print_flush(f\"sure_eval_moment | output {output.__class__} -->\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    y = y_copy\n",
    "    if not cpu: y.to(\"cuda\")\n",
    "    \n",
    "    return output, enc_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d942af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sure_eval_moment(\n",
    "    self, \n",
    "    batch, \n",
    "    input_mask                      = None, \n",
    "    mask                            = None, \n",
    "    padd_step       : int           = 100,\n",
    "    retry           : bool          = False,\n",
    "    max_trials      : int           = 5,\n",
    "    acts_indices    : List [int]    = [0],\n",
    "    continue_if_fail: bool          = False\n",
    "):\n",
    "    func                = self.mssg.function\n",
    "    self.mssg.level     += 1\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    device              = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    batch_copy          = batch.clone()\n",
    "    batch_copy.to(device)\n",
    "    \n",
    "    self.mssg.print_error(f\"Check input mask (should have same size than batch. If padd, with 0s): {input_mask.shape}: {input_mask}\")\n",
    "    self.mssg.print_error(f\"Check mask (is the one with the percentages in 0 to guess): {mask.shape}: {mask}\")\n",
    "    self.mssg.print_error(f\"Check batch | batch~{batch.shape}\")\n",
    "    self.mssg.print(\"Get the embeddings\")\n",
    "    output = self.model(\n",
    "        x_enc       = batch,\n",
    "        input_mask  = input_mask,\n",
    "        mask        = mask\n",
    "    )\n",
    "    self.mssg.final()\n",
    "    self.mssg.level     -= 1\n",
    "    self.mssg.function  = func\n",
    "    return output\n",
    "Encoder.sure_eval_moment = sure_eval_moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a268f-8b4e-4432-b203-79263a247c4c",
   "metadata": {},
   "source": [
    "## Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a992422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_ensure_batch_size_(\n",
    "    dls        : TSDataLoaders,\n",
    "    batch_size : int = None,\n",
    "    verbose    : int = 0\n",
    ") -> None:\n",
    "    if batch_size is None:\n",
    "        if verbose > 1: \n",
    "            ut.print_flush(f\"[ Get Encoder Embeddings Ensure Batch Size ] No batch size proposed\", verbose = verbose)\n",
    "        if dls.bs == 0: \n",
    "            if verbose > 1: \n",
    "                ut.print_flush(f\"[ Get Encoder Embeddings Ensure Batch Size ] Using value 64 as 0 is not a valid value.\", verbose = verbose)\n",
    "            enc_learn.dls.bs = 64\n",
    "        elif verbose > 1: \n",
    "            ut.print_flush(f\"[ Get Encoder Embeddings Ensure Batch Size ] Using the original value: {dls.bs}\", verbose = verbose)\n",
    "    else:\n",
    "        dls.bs = batch_size\n",
    "        if verbose > 1: \n",
    "            ut.print_flush(f\"[ Get Encoder Embeddings Ensure Batch Size ] Batch size proposed. Using {dls.bs}\", verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65c66ae6-3178-49dc-bd16-64c082012e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_MVP(\n",
    "    X               : List [ List [ List [ float ] ] ], \n",
    "    enc_learn       : Learner, \n",
    "    module          : str  = None, \n",
    "    cpu             : bool = False, \n",
    "    average_seq_dim : bool = True, \n",
    "    to_numpy        : bool = True,\n",
    "    batch_size      : int  = None,\n",
    "    verbose         : int  = 0\n",
    "):\n",
    "    \"\"\"\n",
    "        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai\n",
    "        learner. By default, the embeddings are obtained from the last layer\n",
    "        before the model head, although any layer can be passed to `model`.\n",
    "        Input\n",
    "        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n",
    "        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n",
    "        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n",
    "        - `batch_size`: force data loader to use the input batch size\n",
    "        - `verbose`: print flag. More big, more information.\n",
    "    \"\"\"\n",
    "    \n",
    "    if cpu:\n",
    "        if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] CPU\")\n",
    "        enc_learn.dls.cpu()\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] --> GPU\")\n",
    "        if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] GPU | Ensure empty cache\")\n",
    "        torch.cuda.empty_cache()\n",
    "        if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] GPU | Move & exec into CUDA\")\n",
    "        enc_learn.dls.cuda()\n",
    "        enc_learn.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            if verbose > 1: \n",
    "                ut.print_flush(\"[ Get Encoder Embeddings ] GPU | CUDA is available\")\n",
    "                ut.print_flush(f\"[ Get Encoder Embeddings ] GPU | CUDA is available | current device id {torch.cuda.current_device()}\")\n",
    "                ut.print_flush(f\"[ Get Encoder Embeddings ] GPU | CUDA is available | current device name {torch.cuda.get_device_name(torch.cuda.current_device())}\")            \n",
    "        else:\n",
    "            if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] GPU | CUDA is not available\")\n",
    "        if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] GPU -->\")\n",
    "\n",
    "    #if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] Ensure the correct batch size\")\n",
    "    #get_enc_embs_ensure_batch_size_(enc_learn.dls, batch_size, verbose)\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] Set dataloader from X (enc_learn does not contain dls)\")\n",
    "    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n",
    "    get_enc_embs_ensure_batch_size_(aux_dl, batch_size, verbose)\n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] Get module\")\n",
    "    module = nested_attr(enc_learn.model,ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) if module is None else module\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads \")\n",
    "    if verbose > 1: ut.print_flush(f\"[ Get Encoder Embeddings ] get_acts_and_grads bs = {aux_dl.bs}\")\n",
    "    \n",
    "    embs = [\n",
    "        get_acts_and_grads(\n",
    "            model   = enc_learn.model,\n",
    "            modules = module,\n",
    "            x       = xb[0], \n",
    "            cpu     = cpu\n",
    "        )[0] \n",
    "        for xb in aux_dl\n",
    "    ]\n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads | --> Concat\")\n",
    "    if not cpu:\n",
    "        if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads | Concat | Check neccesary & free memory\")\n",
    "        total_emb_size = sum([emb.element_size() * emb.nelement() for emb in embs])\n",
    "        free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()\n",
    "        if (total_emb_size < free_memory):\n",
    "            if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads | Concat | Check neccesary & free memory | Fits in GPU -> Computing in GPU\")\n",
    "            embs=[emb.cuda() for emb in embs]\n",
    "        else:\n",
    "            if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads | Concat | Check neccesary & free memory | Does not fit in GPU -> Computing in CPU\")\n",
    "            embs=[emb.cpu() for emb in embs]\n",
    "    if verbose > 1: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads | Concat | to_concat\")\n",
    "    embs = to_concat(embs)\n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] get_acts_and_grads | Concat -->\")\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] Reduce to 2 dimensions.\")\n",
    "    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n",
    "    if verbose > 0: ut.print_flush(\"[ Get Encoder Embeddings ] Ensure CPU saving & numpy format\")\n",
    "    if to_numpy: embs = embs.numpy() if cpu else embs.cpu().numpy()\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51ad3b28-43c0-4df3-be57-3eecb76b17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_enc_embs_MVP_set_stride_set_batch_size(\n",
    "    X                  : List [ List [ List [ float ] ] ], \n",
    "    enc_learn          : Learner, \n",
    "    stride             : int, \n",
    "    batch_size         : int, \n",
    "    module             : str  = None, \n",
    "    cpu                : bool = False, \n",
    "    average_seq_dim    : bool = True, \n",
    "    to_numpy           : bool = True, \n",
    "    verbose            : int  = 0, \n",
    "    time_flag          : bool = False, \n",
    "    chunk_size         : int  = 0, \n",
    "    check_memory_usage : bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai\n",
    "        learner. By default, the embeddings are obtained from the last layer\n",
    "        before the model head, although any layer can be passed to `model`.\n",
    "        Input\n",
    "        - `X`: encoder input\n",
    "        - `enc_learn`: trained encoder\n",
    "        - `stride`: stride used for the training. Neccesary for adjusting the encoder input\n",
    "        - `batch_size`: value to force the dataloader to use.\n",
    "        - `module`: for geting the embeddings of an specific layer.\n",
    "        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n",
    "        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n",
    "        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n",
    "        - `verbose`: For printing messages. More big, more messages.\n",
    "        - `time_flag`: To take note of the execution time required by this function\n",
    "        - `chunk_size`: For spliting the embedings reading in batches of `chunk_size` size.\n",
    "        - `check_memory_usage`: For showing messages of the current state of the memory.\n",
    "    \"\"\"\n",
    "    if time_flag:\n",
    "        t_start = time.time()\n",
    "    if verbose > 0:\n",
    "        ut.print_flush(\"--> get_enc_embs_MVP_set_stride_set_batch_size\", verbose = verbose)\n",
    "    if check_memory_usage: gpu_memory_status()\n",
    "    X = X[::stride]\n",
    "    enc_learn.dls.bs = batch_size \n",
    "\n",
    "    get_enc_embs_ensure_batch_size_(enc_learn.dls, batch_size, verbose)\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Check CUDA | X ~ {X.shape[0]}\", verbose = verbose)\n",
    "    if cpu:\n",
    "        if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Get enc embs CPU\")\n",
    "        enc_learn.dls.cpu()\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            if verbose > 0: \n",
    "                ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | CUDA device id: {torch.cuda.current_device()}\", verbose = verbose)\n",
    "                ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | CUDA device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\", verbose = verbose)\n",
    "                ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Ensure empty cache & move 2 GPU\", verbose = verbose)\n",
    "            torch.cuda.empty_cache()\n",
    "            enc_learn.dls.cuda()\n",
    "            enc_learn.cuda()\n",
    "        else:\n",
    "            if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | No cuda available. Set CPU = true\")\n",
    "            cpu = True\n",
    "            \n",
    "    get_enc_embs_ensure_batch_size_(enc_learn.dls, batch_size, verbose)\n",
    "\n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Set dataset from X (enc_learn does not contain dls)\", verbose = verbose)\n",
    "    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n",
    "    aux_dl.bs = enc_learn.dls.bs if enc_learn.dls.bs>0 else 64\n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Get module\", verbose = verbose)\n",
    "    module = nested_attr(enc_learn.model,ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) if module is None else module\n",
    "    \n",
    "    if verbose > 0: \n",
    "        #ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | module \", module)\n",
    "        ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | aux_dl len {len(aux_dl)}\", verbose = verbose)\n",
    "        ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | aux_dl.batch_len {len(next(iter(aux_dl)))}\", verbose = verbose)\n",
    "        ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | aux_dl.bs {aux_dl.bs}\", verbose = verbose)\n",
    "        if (not cpu):\n",
    "            total = torch.cuda.get_device_properties(device).total_memory\n",
    "            used = torch.cuda.memory_allocated(torch.cuda.current_device())\n",
    "            reserved = torch.cuda.memory_reserved(torch.cuda.current_device())\n",
    "            ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | total_mem {total}\", verbose = verbose)\n",
    "            ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | used_mem {used}\", verbose = verbose)\n",
    "            ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | reserved_mem {reserved}\" ,verbose = verbose)\n",
    "            ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | available_mem {total-reserved}\", verbose = verbose)\n",
    "            sys.stdout.flush()\n",
    "                                              \n",
    "    if (cpu or ( chunk_size == 0 )):\n",
    "        embs = [\n",
    "            get_acts_and_grads(\n",
    "                model=enc_learn.model,\n",
    "                modules=module, \n",
    "                x=xb[0], \n",
    "                cpu=cpu\n",
    "            )[0] \n",
    "            for xb in aux_dl\n",
    "        ]\n",
    "        if not cpu: embs=[emb.cpu() for emb in embs]\n",
    "    else:\n",
    "        embs = []\n",
    "        total_chunks=max(1,round(len(X)/chunk_size))\n",
    "        if verbose > 0: ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | aux_dl len | {str(len(X))}  chunk size: {str(chunk_size) } => { str(total_chunks) }  chunks\", verbose = verbose)\n",
    "        for i in range(0, total_chunks):\n",
    "            if verbose > 0: \n",
    "                ut.print_flush(f\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | Chunk [ {str(i)}/{str(total_chunks)}] => {str(round(i*100/total_chunks))}%\", verbose = verbose)\n",
    "                sys.stdout.flush()\n",
    "            chunk = [batch for (n, batch) in enumerate(aux_dl) if (chunk_size*i <= n  and chunk_size*(i+1) > n) ]\n",
    "            chunk_embs = [\n",
    "                get_acts_and_grads(\n",
    "                    model=enc_learn.model,\n",
    "                    modules=module,\n",
    "                    x=xb[0], \n",
    "                    cpu=cpu\n",
    "                )[0]\n",
    "                for xb in chunk\n",
    "            ]\n",
    "            # Mueve los embeddings del bloque a la CPU\n",
    "            chunk_embs = [emb.cpu() for emb in chunk_embs]\n",
    "            embs.extend(chunk_embs)\n",
    "            torch.cuda.empty_cache()\n",
    "        if verbose > 0: \n",
    "            ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Get acts and grads | 100%\", verbose = verbose)\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | concat embeddings\", verbose = verbose)\n",
    "    \n",
    "    embs = to_concat(embs)\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Reduce\", verbose = verbose)\n",
    "    \n",
    "    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n",
    "    \n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size | Convert to numpy\", verbose = verbose)\n",
    "    \n",
    "    if to_numpy: \n",
    "        if cpu or chunk_size > 0:\n",
    "            embs = embs.numpy() \n",
    "        else: \n",
    "            embs = embs.cpu().numpy()\n",
    "            torch.cuda.empty_cache()\n",
    "    if time_flag:\n",
    "        t = time.time()-t_start\n",
    "        if verbose > 0:\n",
    "            ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size \" + str(t) + \" seconds -->\", verbose = verbose)\n",
    "        else:\n",
    "            ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size \" + str(t) + \" seconds\", verbose = verbose)\n",
    "    if check_memory_usage: gpu_memory_status()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"get_enc_embs_MVP_set_stride_set_batch_size -->\", verbose = verbose)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a17863e-f5c1-4c4c-8023-37d197598ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_moment(\n",
    "    X               : List [ List [ List [ float ] ] ], \n",
    "    enc_learn       : Learner, \n",
    "    cpu             : bool = False, \n",
    "    to_numpy        : bool = True,\n",
    "    verbose         : int  = 0,\n",
    "    average_seq_dim : bool = True\n",
    "):\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"--> get_enc_embs_moment\", verbose = verbose)\n",
    "    # Move tensor and model to GPU\n",
    "    if cpu or not torch.cuda.is_available():\n",
    "        if verbose > 0: \n",
    "            ut.print_flush(\"get_enc_embs_moment | Using CPU (maybe no cuda available)\", verbose = verbose)\n",
    "        cpu = True\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        if verbose > 0: \n",
    "            ut.print_flush(\"get_enc_embs_moment | Using CUDA\", verbose = verbose)\n",
    "        enc_learn.to(\"cuda\")\n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_moment | Convert y\", verbose = verbose)\n",
    "    enc_learn.eval()\n",
    "    if cpu:\n",
    "        y = torch.from_numpy(X).cpu().float()\n",
    "    else:\n",
    "        y = torch.from_numpy(X).to(\"cuda\").float()\n",
    "    # Get output\n",
    "    with torch.no_grad():\n",
    "        if verbose > 0: \n",
    "            ut.print_flush(\"get_enc_embs_moment | Get outputs\", verbose = verbose)\n",
    "        outputs = enc_learn(y)\n",
    "        if verbose > 0:\n",
    "            ut.print_flush(f\"get_enc_embs_moment | Final shape: X ~ {y.shape}\", verbose = verbose)\n",
    "                \n",
    "    #| move tensors and models back to CPU\n",
    "    if not cpu:\n",
    "        y = y.detach().cpu().numpy()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"get_enc_embs_moment | Get Embeddings\", verbose = verbose)\n",
    "    embeddings = outputs.embeddings.detach().cpu()\n",
    "    if average_seq_dim: \n",
    "        embeddings = embeddings.mean(dim = 1)\n",
    "    if to_numpy:\n",
    "        embeddings = embeddings.cpu().numpy()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"get_enc_embs_moment -->\", verbose = verbose)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aac3e43c-fd7f-4022-8d1a-be1b47e580de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_moment_reconstruction(\n",
    "    X               : List [ List [ List [ float ] ] ], \n",
    "    enc_learn       : Learner, \n",
    "    cpu             : bool          = False, \n",
    "    to_numpy        : bool          = True,\n",
    "    verbose         : int           = 0,\n",
    "    average_seq_dim : bool          = True,\n",
    "    padd_step       : int           = 2,\n",
    "    #- Printing options for debugging\n",
    "    print_to_path   : bool          = False,\n",
    "    print_path      : str           = \"~/data/logs/logs.txt\",\n",
    "    print_mode      : str           = 'a',\n",
    "    continue_if_fail: bool          = False\n",
    "):\n",
    "    \"\"\"\n",
    "    For reconstruction sometimes mask get invalid values\n",
    "    To avoid them, the last dimension (sequence length) is padded with 0's until the error is skippedd\n",
    "    It should only get one iteration as it seems to be some MOMENT internal configuration for patches.\n",
    "    \"\"\"\n",
    "    if cpu:\n",
    "        enc_learn.cpu()\n",
    "        y = torch.from_numpy(X).cpu().float()\n",
    "    else:\n",
    "        enc_learn.to(\"cuda\")\n",
    "        y = torch.from_numpy(X).to(\"cuda\").float()\n",
    "    embs = get_acts_moment(\n",
    "        enc_learn       = enc_learn, \n",
    "        cpu             = cpu, \n",
    "        verbose         = verbose, \n",
    "        y               = y, \n",
    "        mask            = None,\n",
    "        padd_step       = padd_step,\n",
    "        retry           = False ,\n",
    "        max_trials      = 5,\n",
    "        print_to_path   = print_to_path, print_path = print_path, print_mode = print_mode\n",
    "    )\n",
    "    if average_seq_dim: \n",
    "        embs = embs.mean(dim = 1).mean(dim = 1)\n",
    "    if to_numpy:\n",
    "        embs = embs.cpu().numpy()\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f46bd",
   "metadata": {},
   "source": [
    "---> TODO: averiguar de qué module salen realmente los embeddings y usar el get_acts_and_grads como en MVP <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_past_target_moirai(\n",
    "    enc_input   : List [ List [ List [ Float ] ] ]\n",
    "):\n",
    "    return einops.rearrange(\n",
    "        torch.as_tensor(enc_input, dtype = torch.float32),\n",
    "        \"n_windows n_vars window_size -> n_windows window_size n_vars\"\n",
    "    )\n",
    "\n",
    "def get_forecast_model_moirai(\n",
    "    module,\n",
    "    past_target,\n",
    "    patch_size,\n",
    "):\n",
    "    return moirai_forecast.MoiraiForecast(\n",
    "        module                      = module,\n",
    "        prediction_length           = past_target.shape[2],\n",
    "        context_length              = past_target.shape[1],\n",
    "        patch_size                  = patch_size,\n",
    "        num_samples                 = 100,\n",
    "        target_dim                  = past_target.shape[2],\n",
    "        feat_dynamic_real_dim       = 0,\n",
    "        past_feat_dynamic_real_dim  = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9a70cd5-5aa5-44c2-b7cf-4d290e9349ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_moirai(\n",
    "    enc_input       : List [ List [ List [ Float ] ] ], \n",
    "    enc_model       : moirai.MoiraiModule, \n",
    "    cpu             : False,\n",
    "    average_seq_dim : bool = True, \n",
    "    verbose         : int  = 0,\n",
    "    to_numpy        : bool = True,\n",
    "    patch_size      : int  = 8,\n",
    "    time            : bool = False,\n",
    "    return_kwargs   : bool = False\n",
    "):\n",
    "    mssg = ut.Mssg()\n",
    "    if time: \n",
    "        timer = ut.Time(mssg = mssg)\n",
    "        timer.start()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"--> get_enc_embs_moirai\", verbose = verbose)\n",
    "    # Move tensor and model to GPU\n",
    "    past_target = get_past_target_moirai(enc_input)\n",
    "    if cpu or not torch.cuda.is_available():\n",
    "        if verbose > 0: ut.print_flush(\"get_enc_embs_moirai | Using CPU (maybe no cuda available)\", verbose = verbose)\n",
    "        cpu = True\n",
    "        enc_model.cpu()\n",
    "        past_target.cpu()\n",
    "    else:\n",
    "        if verbose > 0: ut.print_flush(\"get_enc_embs_moirai | Using CUDA\", verbose = verbose)\n",
    "        enc_model.to(\"cuda\")\n",
    "        past_target.to(\"cuda\")\n",
    "        \n",
    "    if verbose > 0: ut.print_flush(\"get_enc_embs_moirai | Get Outputs\", verbose = verbose)\n",
    "\n",
    "    \n",
    "    past_observed_target = torch.ones_like(past_target, dtype=torch.bool)\n",
    "    past_is_pad = torch.zeros_like(past_target, dtype=torch.bool)[...,:,-1] # Kill last dimension\n",
    "\n",
    "    if (verbose > 1):\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | past_target ~ {past_target.shape}\")\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | past_observed_target ~ {past_observed_target.shape}\")\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | past_is_pad ~ {past_is_pad.shape}\")\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | Auxiliar model\")\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | Auxiliar model | Before Memory:\")\n",
    "        gpu_memory_status()\n",
    "    \n",
    "    # Auxiliar model for conversions just to ensure correct sizes\n",
    "    #not neccesary, is the same module initially downloaded...\n",
    "    #module = moirai.MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\")\n",
    "    \n",
    "    forecast_model =  moirai_forecast.MoiraiForecast(\n",
    "        module=enc_model,\n",
    "        prediction_length=past_target.shape[2], #random, just for getting the model\n",
    "        context_length=past_target.shape[1],\n",
    "        patch_size=patch_size,\n",
    "        num_samples=100, #Random, is the number of forecasting, not interesting for us\n",
    "        target_dim=past_target.shape[2],\n",
    "        feat_dynamic_real_dim=0,\n",
    "        past_feat_dynamic_real_dim=0,\n",
    "    )\n",
    "    \n",
    "    if verbose > 0:\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | Auxiliar model | After Memory:\")\n",
    "        gpu_memory_status()\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | Convert sizes\")\n",
    "    (\n",
    "    target,\n",
    "    observed_mask,\n",
    "    sample_id,\n",
    "    time_id,\n",
    "    variate_id,\n",
    "    prediction_mask,\n",
    "    ) = forecast_model._convert(\n",
    "        patch_size,\n",
    "        past_target,\n",
    "        past_observed_target,\n",
    "        past_is_pad\n",
    "    )\n",
    "    if verbose > 1:\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | target ~ {target.shape}\")\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | observed_mask ~ {observed_mask.shape}\")\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | sample_id ~ {sample_id.shape}\")\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | time_id ~ {time_id.shape}\")\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | variate_id ~ {variate_id.shape}\")\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | prediction_mask ~ {prediction_mask.shape}\")\n",
    "        gpu_memory_status()\n",
    "    forecast_model = None\n",
    "    if not cpu: torch.cuda.empty_cache()\n",
    "    if verbose > 0:\n",
    "        ut.print_flush(f\"--> get_enc_embs_moirai | Delete Auxiliar model | After Memory:\")\n",
    "        gpu_memory_status()\n",
    "    \n",
    "    model_kwargs={\n",
    "        'target': target, \n",
    "        'observed_mask': observed_mask,\n",
    "        'sample_id': sample_id,\n",
    "        'time_id': time_id,\n",
    "        'variate_id': variate_id,\n",
    "        'prediction_mask': prediction_mask,\n",
    "        'patch_size': torch.ones_like(sample_id, dtype = torch.float32)*patch_size\n",
    "    } \n",
    "    if verbose > 0: \n",
    "        ut.print_flush(f\"get_enc_embs_moirai | About to get activations\")\n",
    "    acts = get_acts(\n",
    "        model  = enc_model, \n",
    "        module = enc_model.encoder.norm, \n",
    "        cpu    = cpu,\n",
    "        verbose = verbose,\n",
    "        retry = True,\n",
    "        acts_indices = [0],\n",
    "        **model_kwargs #Parameters of the model\n",
    "    )\n",
    "    \n",
    "    embs = acts\n",
    "    acts = None\n",
    "    if average_seq_dim :\n",
    "        if verbose > 0: \n",
    "            ut.print_flush(f\"get_enc_embs_moirai | About to reduce activations\", verbose = verbose)\n",
    "        embs = embs.mean(dim = 1)\n",
    "    \n",
    "    if not cpu:\n",
    "        #ut.print_flush(f\"get_enc_embs_moirai | enc_input to cpu\")\n",
    "        #enc_input.cpu()\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | enc_model to cpu\", verbose = verbose)\n",
    "        enc_model.cpu()\n",
    "        ut.print_flush(f\"get_enc_embs_moirai | torch cuda empty cache\", verbose = verbose)\n",
    "        torch.cuda.empty_cache()\n",
    "    if to_numpy: \n",
    "        if cpu > 0:\n",
    "            embs = embs.numpy() \n",
    "        else: \n",
    "            embs = embs.cpu().numpy()\n",
    "            torch.cuda.empty_cache()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(f\"get_enc_embs_moirai | embs ~ {embs.shape}\", verbose = verbose)\n",
    "        ut.print_flush(\"get_enc_embs_moirai -->\", verbose = verbose)\n",
    "    if return_kwargs:\n",
    "        return embs, model_kwargs\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dist_moirai(\n",
    "    enc_input       : List [ List [ List [ Float ] ] ], \n",
    "    enc_model       : moirai.MoiraiModule, \n",
    "    cpu             : False,\n",
    "    verbose         : int  = 0,\n",
    "    patch_size      : int  = 8,\n",
    "    time            : bool = False,\n",
    "    return_kwargs   : bool = False\n",
    "):\n",
    "    mssg = ut.Mssg()\n",
    "    if time: \n",
    "        timer = ut.Time(mssg = mssg)\n",
    "        timer.start()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"--> get_dist_moirai\", verbose = verbose)\n",
    "    # Move tensor and model to GPU\n",
    "    past_target = get_past_target_moirai(enc_input)\n",
    "    if cpu or not torch.cuda.is_available():\n",
    "        if verbose > 0: ut.print_flush(\"get_dist_moirai | Using CPU (maybe no cuda available)\", verbose = verbose)\n",
    "        cpu = True\n",
    "        enc_model.cpu()\n",
    "        past_target.cpu()\n",
    "    else:\n",
    "        if verbose > 0: ut.print_flush(\"get_dist_moirai | Using CUDA\", verbose = verbose)\n",
    "        enc_model.to(\"cuda\")\n",
    "        past_target.to(\"cuda\")\n",
    "        \n",
    "    if verbose > 0: ut.print_flush(\"get_dist_moirai | Get Outputs\", verbose = verbose)\n",
    "\n",
    "    \n",
    "    past_observed_target = torch.ones_like(past_target, dtype=torch.bool)\n",
    "    past_is_pad = torch.zeros_like(past_target, dtype=torch.bool)[...,:,-1] # Kill last dimension\n",
    "\n",
    "    if (verbose > 1):\n",
    "        ut.print_flush(f\"--> get_dist_moirai | past_target ~ {past_target.shape}\")\n",
    "        ut.print_flush(f\"--> get_dist_moirai | past_observed_target ~ {past_observed_target.shape}\")\n",
    "        ut.print_flush(f\"--> get_dist_moirai | past_is_pad ~ {past_is_pad.shape}\")\n",
    "        ut.print_flush(f\"--> get_dist_moirai | Auxiliar model\")\n",
    "        ut.print_flush(f\"--> get_dist_moirai | Auxiliar model | Before Memory:\")\n",
    "        gpu_memory_status()\n",
    "    \n",
    "    # Auxiliar model for conversions just to ensure correct sizes\n",
    "    #not neccesary, is the same module initially downloaded...\n",
    "    #module = moirai.MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\")\n",
    "    \n",
    "    forecast_model =  moirai_forecast.MoiraiForecast(\n",
    "        module=enc_model,\n",
    "        prediction_length=past_target.shape[2], #random, just for getting the model\n",
    "        context_length=past_target.shape[1],\n",
    "        patch_size=patch_size,\n",
    "        num_samples=100, #Random, is the number of forecasting, not interesting for us\n",
    "        target_dim=past_target.shape[2],\n",
    "        feat_dynamic_real_dim=0,\n",
    "        past_feat_dynamic_real_dim=0,\n",
    "    )\n",
    "    \n",
    "    if verbose > 0:\n",
    "        ut.print_flush(f\"--> get_dist_moirai | Auxiliar model | After Memory:\")\n",
    "        gpu_memory_status()\n",
    "        ut.print_flush(f\"--> get_dist_moirai | Convert sizes\")\n",
    "    (\n",
    "    target,\n",
    "    observed_mask,\n",
    "    sample_id,\n",
    "    time_id,\n",
    "    variate_id,\n",
    "    prediction_mask,\n",
    "    ) = forecast_model._convert(\n",
    "        patch_size,\n",
    "        past_target,\n",
    "        past_observed_target,\n",
    "        past_is_pad\n",
    "    )\n",
    "    if verbose > 1:\n",
    "        ut.print_flush(f\"get_dist_moirai | target ~ {target.shape}\")\n",
    "        ut.print_flush(f\"get_dist_moirai | observed_mask ~ {observed_mask.shape}\")\n",
    "        ut.print_flush(f\"get_dist_moirai | sample_id ~ {sample_id.shape}\")\n",
    "        ut.print_flush(f\"get_dist_moirai | time_id ~ {time_id.shape}\")\n",
    "        ut.print_flush(f\"get_dist_moirai | variate_id ~ {variate_id.shape}\")\n",
    "        ut.print_flush(f\"get_dist_moirai | prediction_mask ~ {prediction_mask.shape}\")\n",
    "        gpu_memory_status()\n",
    "    forecast_model = None\n",
    "    if not cpu: torch.cuda.empty_cache()\n",
    "    if verbose > 0:\n",
    "        ut.print_flush(f\"--> get_dist_moirai | Delete Auxiliar model | After Memory:\")\n",
    "        gpu_memory_status()\n",
    "    \n",
    "    model_kwargs={\n",
    "        'target': target, \n",
    "        'observed_mask': observed_mask,\n",
    "        'sample_id': sample_id,\n",
    "        'time_id': time_id,\n",
    "        'variate_id': variate_id,\n",
    "        'prediction_mask': prediction_mask,\n",
    "        'patch_size': torch.ones_like(sample_id, dtype = torch.float32)*patch_size\n",
    "    } \n",
    "    if verbose > 0: \n",
    "        ut.print_flush(f\"get_dist_moirai | About to get activations\")\n",
    "    dist = enc_model(**model_kwargs)\n",
    "    \n",
    "    \n",
    "    if not cpu:\n",
    "        #ut.print_flush(f\"get_dist_moirai | enc_input to cpu\")\n",
    "        #enc_input.cpu()\n",
    "        ut.print_flush(f\"get_dist_moirai | enc_model to cpu\", verbose = verbose)\n",
    "        enc_model.cpu()\n",
    "        ut.print_flush(f\"get_dist_moirai | torch cuda empty cache\", verbose = verbose)\n",
    "        torch.cuda.empty_cache()\n",
    "    if verbose > 0: \n",
    "        ut.print_flush(\"get_dist_moirai -->\", verbose = verbose)\n",
    "    if return_kwargs:\n",
    "        return dist, model_kwargs\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86667613-82af-438f-b66c-c4c5e894634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_enc_embs(\n",
    "    X               , \n",
    "    enc_learn       : Learner, \n",
    "    module          : str  = None, \n",
    "    cpu             : bool = False, \n",
    "    average_seq_dim : bool = True, \n",
    "    to_numpy        : bool = True,\n",
    "    verbose         : int  = 0,\n",
    "    **kwargs        \n",
    "):\n",
    "    embs = None\n",
    "    enc_learn_class = str(enc_learn.__class__)[8:-2]\n",
    "    match enc_learn_class:\n",
    "        case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "            match enc_learn.task_name:\n",
    "                case \"embedding\":\n",
    "                    embs = get_enc_embs_moment(X, enc_learn, cpu, to_numpy, verbose, average_seq_dim, **kwargs)\n",
    "                case \"reconstruction\":\n",
    "                    embs = get_enc_embs_moment_reconstruction(X, enc_learn, cpu, to_numpy, verbose, average_seq_dim, **kwargs)\n",
    "                case _:\n",
    "                    ut.print_flush(f\"Model embeddings for moment-{enc_learn.task_name} is not yet implemented.\", verbose = verbose)\n",
    "        case \"fastai.learner.Learner\":\n",
    "            embs = get_enc_embs_MVP_set_stride_set_batch_size(X, enc_learn, stride, batch_size, module, cpu, average_seq_dim, to_numpy, verbose, False, 0, False)\n",
    "        case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "            embs = get_enc_embs_moirai(\n",
    "                enc_input  = X, \n",
    "                enc_model  = enc_learn,\n",
    "                cpu        = cpu, \n",
    "                average_seq_dim = average_seq_dim,\n",
    "                verbose    = verbose,\n",
    "                **kwargs\n",
    "            )\n",
    "        case _:\n",
    "            ut.print_flush(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\", verbose = verbose)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13ccce1d-aca2-44c1-8b20-4339628e3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_set_stride_set_batch_size(\n",
    "    X                  : List [ List [ List [ float ] ] ], \n",
    "    enc_learn          : Learner, \n",
    "    stride             : int, \n",
    "    batch_size         : int, \n",
    "    module             : str  = None, \n",
    "    cpu                : bool = False, \n",
    "    average_seq_dim    : bool = True, \n",
    "    to_numpy           : bool = True, \n",
    "    verbose            : int  = 0, \n",
    "    time_flag          : bool = False, \n",
    "    chunk_size         : int  = 0, \n",
    "    check_memory_usage : bool = False,\n",
    "    **kwargs\n",
    "):\n",
    "    ut.print_flush(\"--> get_enc_embs_set_stride_set_batch_size\", verbose = verbose)\n",
    "    embs = None\n",
    "    enc_learn_class = str(enc_learn.__class__)[8:-2]\n",
    "    match enc_learn_class:\n",
    "        case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "            if verbose > 0: \n",
    "                ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | Moment | {average_seq_dim}\", verbose = verbose)\n",
    "            match enc_learn.task_name:\n",
    "                case \"embedding\":\n",
    "                    embs = get_enc_embs_moment( X = X, enc_learn = enc_learn, cpu = cpu, to_numpy = to_numpy, verbose = verbose, average_seq_dim = average_seq_dim)\n",
    "                case \"reconstruction\":\n",
    "                    embs = get_enc_embs_moment_reconstruction(X= X, enc_learn = enc_learn, cpu = cpu, to_numpy = to_numpy, verbose = verbose, average_seq_dim = average_seq_dim, **kwargs)\n",
    "                case _:\n",
    "                    ut.print_flush(f\"Model embeddings for moment-{enc_learn.task_name} is not yet implemented.\", verbose = verbose)\n",
    "        case \"fastai.learner.Learner\":\n",
    "            if verbose > 0: \n",
    "                ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | MVP | {average_seq_dim}\", verbose = verbose)\n",
    "            if verbose > 1:\n",
    "                ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | X ~{X.shape}\", verbose = verbose)\n",
    "            embs = get_enc_embs_MVP_set_stride_set_batch_size(\n",
    "                X = X, \n",
    "                enc_learn = enc_learn, \n",
    "                stride = stride, \n",
    "                batch_size = batch_size, \n",
    "                module = module, \n",
    "                cpu = cpu, \n",
    "                average_seq_dim = average_seq_dim,\n",
    "                to_numpy = to_numpy, \n",
    "                verbose = verbose, \n",
    "                time_flag = time_flag, \n",
    "                chunk_size = chunk_size, \n",
    "                check_memory_usage = check_memory_usage\n",
    "            )\n",
    "        case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "            if verbose > 0: \n",
    "                ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | Moirai | {average_seq_dim}\", verbose = verbose)\n",
    "            embs = get_enc_embs_moirai(\n",
    "                enc_input  = X, \n",
    "                enc_model  = enc_learn,\n",
    "                cpu        = cpu, \n",
    "                average_seq_dim = average_seq_dim,\n",
    "                verbose    = verbose,\n",
    "                to_numpy = to_numpy,\n",
    "                **kwargs\n",
    "            )\n",
    "        case _:\n",
    "            ut.print_flush(f\"[ get_enc_embs_set_stride_set_batch_size ] Model embeddings implementation is not yet implemented for {enc_learn_class}.\", verbose = verbose)\n",
    "    # Ñapa: TODO: Gestionar que no se queden en memoria los modelos porque ocupan el 40% de la GPU al llamarlos desde R\n",
    "    if verbose > 0: ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | Before moving to CPU | embs~{embs.shape}\", verbose = verbose)\n",
    "    if cpu:\n",
    "        #X.cpu()\n",
    "        enc_learn.cpu()\n",
    "        try: \n",
    "            enc_lear.dls.cpu()\n",
    "        except Exception as e: \n",
    "            ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | Exception: {e}\", verbose = verbose)\n",
    "        #kwargs_to_cpu_(**kwargs)\n",
    "    if verbose > 0: ut.print_flush(f\"get_enc_embs_set_stride_set_batch_size | embs~{embs.shape} -->\", verbose = verbose)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b1876-14bf-4843-8f3e-8b1d6e80682a",
   "metadata": {},
   "source": [
    "## Validation with customized metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcf0b0-546d-4eca-9321-049ee6869170",
   "metadata": {},
   "source": [
    "### Customized metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e164e9f5-294d-4a5e-b10b-f55924b6ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rmse(preds, targets):\n",
    "    res = torch.sqrt(torch.nn.functional.mse_loss(preds, targets))\n",
    "    return res\n",
    "\n",
    "def smape(preds, targets):\n",
    "    res = 100 * torch.mean(2 * torch.abs(preds - targets) / (torch.abs(preds) + torch.abs(targets)))\n",
    "    return res\n",
    "\n",
    "def rmse_flat(preds, targets):\n",
    "    \"\"\"\n",
    "    Computes RMSE while flattening the tensors to ensure compatibility with MSELossFlat.\n",
    "    \"\"\"\n",
    "    preds, targets = preds.view(-1), targets.view(-1)  # Flatten tensors\n",
    "    return torch.sqrt(torch.nn.functional.mse_loss(preds, targets))\n",
    "\n",
    "def smape_flat(preds, targets):\n",
    "    \"\"\"\n",
    "    Computes SMAPE while flattening the tensors to ensure compatibility with MSELossFlat.\n",
    "    \"\"\"\n",
    "    preds, targets = preds.view(-1), targets.view(-1)  # Flatten tensors\n",
    "    denominator = (torch.abs(preds) + torch.abs(targets))\n",
    "    return 100 * torch.mean(2 * torch.abs(preds - targets) / torch.clamp(denominator, min=1e-7))\n",
    "def mae_flat(preds, targets):\n",
    "    \"\"\"\n",
    "    Computes Mean Absolute Error (MAE) while flattening the tensors to ensure compatibility.\n",
    "    \"\"\"\n",
    "    preds, targets = preds.view(-1), targets.view(-1)  # Flatten tensors\n",
    "    return torch.mean(torch.abs(preds - targets))\n",
    "\n",
    "def mse_loss_flat(preds, targets):\n",
    "    \"\"\"\n",
    "    Computes Mean Squared Error (MSE) while flattening the tensors to ensure compatibility.\n",
    "    \"\"\"\n",
    "    preds, targets = preds.view(-1), targets.view(-1)  # Flatten tensors\n",
    "    return torch.mean((preds - targets) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6f3b836-dff5-4756-b653-b981ed6cb376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RMSELoss(_Loss):\n",
    "    __constants__ = [\"reduction\"]\n",
    "    def __init__(self, size_average = None, reduce = None, reduction: str = \"mean\") -> None:\n",
    "        super().__init__(size_average, reduce, reduction)\n",
    "    \n",
    "    def forward(self, input: Tensor, target:Tensor) -> Tensor:\n",
    "        return torch.nn.functional.mse_loss(input, target, reduction = self.reduction)\n",
    "\n",
    "@use_kwargs_dict(reduction='mean')\n",
    "def RMSELossFlat(\n",
    "    *args,\n",
    "    axis:int = -1,\n",
    "    floatify: bool = True, \n",
    "    **kwargs\n",
    "):\n",
    "    \"Computes RMSE with flattening, similar to MSELossFlat.\"\n",
    "    return BaseLoss(RMSELoss, *args, axis = axis, floatify = floatify, is_2d = False, **kwargs)\n",
    "\n",
    "class SMAPELoss(_Loss):\n",
    "    __constants__ = [\"reduction\"]\n",
    "    \n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = \"mean\") -> None:\n",
    "        \"\"\"\n",
    "        Initializes the SMAPE Loss.\n",
    "        \n",
    "        Args:\n",
    "            size_average (bool, optional): Deprecated (use reduction).\n",
    "            reduce (bool, optional): Deprecated (use reduction).\n",
    "            reduction (str): Specifies the reduction to apply to the output ('none', 'mean', 'sum').\n",
    "        \"\"\"\n",
    "        super().__init__(size_average, reduce, reduction)\n",
    "    \n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the SMAPE loss.\n",
    "        \n",
    "        Args:\n",
    "            input (Tensor): Predicted values.\n",
    "            target (Tensor): Ground truth values.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Computed SMAPE loss.\n",
    "        \"\"\"\n",
    "        return self.smape_loss(input, target)\n",
    "    \n",
    "    @staticmethod\n",
    "    def smape_loss(preds: Tensor, targets: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the SMAPE loss for the given predictions and targets.\n",
    "        \n",
    "        Args:\n",
    "            preds (Tensor): Predicted values.\n",
    "            targets (Tensor): Ground truth values.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: SMAPE loss.\n",
    "        \"\"\"\n",
    "        denominator = (torch.abs(preds) + torch.abs(targets))\n",
    "        smape = 100 * torch.mean(2 * torch.abs(preds - targets) / torch.clamp(denominator, min=1e-7))\n",
    "        return smape\n",
    "\n",
    "\n",
    "@use_kwargs_dict(reduction=\"mean\")\n",
    "def SMAPELossFlat(\n",
    "    *args,\n",
    "    axis: int = -1,\n",
    "    floatify: bool = True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes SMAPE with flattening, similar to MSELossFlat.\n",
    "    \n",
    "    Args:\n",
    "        axis (int): Axis to flatten. Default is -1.\n",
    "        floatify (bool): Convert target to float. Default is True.\n",
    "        **kwargs: Additional arguments.\n",
    "    \"\"\"\n",
    "    return BaseLoss(SMAPELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n",
    "\n",
    "# Class alias for clarity\n",
    "MAELossFlat = L1LossFlat\n",
    "\n",
    "# Evaluation metrics alias for clarity\n",
    "EvalMSE     = evaluate.load('mse', 'multilist')\n",
    "EvalRMSE    = evaluate.load('mse', 'multilist')\n",
    "EvalMAE     = evaluate.load('mae', 'multilist')\n",
    "EvalSMAPE   = evaluate.load('smape', 'multilist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ef05a-387b-46e0-8a76-3bc7f2a4a3a8",
   "metadata": {},
   "source": [
    "### Computation & structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e84a46c2-835f-41b6-b786-e420c0f93764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_with_metrics(\n",
    "    learner : Learner, \n",
    "    metrics        = None,\n",
    "    default_metric = MSELossFlat #- Default for MVP\n",
    "):\n",
    "    \"\"\"\n",
    "    Validates a `Learner` using multiple metrics and restores the default metric after computation.\n",
    "\n",
    "    Args:\n",
    "        learner (Learner): The `Learner` object to validate.\n",
    "        metrics (list, optional): A list of metric functions to use for validation. \n",
    "            If not provided or empty, the `default_metric` will be used. \n",
    "            Each metric function should be compatible with the `Learner`'s `crit` attribute.\n",
    "        default_metric (Callable, optional): The default metric to restore after validation. \n",
    "            Defaults to `MSELossFlat`.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of validation results, where each result corresponds to the validation \n",
    "        score for the respective metric in the `metrics` list.\n",
    "\n",
    "    Raises:\n",
    "        Warning: If no metric is provided, a warning is issued, and the `default_metric` is used.\n",
    "\n",
    "    Example:\n",
    "        >>> learner = Learner(...)  # Initialize your learner\n",
    "        >>> metrics = [MSELossFlat, L1Loss]\n",
    "        >>> results = validate_with_metrics(learner, metrics)\n",
    "        >>> print(results)  # [0.25, 0.35]\n",
    "\n",
    "    Notes:\n",
    "        - The function temporarily replaces the `crit` attribute of the `Learner` object \n",
    "          with each metric in the `metrics` list for validation.\n",
    "        - After validation, the `crit` attribute is restored to the `default_metric`.\n",
    "    \"\"\"\n",
    "    metrics_dict = {}\n",
    "    #-- Ensure well formated metrics list\n",
    "    if metrics is None or len(metrics) == 0:\n",
    "        warnings.warn(f\"No metric selected. Using default: {MSELossFlat.__name__}\")\n",
    "        metrics = [MSELossFlat]\n",
    "        metrics_dict = {\n",
    "            'mse': {\n",
    "                'metric': MSELossFlat,\n",
    "                'args': {}\n",
    "            }\n",
    "        }\n",
    "    #-- Compute the results by\n",
    "    # 1) Changing learner criteria to the current metric\n",
    "    # 2) Use learner.validate()\n",
    "    results = []\n",
    "    for metric in metrics:\n",
    "        learner.crit = metric\n",
    "        result = learner.validate()\n",
    "        result = result.item() if hasattr(result, 'item') else result\n",
    "        results.append(result)\n",
    "    \n",
    "    #-- Restore default metric\n",
    "    learner.crit=default_metric\n",
    "    return results, metrics_dict\n",
    "\n",
    "def validate_with_metrics_(\n",
    "    self : Encoder\n",
    "): \n",
    "    results, metrics_dict = validate_with_metrics(\n",
    "        learner        = self.model, \n",
    "        metrics        = self.metrics, \n",
    "        default_metric = self.default_metric\n",
    "    )\n",
    "    self.metrics_dict = self.metrics_dict if self.metrics_dict else metrics_dict\n",
    "    return results\n",
    "\n",
    "Encoder.validate_with_metrics_ = validate_with_metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08ca0b67-34ab-4add-9712-1350fd9de3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_metrics_dict(\n",
    "    metrics: List[Callable],\n",
    "    metrics_names: List[str] = None\n",
    ") -> Dict[str, Callable]:\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping metric names to metric functions.\n",
    "\n",
    "    Args:\n",
    "        metrics (List[Callable]): A list of metric functions.\n",
    "        metrics_names (List[str], optional): A list of metric names corresponding to the functions.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Callable]: A dictionary mapping metric names to their corresponding functions.\n",
    "    \"\"\"\n",
    "    if metrics_names is None:\n",
    "        # Use the function's name as the key if names are not provided\n",
    "        metrics_dict = {metric.__name__: metric for metric in metrics}\n",
    "    elif len(metrics) == len(metrics_names):\n",
    "        # Use provided names if lengths match\n",
    "        metrics_dict = {name: metric for name, metric in zip(metrics_names, metrics)}\n",
    "    else:\n",
    "        raise ValueError(\"Length of metrics and metrics_names must match when metrics_names is provided.\")\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa7bde8a-835d-4dc8-a117-1dbf300ea8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_with_metrics_format_results(\n",
    "    results, metrics, metrics_names = None\n",
    "):\n",
    "    if metrics_names is None:\n",
    "        # Use the function's name as the key if names are not provided\n",
    "        metrics_dict = {\n",
    "            metric.__name__: results[i] for \n",
    "            (i, metric) in enumerate(metrics)\n",
    "        }\n",
    "    elif len(metrics) == len(metrics_names):\n",
    "        # Use provided names if lengths match\n",
    "        metrics_dict = {\n",
    "            name: results[i] for \n",
    "            name, (i, metric) in \n",
    "            zip(metrics_names, enumerate(metrics))\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Length of metrics and metrics_names must match when metrics_names is provided.\")\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19244b0d-fc6d-4b79-8701-36caedf603b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = validate_with_metrics_format_results(\n",
    "    [3,1,2,9],\n",
    "    metrics_names = [\"a\", \"b\", \"c\", \"d\"],\n",
    "    metrics = [RMSELossFlat, MSELossFlat, MAELossFlat, SMAPELossFlat]\n",
    ")\n",
    "print(foo)\n",
    "foo = validate_with_metrics_format_results(\n",
    "    [3,1,2,9],\n",
    "    [RMSELossFlat, MSELossFlat, MAELossFlat, SMAPELossFlat],\n",
    "    None\n",
    ")\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1ef71",
   "metadata": {},
   "source": [
    "## Fine-tunning\n",
    "> Take a look on [HuggingFace - Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training) if not used to few-shot learning or fine-tuning models.\n",
    "\n",
    "Steps: \n",
    "\n",
    "1) Prepare the dataset\n",
    "2) Batch the data\n",
    "   - Remember splitting between train & test dataset\n",
    "   - Remember to use DataLoader to iterate over batches\n",
    "4) Load the trained model and check if any modification is needed\n",
    "   - Check wether any layer may be substituted by an \"identity\" if not needed for your case\n",
    "   - Check if any dimension in a conversion layer may be changed to fit your dataset.\n",
    "5) Select an optimizer from torch.optim (Adam)\n",
    "6) ¿If using transformer, lr_scheduler? \n",
    "7) Training loop\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0d63a-96d8-450f-8a4b-0c5555b4ff25",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11f146b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def random_windows(\n",
    "    X           : List [ List [ List [ float ]]], \n",
    "    n_windows   : int       = None, \n",
    "    percent     : float     = None, \n",
    "    mssg        : ut.Mssg   = ut.Mssg()\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    - X: Numpy array of windows. Expected shape: [batch_size or n_samples, n_vars, window_len]\n",
    "    Given a numpy array of windows, selects:\n",
    "    - n_windows random windows from the array, if n_windows is given.\n",
    "    - ceil(percent*len(X)) random windows otherwise\n",
    "    \"\"\"\n",
    "    mssg_ = deepcopy(mssg)\n",
    "    mssg_.initial(func_name=f\"{mssg.function} | {ut.funcname()}\")\n",
    "    mssg_.print(f\"N windows: {n_windows}\")\n",
    "    if n_windows is None and percent is None:\n",
    "        windows = torch.from_numpy(X)\n",
    "    else: \n",
    "        n_windows = int(min(X.shape[0], n_windows) if n_windows is not None else np.ceil(percent*X.shape[0]))\n",
    "        mssg_.print(f\"n_windows: {n_windows}\")\n",
    "        random_indices = np.random.randint(0, int(X.shape[0]), n_windows)\n",
    "        windows = X[ random_indices ]\n",
    "        windows = torch.from_numpy(windows)\n",
    "    mssg.print(f\"windows~{windows.shape}\")\n",
    "    mssg_.final()\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38c5f2b5-026c-4822-b89f-7f564c2a1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def windowed_dataset(\n",
    "    X                               : Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ],\n",
    "    stride                          : int           = 1,\n",
    "    window_sizes                    : List [int]    = None,\n",
    "    n_window_sizes                  : int           = 1,\n",
    "    window_sizes_offset             : int           = 0.05,\n",
    "    windows_min_distance            : int           = 1,\n",
    "    full_dataset                    : bool          = False,\n",
    "    mssg                            : ut.Mssg       = ut.Mssg()\n",
    "): \n",
    "    stride = 1 if stride is None else stride \n",
    "    n_window_sizes = 1 if n_window_sizes is None else n_window_sizes\n",
    "    window_sizes_offset = 0.05 if window_sizes_offset is None else window_sizes_offset\n",
    "    windows_min_distance = 1 if windows_min_distance is None else windows_min_distance\n",
    "    full_dataset = False if full_dataset is None else full_dataset\n",
    "    mssg = ut.Mssg() if mssg is None else mssg\n",
    "    mssg.level += 1\n",
    "    mssg.initial(ut.funcname())\n",
    "    dss = []\n",
    "    if isinstance(X, list):\n",
    "        mssg_print(\"X is a list. Converting to dataFrame\")\n",
    "        X = np.array(X)\n",
    "        X = pd.DataFrame(X)        \n",
    "    if ( isinstance(X,pd.DataFrame) or full_dataset): \n",
    "        mssg.print(f\"X is a DataFrame, X~{X.shape} | window_sizes {len(window_sizes) if window_sizes is not None else 0}, n_window_sizes {n_window_sizes}\")\n",
    "        if window_sizes is None or n_window_sizes > len(window_sizes):\n",
    "            mssg.print(\"X is a DataFrame | Selecting Fourier's dominant frequences\")\n",
    "            # Select Fourier's dominant frequences\n",
    "            window_sizes_ = find_dominant_window_sizes_list(\n",
    "                X               = X, \n",
    "                nsizes          = n_window_sizes, \n",
    "                offset          = window_sizes_offset, \n",
    "                min_distance    = windows_min_distance,\n",
    "                mssg            = mssg\n",
    "            )\n",
    "            window_sizes = window_sizes_ if window_sizes is None else list(set(window_sizes + window_sizes_))[:n_window_sizes]\n",
    "            mssg.print(f\"X is a DataFrame | Window sizes: {len(window_sizes)}\", func_name = ut.funcname())\n",
    "        mssg.print(f\"Building the windows\")\n",
    "        for w in window_sizes:\n",
    "            mssg.print(f\"w = {w}\", verbose_level = mssg.level+1)\n",
    "            enc_input, _ = SlidingWindow(window_len = w, stride = stride, get_y=[])(X)\n",
    "            dss.append(enc_input)\n",
    "            mssg.print(f\"w {w} | enc_input~{enc_input.shape} | dss~{len(dss)}\",  verbose_level = mssg.level+1, func_name = ut.funcname())\n",
    "    else: \n",
    "        mssg.print(\"X is already windowed\")\n",
    "        dss = [X]\n",
    "    mssg.print(f\"Number of windows: {len(dss)}\")\n",
    "    mssg.final()\n",
    "    mssg.level -= 1\n",
    "    return dss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0aca76e-2c3b-4445-b761-8da138cae435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def setup_scheduler(\n",
    "    self : Encoder,\n",
    "    dl_train,\n",
    "    optimizer                             = None,\n",
    "    num_training_steps              : int = None,\n",
    "    lr_scheduler_perc_warmup_steps  : int = 0.02,\n",
    "    lr_scheduler_max_lr             : float = None,\n",
    "):\n",
    "    num_training_steps = num_epochs * len(dl_train) if num_training_steps is None else num_training_steps\n",
    "    if not self.optim.lr.num_warmup_steps:\n",
    "        lr_scheduler_num_warmup_steps = lr_scheduler_perc_warmup_steps*num_training_steps\n",
    "    lr_scheduler_max_lr = 5 - 10 *self.optim.lr.lr if lr_scheduler_max_lr is None else lr_scheduler_max_lr\n",
    "    if self.optim.lr.flag:\n",
    "        match self.optim.lr.name:\n",
    "            case \"OneCycleLR\": \n",
    "                lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                    optimizer           = optimizer,\n",
    "                    max_lr              = lr_scheduler_max_lr,\n",
    "                    epochs              = self.num_epochs,\n",
    "                    steps_per_epoch     = len(dl_train)\n",
    "                )\n",
    "            case _:\n",
    "                lr_scheduler = get_scheduler(\n",
    "                    name                = self.optim.lr.name,\n",
    "                    optimizer           = optimizer,\n",
    "                    num_warmup_steps    = lr_scheduler_num_warmup_steps,\n",
    "                    num_training_steps  = num_training_steps\n",
    "                )\n",
    "    return lr_scheduler\n",
    "Encoder.setup_scheduler = setup_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eca2ee84-52a5-43fa-8c4c-2659324e50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_train_and_eval_dataloaders(\n",
    "    X                   : Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ],\n",
    "    batch_size          : int,\n",
    "    n_windows           : int       = None,\n",
    "    n_windows_percent   : int       = None,\n",
    "    training_percent    : int       = 0.4,\n",
    "    validation_percent  : int       = 0.3,\n",
    "    shot                : bool      = False,\n",
    "    eval_pre            : bool      = False,\n",
    "    eval_post           : bool      = False,\n",
    "    mssg                : ut.Mssg   = ut.Mssg()\n",
    "):\n",
    "    dl_eval  = None\n",
    "    ds_train = None,\n",
    "    dl_train = None\n",
    "    mssg.function = f\"{mssg.function} | prepare_train_and_eval_dataloaders\"\n",
    "    if n_windows is None and n_windows_percent is None:\n",
    "        train_split_index = min(X.shape[0], np.ceil(training_percent * X.shape[0]))\n",
    "        eval_split_index = min(X.shape[0], np.ceil(validation_percent * X.shape[0]))\n",
    "    else:\n",
    "        train_split_index = min(X.shape[0], np.ceil(training_percent * n_windows)) if n_windows is not None else np.ceil(training_percent * n_windows_percent * X.shape[0])\n",
    "        eval_split_index = min(X.shape[0], np.ceil(validation_percent * n_windows)) if n_windows is not None else np.ceil(validation_percent * n_windows_percent * X.shape[0])\n",
    "    \n",
    "    train_split_index = int(train_split_index)\n",
    "    eval_split_index = int(eval_split_index)\n",
    "    if shot: \n",
    "        mssg.print(f\"Selecting ds train | {train_split_index} windows\")\n",
    "        ds_train = X[:train_split_index]\n",
    "    if eval_pre or eval_post: \n",
    "        mssg.print(f\"Selecting validation train | {eval_split_index} windows\")\n",
    "        ds_test  = torch.from_numpy(X[:eval_split_index]).float()\n",
    "    # -- Select only the small percentage for few-shot\n",
    "    if shot:\n",
    "        mssg.print(f\"Train DataLoader | Random windows\")\n",
    "        mssg.verbose -= 1\n",
    "        ds_train = random_windows(ds_train, n_windows, n_windows_percent, mssg = mssg)\n",
    "        mssg.verbose += 1\n",
    "        ds_train = ds_train.float()\n",
    "        # Create the dataloader\n",
    "        mssg.print(f\"Train DataLoader | DataLoader\")\n",
    "        dl_train = DataLoader(ds_train, batch_size = batch_size, shuffle = True)\n",
    "    if eval_pre or eval_post: \n",
    "        mssg.print(f\"Validation DataLoader\")\n",
    "        dl_eval  = DataLoader(ds_test, batch_size = batch_size, shuffle = False)\n",
    "    return dl_eval, dl_train, ds_test, ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e61b7c-ef87-4c1b-99d6-55a424095fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_enc_input(\n",
    "    mssg                            : ut.Mssg,\n",
    "    # Encoder Input\n",
    "    ## -- Using all parammeters\n",
    "    X                               : Optional [ Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ] ],\n",
    "    stride                          : Optional [ int ]          = None,\n",
    "    batch_size                      : Optional [ int ]          = None,\n",
    "    n_windows                       : Optional [ int ]          = None,\n",
    "    n_windows_percent               : Optional [ float ]        = None,\n",
    "    validation_percent              : Optional [ float ]        = None,\n",
    "    training_percent                : Optional [ float ]        = None,\n",
    "    window_mask_percent             : Optional [ float ]        = None,\n",
    "    window_sizes                    : Optional [ List [int] ]   = None,\n",
    "    n_window_sizes                  : Optional [ int ]          = 1,\n",
    "    window_sizes_offset             : Optional [ int ]          = 0.05,\n",
    "    windows_min_distance            : Optional [ int ]          = 1,\n",
    "    full_dataset                    : Optional [ bool ]         = False,\n",
    "    ## -- Using Type\n",
    "    enc_input                       : Optional [ EncoderInput ] = None\n",
    "): \n",
    "    mssg.level += 1\n",
    "    func = mssg.function\n",
    "    mssg.initial_(func_name = ut.funcname())\n",
    "    enc_input, _ = ut._check_value(enc_input, None, \"enc_input\", EncoderInput, True, False, False)\n",
    "    mssg.print(f\"is none enc_input? {enc_input is None}\")\n",
    "    if enc_input is None:\n",
    "        mssg.print(f\"About to get the windows\")\n",
    "        enc_input = windowed_dataset(\n",
    "            X                       = X,\n",
    "            stride                  = stride,\n",
    "            window_sizes            = window_sizes,\n",
    "            n_window_sizes          = n_window_sizes,\n",
    "            window_sizes_offset     = window_sizes_offset,\n",
    "            windows_min_distance    = windows_min_distance,\n",
    "            full_dataset            = full_dataset,\n",
    "            mssg                    = mssg\n",
    "        )\n",
    "        mssg.print(f\"About to get the encoder input | windows~{len(enc_input)}\", func_name = ut.funcname())\n",
    "        enc_input = EncoderInput(\n",
    "            _data               = enc_input, \n",
    "            stride              = stride,\n",
    "            batch_size          = batch_size,\n",
    "            n_windows           = n_windows,\n",
    "            n_windows_percent   = n_windows_percent,\n",
    "            validation_percent  = validation_percent,\n",
    "            training_percent    = training_percent,\n",
    "            window_mask_percent = window_mask_percent,\n",
    "        )\n",
    "        mssg.print(f\"Enc input obtained | enc_input~{enc_input.shape}\")\n",
    "    mssg.final(func_name = func)\n",
    "    mssg.level -= 1\n",
    "    return enc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6e2ab-8bc9-4921-8b42-c5180a18b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_optimizer(\n",
    "    mssg                            : ut.Mssg,\n",
    "    optim                           : EncoderOptimizer = None,\n",
    "    criterion                       : _Loss         = torch.nn.MSELoss, \n",
    "    optimizer                                       = None, \n",
    "    lr                              : float         = 5e-5, #1e-4, \n",
    "    lr_scheduler_flag               : bool          = False, \n",
    "    lr_scheduler_name               : str           = \"linear\",\n",
    "    lr_scheduler_num_warmup_steps   : int           = None\n",
    "):\n",
    "    mssg.initial(ut.funcname())\n",
    "    optim,_ = ut._check_value(optim, None, \"optim\", EncoderOptimizer, True)\n",
    "    if optim is None:\n",
    "        optim = EncoderOptimizer(\n",
    "            criterion   = criterion,\n",
    "            optimizer   = optimizer,\n",
    "            lr          = LRScheduler (\n",
    "                            lr              = lr,\n",
    "                            flag            = lr_scheduler_flag,\n",
    "                            name            = lr_scheduler_name,\n",
    "                            num_warmup_steps= lr_scheduler_num_warmup_steps\n",
    "            ),\n",
    "        )\n",
    "    mssg.final()\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f4bb8-7b7c-4127-8875-56d9ea25495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_encoder(\n",
    "    ## -- Using all parammeters\n",
    "    X                               : Optional [ Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ] ],\n",
    "    stride                          : Optional [ int ]          = None,\n",
    "    batch_size                      : Optional [ int ]          = None,\n",
    "    n_windows                       : Optional [ int ]          = None,\n",
    "    n_windows_percent               : Optional [ float ]        = None,\n",
    "    validation_percent              : Optional [ float ]        = None, \n",
    "    training_percent                : Optional [ float ]        = None,\n",
    "    window_mask_percent             : Optional [ float ]        = None,\n",
    "    window_sizes                    : Optional [ List [int] ]   = None,\n",
    "    n_window_sizes                  : Optional [ int ]          = 1,\n",
    "    window_sizes_offset             : Optional [ int ]          = 0.05,\n",
    "    windows_min_distance            : Optional [ int ]          = 1,\n",
    "    full_dataset                    : Optional [ bool ]         = False,\n",
    "    ##-- Given by Type \n",
    "    enc_input                       : Optional [ EncoderInput ] = None,\n",
    "    # Optimizer\n",
    "    optim                           : Optional [ EncoderOptimizer ] = None,\n",
    "    ## -- Using all parameters\n",
    "    criterion                       : Optional [ _Loss ]            = torch.nn.MSELoss, \n",
    "    optimizer                                                       = None, \n",
    "    lr                              : Optional [ float ]            = 5e-5, #1e-4, \n",
    "    lr_scheduler_flag               : Optional [ bool ]             = False, \n",
    "    lr_scheduler_name               : Optional [ str ]              = \"linear\",\n",
    "    lr_scheduler_num_warmup_steps   : Optional [ int ]              = None,\n",
    "    # Mssg\n",
    "    ## -- Using all parameters\n",
    "    verbose                         : Optional[ int ]               = 0, \n",
    "    print_to_path                   : Optional[ bool ]              = False,\n",
    "    print_path                      : Optional[ str ]               = \"~/data/logs/logs.txt\",\n",
    "    print_mode                      : Optional[ str ]               = 'a',\n",
    "    ## -- Using Type\n",
    "    mssg                            : Optional [ ut.Mssg ]          = None,\n",
    "    ## Encoder \n",
    "    enc                             : Optional [ Encoder ]          = None,\n",
    "    ## -- Using all parameters\n",
    "    num_epochs                      : Optional [ int]               = 3,\n",
    "    enc_learn                       : Optional [Learner]            = None, \n",
    "    cpu                             : Optional [ bool ]             = False,\n",
    "    to_numpy                        : Optional [ bool ]             = True,\n",
    "    #- Masking options\n",
    "    mask_stateful                   : Optional [ bool ]             = False,\n",
    "    mask_future                     : Optional [ bool ]             = False,\n",
    "    mask_sync                       : Optional [ bool ]             = False,\n",
    "    #- Loss criterions\n",
    "    metrics                         : Optional [ List [ Callable ]] = None,\n",
    "    metrics_names                   : Optional [ List [ str ] ]     = None,\n",
    "    metrics_args                    : Optional [ AttrDict ]         = None,\n",
    "    metrics_dict                    : Optional [ AttrDict ]         = None,\n",
    "    scheduler_specific_kwargs       : Optional [ AttrDict ]         = None\n",
    "):\n",
    "    enc,_ = ut._check_value(enc, None, \"enc\", Encoder, True)\n",
    "    \n",
    "    if enc is None: \n",
    "        mssg = ut._get_mssg(\n",
    "            mssg          = mssg,\n",
    "            verbose       = verbose, \n",
    "            print_to_path = print_to_path, \n",
    "            print_path    = print_path, \n",
    "            print_mode    = print_mode\n",
    "        )\n",
    "        mssg.initial(ut.funcname())\n",
    "        mssg.print(\"About to exec _get_enc_input\")\n",
    "        enc_input = _get_enc_input(mssg, X, stride, batch_size, n_windows, n_windows_percent, validation_percent, training_percent, window_mask_percent, window_sizes, n_window_sizes, window_sizes_offset, windows_min_distance, full_dataset, enc_input)\n",
    "        mssg.print(f\"enc_input~{enc_input.shape}\")\n",
    "        mssg.print(\"About to exec _get_optimizer\")\n",
    "        optim = _get_optimizer(mssg, optim, criterion, optimizer, lr, lr_scheduler_flag, lr_scheduler_name, lr_scheduler_num_warmup_steps)\n",
    "        \n",
    "        if metrics_dict is None and (\n",
    "                metrics and metrics_names and metrics_args and \n",
    "                len(metrics) == len(metrics_names) == len(metrics_args)\n",
    "            ):\n",
    "            metrics_dict = {\n",
    "                metrics_names[i]: {\n",
    "                    'metric': metrics[i],\n",
    "                    'args'  : metrics_args[i]\n",
    "                }\n",
    "                for i in range(len(metrics_names))\n",
    "            }\n",
    "            \n",
    "        enc = Encoder(\n",
    "            model           = enc_learn,\n",
    "            input           = enc_input,\n",
    "            mssg            = mssg,\n",
    "            cpu             = cpu,\n",
    "            to_numpy        = to_numpy, \n",
    "            num_epochs      = num_epochs, \n",
    "            optim           = optim,\n",
    "            mask_stateful   = mask_stateful,\n",
    "            mask_future     = mask_future,\n",
    "            mask_sync       = mask_sync,\n",
    "            eval_stats_pre  = None,\n",
    "            eval_stats_post = None,\n",
    "            metrics_dict    = metrics_dict,\n",
    "            scheduler_specific_kwargs=scheduler_specific_kwargs\n",
    "        )\n",
    "    enc.mssg.final(ut.funcname())\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca51dd",
   "metadata": {},
   "source": [
    "### Moment\n",
    "> Follow the tutorial in the original repository: [Moment - Imputation](https://github.com/moment-timeseries-foundation-model/moment/blob/main/tutorials/imputation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7548dcac-1a8e-4933-a8e9-85a3309f3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_compute_loss_check_sizes_(\n",
    "    batch           : List [ List [ List [ float ] ] ], \n",
    "    output, \n",
    "    verbose         : int   = 0,\n",
    "    # Print options\n",
    "    print_to_path   : bool  = False,\n",
    "    print_path      : str   = \"~/data/logs/logs.txt\",\n",
    "    print_mode      : str   = 'a'\n",
    "):\n",
    "    if verbose > 0: ut.print_flush(\"--> fine_tune_moment_compute_loss_check_sizes_\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    b = batch.clone()\n",
    "    b_2 = batch.shape[2]\n",
    "    re_2 = output.reconstruction.shape[2]\n",
    "    if b_2 > re_2:\n",
    "        if verbose > 0: ut.print_flush(f\" Fine tune loop | TODO: Why? Original {b_2} > {re_2}  Reconstruction\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "        b = b[...,:re_2]\n",
    "    elif re_2 > b_2:\n",
    "        if verbose > 1: ut.print_flush(f\" Fine tune loop | Why ? Original {b_2} < {re_2} Reconstruction ? Padding\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "        output.reconstruction = output.reconstruction[...,:b_2]\n",
    "    else: \n",
    "        if verbose > 1: ut.print_flush(f\" Fine tune loop | re_2 {re_2} == {b_2} y_2\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    if verbose > 1: \n",
    "        ut.print_flush(f\"---------- Checking loss  ------- | reconstruction ~ {output.reconstruction.shape} | original_ ~ {b.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    if verbose > 0: ut.print_flush(\"fine_tune_moment_compute_loss_check_sizes_ -->\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e36e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_compute_loss(\n",
    "    batch, \n",
    "    output, \n",
    "    criterion   = torch.nn.MSELoss, \n",
    "    verbose     = 0, \n",
    "    input_mask  = None, \n",
    "    mask        = None,\n",
    "    # Print options\n",
    "    print_to_path   : bool          = False,\n",
    "    print_path      : str           = \"~/data/logs/logs.txt\",\n",
    "    print_mode      : str           = 'a'\n",
    "):\n",
    "    if verbose > 0: ut.print_flush(\"--> fine_tune_moment_compute_loss\", print_to_path = print_to_path, print_path = print_path, print_mode = print_mode, verbose = verbose, print_time = print_to_path)\n",
    "    b = fine_tune_moment_compute_loss_check_sizes_(batch = batch, output = output, verbose = verbose, print_to_path = print_to_path, print_path = print_path, print_mode = 'a')\n",
    "    if verbose > 0: ut.print_flush(f\"fine_tune_moment_compute_loss | b~{b.shape} | o~{output.reconstruction.shape}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    o = output.reconstruction\n",
    "    device = b.device if b.device != \"cpu\" else o.device\n",
    "    b = b.to(device)\n",
    "    o = o.to(device)\n",
    "    compute_loss = criterion()\n",
    "    recon_loss = compute_loss(o, b)\n",
    "    batch_masks = output.input_mask if input_mask is None else input_mask\n",
    "    mask = output.pretrain_mask if mask is None else mask\n",
    "    batch_masks = batch_masks.to(device)\n",
    "    mask = mask.to(device)\n",
    "    if verbose > 1: ut.print_flush(f\"fine_tune_moment_compute_loss | batch ~ {b.shape} | {b.device}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    if verbose > 1: ut.print_flush(f\"fine_tune_moment_compute_loss | batch_masks ~ {batch_masks.shape} | {batch_masks.device}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    if verbose > 1: ut.print_flush(f\"fine_tune_moment_compute_loss | mask ~ {mask.shape} | {mask.device}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    \n",
    "    observed_mask = batch_masks * (1-mask)\n",
    "    masked_loss = observed_mask * recon_loss\n",
    "    loss = masked_loss.nansum() / (observed_mask.nansum() + 1e-7)\n",
    "    if verbose > 2: ut.print_flush(f\"Loss type: {type(loss)}\",print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)  # Debe ser <class 'torch.Tensor'>\n",
    "    if verbose > 1: ut.print_flush(f\"fine_tune_moment_compute_loss | loss: {loss.item()}\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    if verbose > 0: ut.print_flush(\"fine_tune_moment_compute_loss -->\", print_to_path = print_to_path, print_path = print_path, print_mode = 'a', verbose = verbose, print_time = print_to_path)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ff7b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_eval_preprocess(\n",
    "    self        : Encoder,\n",
    "    predictions : List [ List [ float ]],\n",
    "    references  : List [ List [ float ]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - predictions torch (float)\n",
    "    - references torch (float)\n",
    "    Returns: \n",
    "        - Predictions and references ensuring same shape and no NaN values. \n",
    "        - Uses the shape of the smallest torch for the modification.\n",
    "    \"\"\"\n",
    "    #-- Mssg verbose & name\n",
    "    func = self.mssg.function\n",
    "    self.mssg.level += 1\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    #--- Go!\n",
    "    self.mssg.print(f\"Before reshape | preds~{predictions.shape}\")\n",
    "    self.mssg.print(f\"Before reshape | refs~{references.shape}\")\n",
    "    predictions = einops.rearrange(predictions, \"b v w -> (b v) w\")\n",
    "    references = einops.rearrange(references, \"b v w -> (b v) w\")\n",
    "    # Avoid NaN \n",
    "    if predictions.shape[1] > references.shape[1]: predictions = predictions[:,:references.shape[1]]\n",
    "    if predictions.shape[1] < references.shape[1]: references = references[:,:predictions.shape[1]]\n",
    "    self.mssg.print(f\"After reshape | preds~{predictions.shape}\")\n",
    "    self.mssg.print(f\"After reshape | refs~{references.shape}\")\n",
    "        \n",
    "    nan_mask    = torch.isnan(predictions) | torch.isnan(references)\n",
    "    predictions = torch.where(nan_mask, torch.tensor(0.0), predictions)\n",
    "    references  = torch.where(nan_mask, torch.tensor(0.0), references)\n",
    "    self.mssg.print(f\"After NaN | preds~{predictions.shape}\")\n",
    "    self.mssg.print(f\"After NaN | refs~{references.shape}\")\n",
    "    self.mssg.final()\n",
    "    #-- Restore mssg\n",
    "    self.mssg.level -= 1\n",
    "    self.mssg.function = func\n",
    "    return predictions, references\n",
    "\n",
    "Encoder.fine_tune_moment_eval_preprocess = fine_tune_moment_eval_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b95308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def moment_build_masks(\n",
    "    batch, \n",
    "    batch_masks,\n",
    "    window_mask_percent     : float     = 0.3,\n",
    "    mssg                    : ut.Mssg   = ut.Mssg(),\n",
    "    use_moment_masks        : bool      = False,\n",
    "    mask_stateful           : bool      = False,\n",
    "    mask_future             : bool      = False,\n",
    "    mask_sync               : bool      = False\n",
    "):\n",
    "    func = mssg.function \n",
    "    mssg.initial_(ut.funcname())\n",
    "    bms = batch_masks\n",
    "    if use_moment_masks:\n",
    "        mssg.print(f\"Using mask generator with mask ratio {window_mask_percent}\")\n",
    "        mask_generator = Masking(mask_ratio = window_mask_percent)\n",
    "    if batch.shape[0] < batch_masks.shape[0]:  \n",
    "        bms = batch_masks[:batch.shape[0]]\n",
    "    mssg.level += 1\n",
    "    mssg.print(f\"moment_build_masks | batch ~ {batch.shape} | batch_masks ~ {bms.shape}\")\n",
    "    if bms.shape[0] > batch.shape[0]: bms = bms[:batch.shape[0]]\n",
    "    mssg.level -= 1\n",
    "    mssg.print(f\"window_mask_percent {window_mask_percent} | batch ~ {batch.shape}\")\n",
    "    device = batch.device if batch.device != \"cpu\" else bms.device\n",
    "    batch = batch.to(device)\n",
    "    bms = bms.to(device)\n",
    "    if use_moment_masks:\n",
    "        mask = mask_generator.generate_mask(\n",
    "            x           = batch,\n",
    "            input_mask  = bms\n",
    "        )\n",
    "        mssg.print(f\"Moment mode Mask: {mask}\")\n",
    "    else: \n",
    "        mssg.print(\"Using MVP masking generation style\")\n",
    "        o = torch.zeros(batch.shape[0], batch.shape[2])\n",
    "        mssg.print(f\"o ~ {o.shape} | stateful = {mask_stateful} | sync = {mask_sync} | r = {window_mask_percent}\")\n",
    "        if mask_future:\n",
    "            try:\n",
    "                mask = create_future_mask(\n",
    "                    o       = o, \n",
    "                    r       = float(window_mask_percent), \n",
    "                    sync    = mask_sync\n",
    "                )[0,:,:].int() # As there is only 1 variable/variables are flattened, an extra dim is created by the masking function\n",
    "            except Exception as e:\n",
    "                mssg.print(f\"Create future mask failed | Error {e}\")\n",
    "                mask = create_future_mask(\n",
    "                    o       = o,\n",
    "                    r       = float(window_mask_percent),\n",
    "                    sync    = mask_sync\n",
    "                ).int()\n",
    "        else:\n",
    "            mask = create_subsequence_mask(\n",
    "                o       = o,\n",
    "                r       = float(window_mask_percent),\n",
    "                stateful= mask_stateful,\n",
    "                sync    = mask_sync\n",
    "            )[0,:,:].int() # As there is only 1 variable/variables are flattened, an extra dim is created by the masking function\n",
    "        mssg.print_error(f\"MVP mode Mask: {mask}\")\n",
    "        mssg.print(f\"Before shape adjustment | batch ~ {batch.shape} | batch_masks ~ {bms.shape} | mask ~ {mask.shape}\")\n",
    "    if mask.shape[0] < bms.shape[0]:  bms = batch_masks[:mask.shape[0]]\n",
    "    if mask.shape[1]  < batch_masks.shape[1] :\n",
    "        mask = torch.nn.functional.pad(mask,(0,batch_masks.shape[1]-mask.shape[1]))\n",
    "    mssg.final()\n",
    "    mssg.level -= 1\n",
    "    mssg.function = func\n",
    "    if mask is None:\n",
    "        raise ValueError(\"Mask is none after building\")\n",
    "    return mask, bms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20e68c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_eval_step_(\n",
    "    self : Encoder, \n",
    "    batch,\n",
    "    mse_metric, \n",
    "    rmse_metric,\n",
    "    mae_metric,\n",
    "    smape_metric#,\n",
    "#    total_loss\n",
    "):\n",
    "    func = self.mssg.function \n",
    "    self.mssg.level += 1\n",
    "    self.mssg.initial(ut.funcname())\n",
    "    window_size = self.input.shape[2]\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    batch_masks = torch.ones((self.input.batch_size, window_size), device = device).long()\n",
    "    mask, bms = moment_build_masks(\n",
    "        batch               = batch,\n",
    "        batch_masks         = batch_masks,\n",
    "        window_mask_percent = self.input.window_mask_percent,\n",
    "        mssg                = self.mssg,\n",
    "        use_moment_masks    = self.use_moment_masks,\n",
    "        mask_stateful       = self.mask_stateful,\n",
    "        mask_future         = self.mask_future,\n",
    "        mask_sync           = self.mask_sync\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        ##output, self.model = sure_eval_moment(\n",
    "        ##    enc_learn       = self.model, \n",
    "        ##    cpu             = self.cpu,\n",
    "        ##    verbose         = self.mssg.verbose-self.mssg.level+1,\n",
    "        ##    y               = batch, \n",
    "        ##    input_mask      = bms,\n",
    "        ##    mask            = mask,\n",
    "        ##    padd_step       = 100, \n",
    "        ##    max_trials      = 5, \n",
    "        ##    acts_indices    = None,\n",
    "        ##    print_to_path   = self.mssg.to_path, \n",
    "        ##    print_path      = self.mssg.path, \n",
    "        ##    print_mode      = self.mssg.mode\n",
    "        ##)\n",
    "        output = self.sure_eval_moment(\n",
    "            batch                   = batch, \n",
    "            input_mask              = bms, \n",
    "            mask                    = mask, \n",
    "            padd_step               = 100, \n",
    "            max_trials              = 5, \n",
    "            acts_indices            = None, \n",
    "            continue_if_fail        = False\n",
    "        )\n",
    "        #loss = self.model.criterion(output.logits, batch)\n",
    "        #total_loss += loss.item()\n",
    "        predictions = output.reconstruction\n",
    "        references  = batch\n",
    "        predictions = predictions.to(device)\n",
    "        references  = references.to(device)\n",
    "        predictions, references = self.fine_tune_moment_eval_preprocess(predictions = predictions, references = references)\n",
    "        mse_metric.add_batch(predictions=predictions, references = references)\n",
    "        rmse_metric.add_batch(predictions=predictions, references = references)\n",
    "        mae_metric.add_batch(predictions=predictions, references = references)\n",
    "        smape_metric.add_batch(predictions=predictions, references = references)\n",
    "    self.mssg.final()\n",
    "    self.mssg.level -= 1\n",
    "    self.mssg.function = func\n",
    "    return mse_metric, rmse_metric, mae_metric, smape_metric#, total_loss\n",
    "Encoder.fine_tune_moment_eval_step_ = fine_tune_moment_eval_step_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cc18bf9-fd6f-4758-9862-e0e73206c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_eval_(\n",
    "    self      : Encoder,\n",
    "    dl_eval   : DataLoader\n",
    "):\n",
    "    func = self.mssg.function \n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    # Select device\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    self.mssg.print_error(f\"Device?: {device} | cpu? {self.cpu}\")\n",
    "    # Load metric\n",
    "    mse_metric  = EvalMSE\n",
    "    rmse_metric = EvalRMSE\n",
    "    mae_metric  = EvalMAE\n",
    "    smape_metric= EvalSMAPE\n",
    "    #total_loss  = 0.0\n",
    "\n",
    "    num_evaluation_steps = len(dl_eval)\n",
    "    try: \n",
    "        self.model = self.model.to(device)\n",
    "    except: \n",
    "        self.mssg.print_error(f\"Could not move model to {device}\")\n",
    "    self.model.eval()\n",
    "    progress_bar = tqdm(range(num_evaluation_steps))\n",
    "    for batch in dl_eval:\n",
    "        batch = batch.to(device)\n",
    "        (\n",
    "            mse_metric, \n",
    "            rmse_metric, \n",
    "            mae_metric, \n",
    "            smape_metric\n",
    "            #total_loss\n",
    "        ) = self.fine_tune_moment_eval_step_(\n",
    "            batch       = batch, \n",
    "            mse_metric  = mse_metric, \n",
    "            rmse_metric = rmse_metric,\n",
    "            mae_metric  = mae_metric,\n",
    "            smape_metric= smape_metric\n",
    "            #total_loss  = total_loss\n",
    "        )\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "    mse   = mse_metric.compute(squared = False)\n",
    "    rmse  = rmse_metric.compute(squared = True)\n",
    "    mae   = mae_metric.compute()\n",
    "    smape = smape_metric.compute()\n",
    "    eval_results = {\n",
    "        #\"loss\"  : total_loss,\n",
    "        \"mse\"   : mse['mse'],\n",
    "        \"rmse\"  : rmse['mse'],\n",
    "        \"mae\"   : mae['mae'],\n",
    "        \"smape\" : smape['smape']\n",
    "    }\n",
    "    #self.mssg.print_error(f\"Eval results: {eval_results}.\")\n",
    "    self.model.train()\n",
    "    self.mssg.final()\n",
    "    self.mssg.function = func\n",
    "    return eval_results\n",
    "Encoder.fine_tune_moment_eval_ = fine_tune_moment_eval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38f59b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_train_loop_step_(\n",
    "    self : Encoder,\n",
    "    batch, \n",
    "    batch_masks,\n",
    "    criterion                   = torch.nn.MSELoss,\n",
    "    use_moment_masks    : bool  = False,\n",
    "): \n",
    "    func = self.mssg.function\n",
    "    self.mssg.level += 1\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    \n",
    "    device = torch.cuda.current_device() if not self.cpu else \"cpu\"\n",
    "    self.mssg.print(\"Get the masks\")    \n",
    "    mask, bms = moment_build_masks(batch, batch_masks, self.input.window_mask_percent, self.mssg, use_moment_masks, self.mask_stateful, self.mask_future, self.mask_sync)\n",
    "    \n",
    "    batch   = batch.to(device)\n",
    "    bms     = bms.to(device) \n",
    "    \n",
    "    batch   = batch.to(device)\n",
    "    mask    = mask.to(device)\n",
    "    bms     = bms.to(device)\n",
    "    \n",
    "    self.model = self.model.to(device)\n",
    "    self.mssg.level += 1\n",
    "    self.mssg.print(f\"batch ~ {batch.shape} | batch_masks ~ {bms.shape} | mask ~ {mask.shape}\")\n",
    "    self.mssg.print(f\"Mask given to eval: {mask}\", verbose = 5)\n",
    "    for param in self.model.parameters():\n",
    "        param = param.to(device)\n",
    "    self.mssg.print(f\"sure_eval_moment | b{batch.device} | m{mask.device} | bm{bms.device}\")\n",
    "    self.mssg.level -= 1\n",
    "    #output, self.model = sure_eval_moment(\n",
    "    #    enc_learn           = self.model, \n",
    "    #    cpu                 = self.cpu,\n",
    "    #    verbose             = self.mssg.verbose-self.mssg.level + 1, \n",
    "    #    y                   = batch, \n",
    "    #    input_mask          = bms,  # None\n",
    "    #    mask                = mask, # None\n",
    "    #    padd_step           = 100, \n",
    "    #    max_trials          = 5, \n",
    "    #    acts_indices        = None,\n",
    "    #    print_to_path       = self.mssg.to_path, print_path = self.mssg.path, print_mode = 'a',\n",
    "    #    continue_if_fail    = True\n",
    "    #)\n",
    "    output = self.sure_eval_moment(\n",
    "        batch           = batch,\n",
    "        input_mask      = bms,\n",
    "        mask            = mask, # Cambiado None a mask\n",
    "        padd_step       = 100,\n",
    "        max_trials      = 5,\n",
    "        acts_indices    = None,\n",
    "        continue_if_fail= False \n",
    "    )\n",
    "    # Compute output loss\n",
    "    if output is None:\n",
    "        self.mssg.print(f\"fine_tune_moment_train_loop_step_ | Execution failed | Output none \")\n",
    "        loss = 0\n",
    "    else: \n",
    "        loss = fine_tune_moment_compute_loss(batch, output, criterion, verbose = self.mssg.verbose, input_mask = bms, mask = mask, print_to_path = self.mssg.to_path, print_path = self.mssg.path, print_mode = 'a')\n",
    "    self.mssg.final()\n",
    "    self.mssg.level -= 1\n",
    "    self.mssg.function = func\n",
    "    return loss\n",
    "Encoder.fine_tune_moment_train_loop_step_ = fine_tune_moment_train_loop_step_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def config_optim(\n",
    "    self : Encoder, dl_train, num_training_steps\n",
    "):\n",
    "    if self.optim.optimizer is None: \n",
    "        self.optim.optimizer    = torch.optim.AdamW(self.model.parameters(), self.optim.lr.lr)\n",
    "    if self.optim.lr.flag:\n",
    "        self.optim.lr.scheduler = self.setup_scheduler(\n",
    "            dl_train            = dl_train, \n",
    "            optimizer           = self.optim.optimizer, \n",
    "            num_training_steps  = num_training_steps \n",
    "        )\n",
    "    else:\n",
    "        self.optim.lr.scheduler = None\n",
    "Encoder.config_optim = config_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f06b0ec-8c25-470c-a315-fb89c40e2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fine_tune_moment_train_(\n",
    "    self                            : Encoder,\n",
    "    dl_train                        : DataLoader,\n",
    "    ds_train                        : pd.DataFrame,\n",
    "    use_moment_masks                : bool      = False\n",
    "):\n",
    "    self.mssg.level += 1\n",
    "    func = self.mssg.function\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    losses = []\n",
    "    # Select device\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    # Optimizer and learning rate scheduler\n",
    "    num_training_steps = self.num_epochs* len(dl_train)\n",
    "    self.config_optim( dl_train = dl_train, num_training_steps=num_training_steps)\n",
    "    # Masks\n",
    "    window_size = ds_train.shape[2]\n",
    "    batch_masks = torch.ones((self.input.batch_size, window_size), device = device).long()\n",
    "    # Training loop\n",
    "    self.mssg.print(\"Training loop\")\n",
    "    self.mssg.level += 1\n",
    "    self.mssg.print(f\"Fine tune loop | batch_masks~{batch_masks.shape}\")\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    self.mssg.level -= 1\n",
    "    self.mssg.print(f\"num_epochs {self.num_epochs} | n_batches {len(dl_train)}\")\n",
    "    for epoch in range(self.num_epochs):\n",
    "        for i, batch in enumerate(dl_train):\n",
    "            self.mssg.print(f\"batch {i} ~ {batch.shape} | epoch {epoch} | train {i+epoch} of {num_training_steps} | Before loop step\")\n",
    "            loss  = self.fine_tune_moment_train_loop_step_(\n",
    "                    batch            = batch,\n",
    "                    batch_masks      = batch_masks, \n",
    "                    use_moment_masks = use_moment_masks,\n",
    "                )\n",
    "            try: \n",
    "                self.mssg.print(f\"fine_tune_moment_train | batch {i} ~ {batch.shape} | epoch {epoch} | train {i+epoch} of {num_training_steps} | Loss backward | After loop step \")\n",
    "                if hasattr(loss, 'item'):\n",
    "                    losses.append(loss.item())\n",
    "                    loss.backward()\n",
    "                else:\n",
    "                    losses.append(loss)\n",
    "                self.optim.optimizer.zero_grad()  \n",
    "                self.optim.optimizer.step()\n",
    "            except Exception as e: \n",
    "                self.mssg.print(f\"fine_tune_moment_train | batch {i} ~ {batch.shape} | epoch {epoch} | train {i+epoch} of {num_training_steps} | Loss backward failed: {e}\")\n",
    "                losses.append(np.nan)\n",
    "                self.optim.optimizer.zero_grad()\n",
    "                self.optim.optimizer.step()\n",
    "            if self.optim.lr.flag: self.optim.lr.scheduler.step()\n",
    "            progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "    self.mssg.final()\n",
    "    self.mssg.level -= 1\n",
    "    self.mssg.function = func \n",
    "    return losses, self.model\n",
    "Encoder.fine_tune_moment_train_ = fine_tune_moment_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93677275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_single_(\n",
    "    self                : Encoder,\n",
    "    eval_pre            : bool = False,\n",
    "    eval_post           : bool = False,\n",
    "    shot                : bool = True,\n",
    "    sample_id           : int  = 0,\n",
    "    use_moment_masks    : bool = False,\n",
    "    register_errors      : bool = True\n",
    "):\n",
    "    self.mssg.level += 1\n",
    "    func = self.mssg.function\n",
    "    self.mssg.initial_(\"fine_tune_moment_single\")\n",
    "    t_shot              = 0\n",
    "    t_eval_1            = 0\n",
    "    t_eval_2            = 0\n",
    "    losses              = []\n",
    "    eval_results_pre    = {}\n",
    "    eval_results_post   = {}\n",
    "    error_val           = 0\n",
    "    if self.time_flag: timer = ut.Time(mssg = self.mssg)\n",
    "    self.mssg.print(f\"fine_tune_moment_single | Prepare the dataset | X ~ {self.input.data[sample_id].shape}\")\n",
    "    # Prepare the dataset\n",
    "    dl_eval, dl_train, ds_eval, ds_train = prepare_train_and_eval_dataloaders(\n",
    "        X                   = self.input.data[sample_id], \n",
    "        batch_size          = self.input.batch_size, \n",
    "        n_windows           = self.input.n_windows, \n",
    "        n_windows_percent   = self.input.n_windows_percent,\n",
    "        training_percent    = self.input.training_percent, \n",
    "        validation_percent  = self.input.validation_percent, \n",
    "        shot                = shot, \n",
    "        eval_pre            = eval_pre, \n",
    "        eval_post           = eval_post,\n",
    "        mssg                = deepcopy(self.mssg)\n",
    "    )\n",
    "    try:\n",
    "        self.mssg.print(f\"Processing wlen {self.input.data[sample_id].shape[2]} | Lengths list: {self.window_sizes}\")\n",
    "        if eval_pre:\n",
    "            self.mssg.print(f\"Eval Pre | wlen {self.input.data[sample_id].shape[2]}\")\n",
    "            if self.time_flag: timer.start()\n",
    "            eval_results_pre    = self.fine_tune_moment_eval_(dl_eval = dl_eval)\n",
    "            if self.time_flag: \n",
    "                timer.end()\n",
    "                t_eval_1 = timer.duration()\n",
    "                timer.show(verbose = self.mssg.verbose)\n",
    "        if shot:\n",
    "            if self.time_flag: timer.start()\n",
    "            self.mssg.print(f\"Train | wlen {self.input.data[sample_id].shape[2]}\")\n",
    "            try:\n",
    "                losses, self.model                  = self.fine_tune_moment_train_(\n",
    "                    dl_train                        = dl_train,\n",
    "                    ds_train                        = ds_train,\n",
    "                    use_moment_masks                = use_moment_masks,\n",
    "                )\n",
    "                if self.time_flag:\n",
    "                    timer.end()\n",
    "                    t_shot = timer.duration()\n",
    "                    timer.show()\n",
    "            except Exception as e:\n",
    "                self.mssg.print(f\"fine_tune_moment_single | Train | Window {self.input.shape[2]} not valid | {e}\")\n",
    "                traceback.print_exc()\n",
    "                raise(e)\n",
    "        if eval_post:    \n",
    "            self.mssg.print(f\"fine_tune_moment_single | Eval Post | wlen {self.input.shape[2]}\")\n",
    "            if self.time_flag: timer.start()\n",
    "            eval_results_post = self.fine_tune_moment_eval_(dl_eval=dl_eval)\n",
    "            #self.mssg.print_error(f\"Eval_results_post = {eval_results_post}\")\n",
    "            if self.time_flag:\n",
    "                timer.end()\n",
    "                t_eval_2 = timer.duration()\n",
    "                if self.mssg.verbose > 0: \n",
    "                    timer.show()\n",
    "                if self.mssg.verbose > 0: \n",
    "                    self.show_eval_stats(\n",
    "                        # Wether computed or not pre & post errors\n",
    "                        eval_pre        = eval_pre, \n",
    "                        eval_post       = eval_post, \n",
    "                        # Results\n",
    "                        eval_stats_pre  = eval_results_pre,\n",
    "                        eval_stats_post = eval_results_post,\n",
    "                        # Function name\n",
    "                        func_name       = ut.funcname()\n",
    "                    )\n",
    "    except Exception as e:\n",
    "        if register_errors:\n",
    "            error_val = 1\n",
    "            window = self.input.data[sample_id].shape[2]\n",
    "            self.mssg.print_error(f\"Registering error in DataFrame | window: {window} | error: {e}\")\n",
    "            error = {\"window\": window, \"error\": e}\n",
    "            self.errors = pd.concat([self.errors, pd.DataFrame([error])])\n",
    "            display(self.errors)\n",
    "        else: \n",
    "            raise(e)\n",
    "    self.mssg.final(ut.funcname())\n",
    "    self.mssg.level -= 1\n",
    "    self.mssg.function = func\n",
    "    return losses, eval_results_pre, eval_results_post, t_shot, t_eval_1, t_eval_2, self.model, error_val\n",
    "\n",
    "Encoder.fine_tune_moment_single_ = fine_tune_moment_single_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f21133e9-63d4-41e6-8fa0-42265ede334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moment_(\n",
    "    self                : Encoder, \n",
    "    eval_pre            : bool = False, \n",
    "    eval_post           : bool = False, \n",
    "    shot                : bool = False,\n",
    "    time_flag           : bool = None,\n",
    "    use_moment_masks    : bool = None,\n",
    "    register_errors     : bool = True\n",
    "):   \n",
    "    self.mssg.initial(ut.funcname())\n",
    "    self.time_flag = self.time_flag if time_flag is None else time_flag\n",
    "    self.use_moment_masks = self.use_moment_masks if use_moment_masks is None else use_moment_masks\n",
    "    # Return values\n",
    "    lossess             = []\n",
    "    eval_results_pre    = {}\n",
    "    eval_results_post   = {}\n",
    "    t_shots             = []\n",
    "    t_shot              = 0\n",
    "    t_evals             = []\n",
    "    t_eval              = 0\n",
    "    if self.input.size is None:\n",
    "        self.mssg.print(f\"Windows: {len(self.input._data)}\")\n",
    "        raise ValueError(f\"Invalid number of windows: {self.input.size}\")\n",
    "    self.mssg.print(f\"Processing {self.input.size} datasets : {self.input.shape}\")\n",
    "    # Build optimizer\n",
    "    if self.optim.optimizer is None: \n",
    "        self.mssg.print(f\"Setting up optimizer as AdamW\")\n",
    "        self.optim.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.optim.lr.lr)\n",
    "    # Compute model for each window in the windowed dataset\n",
    "    \n",
    "    for i in range(self.input.size):\n",
    "        window_size = self.input._data[i].shape[2]\n",
    "        self.mssg.print_error(f\"Processing wlen {window_size} | wlens {self.window_sizes} | i {i+1}/{self.input.size}\")\n",
    "        self.window_sizes.append(window_size)\n",
    "        \n",
    "        ( \n",
    "            losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, self.model, error_val\n",
    "        ) =  self.fine_tune_moment_single_(eval_pre, eval_post, shot, i, use_moment_masks, register_errors)\n",
    "        if (error_val == 0): lossess.append(losses)\n",
    "        if (eval_pre and error_val == 0): eval_results_pre = eval_results_pre_\n",
    "        #self.mssg.print_error(f\"About to concat {eval_results_post_} to {eval_results_post}\")\n",
    "        if (eval_post and error_val == 0):\n",
    "            if eval_results_post == {}: \n",
    "                eval_results_post = {\n",
    "                    key:[eval_results_post_[key]] for key in eval_results_post_.keys()\n",
    "                }\n",
    "            else:\n",
    "                for key in eval_results_post_.keys():\n",
    "                    self.mssg.print_error(print(eval_results_post_[key]))\n",
    "                    eval_results_post[key] += [eval_results_post_[key]]\n",
    "        #self.mssg.print_error(f\"After concat {eval_results_post}\")\n",
    "        t_shots.append(t_shot_)\n",
    "        if eval_pre: t_evals.append(t_eval_1)\n",
    "        if eval_post: t_evals.append(t_eval_2)\n",
    "        eval_pre = False\n",
    "    t_shot = sum(t_shots)\n",
    "    t_eval = sum(t_evals)\n",
    "    self.eval_stats_pre = eval_results_pre\n",
    "    self.eval_stats_post = eval_results_post\n",
    "    self.mssg.final(ut.funcname())\n",
    "    if register_errors: return lossess, eval_results_pre, eval_results_post, t_shots, t_shot, t_evals, t_eval, self.model, self.window_sizes, self.errors\n",
    "    return lossess, eval_results_pre, eval_results_post, t_shots, t_shot, t_evals, t_eval, self.model, self.window_sizes\n",
    "\n",
    "Encoder.fine_tune_moment_ = fine_tune_moment_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455264d-4c8c-4c4f-9197-ea522878ecc9",
   "metadata": {},
   "source": [
    "### MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715004ed-325c-4f7c-b00c-08b37af8f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fit_fastai(\n",
    "    self     : Encoder,\n",
    "    dl_train : DataLoader,\n",
    "    lr_funcs : Tuple[Callable, ...] = (valley,),  # steep\n",
    "    show_plot: bool = False,\n",
    "    n_cycles : Optional[int] = None,  # Allow dynamic calculation\n",
    "    cycle_len : Optional[int] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Trains an `Encoder` model using different learning rate schedules, with support for\n",
    "    automatic learning rate finding and early stopping.\n",
    "\n",
    "    Args:\n",
    "        self (Encoder): The `Encoder` instance to be trained.\n",
    "        dl_train (DataLoader): The training DataLoader.\n",
    "        lr_funcs (Tuple[Callable, ...], optional): Functions to suggest the learning rate \n",
    "            using `lr_find`. Defaults to `(valley,)`.\n",
    "        show_plot (bool, optional): Whether to display the learning rate finder plot.\n",
    "            Defaults to `False`.\n",
    "        n_cycles (int, optional): Number of cycles for cyclical learning rate methods.\n",
    "            If not provided, it is calculated as `n_epoch // cycle_len`.\n",
    "        cycle_len (int, optional): Length of each cycle (in epochs) for cyclical \n",
    "            learning rate methods. If not provided, defaults to `1`.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If `lr_find` fails to calculate the learning rate.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Behavior:\n",
    "        - Uses the `lr_find` method to determine the optimal maximum learning rate (`lr_max`).\n",
    "        - Calculates `pct_start` based on the number of warm-up steps relative to the total training steps.\n",
    "        - Supports multiple learning rate schedules, including:\n",
    "          - `OneCycleLR`: Trains with a one-cycle learning rate policy.\n",
    "          - `FlatCosLR`: Trains with a flat cosine annealing schedule.\n",
    "          - `SgdrLR`: Trains using stochastic gradient descent with restarts (SGDR).\n",
    "          - Default `fit`: Trains using the basic fastai training loop if no scheduler matches.\n",
    "\n",
    "    Notes:\n",
    "        - Early stopping is enabled by default, monitoring `valid_loss` with a minimum delta of `1e-6` \n",
    "          and a patience of 10 epochs.\n",
    "        - If `cycle_len` or `n_cycles` is not provided, default values are calculated to distribute \n",
    "          training evenly across cycles.\n",
    "\n",
    "    Example:\n",
    "        >>> encoder = Encoder(...)\n",
    "        >>> dl_train = DataLoader(...)\n",
    "        >>> encoder.fit_fastai(dl_train, lr_funcs=(valley,), show_plot=True, n_cycles=3, cycle_len=2)\n",
    "    \"\"\"\n",
    "    self.mssg.level += 1\n",
    "    self.mssg.initial_(\"fit_fastai\")\n",
    "    # Callbacks\n",
    "    cbs = [\n",
    "        EarlyStoppingCallback(\n",
    "            monitor=\"valid_loss\", \n",
    "            min_delta=0.000001, \n",
    "            patience=10\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Learning rate finding\n",
    "    lr = self.optim.lr if isinstance(self.optim.lr, float) else self.optim.lr.lr\n",
    "    try:\n",
    "        lr_max = self.model.lr_find(\n",
    "            suggest_funcs = lr_funcs, \n",
    "            show_plot     = show_plot\n",
    "        )\n",
    "    except Exception as e:\n",
    "        self.mssg.print_error(\n",
    "            f\"fit_fastai | error | {lr_funcs}\"+\n",
    "            f\"lr | {lr} | {e}\" \n",
    "        )\n",
    "        raise \n",
    "    \n",
    "    # Training steps and pct_start\n",
    "    steps_per_epoch = len(dl_train)\n",
    "    training_steps = self.num_epochs * steps_per_epoch\n",
    "    warmup_steps = self.optim.lr.num_warmup_steps\n",
    "    pct_start = warmup_steps / training_steps\n",
    "    assert training_steps > 0, (\n",
    "        f\"Training steps must be greater than 0. Got: {training_steps}. \"\n",
    "        f\"Check if num_epochs={self.num_epochs} or steps_per_epoch={steps_per_epoch} is invalid.\"\n",
    "    )\n",
    "    assert 0 <= warmup_steps <= training_steps, (\n",
    "        f\"Warmup steps must be between 0 and the total training steps. \"\n",
    "        f\"Got: warmup_steps={warmup_steps}, training_steps={training_steps}.\"\n",
    "    )\n",
    "    assert 0 <= pct_start <= 1, (\n",
    "        f\"pct_start must be a valid percentage (0 <= pct_start <= 1). \"\n",
    "        f\"Calculated: pct_start={pct_start} with warmup_steps={warmup_steps} and training_steps={training_steps}.\"\n",
    "    )\n",
    "    # Calculate n_cycles and cycle_len if not provided\n",
    "    if cycle_len is None:\n",
    "        cycle_len = 1  # Default to 1 epoch per cycle\n",
    "    if n_cycles is None:\n",
    "        n_cycles = self.num_epochs // cycle_len\n",
    "\n",
    "    # Shared arguments\n",
    "    args = {\n",
    "        \"n_epoch\": self.num_epochs,\n",
    "        \"lr_max\": lr_max,\n",
    "        \"pct_start\": pct_start,\n",
    "        \"cbs\": cbs\n",
    "    }\n",
    "    # change to print (error just print red, debugging this part)\n",
    "    self.mssg.print_error(f\"{args}\")\n",
    "    # Choose learning rate scheduler\n",
    "    if (\n",
    "        isinstance(self.optim.lr, float) or \n",
    "        not self.optim.lr.flag\n",
    "    ):\n",
    "        self.model.fit_one_cycle(**args)\n",
    "    else:\n",
    "        self.model.opt = self.optim.optimizer\n",
    "        match self.optim.lr.name:\n",
    "            case \"OneCycleLr\":\n",
    "                self.model.fit_one_cycle(**args)\n",
    "            case \"FlatCosLR\":\n",
    "                self.model.fit_flat_cos(**args)\n",
    "            case \"SgdrLR\":\n",
    "                # Use calculated or provided n_cycles and cycle_len\n",
    "                self.model.fit_sgdr(\n",
    "                    n_cycles=n_cycles,\n",
    "                    cycle_len=cycle_len,\n",
    "                    lr_max=lr_max,\n",
    "                    cbs=cbs\n",
    "                )\n",
    "            case _:\n",
    "                self.model.fit(self.num_epochs)\n",
    "    self.mssg.final()\n",
    "    self.mssg.level -= 1\n",
    "Encoder.fit_fastai = fit_fastai    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94967aec-fa42-415a-8188-403d8fa53875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_mvp_single_(\n",
    "    self            : Encoder,\n",
    "    eval_pre        : bool  = False,\n",
    "    eval_post       : bool  = False,\n",
    "    shot            : bool  = False,\n",
    "    show_plot       : bool  = False,\n",
    "    sample_id       : int   = 0\n",
    "):\n",
    "    self.mssg.level+=1\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    #--- Setup object parameters ---\n",
    "    self.show_plot = self.show_plot if show_plot is None else show_plot\n",
    "    #--- Setup output values\n",
    "    # Time\n",
    "    t_shot = 0\n",
    "    t_eval_1 = 0\n",
    "    t_eval_2 = 0\n",
    "    # Training losses\n",
    "    losses = [],\n",
    "    # Callbacks\n",
    "    cbs = L()\n",
    "    if self.use_wandb: cbs = L(CustomWandbCallback(log_preds=False))\n",
    "    # Evaluation metrics & results\n",
    "    #metrics_dict = get_metrics_dict(self.metrics, self.metrics_names)\n",
    "    metrics_dict = self.metrics_dict #TODO: clean\n",
    "    eval_results_pre = {key: 0.0 for key in metrics_dict.keys()}\n",
    "    eval_results_post = {key: [] for key in metrics_dict.keys()}\n",
    "    # Computation device\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    \n",
    "    #### -------- Start -------####\n",
    "    if self.time_flag : timer = ut.Time(mssg = self.mssg)\n",
    "    # Split dataset and get the encoder input\n",
    "    X = self.get_splits_(sample_id)\n",
    "    self.mssg.print(\"About to set batch tfms\")\n",
    "    tfms = [ToFloat(), None]\n",
    "    batch_tfms = [\n",
    "        TSStandardize(\n",
    "            by_sample       = self.norm_by_sample, \n",
    "            use_single_batch= self.norm_use_single_batch\n",
    "        )\n",
    "    ]\n",
    "    # Get dataloaders\n",
    "    dls = get_ts_dls(\n",
    "        X           = X, \n",
    "        splits      = self.splits, \n",
    "        tfms        = tfms, \n",
    "        bs          = self.input.batch_size, \n",
    "        batch_tfms  = batch_tfms\n",
    "    )\n",
    "\n",
    "    if self.show_plot: \n",
    "        self.mssg.print(\"Show plot\")\n",
    "        display(dls.show_at(0))\n",
    "        sgc = ShowGraphCallback2()\n",
    "        self.model = ts_learner(\n",
    "            dls, \n",
    "            InceptionTimePlus,\n",
    "            cbs = cbs + sgc + MVP(\n",
    "                r           = self.optim.lr if isinstance(self.optim.lr, float) else self.optim.lr.lr,\n",
    "                window_size = X.shape[2]-1,\n",
    "                future_mask = self.mask_future,\n",
    "                target_dir  = './models',\n",
    "                sync        = self.mask_sync,\n",
    "                stateful    = self.mask_stateful,\n",
    "                fname       = f'encoder_MVP',\n",
    "            ),\n",
    "            y_range = [X.min(), X.max()]#,\n",
    "        )\n",
    "    else:\n",
    "        self.mssg.print(\"Don't show plot\")\n",
    "        self.model = ts_learner(\n",
    "            dls, \n",
    "            InceptionTimePlus,\n",
    "            cbs = cbs + mvp(\n",
    "                r           = self.optim.lr if ( isinstance(self.optim.lr, float) or isinstance(self.optim.lr, int)) else self.optim.lr.lr,\n",
    "                window_size = X.shape[2]-1,\n",
    "                future_mask = self.mask_future,\n",
    "                target_dir  = './models',\n",
    "                sync        = self.mask_sync,\n",
    "                stateful    = self.mask_stateful,\n",
    "                fname       = f'encoder_MVP',\n",
    "            ),\n",
    "            y_range = [X.min(), X.max()]\n",
    "        )\n",
    "    \n",
    "    self.model.to(device)\n",
    "    self.mssg.print(f\"Model Class {self.model.__class__} | Type: {type(self.model)}\")\n",
    "    \n",
    "    # Eval - pre \n",
    "    if eval_pre:\n",
    "        if self.time_flag: timer.start()\n",
    "        self.mssg.print(f\"Eval Pre | wlen {X.shape[2]} | Model: {self.model.__class__} | {type(self.model)} \")\n",
    "        self.mssg.print(f\"Model metrics: {self.model.metrics}\")\n",
    "        self.mssg.print(f\"metrics: {self.metrics}\")\n",
    "        # Get metrics\n",
    "        self.model.eval() # Evaluation mode\n",
    "        results = self.validate_with_metrics_()\n",
    "        # Format the results in json\n",
    "        eval_results_pre = validate_with_metrics_format_results(\n",
    "            results = results, \n",
    "            metrics = self.metrics, \n",
    "            metrics_names = self.metrics_names\n",
    "        )\n",
    "        self.mssg.print(f\"Eval results pre with custom metrics: {eval_results_pre}\")\n",
    "        # Compute time\n",
    "        if self.time_flag:\n",
    "            timer.end()\n",
    "            t_eval_1 = timer.duration()\n",
    "            timer.show(verbose = self.mssg.verbose)\n",
    "    # Train \n",
    "    if shot:\n",
    "        if self.time_flag: timer.start()\n",
    "        self.mssg.print(f\"Training the model | window size {X.shape[2]} | X ~ {X.shape}\")\n",
    "        # Train the model \n",
    "        self.model.train() #Training mode\n",
    "        # Train using the selected optimizer & scheduler\n",
    "        self.fit_fastai(dls, show_plot = show_plot)\n",
    "        losses = self.model.recorder.losses\n",
    "        # Compute time\n",
    "        if self.time_flag:\n",
    "            timer.end()\n",
    "            t_shot= timer.duration()\n",
    "            timer.show(verbose = self.mssg.verbose)\n",
    "    \n",
    "    # Eval - post\n",
    "    if eval_post:\n",
    "        if self.time_flag: timer.start()\n",
    "        self.mssg.print(f\"Eval Pre | wlen {X.shape[2]}\")\n",
    "        # Get metrics\n",
    "        self.model.eval() # Evaluation mode\n",
    "        results = self.validate_with_metrics_()\n",
    "        self.mssg.print(f\"Format results | results~{len(results)}\")\n",
    "        eval_results_post = validate_with_metrics_format_results(\n",
    "            results = results, metrics = self.metrics, metrics_names = self.metrics_names)\n",
    "        #self.model.validate()\n",
    "        self.mssg.print(f\"Eval results post with custom metrics: {eval_results_post}\")\n",
    "        if self.time_flag:\n",
    "            timer.end()\n",
    "            t_eval_2 = timer.duration()\n",
    "            timer.show(verbose = self.mssg.verbose)\n",
    "    self.mssg.final()\n",
    "    self.mssg.level += 1\n",
    "    return losses, eval_results_pre, eval_results_post, t_shot, t_eval_1, t_eval_2, self.model\n",
    "Encoder.fine_tune_mvp_single_ = fine_tune_mvp_single_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f1491-6a8b-41d7-b09f-b345ae0524ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_mvp_(\n",
    "    self                    : Encoder,\n",
    "    eval_pre                : bool  = True,\n",
    "    eval_post               : bool  = True,\n",
    "    shot                    : bool  = False,\n",
    "    time_flag               : bool  = None,\n",
    "    use_wandb               : bool  = None,\n",
    "    analysis_mode           : str   = None,\n",
    "    norm_by_sample          : bool  = None,\n",
    "    norm_use_single_batch   : bool  = None,\n",
    "    show_plot               : bool  = None\n",
    "):\n",
    "    self.mssg.initial_(\"fine_tune_mvp_\")\n",
    "    self.time_flag      = self.time_flag if time_flag is None else time_flag\n",
    "    self.use_wandb      = self.use_wandb if use_wandb is None else use_wandb\n",
    "    self.analysis_mode  = self.analysis_mode if analysis_mode is None else analysis_mode\n",
    "    self.norm_by_sample = self.norm_by_sample if norm_by_sample is None else norm_by_sample\n",
    "    self.norm_use_single_batch = self.norm_use_single_batch if norm_use_single_batch is None else norm_use_single_batch\n",
    "    # Return values\n",
    "    lossess             = []\n",
    "    eval_results_pre    = {} # Only 1 (before fine-tune)\n",
    "    eval_results_post   = {} # One per window size (after training)\n",
    "    t_shots             = []\n",
    "    t_shot              = 0\n",
    "    t_evals             = []\n",
    "    t_eval              = 0\n",
    "    \n",
    "    if self.input.size is None:\n",
    "        self.mssg.print(f\"Windows: {len(self.input._data)}\")\n",
    "        raise ValueError(f\"Invalid number of windows: {self.input.size}\")\n",
    "    self.mssg.print(f\"Processing {self.input.size} datasets: {self.input.shapes}\")\n",
    "    # Build optimizer\n",
    "    if self.optim.optimizer is None: \n",
    "        self.mssg.print(f\"Setting up optimizer as Adam\")\n",
    "        lr = self.optim.lr\n",
    "        if (not isinstance(self.optim.lr, float)): \n",
    "            lr = self.optim.lr.lr,\n",
    "       \n",
    "        self.optim.optimizer = Adam(\n",
    "            self.model.parameters(),\n",
    "            lr = lr,\n",
    "            mom = 0.0,\n",
    "            sqr_mom = 0.99,\n",
    "            eps = 1e-8,\n",
    "            wd = 0.01,\n",
    "            decouple_wd = True\n",
    "        )\n",
    "    self.mssg.print(f\"Optimizer: {self.optim.optimizer}\")\n",
    "    # Compute model for each window in the windowed dataset\n",
    "    for i in range(self.input.size):\n",
    "        self.mssg.print(f\"Processing wlen {self.input.shape[2]}\")\n",
    "        ( \n",
    "            losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, self.model\n",
    "        ) =  self.fine_tune_mvp_single_(eval_pre, eval_post, shot, sample_id = i, show_plot = show_plot)\n",
    "        lossess.append(losses)\n",
    "        if (eval_pre): eval_results_pre = eval_results_pre_\n",
    "        \n",
    "        if (eval_post): \n",
    "            if eval_results_post == {}: eval_results_post = {key:[] for key in eval_results_post_.keys()}\n",
    "            #self.mssg.print_error(f\"About to concat {eval_results_post_} to {eval_results_post}\")\n",
    "            for key in eval_results_post.keys():\n",
    "                eval_results_post[key] += eval_results_post_[key]\n",
    "            #self.mssg.print_error(f\"After concat: {eval_results_post}\")\n",
    "        t_shots.append(t_shot_)\n",
    "        if eval_pre: t_evals.append(t_eval_1)\n",
    "        if eval_post: t_evals.append(t_eval_2)\n",
    "        eval_pre = False\n",
    "    t_shot = sum(t_shots)\n",
    "    t_eval = sum(t_evals)\n",
    "    self.mssg.final(ut.funcname())\n",
    "    return lossess, eval_results_pre, eval_results_post, t_shots, t_shot, t_evals, t_eval, self.model\n",
    "\n",
    "Encoder.fine_tune_mvp_ = fine_tune_mvp_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc806e5c-f799-470a-a925-04de33240a05",
   "metadata": {},
   "source": [
    "### Moirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def configure_optimizer_moirai(\n",
    "    self                : Encoder, \n",
    "    dl_train            : DataLoader,\n",
    "    weight_decay        : float = 1e-2\n",
    "):\n",
    "    \"\"\"\n",
    "    Configures the optimizer for fine-tuning the Moirai model.\n",
    "\n",
    "    Args:\n",
    "        enc (Encoder): The encoder containing the Moirai model to optimize.\n",
    "        lr (float): Learning ratse.\n",
    "        beta1 (float): Beta1 hyperparameter for AdamW optimizer.\n",
    "        beta2 (float): Beta2 hyperparameter for AdamW optimizer.\n",
    "        weight_decay (float): Weight decay for AdamW optimizer.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with optimizer and learning rate scheduler configuration.\n",
    "    \"\"\"\n",
    "    self.mssg.level += 1\n",
    "    func = self.mssg.function\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    \n",
    "    if self.optim.optimizer is None:\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "\n",
    "        whitelist_params = (\n",
    "            nn.Linear, \n",
    "            uni2ts.module.ts_embed.MultiInSizeLinear, \n",
    "            uni2ts.module.ts_embed.MultiOutSizeLinear, \n",
    "            uni2ts.module.position.attn_projection.LearnedProjection\n",
    "        )\n",
    "        \n",
    "        blacklist_params = (\n",
    "            nn.LayerNorm, \n",
    "            nn.Embedding, \n",
    "            uni2ts.module.norm.RMSNorm, \n",
    "            uni2ts.module.position.attn_bias.BinaryAttentionBias, \n",
    "            uni2ts.module.position.additive.LearnedEmbedding\n",
    "        )\n",
    "\n",
    "        for mn, module in self.model.named_modules():\n",
    "            for pn, param in module.named_parameters():\n",
    "                if not param.requires_grad:\n",
    "                    continue\n",
    "                fpn = f\"{mn}.{pn}\" if mn else pn\n",
    "                if pn.endswith(\"bias\"):\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith(\"weight\") and isinstance(module, whitelist_params):\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith(\"weight\") and isinstance(module, blacklist_params):\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        param_dict = {pn: p for pn, p in self.model.named_parameters() if p.requires_grad}\n",
    "        optim_groups = [\n",
    "            {\n",
    "                \"params\": [param_dict[pn] for pn in sorted(list(decay))],\n",
    "                \"weight_decay\": weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [param_dict[pn] for pn in sorted(list(no_decay))],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=self.optim.lr.lr)\n",
    "    else: \n",
    "        self.mssg.print(\"Optimizer already configured.\")\n",
    "    try:\n",
    "        scheduler = None\n",
    "        if self.optim.lr.flag:\n",
    "            self.mssg.print(\"Get scheduler\")\n",
    "            steps_per_epoch     = len(dl_train)\n",
    "            scheduler = moirai_opt.get_scheduler(\n",
    "                #name = uni2ts.optim.lr_scheduler.SchedulerType[self.optim.lr.name.upper()],\n",
    "                name                        = self.optim.lr.name.lower(),\n",
    "                optimizer                   = optimizer,\n",
    "                num_warmup_steps            = self.optim.lr.num_warmup_steps,\n",
    "                num_training_steps          = self.num_epochs*steps_per_epoch,\n",
    "                scheduler_specific_kwargs   = self.scheduler_specific_kwargs\n",
    "            )\n",
    "    except Exception as e:\n",
    "        scheds = [ \"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"inverse_sqrt\", \"reduce_lr_on_plateau\"]\n",
    "        self.mssg.print_error(\n",
    "            f\"Please check that lr_scheduler_name is one of the following: {scheds}. Check https://github.com/SalesforceAIResearch/uni2ts/blob/main/src/uni2ts/optim/lr_scheduler.py for updates.\"\n",
    "        )\n",
    "        raise e\n",
    "\n",
    "    self.optim.optimizer = optimizer\n",
    "    self.optim.lr.scheduler = scheduler\n",
    "    self.mssg.final()\n",
    "    self.mssg.function = func\n",
    "    self.mssg.level -= 1\n",
    "Encoder.configure_optimizer_moirai = configure_optimizer_moirai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_enc_embs_moirai_(# Obtain the embeddings\n",
    "    self            : Encoder,\n",
    "    enc_input       : List [ List [ List [ float ] ] ],\n",
    "    patch_size      : int,\n",
    "    return_kwargs   : bool,\n",
    "    to_numpy        : bool = True\n",
    "):\n",
    "    return get_enc_embs_moirai(\n",
    "        enc_input       = enc_input,\n",
    "        enc_model       = self.model,\n",
    "        cpu             = self.cpu,\n",
    "        average_seq_dim = True,\n",
    "        verbose         = 3, #self.mssg.verbose-self.mssg.level+1,\n",
    "        to_numpy        = to_numpy,\n",
    "        patch_size      = patch_size,\n",
    "        time            = self.time_flag,\n",
    "        return_kwargs   = return_kwargs\n",
    "    )\n",
    "\n",
    "Encoder.get_enc_embs_moirai_ = get_enc_embs_moirai_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dist_moirai_(# \"Normal\" execution\n",
    "    self            : Encoder,\n",
    "    enc_input       : List [ List [ List [ float ] ] ],\n",
    "    patch_size      : int,\n",
    "    return_kwargs   : bool\n",
    "):\n",
    "    return get_dist_moirai(\n",
    "        enc_input       = enc_input,\n",
    "        enc_model       = self.model,\n",
    "        cpu             = self.cpu,\n",
    "        verbose         = self.mssg.verbose-self.mssg.level+1,\n",
    "        patch_size      = patch_size,\n",
    "        time            = self.time_flag,\n",
    "        return_kwargs   = return_kwargs\n",
    "    )\n",
    "\n",
    "Encoder.get_dist_moirai_ = get_dist_moirai_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moirai_eval_step_(\n",
    "    self        : Encoder, \n",
    "    enc_input   : List [ List [ List [ float ] ] ],\n",
    "    patch_size  : int\n",
    "):    \n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    with torch.no_grad():\n",
    "        embs, moirai_args = self.get_enc_embs_moirai_(enc_input, patch_size, True, False)\n",
    "\n",
    "        references = enc_input\n",
    "        mask = moirai_args['observed_mask']\n",
    "        self.mssg.print_error(f\"mask~{mask.shape}, embs~{embs.shape}, references~{references.shape}, data~{self.input.shape}\")\n",
    "        embs = embs * ~mask\n",
    "        references = references * ~mask \n",
    "        embs = embs.to(device)\n",
    "        references = references.to(device)\n",
    "        ## -- ver si hay que meter algun preprocesado de tamaños\n",
    "        for metric in self.metrics:\n",
    "            metric.add_batch(predictions = embs, references = references)\n",
    "    return self.metrics\n",
    "        \n",
    "Encoder.fine_tune_moirai_eval_step_ = fine_tune_moirai_eval_step_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moirai_eval_(\n",
    "    self    : Encoder,\n",
    "    dl_eval,\n",
    "    eval_results_dict,\n",
    "    patch_size = 8\n",
    "):    \n",
    "    # Select device\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    self.model.to(device)\n",
    "    num_evaluation_steps = len(dl_eval)\n",
    "    self.model.eval()\n",
    "    progress_bar = tqdm(range(num_evaluation_steps))\n",
    "    for batch in dl_eval:\n",
    "        batch = batch.to(device)\n",
    "        self.fine_tune_moirai_eval_step_(\n",
    "            enc_input   = batch,\n",
    "            patch_size  = patch_size\n",
    "        )\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "    for name in self.metrics_dict.keys():\n",
    "        metric                  = self.metrics[name]['metric']\n",
    "        args                    = self.metrics[name]['args']\n",
    "        eval_results_dict[name] = metric.compute(**args)\n",
    "    self.model.train()\n",
    "    return eval_results_dict\n",
    "\n",
    "Encoder.fine_tune_moirai_eval_ = fine_tune_moirai_eval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def fine_tune_moirai_train_loop_step_(\n",
    "    self        : Encoder,\n",
    "    enc_input   : List[ List [ List [ float ] ] ],\n",
    "    patch_size  : int \n",
    "):\n",
    "    loss = 0\n",
    "    #device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    #embs, moirai_args = self.get_enc_embs_moirai_(enc_input, patch_size, True)\n",
    "    #mask = moirai_args['observed_mask']\n",
    "    loss_func = uni2ts.loss.packed.distribution.PackedNLLLoss()\n",
    "    distr, args = get_dist_moirai_(enc_input, patch_size, True)\n",
    "    loss = loss_func(pred = distr,**args)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def fine_tune_moirai_train_(\n",
    "    self                : Encoder,\n",
    "    dl_train            : DataLoader\n",
    "): \n",
    "    func = self.mssg.function\n",
    "    self.mssg.level += 1\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    losses  = []\n",
    "    # Training loop\n",
    "    self.mssg.print(\"Training loop\")\n",
    "    # Mask\n",
    "    num_training_steps = self.num_epochs*len(dl_train)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    for epoch in range(self.num_epochs):\n",
    "        for i, batch in enumerate(dl_train):\n",
    "            self.mssg.print(f\"batch {i}~{batch.shape} | epoch {epoch} | train step {i+epoch} / {num_training_steps}\")\n",
    "            loss = fine_tune_moirai_train_loop_step_()\n",
    "            self.mssg.print(f\"batch {i}~{batch.shape} | epoch {epoch} | After train step {i+epoch} / {num_training_steps}\")\n",
    "            if hasattr(loss, 'item'):\n",
    "                losses.append(loss)\n",
    "            else: \n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "            self.optim.optimizer.zero_grad()\n",
    "            self.optim.optimizer.step()\n",
    "            if self.optim.lr.flag:\n",
    "                self.optim.lr.scheduler.step()\n",
    "            progress_bar.update(1)\n",
    "    progress_bar.close() \n",
    "    self.mssg.final()\n",
    "    self.mssg.function = func\n",
    "    self.mssg.level -= 1\n",
    "Encoder.fine_tune_moirai_train_ = fine_tune_moirai_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbf176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moirai_single_(\n",
    "    self            : Encoder,\n",
    "    eval_pre        : bool  = False,\n",
    "    eval_post       : bool  = False,\n",
    "    shot            : bool  = False,\n",
    "    show_plot       : bool  = False,\n",
    "    sample_id       : int   = 0,\n",
    "    patch_size      : int   = 8,\n",
    "    register_errors  : bool  = True\n",
    "):\n",
    "    self.mssg.level+=1\n",
    "    func = self.mssg.function\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    #--- Setup object parameters ---\n",
    "    self.show_plot = self.show_plot if show_plot is None else show_plot\n",
    "    #--- Setup output values\n",
    "    # Time\n",
    "    t_shot = 0\n",
    "    t_eval_1 = 0\n",
    "    t_eval_2 = 0\n",
    "    # Training losses\n",
    "    losses = [],\n",
    "    # Evaluation metrics & results\n",
    "    eval_results_pre = {k:[] for k in self.metrics_dict}\n",
    "    eval_results_post = {k:[] for k in self.metrics_dict}\n",
    "    # Computation device\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    \n",
    "    #### -------- Start -------####\n",
    "    if self.time_flag : timer = ut.Time(mssg = self.mssg)\n",
    "    self.model.to(device)\n",
    "    self.mssg.print(f\"Model Class {self.model.__class__} | Type: {type(self.model)}\")\n",
    "    # Get dataloaders\n",
    "    self.mssg.print(f\"fine_tune_moirai_single | Prepare the dataset | X ~ {self.input.data[sample_id].shape}\")\n",
    "    dl_eval, dl_train, ds_eval, ds_train = prepare_train_and_eval_dataloaders(\n",
    "        X                   = self.input.data[sample_id], \n",
    "        batch_size          = self.input.batch_size, \n",
    "        n_windows           = self.input.n_windows, \n",
    "        n_windows_percent   = self.input.n_windows_percent,\n",
    "        training_percent    = self.input.training_percent, \n",
    "        validation_percent  = self.input.validation_percent, \n",
    "        shot                = shot, \n",
    "        eval_pre            = eval_pre, \n",
    "        eval_post           = eval_post,\n",
    "        mssg                = deepcopy(self.mssg)\n",
    "    )\n",
    "    \n",
    "    # Setup optimizer\n",
    "    if self.optim.optimizer is None:\n",
    "        self.configure_optimizer_moirai(dl_train)\n",
    "    try:\n",
    "        ##-- Eval - Pre\n",
    "        if eval_pre:\n",
    "            self.mssg.print(f\"Eval Pre | wlen {self.input.data[sample_id].shape[2]}\")\n",
    "            if self.time_flag: timer.start()\n",
    "            eval_results_pre = self.fine_tune_moirai_eval_(dl_eval, eval_results_pre, patch_size)\n",
    "            if self.time_flag:\n",
    "                timer.end()\n",
    "                t_eval_1 = timer.duration()\n",
    "                timer.show(verbose = self.mssg.verbose)\n",
    "        ##-- Train\n",
    "        if shot:\n",
    "            if self.time_flag: timer.start()\n",
    "            self.mssg.print(f\"Train | wlen {self.input.data[sample_id].shape[2]}\")\n",
    "            losses, self.model = fine_tune_moirai_train_()\n",
    "            if self.time_flag: \n",
    "                timer.end()\n",
    "                t_shot = timer.duration()\n",
    "                timer.show(verbose = self.mssg.verbose)\n",
    "\n",
    "        ##-- Eval - Post\n",
    "        if eval_post:\n",
    "            self.mssg.print(f\"Eval Post | wlen {self.input.data[sample_id].shape[2]}\")\n",
    "            if self.time_flag: timer.start()\n",
    "            eval_results_post = self.fine_tune_moirai_eval_(dl_eval, eval_results_post, patch_size)\n",
    "            if self.time_flag:\n",
    "                timer.end()\n",
    "                t_eval_2 = timer.duration()\n",
    "                timer.show(verbose = self.mssg.verbose)\n",
    "    except Exception as e:\n",
    "        if register_errors:\n",
    "            self.mssg.print_error(\"Registering error in DataFrame\")\n",
    "            error = {\"window\": self.input.data[sample_id].shape[2], \"error\": e}\n",
    "            self.errors = pd.concat([self.errors, pd.DataFrame([error])])\n",
    "        else: \n",
    "            raise(e)\n",
    "    self.mssg.final()   \n",
    "    self.mssg.level += 1\n",
    "    self.mssg.function = func\n",
    "    return losses, eval_results_pre, eval_results_post, t_shot, t_eval_1, t_eval_2, self.model\n",
    "Encoder.fine_tune_moirai_single_ = fine_tune_moirai_single_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8172f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63b933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7eb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune_moirai_(\n",
    "    self      : Encoder, \n",
    "    eval_pre  : bool = False, \n",
    "    eval_post : bool = False, \n",
    "    shot      : bool = False,\n",
    "    time_flag : bool = None,\n",
    "    show_plot : bool = False,\n",
    "    register_errors : bool = False\n",
    "):  \n",
    "    self.mssg.initial(ut.funcname())\n",
    "    self.time_flag = self.time_flag if time_flag is None else time_flag\n",
    "    # Return values\n",
    "    lossess             = []\n",
    "    eval_results_pre    = {}\n",
    "    eval_results_post   = {}\n",
    "    t_shots             = []\n",
    "    t_shot              = 0\n",
    "    t_evals             = []\n",
    "    t_eval              = 0\n",
    "    \n",
    "    # Computation device\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    \n",
    "    # Metrics\n",
    "    if self.metrics is None:\n",
    "        self.metrics        = [ EvalMAE ]\n",
    "        self.metrics_names  = ['mae']\n",
    "        self.metrics_args   = [{'squared':False}]\n",
    "        self.metrics_dict   = {\n",
    "            'mae': {\n",
    "                'metric': self.metrics[0], \n",
    "                'args'  : self.metrics_args[0]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    ### ----- Start ----\n",
    "    if self.input.size is None:\n",
    "        self.mssg.print(f\"Windows: {len(self.input._data)}\")\n",
    "        raise ValueError(f\"Invalid number of windows: {self.input.size}\")\n",
    "\n",
    "    self.mssg.print(f\"Processing {self.input.size} datasets : {self.input.shape}\")\n",
    "\n",
    "    self.model.to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range (self.input.size):\n",
    "        self.mssg.print(f\"Processing wlen {self.input.shape[2]}\")\n",
    "        ( \n",
    "            losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, self.model\n",
    "        ) =  self.fine_tune_moirai_single_(eval_pre, eval_post, shot, sample_id = i, show_plot = show_plot, register_errors = register_errors)\n",
    "    \n",
    "        lossess.append(losses)\n",
    "        if (eval_pre): eval_results_pre = eval_results_pre_\n",
    "        \n",
    "        if (eval_post): \n",
    "            if eval_results_post == {}: eval_results_post = {key:[] for key in eval_results_post_.keys()}\n",
    "            #self.mssg.print_error(f\"About to concat {eval_results_post_} to {eval_results_post}\")\n",
    "            for key in eval_results_post.keys():\n",
    "                eval_results_post[key] += eval_results_post_[key]\n",
    "            #self.mssg.print_error(f\"After concat: {eval_results_post}\")\n",
    "        t_shots.append(t_shot_)\n",
    "        if eval_pre: t_evals.append(t_eval_1)\n",
    "        if eval_post: t_evals.append(t_eval_2)\n",
    "        eval_pre = False\n",
    "    t_shot = sum(t_shots)\n",
    "    t_eval = sum(t_evals)\n",
    "    self.mssg.final(ut.funcname())\n",
    "\n",
    "    if register_errors: \n",
    "        return losses, eval_results_pre, eval_results_post, t_shots, t_shot, t_evals, t_eval, self.model, self.errors\n",
    "    return lossess, eval_results_pre, eval_results_post, t_shots, t_shot, t_evals, t_eval, self.model\n",
    "\n",
    "Encoder.fine_tune_moirai_ = fine_tune_moirai_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7756b3e-a227-4790-bd1a-5f9c21ce0880",
   "metadata": {},
   "source": [
    "### Global method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fc4c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fine_tune(\n",
    "    # Optional parameters\n",
    "    ## Encoder Input\n",
    "    ## -- Using all parammeters\n",
    "    X                               : Optional [ Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ] ],\n",
    "    stride                          : Optional [ int ]              = None,\n",
    "    batch_size                      : Optional [ int ]              = None,\n",
    "    n_windows                       : Optional [ int ]              = None,\n",
    "    n_windows_percent               : Optional [ float ]            = None,\n",
    "    validation_percent              : Optional [ float ]            = None, \n",
    "    training_percent                : Optional [ float ]            = None,\n",
    "    window_mask_percent             : Optional [ float ]            = None,\n",
    "    window_sizes                    : Optional [ List [int] ]       = None,\n",
    "    n_window_sizes                  : Optional [ int ]              = 1,\n",
    "    window_sizes_offset             : Optional [ int ]              = 0.05,\n",
    "    windows_min_distance            : Optional [ int ]              = 1,\n",
    "    full_dataset                    : Optional [ bool ]             = False,\n",
    "    ##-- Given by Type  \n",
    "    enc_input                       : Optional [ EncoderInput ]     = None,\n",
    "    # Optimizer\n",
    "    optim                           : Optional [ EncoderOptimizer ] = None,\n",
    "    ## -- Using all parameters\n",
    "    criterion                       : Optional [ _Loss ]            = torch.nn.MSELoss, \n",
    "    optimizer                                                       = None, \n",
    "    lr                              : Optional [ float ]            = 5e-5, #1e-4, \n",
    "    lr_scheduler_flag               : Optional [ bool ]             = False, \n",
    "    lr_scheduler_name               : Optional [ str ]              = \"linear\",\n",
    "    lr_scheduler_num_warmup_steps   : Optional [ int ]              = None,\n",
    "    # Mssg\n",
    "    ## -- Using all parameters\n",
    "    verbose                         : Optional[ int ]               = 0, \n",
    "    print_to_path                   : Optional[ bool ]              = False,\n",
    "    print_path                      : Optional[ str ]               = \"~/data/logs/logs.txt\",\n",
    "    print_mode                      : Optional[ str ]               = 'a',\n",
    "    ## -- Using Type\n",
    "    mssg                            : Optional [ ut.Mssg ]          = None,\n",
    "    ## Encoder \n",
    "    enc                             : Optional [ Encoder ]          = None,\n",
    "    ## -- Using all parameters\n",
    "    num_epochs                      : Optional [ int]               = 3,\n",
    "    enc_learn                       : Optional [Learner]            = None, \n",
    "    cpu                             : Optional [ bool ]             = False,\n",
    "    to_numpy                        : Optional [ bool ]             = True,\n",
    "    #- Only for moment\n",
    "    use_moment_masks                : Optional [ bool ]             = False,\n",
    "    #- Masking options\n",
    "    mask_stateful                   : Optional [ bool ]             = False,\n",
    "    mask_future                     : Optional [ bool ]             = False,\n",
    "    mask_sync                       : Optional [ bool ]             = False,\n",
    "    # Non-Optional parameters\n",
    "    time_flag                       : bool                          = False,\n",
    "    shot                            : bool                          = True, \n",
    "    eval_pre                        : bool                          = True, \n",
    "    eval_post                       : bool                          = True,\n",
    "    use_wandb                       : bool                          = None,\n",
    "    analysis_mode                   : str                           = None,\n",
    "    norm_by_sample                  : bool                          = None,\n",
    "    norm_use_single_batch           : bool                          = None,\n",
    "    show_plot                       : bool                          = False,\n",
    "    # Optional metrics\n",
    "    metrics                                                         = None,\n",
    "    metrics_names                   : List [ str ]                  = None,\n",
    "    metrics_args                    : List [ AttrDict ]             = None,\n",
    "    metrics_dict                    : AttrDict                      = None,\n",
    "    scheduler_specific_kwargs       : AttrDict                      = None,\n",
    "    register_errors                 : bool                          = True\n",
    "): \n",
    "    enc = _get_encoder(\n",
    "        X                               = X,\n",
    "        stride                          = stride,\n",
    "        batch_size                      = batch_size,\n",
    "        n_windows                       = n_windows,\n",
    "        n_windows_percent               = n_windows_percent,\n",
    "        validation_percent              = validation_percent,\n",
    "        training_percent                = training_percent,\n",
    "        window_mask_percent             = window_mask_percent,\n",
    "        window_sizes                    = window_sizes,\n",
    "        n_window_sizes                  = n_window_sizes,\n",
    "        window_sizes_offset             = window_sizes_offset,\n",
    "        windows_min_distance            = windows_min_distance,\n",
    "        full_dataset                    = full_dataset,\n",
    "        enc_input                       = enc_input,\n",
    "        optim                           = optim,\n",
    "        criterion                       = criterion,\n",
    "        optimizer                       = optimizer,\n",
    "        lr                              = lr,\n",
    "        lr_scheduler_flag               = lr_scheduler_flag,\n",
    "        lr_scheduler_name               = lr_scheduler_name,\n",
    "        lr_scheduler_num_warmup_steps   = lr_scheduler_num_warmup_steps,\n",
    "        verbose                         = verbose,\n",
    "        print_to_path                   = print_to_path,\n",
    "        print_path                      = print_path,\n",
    "        print_mode                      = print_mode,\n",
    "        mssg                            = mssg,\n",
    "        enc                             = enc,\n",
    "        num_epochs                      = num_epochs,\n",
    "        enc_learn                       = enc_learn,\n",
    "        cpu                             = cpu,\n",
    "        to_numpy                        = to_numpy,\n",
    "        mask_stateful                   = mask_stateful,\n",
    "        mask_future                     = mask_future,\n",
    "        mask_sync                       = mask_sync,\n",
    "        metrics                         = metrics,\n",
    "        metrics_names                   = metrics_names,\n",
    "        metrics_args                    = metrics_args,\n",
    "        metrics_dict                    = metrics_dict,\n",
    "        scheduler_specific_kwargs       = scheduler_specific_kwargs\n",
    "    )\n",
    "    enc.mssg.initial_(\"fine_tune\")\n",
    "    enc.mssg.print(f\"Original enc_learn { enc_learn }  | Final model { enc.model }\")\n",
    "    enc.set_fine_tune_()\n",
    "    match enc.fine_tune_.__name__:\n",
    "        case \"fine_tune_moment_\":\n",
    "            enc.mssg.print(\"Use fine_tune_moment parameters\")\n",
    "            result = enc.fine_tune_(\n",
    "                eval_pre, eval_post, shot, time_flag, use_moment_masks, register_errors\n",
    "            )\n",
    "        case \"fine_tune_mvp_\":\n",
    "            enc.mssg.print(\"Use fine_tune_mvp parameters\")\n",
    "            result = enc.fine_tune_(eval_pre, eval_post, shot, time_flag, use_wandb = use_wandb, analysis_mode = analysis_mode, norm_by_sample = norm_by_sample, norm_use_single_batch = norm_use_single_batch, show_plot = show_plot)\n",
    "        case _:\n",
    "            enc.mssg.print(\"Use generic fine_tune parameters\")\n",
    "            result = enc.fine_tune_(eval_pre = eval_pre, eval_post = eval_post, shot = shot, time_flag = time_flag)\n",
    "    enc.mssg.final()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0b3a8-62ee-4009-bc18-7080a61c21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
