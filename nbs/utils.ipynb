{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utilities used in the rest of the notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dvats.imports import *\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random time series dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_TS_df(rows, cols):\n",
    "    \"Generates a dataframe containing a multivariate time series, where each column \\\n",
    "    represents a variable and each row a time point (sample). The timestamp is in the \\\n",
    "    index of the dataframe, and it is created with a even space of 1 second between samples\"\n",
    "    index = np.arange(pd.Timestamp.now(),\n",
    "                      pd.Timestamp.now() + pd.Timedelta(rows-1, 'seconds'),\n",
    "                      pd.Timedelta(1, 'seconds'))\n",
    "    data = np.random.randn(len(index), cols)\n",
    "    return pd.DataFrame(data, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df = generate_TS_df(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(df.shape, (3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  pandas Dataframe utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize_columns(df:pd.DataFrame):\n",
    "    \"Normalize columns from `df` to have 0 mean and 1 standard deviation\"\n",
    "    mean = df.mean()\n",
    "    std = df.std() + 1e-7\n",
    "    return (df-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = generate_TS_df(3, 3)\n",
    "foo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "bar = normalize_columns(foo)\n",
    "bar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_close(bar.describe().loc['mean'].values, np.repeat(0.0, len(bar.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_close(bar.describe().loc['std'].values, np.repeat(1.0, len(bar.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_constant_columns(df:pd.DataFrame):\n",
    "    return df.loc[:, (df != df.iloc[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = generate_TS_df(3, 3)\n",
    "foo['constant'] = [0.0]*len(foo)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "bar = remove_constant_columns(foo)\n",
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "column_diff = set(foo.columns) - set(bar.columns)\n",
    "test_eq_type(column_diff, set(['constant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create wandb artifact containing just the reference to an object pass as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReferenceArtifact(wandb.Artifact):\n",
    "    default_storage_path = Path('data/wandb_artifacts/') # * this path is relative to Path.home()\n",
    "    \"This class is meant to create an artifact with a single reference to an object \\\n",
    "    passed as argument in the contructor. The object will be pickled, hashed and stored \\\n",
    "    in a specified folder.\"\n",
    "    @delegates(wandb.Artifact.__init__)\n",
    "    def __init__(self, obj, name, type='object', folder=None, **kwargs):\n",
    "        super().__init__(type=type, name=name, **kwargs)\n",
    "        # pickle dumps the object and then hash it\n",
    "        hash_code = str(hash(pickle.dumps(obj)))\n",
    "        folder = Path(ifnone(folder, Path.home()/self.default_storage_path))\n",
    "        with open(f'{folder}/{hash_code}', 'wb') as f:\n",
    "            pickle.dump(obj, f)\n",
    "        self.add_reference(f'file://{folder}/{hash_code}')\n",
    "        if self.metadata is None:\n",
    "            self.metadata = dict()\n",
    "        self.metadata['ref'] = dict()\n",
    "        self.metadata['ref']['hash'] = hash_code\n",
    "        self.metadata['ref']['type'] = str(obj.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = np.arange(10)\n",
    "bar = ReferenceArtifact(obj=foo, name='foo', folder='.')\n",
    "bar_path = Path(f'./{bar.metadata[\"ref\"][\"hash\"]}')\n",
    "test_eq(bar_path.exists(), True)\n",
    "test_eq(bar.metadata['ref']['type'], \"<class 'numpy.ndarray'>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a reference artifact is used by one wandb run, we should have a method to get the original object from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_obj(self:wandb.apis.public.Artifact):\n",
    "    \"\"\"Download the files of a saved ReferenceArtifact and get the referenced object. The artifact must \\\n",
    "    come from a call to `run.use_artifact` with a proper wandb run.\"\"\"\n",
    "    if self.metadata.get('ref') is None:\n",
    "        print(f'ERROR:{self} does not come from a saved ReferenceArtifact')\n",
    "        return None\n",
    "    original_path = ReferenceArtifact.default_storage_path/self.metadata['ref']['hash']\n",
    "    path = original_path if original_path.exists() else Path(self.download()).ls()[0]\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Reference artifact from a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = generate_TS_df(3, 3)\n",
    "bar = ReferenceArtifact(obj=foo, name='test_reference_artifact')\n",
    "bar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(bar.name, 'test_reference_artifact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(bar.metadata['ref']['type'], str(type(foo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Test method `to_obj`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReferenceArtifact with a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = np.random.randn(5)\n",
    "bar = ReferenceArtifact(obj=foo, name='test_reference_artifact')\n",
    "bar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(bar.metadata['ref']['type'], str(type(foo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def export_and_get(self:Learner, keep_exported_file=False):\n",
    "    \"\"\"\n",
    "        Export the learner into an auxiliary file, load it and return it back.\n",
    "    \"\"\"\n",
    "    aux_path = Path('aux.pkl')\n",
    "    self.export(fname='aux.pkl')\n",
    "    aux_learn = load_learner('aux.pkl')\n",
    "    if not keep_exported_file: aux_path.unlink()\n",
    "    return aux_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_wandb_artifacts(project_path, type=None, name=None, last_version=True):\n",
    "    \"\"\"\n",
    "        Get the artifacts logged in a wandb project.\n",
    "        Input:\n",
    "        - `project_path` (str): entity/project_name\n",
    "        - `type` (str): whether to return only one type of artifacts\n",
    "        - `name` (str): Leave none to have all artifact names\n",
    "        - `last_version`: whether to return only the last version of each artifact or not\n",
    "\n",
    "        Output: List of artifacts\n",
    "    \"\"\"\n",
    "    public_api = wandb.Api()\n",
    "    if type is not None:\n",
    "        types = [public_api.artifact_type(type, project_path)]\n",
    "    else:\n",
    "        types = public_api.artifact_types(project_path)\n",
    "\n",
    "    res = L()\n",
    "    for kind in types:\n",
    "        for collection in kind.collections():\n",
    "            if name is None or name == collection.name:\n",
    "                versions = public_api.artifact_versions(\n",
    "                    kind.type,\n",
    "                    \"/\".join([kind.entity, kind.project, collection.name]),\n",
    "                    per_page=1,\n",
    "                )\n",
    "                if last_version: res += next(versions)\n",
    "                else: res += L(versions)\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_wandb_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = get_wandb_artifacts('wandb/artifacts-example', type='model')\n",
    "test_eq(len(foo), 2)\n",
    "foo = get_wandb_artifacts('wandb/artifacts-example', type='model', name='convnet')\n",
    "test_eq(len(foo), 1)\n",
    "foo = get_wandb_artifacts('wandb/artifacts-example', type='model', name='convnet', last_version=False)\n",
    "test_eq(len(foo), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_pickle_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_pickle_artifact(filename):\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exec from feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pyarrow.feather as ft\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exec_with_feather(function, path = None, print_flag = False, *args, **kwargs):\n",
    "    result = None\n",
    "    if not (path is none):\n",
    "        if print_flag: print(\"--> Exec with feather | reading input from \", path)\n",
    "        input = ft.read_feather(path)\n",
    "        if print_flag: print(\"--> Exec with feather | Apply function \", path)\n",
    "        result = function(input, *args, **kwargs)\n",
    "        if print_flag: print(\"Exec with feather --> \", path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def py_function(module_name, function_name, print_flag = False):\n",
    "    try:\n",
    "        function = getattr(__import__('__main__'), function_name)\n",
    "    except:\n",
    "        module = __import__(module_name, fromlist=[''])\n",
    "        function = getattr(module, function_name)\n",
    "    print(\"py function: \", function_name, \": \", function)\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def suma(a,b,c): return a+b+c\n",
    "foo = py_function(\"main\", \"suma\", True)\n",
    "print(foo(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "function_name = \"prepare_forecasting_data\"\n",
    "module_name = \"tsai.data.preparation\"\n",
    "foo = py_function(module_name, function_name, True)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "def exec_with_feather_k_output(function_name, module_name = \"main\", path = None, k_output = 0, print_flag = False, time_flag = False, *args, **kwargs):\n",
    "    result = None\n",
    "    function = py_function(module_name, function_name, print_flag)\n",
    "    if time_flag: t_start = time.time()\n",
    "    if not (path is None):\n",
    "        if print_flag: print(\"--> Exec with feather | reading input from \", path)\n",
    "        input = ft.read_feather(path)\n",
    "        if print_flag: print(\"--> Exec with feather | Apply function \", path)\n",
    "        result = function(input, *args, **kwargs)[k_output]\n",
    "    if time_flag:\n",
    "        t_end = time.time()\n",
    "        print(\"Exec with feather | time: \", t_end-t_start)\n",
    "    if print_flag: print(\"Exec with feather --> \", path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "enc_input = exec_with_feather_k_output(\n",
    "            function_name = \"prepare_forecasting_data\",\n",
    "            module_name   = \"tsai.data.preparation\",\n",
    "            path = \"/home/macu/data/wandb_artifacts/-2535364569820284064\",\n",
    "            k_output = 0,\n",
    "            print_flag = True,\n",
    "            time_flag = True,\n",
    "            fcst_history = 450\n",
    "        )\n",
    "enc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exec_with_and_feather_k_output(function_name, module_name = \"main\", path_input = None, path_output = None, k_output = 0, print_flag = False, time_flag = False, *args, **kwargs):\n",
    "    result = None\n",
    "    function = py_function(module_name, function_name, print_flag)\n",
    "    if time_flag: t_start = time.time()\n",
    "    if not (path_input is None):\n",
    "        if print_flag: print(\"--> Exec with feather | reading input from \", path_input)\n",
    "        input = ft.read_feather(path_input)\n",
    "        if print_flag: \n",
    "            print(\"--> Exec with feather | Apply function \", function_name, \"input type: \", type(input))\n",
    "        \n",
    "        result = function(input, *args, **kwargs)[k_output]\n",
    "        ft.write_feather(df, path, compression = 'lz4')\n",
    "    if time_flag:\n",
    "        t_end = time.time()\n",
    "        print(\"Exec with feather | time: \", t_end-t_start)\n",
    "    if print_flag: print(\"Exec with feather --> \", path_output)\n",
    "    return path_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSCode update path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Function for making notebooks clearer\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "    print(\"... Enabling Vs Code execution ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#from nbdev.export import notebook2script\n",
    "#notebook2script()\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastai Learner utilities\n",
    "Utils for obtaining information from fastai Learner objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submodules summary\n",
    "```learner_module_leave``` takes a fastai Learner ```learner`` abd returns a pandas dataframe with the following information from the leave modules: \n",
    "* Modules tree\n",
    "* Leave modules type (convolutional, batchnorm, etc.)\n",
    "* Leave module name\n",
    "* Module call with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def learner_module_leaves(learner):\n",
    "    modules = list(learner.modules())[0]  # Obtener el módulo raíz\n",
    "    rows = []\n",
    "\n",
    "    def find_leave_modules(module, path=[]):\n",
    "        for name, sub_module in module.named_children():\n",
    "            current_path = path + [f\"{type(sub_module).__name__}\"]\n",
    "            if not list(sub_module.children()):\n",
    "                leave_name = ' -> '.join(current_path)\n",
    "                leave_params = str(sub_module).strip()  \n",
    "                rows.append([\n",
    "                    leave_name,\n",
    "                    f\"{type(sub_module).__name__}\",\n",
    "                    name,\n",
    "                    leave_params\n",
    "                ]\n",
    "                )\n",
    "\n",
    "            find_leave_modules(sub_module, current_path)\n",
    "\n",
    "    find_leave_modules(modules)\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns=['Path', 'Module_type', 'Module_name', 'Module'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "wandb_api = wandb.Api()\n",
    "foo = wandb_api.artifact('deepvats/mvp-SWV:latest').to_obj()\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "learner_module_leaves(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table can be read as two as follow for clearer information: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def learner_module_leaves_subtables(learner, print_flag = False):\n",
    "    df = pd.DataFrame(columns=['Path', 'Module_type', 'Module_name', 'Module'])\n",
    "    md = learner_module_leaves(learner).drop(\n",
    "            'Path', axis = 1\n",
    "        ).sort_values(\n",
    "            by = 'Module_type'\n",
    "        )\n",
    "    if print_flag: print(\"The layers are of this types:\")\n",
    "\n",
    "    md_types = pd.DataFrame(md['Module_type'].drop_duplicates())\n",
    "    if print_flag: \n",
    "        display(md_types)\n",
    "        print(\"And they are called with this parameters:\")\n",
    "    \n",
    "    md_modules = pd.DataFrame(md['Module'].drop_duplicates())\n",
    "    \n",
    "    if print_flag: display(md_modules)\n",
    "    \n",
    "    return md_types, md_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "_, _ = learner_module_leaves_subtables(foo, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "beep(1)\n",
    "beep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
