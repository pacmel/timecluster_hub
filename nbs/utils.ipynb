{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utilities used in the rest of the notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dvats.imports import *\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random time series dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_TS_df(rows, cols):\n",
    "    \"Generates a dataframe containing a multivariate time series, where each column \\\n",
    "    represents a variable and each row a time point (sample). The timestamp is in the \\\n",
    "    index of the dataframe, and it is created with a even space of 1 second between samples\"\n",
    "    index = np.arange(pd.Timestamp.now(),\n",
    "                      pd.Timestamp.now() + pd.Timedelta(rows-1, 'seconds'),\n",
    "                      pd.Timedelta(1, 'seconds'))\n",
    "    data = np.random.randn(len(index), cols)\n",
    "    return pd.DataFrame(data, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df = generate_TS_df(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(df.shape, (3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  pandas Dataframe utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize_columns(df:pd.DataFrame):\n",
    "    \"Normalize columns from `df` to have 0 mean and 1 standard deviation\"\n",
    "    mean = df.mean()\n",
    "    std = df.std() + 1e-7\n",
    "    return (df-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.087042</td>\n",
       "      <td>-0.465471</td>\n",
       "      <td>0.282115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.309326</td>\n",
       "      <td>1.190770</td>\n",
       "      <td>1.679598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.435910</td>\n",
       "      <td>-1.772797</td>\n",
       "      <td>-1.656772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.207427</td>\n",
       "      <td>-0.976768</td>\n",
       "      <td>-0.222520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.021057</td>\n",
       "      <td>-0.180739</td>\n",
       "      <td>1.211731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.087393</td>\n",
       "      <td>0.188191</td>\n",
       "      <td>1.251559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.153729</td>\n",
       "      <td>0.557121</td>\n",
       "      <td>1.291386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2\n",
       "count  3.000000  3.000000  3.000000\n",
       "mean  -0.087042 -0.465471  0.282115\n",
       "std    0.309326  1.190770  1.679598\n",
       "min   -0.435910 -1.772797 -1.656772\n",
       "25%   -0.207427 -0.976768 -0.222520\n",
       "50%    0.021057 -0.180739  1.211731\n",
       "75%    0.087393  0.188191  1.251559\n",
       "max    0.153729  0.557121  1.291386"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "foo = generate_TS_df(3, 3)\n",
    "foo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.127835</td>\n",
       "      <td>-1.097882</td>\n",
       "      <td>-1.154376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.389185</td>\n",
       "      <td>-0.429383</td>\n",
       "      <td>-0.300450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.349466</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.553476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.563918</td>\n",
       "      <td>0.548941</td>\n",
       "      <td>0.577188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.778370</td>\n",
       "      <td>0.858766</td>\n",
       "      <td>0.600900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2\n",
       "count  3.000000  3.000000  3.000000\n",
       "mean   0.000000  0.000000  0.000000\n",
       "std    1.000000  1.000000  1.000000\n",
       "min   -1.127835 -1.097882 -1.154376\n",
       "25%   -0.389185 -0.429383 -0.300450\n",
       "50%    0.349466  0.239116  0.553476\n",
       "75%    0.563918  0.548941  0.577188\n",
       "max    0.778370  0.858766  0.600900"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "bar = normalize_columns(foo)\n",
    "bar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_close(bar.describe().loc['mean'].values, np.repeat(0.0, len(bar.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_close(bar.describe().loc['std'].values, np.repeat(1.0, len(bar.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_constant_columns(df:pd.DataFrame):\n",
    "    return df.loc[:, (df != df.iloc[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-22 13:49:04.883534</th>\n",
       "      <td>1.907457</td>\n",
       "      <td>0.827376</td>\n",
       "      <td>-0.531644</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22 13:49:05.883534</th>\n",
       "      <td>-0.097507</td>\n",
       "      <td>-1.992590</td>\n",
       "      <td>-0.396741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22 13:49:06.883534</th>\n",
       "      <td>0.654543</td>\n",
       "      <td>-0.939969</td>\n",
       "      <td>1.752050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0         1         2  constant\n",
       "2024-07-22 13:49:04.883534  1.907457  0.827376 -0.531644       0.0\n",
       "2024-07-22 13:49:05.883534 -0.097507 -1.992590 -0.396741       0.0\n",
       "2024-07-22 13:49:06.883534  0.654543 -0.939969  1.752050       0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "foo = generate_TS_df(3, 3)\n",
    "foo['constant'] = [0.0]*len(foo)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-22 13:49:04.883534</th>\n",
       "      <td>1.907457</td>\n",
       "      <td>0.827376</td>\n",
       "      <td>-0.531644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22 13:49:05.883534</th>\n",
       "      <td>-0.097507</td>\n",
       "      <td>-1.992590</td>\n",
       "      <td>-0.396741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22 13:49:06.883534</th>\n",
       "      <td>0.654543</td>\n",
       "      <td>-0.939969</td>\n",
       "      <td>1.752050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0         1         2\n",
       "2024-07-22 13:49:04.883534  1.907457  0.827376 -0.531644\n",
       "2024-07-22 13:49:05.883534 -0.097507 -1.992590 -0.396741\n",
       "2024-07-22 13:49:06.883534  0.654543 -0.939969  1.752050"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "bar = remove_constant_columns(foo)\n",
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "column_diff = set(foo.columns) - set(bar.columns)\n",
    "test_eq_type(column_diff, set(['constant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create wandb artifact containing just the reference to an object pass as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReferenceArtifact(wandb.Artifact):\n",
    "    default_storage_path = Path('data/wandb_artifacts/') # * this path is relative to Path.home()\n",
    "    \"This class is meant to create an artifact with a single reference to an object \\\n",
    "    passed as argument in the contructor. The object will be pickled, hashed and stored \\\n",
    "    in a specified folder.\"\n",
    "    @delegates(wandb.Artifact.__init__)\n",
    "    def __init__(self, obj, name, type='object', folder=None, **kwargs):\n",
    "        super().__init__(type=type, name=name, **kwargs)\n",
    "        # pickle dumps the object and then hash it\n",
    "        hash_code = str(hash(pickle.dumps(obj)))\n",
    "        folder = Path(ifnone(folder, Path.home()/self.default_storage_path))\n",
    "        with open(f'{folder}/{hash_code}', 'wb') as f:\n",
    "            pickle.dump(obj, f)\n",
    "        self.add_reference(f'file://{folder}/{hash_code}')\n",
    "        if self.metadata is None:\n",
    "            self.metadata = dict()\n",
    "        self.metadata['ref'] = dict()\n",
    "        self.metadata['ref']['hash'] = hash_code\n",
    "        self.metadata['ref']['type'] = str(obj.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Path \"file://./8416933980043224972\" must be a valid file or directory path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m foo \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m bar \u001b[38;5;241m=\u001b[39m \u001b[43mReferenceArtifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfoo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfoo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m bar_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbar\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_eq(bar_path\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mReferenceArtifact.__init__\u001b[0;34m(self, obj, name, type, folder, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(obj, f)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhash_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:479\u001b[0m, in \u001b[0;36mArtifact.add_reference\u001b[0;34m(self, uri, name, checksum, max_objects)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url\u001b[38;5;241m.\u001b[39mscheme:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReferences must be URIs. To reference a local file, use file://\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m     )\n\u001b[0;32m--> 479\u001b[0m manifest_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mURIStr\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m manifest_entries:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manifest\u001b[38;5;241m.\u001b[39madd_entry(entry)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:901\u001b[0m, in \u001b[0;36mWandbStoragePolicy.store_reference\u001b[0;34m(self, artifact, path, name, checksum, max_objects)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore_reference\u001b[39m(\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     artifact: ArtifactInterface,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     max_objects: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[ArtifactManifestEntry]:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_objects\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:1140\u001b[0m, in \u001b[0;36mMultiHandler.store_path\u001b[0;34m(self, artifact, path, name, checksum, max_objects)\u001b[0m\n\u001b[1;32m   1138\u001b[0m handler: StorageHandler\n\u001b[1;32m   1139\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handlers[url\u001b[38;5;241m.\u001b[39mscheme]\n\u001b[0;32m-> 1140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_objects\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py:1318\u001b[0m, in \u001b[0;36mLocalFileHandler.store_path\u001b[0;34m(self, artifact, path, name, checksum, max_objects)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     entries\u001b[38;5;241m.\u001b[39mappend(entry)\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;66;03m# TODO: update error message if we don't allow directories.\u001b[39;00m\n\u001b[0;32m-> 1318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m must be a valid file or directory path\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m path)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m entries\n",
      "\u001b[0;31mValueError\u001b[0m: Path \"file://./8416933980043224972\" must be a valid file or directory path"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "foo = np.arange(10)\n",
    "bar = ReferenceArtifact(obj=foo, name='foo', folder='.')\n",
    "bar_path = Path(f'./{bar.metadata[\"ref\"][\"hash\"]}')\n",
    "test_eq(bar_path.exists(), True)\n",
    "test_eq(bar.metadata['ref']['type'], \"<class 'numpy.ndarray'>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a reference artifact is used by one wandb run, we should have a method to get the original object from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def to_obj(self:wandb.apis.public.Artifact):\n",
    "    \"\"\"Download the files of a saved ReferenceArtifact and get the referenced object. The artifact must \\\n",
    "    come from a call to `run.use_artifact` with a proper wandb run.\"\"\"\n",
    "    if self.metadata.get('ref') is None:\n",
    "        print(f'ERROR:{self} does not come from a saved ReferenceArtifact')\n",
    "        return None\n",
    "    original_path = ReferenceArtifact.default_storage_path/self.metadata['ref']['hash']\n",
    "    path = original_path if original_path.exists() else Path(self.download()).ls()[0]\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Reference artifact from a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = generate_TS_df(3, 3)\n",
    "bar = ReferenceArtifact(obj=foo, name='test_reference_artifact')\n",
    "bar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(bar.name, 'test_reference_artifact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(bar.metadata['ref']['type'], str(type(foo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Test method `to_obj`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReferenceArtifact with a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = np.random.randn(5)\n",
    "bar = ReferenceArtifact(obj=foo, name='test_reference_artifact')\n",
    "bar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(bar.metadata['ref']['type'], str(type(foo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn as nn\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def export_and_get(self:Learner, keep_exported_file=False):\n",
    "    \"\"\"\n",
    "        Export the learner into an auxiliary file, load it and return it back.\n",
    "    \"\"\"\n",
    "    aux_path = Path('aux.pkl')\n",
    "    self.export(fname='aux.pkl')\n",
    "    aux_learn = load_learner('aux.pkl')\n",
    "    if not keep_exported_file: aux_path.unlink()\n",
    "    return aux_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_wandb_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_wandb_artifacts(project_path, type=None, name=None, last_version=True):\n",
    "    \"\"\"\n",
    "        Get the artifacts logged in a wandb project.\n",
    "        Input:\n",
    "        - `project_path` (str): entity/project_name\n",
    "        - `type` (str): whether to return only one type of artifacts\n",
    "        - `name` (str): Leave none to have all artifact names\n",
    "        - `last_version`: whether to return only the last version of each artifact or not\n",
    "\n",
    "        Output: List of artifacts\n",
    "    \"\"\"\n",
    "    public_api = wandb.Api()\n",
    "    if type is not None:\n",
    "        types = [public_api.artifact_type(type, project_path)]\n",
    "    else:\n",
    "        types = public_api.artifact_types(project_path)\n",
    "\n",
    "    res = L()\n",
    "    for kind in types:\n",
    "        for collection in kind.collections():\n",
    "            if name is None or name == collection.name:\n",
    "                versions = public_api.artifact_versions(\n",
    "                    kind.type,\n",
    "                    \"/\".join([kind.entity, kind.project, collection.name]),\n",
    "                    per_page=1,\n",
    "                )\n",
    "                if last_version: res += next(versions)\n",
    "                else: res += L(versions)\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo = get_wandb_artifacts('wandb/artifacts-example', type='model')\n",
    "test_eq(len(foo), 2)\n",
    "foo = get_wandb_artifacts('wandb/artifacts-example', type='model', name='convnet')\n",
    "test_eq(len(foo), 1)\n",
    "foo = get_wandb_artifacts('wandb/artifacts-example', type='model', name='convnet', last_version=False)\n",
    "test_eq(len(foo), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_pickle_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_pickle_artifact(filename):\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exec from feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pyarrow.feather as ft\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exec_with_feather(function, path = None, verbose = 0, *args, **kwargs):\n",
    "    result = None\n",
    "    if not (path is None):\n",
    "        if verbose > 0: print(\"--> Exec with feather | reading input from \", path)\n",
    "        input = ft.read_feather(path)\n",
    "        if verbose > 0: print(\"--> Exec with feather | Apply function \", path)\n",
    "        result = function(input, *args, **kwargs)\n",
    "        if verbose > 0: print(\"Exec with feather --> \", path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def py_function(module_name, function_name, verbose = 0):\n",
    "    try:\n",
    "        function = getattr(__import__('__main__'), function_name)\n",
    "    except:\n",
    "        module = __import__(module_name, fromlist=[''])\n",
    "        function = getattr(module, function_name)\n",
    "    print(\"py function: \", function_name, \": \", function)\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def suma(a,b,c): return a+b+c\n",
    "foo = py_function(\"main\", \"suma\", True)\n",
    "print(foo(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "function_name = \"prepare_forecasting_data\"\n",
    "module_name = \"tsai.data.preparation\"\n",
    "foo = py_function(module_name, function_name, True)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "def exec_with_feather_k_output(function_name, module_name = \"main\", path = None, k_output = 0, verbose = 0, time_flag = False, *args, **kwargs):\n",
    "    result = None\n",
    "    function = py_function(module_name, function_name,verbose)\n",
    "    if time_flag: t_start = time.time()\n",
    "    if not (path is None):\n",
    "        if verbose > 0: print(\"--> Exec with feather | reading input from \", path)\n",
    "        input = ft.read_feather(path)\n",
    "        if verbose > 0: print(\"--> Exec with feather | Apply function \", path)\n",
    "        result = function(input, *args, **kwargs)[k_output]\n",
    "    if time_flag:\n",
    "        t_end = time.time()\n",
    "        print(\"Exec with feather | time: \", t_end-t_start)\n",
    "    if verbose > 0: print(\"Exec with feather --> \", path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "enc_input = exec_with_feather_k_output(\n",
    "            function_name = \"prepare_forecasting_data\",\n",
    "            module_name   = \"tsai.data.preparation\",\n",
    "            path = \"/home/macu/data/wandb_artifacts/-2535364569820284064\",\n",
    "            k_output        = 0,\n",
    "            verbose         = 1,\n",
    "            time_flag       = True,\n",
    "            fcst_history    = 450\n",
    "        )\n",
    "enc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exec_with_and_feather_k_output(function_name, module_name = \"main\", path_input = None, path_output = None, k_output = 0, verbose = 0, time_flag = False, *args, **kwargs):\n",
    "    result = None\n",
    "    function = py_function(module_name, function_name, verbose-1)\n",
    "    if time_flag: t_start = time.time()\n",
    "    if not (path_input is None):\n",
    "        if verbose > 0: print(\"--> Exec with feather | reading input from \", path_input)\n",
    "        input = ft.read_feather(path_input)\n",
    "        if verbose > 0: \n",
    "            print(\"--> Exec with feather | Apply function \", function_name, \"input type: \", type(input))\n",
    "        \n",
    "        result = function(input, *args, **kwargs)[k_output]\n",
    "        ft.write_feather(df, path, compression = 'lz4')\n",
    "    if time_flag:\n",
    "        t_end = time.time()\n",
    "        print(\"Exec with feather | time: \", t_end-t_start)\n",
    "    if verbose > 0: print(\"Exec with feather --> \", path_output)\n",
    "    return path_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import time\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Time:\n",
    "    time_start  : float =  None\n",
    "    time_end    : float =  None\n",
    "    time_total  : float =  0.0\n",
    "    function    : str   =  ''\n",
    "\n",
    "    def start(self, verbose = 0): \n",
    "        if verbose > 0: print(\"--> Start: \", self.function)\n",
    "        self.time_start = time.time()\n",
    "        return self.time_start\n",
    "\n",
    "    def end(self, verbose= 0):\n",
    "        self.time_end = time.time()\n",
    "        self.time_total = self.duration()\n",
    "        if verbose > 0: print(\"End: \", self.function, \"-->\")\n",
    "        return self.time_end\n",
    "        \n",
    "    def duration(self):\n",
    "        self.time_total=self.time_end - self.time_start\n",
    "        return self.time_total\n",
    "    def show(self):\n",
    "        if self.time_start is None: \n",
    "            print(f\"[{self.function}] Not started\")\n",
    "        elif self.time_end is None:\n",
    "            print(f\"[{self.function}] Not ended | Start: \", self.time_start)\n",
    "        else:\n",
    "            print(f\"[{self.function}] Start: {self.time_start} | End: {self.time_end} | Duration: {self.time_total} seconds\")\n",
    "        return self.time_total     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def funcname():\n",
    "    \"\"\"Get calling function name\"\"\"\n",
    "    return inspect.stack()[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Timer basic example\n",
    "foo = Time()\n",
    "foo.start()\n",
    "time.sleep(2) \n",
    "foo.end()\n",
    "foo.show()\n",
    "def foo(): return funcname()\n",
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSCode update path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#Function for making notebooks clearer\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "    print(\"... Enabling Vs Code execution ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#from nbdev.export import notebook2script\n",
    "#notebook2script()\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Styled printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def styled_print(text, color='black', size='16px', weight='normal'):\n",
    "    html_text = f\"<span style='color: {color}; font-size: {size}; font-weight: {weight};'>{text}</span>\"\n",
    "    display(HTML(html_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_sequence(\n",
    "    data         : List[ List [ float ] ] = None, \n",
    "    hide_rows    : bool = False, \n",
    "    hide_columns : bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Show the sequence in a nice format similar to stumpy tutorials\n",
    "    \"\"\"\n",
    "    df          = pd.DataFrame(data)\n",
    "    styled_df   = df.style\n",
    "    if hide_rows: \n",
    "        styled_df = styled_df.hide(axis='index')\n",
    "    if hide_columns: \n",
    "        styled_df = styled_df.hide(axis='columns')\n",
    "    styled_df = styled_df.set_table_styles([\n",
    "        {'selector': '',\n",
    "         'props': [('border', '2px solid black'),\n",
    "                   ('text-align', 'center'),\n",
    "                   ('font-family', 'Arial'),\n",
    "                   ('border-collapse', 'collapse')]},\n",
    "        {'selector': 'td',\n",
    "         'props': [('border', '1px solid black'),\n",
    "                   ('padding', '5px')]}\n",
    "    ])\n",
    "    display(styled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_with_dots(\n",
    "    time_series             : List[float]    = None,\n",
    "    xlabel                  : str            = 'Index (time)',\n",
    "    ylabel                  : str            = 'Value',\n",
    "    title                   : str            = 'Time series',\n",
    "    sequence_flag           : bool           = True,\n",
    "    show_sequence_before    : bool           = True, \n",
    "    hide_rows               : bool           = True,\n",
    "    hide_columns            : bool           = False,\n",
    "    show_title              : bool           = True,\n",
    "    fontsize                : int            = 10,\n",
    "    save_plot               : bool           = False,\n",
    "    dots                    : bool           = True,\n",
    "    figsize                 : Tuple[int, int]= (10, 6),\n",
    "    plot_path               : str            = \"./\",\n",
    "    plot_name               : str            = \"\"\n",
    "  ) -> None:\n",
    "    if sequence_flag and show_sequence_before: \n",
    "        show_sequence([time_series], hide_rows, hide_columns)\n",
    "    n = len(time_series)\n",
    "    x_coords = range(n)\n",
    "    \n",
    "    plt.figure(figsize=figsize)  # Crear la figura con el tamaño especificado\n",
    "    \n",
    "    if dots: \n",
    "        plt.plot(x_coords, time_series)\n",
    "        plt.scatter(x_coords, time_series, color='red')\n",
    "    else:\n",
    "        plt.plot(x_coords, time_series, linestyle='-')\n",
    "        \n",
    "    if show_title: \n",
    "        plt.title(title, fontsize=fontsize)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if save_plot:\n",
    "        plot_path = os.path.expanduser(plot_path)\n",
    "        if plot_name == \"\":\n",
    "            plot_name = title\n",
    "        plot_path = os.path.join(plot_path, plot_name + \".png\")\n",
    "        plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "    if sequence_flag and not show_sequence_before:\n",
    "        show_sequence([time_series], hide_rows, hide_columns)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Example following Stumpy's 13-length case\n",
    "plt.close('all')\n",
    "foo_data = np.array([0, 1, 3, 2, 9, 1, 14, 15, 1, 2, 2, 10, 7])\n",
    "foo_title = title = \"Example 1: Time series of length 13\"\n",
    "show_sequence([foo_data], hide_rows = True, hide_columns = False)\n",
    "plot_with_dots(\n",
    "    time_series             = foo_data,\n",
    "    title                   = foo_title,\n",
    "    sequence_flag           = False,\n",
    "    fontsize                = 20,\n",
    "    figsize                 = (10,3)\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Aggregate Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "## -- Classes & types\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Interpolator(BaseEstimator, TransformerMixin):\n",
    "    method            : str  ='linear'\n",
    "    n_segments        : int  = 1\n",
    "    plot_original_data: bool = False\n",
    "    plot_interpolated : bool = False\n",
    "    verbose           : int  = 0\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "                \n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        \n",
    "        if self.plot_original_data:\n",
    "            if self.verbose > 0: print(\"Interpolator | Plot original data\")\n",
    "            for dim in range (X.ndim-1):\n",
    "                if self.verbose > 1: print(f\"Interpolator | Plot original data dimension {dim}\")\n",
    "                plot_with_dots(\n",
    "                    X[dim], \n",
    "                    sequence_flag = False, \n",
    "                    title = f'Original data | dim {dim}'\n",
    "                )\n",
    "                \n",
    "        n_samples, n_features = X.shape\n",
    "        if n_features % self.n_segments != 0 or n_features == self.n_segments:\n",
    "            raise ValueError(\n",
    "                f\"The number of segments {self.n_segments} must divide (and be different of) the number of features {n_features} | Reminder: {n_features // self.n_segments}\"\n",
    "            )\n",
    "\n",
    "        segment_size = n_features // self.n_segments\n",
    "        interpolated_result = np.full_like(X, np.nan)\n",
    "\n",
    "        if self.verbose > 0: print(f\"NFeatures: {n_features} | NSegments: {self.n_segments} | segment_size: {segment_size} | interpolated result ~ {interpolated_result.shape}\")\n",
    "        \n",
    "        for i in np.arange(self.n_segments):\n",
    "            start = i * segment_size \n",
    "            end = start + segment_size\n",
    "            segment_mean = np.nanmean(X[:, start:end], axis=1)\n",
    "            for j in np.arange(n_samples):\n",
    "                nan_mask = np.isnan(X[j, start:end])\n",
    "                interpolated_result[j, start:end][nan_mask] = segment_mean[j]\n",
    "        res = np.where(np.isnan(X), interpolated_result, X)\n",
    "        if self.plot_interpolated:\n",
    "            for dim in range (X.ndim-1):\n",
    "                plot_with_dots(\n",
    "                    res[dim], \n",
    "                    sequence_flag = False, \n",
    "                    title = f'Interpolated data | dim {dim}'\n",
    "                )\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_data = np.array([1.0, 2.0, np.nan, 4.0, 5.0, np.nan, 7.0, 8.0])\n",
    "\n",
    "foo_inter = Interpolator(\n",
    "            method='polynomial', \n",
    "            n_segments         = 4,\n",
    "            plot_interpolated  = True,\n",
    "            plot_original_data = False,\n",
    "            verbose            = 2\n",
    "        )\n",
    "\n",
    "foo = foo_inter.fit_transform(foo_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class PAATransformer(BaseEstimator, TransformerMixin):\n",
    "    n_segments       : int  = 1\n",
    "    plot_aggregated  : bool = True\n",
    "    verbose          : int  = 0\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_features <= self.n_segments:\n",
    "            raise ValueError(f\"The number of segments ({self.n_segments}) must be lower than the number of points ({n_features})\")\n",
    "\n",
    "        segment_size = n_features // ( self.n_segments + 1)\n",
    "        remainder = n_features % ( self.n_segments + 1)\n",
    "\n",
    "        if self.verbose > 0: \n",
    "            print(f\"NFeatures: {n_features} | NSegments: {self.n_segments} | Segment size: {segment_size} | Reminder: {remainder}\")\n",
    "\n",
    "        # Crear un array para los resultados\n",
    "        result = np.zeros((n_samples, self.n_segments + 1))\n",
    "\n",
    "        if self.verbose > 1: print(f\"Result ~ {result.shape}\")\n",
    "\n",
    "        # Procesar cada segmento\n",
    "        for i in range(self.n_segments+1):\n",
    "            start = i * segment_size + min(i, remainder)\n",
    "            end = start + segment_size + (1 if i < remainder else 0)\n",
    "            result[:, i] = np.mean(X[:, start:end], axis=1)\n",
    "\n",
    "        if self.plot_aggregated:\n",
    "            for dim in range (X.ndim-1):\n",
    "                if self.verbose > 1:\n",
    "                    print(\"Plos res | Dim\", dim)\n",
    "                plot_with_dots(\n",
    "                    result[dim], \n",
    "                    sequence_flag = False, \n",
    "                    title = f'Aggregated data | dim {dim}',\n",
    "                    fontsize = 20,\n",
    "                    save_plot = True\n",
    "                )\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo_data = np.array([1.0, 2.0, np.nan, 4.0, 5.0, np.nan, 7.0, 8.0])\n",
    "foo_paa_pipeline = Pipeline([\n",
    "    (\n",
    "        # Step for interpolating NaNs in the original data\n",
    "        'interpolator', \n",
    "        Interpolator(\n",
    "            method='polynomial', \n",
    "            n_segments         = 4, \n",
    "            plot_interpolated  = True,\n",
    "            plot_original_data = False,\n",
    "            verbose            = 2\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        # Step for applying Peicewise Aggregated Approximation\n",
    "        'paa', PAATransformer(\n",
    "            n_segments      = 3, \n",
    "            plot_aggregated = True, \n",
    "            verbose         = 2\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "foo = foo_paa_pipeline.fit_transform(foo_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Errors definitions\n",
    "class DownsampleError(Exception):\n",
    "    \"\"\"Exception raised for errors in the downsample process.\"\"\"\n",
    "    def __init__(self, message=\"Invalid number of min/max points for the proposed time series. You must allow cropping and check the final length\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "class DivisorsError(Exception):\n",
    "    def __init__(self, message = \"Invalid parameters\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def divisors(\n",
    "    N : int, \n",
    "    min_val:int, \n",
    "    max_val:int, \n",
    "    verbose = 0\n",
    ") -> List [ int ] : \n",
    "    print(\"Verbose: \", verbose)\n",
    "    if verbose > 0: \n",
    "        print(f\"Looking for the divisors of {N} between {min_val} and {max_val}\")\n",
    "    if (N < 0 or min_val < 0):\n",
    "        mssg = f\"N, min_val, max_val {N}, {min_val}, {max_val} must be a positive integer (>0)\"\n",
    "        raise DivisorsError(mssg)\n",
    "    elif ( min_val > max_val):\n",
    "        mssg = f\"min_val > max_val ({min_val} > {max_val}). Please take a look\"\n",
    "        raise DivisorsError(mssg)\n",
    "    arr = np.arange(min_val,max_val+1)\n",
    "    arr = arr[ N % arr == 0]\n",
    "    if verbose > 0: print(f\"Found {len(arr)} divisors of {N} between {min_val} and {max_val}\")\n",
    "    return arr\n",
    "\n",
    "def downsample_propose_crop_(\n",
    "    N            : int, \n",
    "    min_points   : int, \n",
    "    max_points   : int, \n",
    "    verbose      : int  = 0,\n",
    "    allow_crop   : bool = True,\n",
    "    nearest_val  : bool = False,\n",
    "    potential_val: int = 1\n",
    ") -> int:\n",
    "    if verbose > 0: \n",
    "        print(f\"Verbose: {verbose}\")\n",
    "        print(f\"Downsample Propose Crop | Prev N: {N}\")\n",
    "    all_divisors = divisors(\n",
    "        N       = N, \n",
    "        min_val = min_points, \n",
    "        max_val = max_points,\n",
    "        verbose = verbose-1\n",
    "    )\n",
    "    val = 0\n",
    "    if len(all_divisors) == 0:\n",
    "        if ( not nearest_val or potential_val < 1):\n",
    "            raise ValueError(\"No valid divisors found for the given N within the min and max points range.\")\n",
    "    else:\n",
    "        if ( nearest_val and potential_val > 0):\n",
    "                val = min(all_divisors, key=lambda x: abs(x - potential_val))\n",
    "        elif (divisors_flag):\n",
    "            val = divisors(\n",
    "                N       = N, \n",
    "                min_val = min_points, \n",
    "                max_val = max_points, \n",
    "                verbose = verbose-1\n",
    "            )[-1]\n",
    "    \n",
    "    if (allow_crop):\n",
    "        while (val < min_points and N > min_points): \n",
    "            N = N-1\n",
    "            all_divisors = divisors(\n",
    "                N       = N, \n",
    "                min_val = min_points, \n",
    "                max_val = max_points, \n",
    "                verbose = verbose-1\n",
    "            )\n",
    "            if len(all_divisors) > 0:\n",
    "                if ( nearest_val and potential_val > 0):\n",
    "                    val = min(all_divisors, key=lambda x: abs(x - potential_val))\n",
    "    else: \n",
    "        raise DownsampleError()\n",
    "        return -1\n",
    "    if verbose > 0: print(f\"Downsample Propose Crop | Post N: {N} | Largest Divisor: {val}\")\n",
    "    return (val, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#print(downsample_propose_crop_(7397222, 10000, 20000, 1, False))\n",
    "print(downsample_propose_crop_(\n",
    "    N = 7397222, \n",
    "    min_points = 10000, \n",
    "    max_points = 20000, \n",
    "    verbose = 2, \n",
    "    allow_crop = True, \n",
    "    nearest_val = True, \n",
    "    potential_val = 14500\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def downsample(\n",
    "    data  : List [ float ] = None,\n",
    "    min_position : int  = 0,\n",
    "    max_position : int  = -1, \n",
    "    min_points   : int  = 1,\n",
    "    max_points   : int  = 10000,\n",
    "    verbose      : int  = 1,\n",
    "    show_plots   : bool = False,\n",
    "    allow_crop   : bool = True\n",
    ") -> Tuple [ List [ float ], float ]:  \n",
    "    if max_points >= data.shape[0]: return data, 1\n",
    "    if verbose > 1: print(f\"[ Downsample | Position ] Before | Pos ({min_position}, {max_position})\")\n",
    "    min_position = min_position if min_position > 0 else 0\n",
    "    max_position = max_position if ( max_position > -1 and max_position < data.shape[0]) else data.shape[0]\n",
    "    if verbose > 1: print(f\"[ Downsample | Position ] After | Pos ({min_position}, {max_position})\")\n",
    "    \n",
    "    n_timestamps = max_position - min_position\n",
    "    paa_factor   = np.maximum(1, n_timestamps // max_points)\n",
    "\n",
    "    min_points   = max(1,min(min_points, data.shape[0]))\n",
    "    max_points   = min(data.shape[0], min(max_points, max_position-min_position))\n",
    "\n",
    "    if verbose > 1:\n",
    "        print(f\"[ Downsample | downsample_propose_crop ] Max points: {max_points}\")\n",
    "        print(f\"[ Downsample | downsample_propose_crop ] Min points: {min_points}\")\n",
    "    \n",
    "    \n",
    "    min_points   = min(min_points, max_points)\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(f\"[ Downsample | downsample_propose_crop ] N timestamps {n_timestamps}\")\n",
    "        print(f\"[ Downsample | downsample_propose_crop ] PAA factor: {paa_factor}\")\n",
    "        \n",
    "        print(f\"[ Downsample | downsample_propose_crop ] allow_crop: {allow_crop}\")\n",
    "\n",
    "    potential_segments = np.floor(n_timestamps / paa_factor).astype(int)\n",
    "    \n",
    "    N = max_position-min_position\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print(f\"[ Downsample | downsample_propose_crop ] N: {N}\")\n",
    "        print(f\"[ Downsample | downsample_propose_crop ] potential_segments: {potential_segments}\")\n",
    "        \n",
    "    n_segments, N = downsample_propose_crop_(\n",
    "        N             = N, \n",
    "        min_points    = min_points,\n",
    "        max_points    = max_points,\n",
    "        verbose       = verbose-1,\n",
    "        allow_crop    = allow_crop,\n",
    "        nearest_val   = allow_crop, # If allow_crop, try to get as near of potential_segment as possible\n",
    "        potential_val = potential_segments # The most desired one \n",
    "    ) \n",
    "\n",
    "    if allow_crop: \n",
    "        if verbose > 1: print(f\"[ Downsample | downsample_propose_crop ] Allow crop => change n_timestamp | Before {n_timestamps}\")\n",
    "        max_position = min_position + N\n",
    "        if verbose > 1: print(f\"[ Downsample | downsample_propose_crop ] Allow crop => change n_timestamp | After {n_timestamps}\")\n",
    "    \n",
    "    data = data[min_position:max_position]\n",
    "    n_timestamps = data.shape[0]\n",
    "\n",
    "    if verbose > 0: \n",
    "        print(f\"[ Downsample | downsample_propose_crop --> ] | N segments: {n_segments} | Data ~ {data.shape}\")\n",
    "        print(f\"[ Downsample | downsample_propose_crop --> ] | N = {N} | n_timestamps = {n_timestamps} | min_position {min_position} | max_position {max_position}\")\n",
    "\n",
    "    if n_timestamps < max_points: \n",
    "        if verbose > 0: \n",
    "            print(f\"[ Downsample ] n_timestamps {n_timestamps} < max_points {max_points}\")\n",
    "        return data, 1\n",
    "        \n",
    "    #| export\n",
    "    paa_pipeline = Pipeline([\n",
    "        (\n",
    "            # Step for interpolating NaNs in the original data\n",
    "            'interpolator', \n",
    "            Interpolator(\n",
    "                method             = 'polynomial', \n",
    "                n_segments         = n_segments, \n",
    "                plot_original_data = show_plots,\n",
    "                plot_interpolated  = show_plots\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            # Step for applying Peicewise Aggregated Approximation\n",
    "            'paa', PAATransformer(\n",
    "                n_segments      = n_segments, \n",
    "                plot_aggregated = show_plots\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    ts_paa = paa_pipeline.fit_transform(data[min_position:max_position])[0]\n",
    "    if verbose > 0: \n",
    "        print(f\"Downsample | ts_paa~{len(ts_paa)}\")\n",
    "        print(f\"Downsample ------------------------>\")\n",
    "    return ts_paa, paa_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "foo_data = np.array([1.0, 2.0, np.nan, 4.0, 5.0, np.nan, 7.0, 8.0])\n",
    "foo_data_2 = downsample(foo_data, min_points = 3, max_points = 5, verbose = 5, show_plots = True)\n",
    "print(foo_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Testing failed case\n",
    "foo = np.random.rand(7397222)\n",
    "downsample(foo, min_points = 10000, max_points = 20000, verbose = 5, show_plots = True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
